[{"title":"基于Redis Bitmap实现用户签到功能","url":"/2022/02/08/基于Redis-Bitmap实现用户签到功能/","content":"\n### 背景\n\n在之前做过的需求里，有个养鱼活动，用户每天来签到，就可以领一定的饲料，拿来喂养鱼。连续签到的天数越多，每天能领取的饲料克数就越多。每7天为一个周期，一个周期内开始第一天签到，领取的饲料克数重新从100g开始算起，签到中断也是重新开始计算。\n\n### 技术实现原理\n在高并发的场景下，用户签到的数据，如果直接使用数据库存储，数据库的压力会很大。另外，签到的数据比较简单，只需要记录用户ID、是否签到即可。在这里就考虑到使用Redis Bitmap来存储实现，key为`{userId}:{yyyyMM}`。Redis提供的数据类型BitMap（位图），每个bit位对应0和1两个状态，设置为1时，代表这一天已经签到了。虽然内部还是采用String类型存储，但Redis提供了一些指令用于直接操作BitMap，可以把它看作一个bit数组，数组的下标就是偏移量。\n\n位图不是真正的数据类型，它是定义在字符串类型中，一个字符串类型的值最多能存储512M字节的内容，最大位数为：`2^32b = (2^9) * (2^10) * (2^10) * (2^3)` 。\n\n它的优点是内存开销小，效率高且操作简单，很适合用于签到这类场景。缺点在于位计算和位表示数值的局限。如果要用位来做业务数据记录，就不要在意value的值。如果位图很大，建议拆分键。另外，bitmap设置时候时间复杂度`O(1)`、读取时候时间复杂度`O(n)`，操作是非常快的。因为读取时候时间复杂度`O(n)`，越大的串读的时间花销越多。\n\n### API介绍\n\n#### setbit\n作用：设置某一位上的值\n语法：`SETBIT key offset value `（offset位偏移量，从0开始）\n```Java\nsetbit k1 1 1\nsetbit k1 7 1\n```\n![](setbit.png) \n\n#### getbit \n作用：获取某一位上的值\n语法：`GETBIT key offset`\n```java\ngetbit k1 7\n```\n\n#### bitpos\n作用：返回指定值0或者1在指定区间上首次出现的下标\n语法：`BITPOS key bit [start] [end]`（字节索引，0表示第一个字节）\n\n不指定查找范围，表示从全部内容中查找：`BITPOS key bit`\n```java\nbitpos k1 1\n```\n指定查找范围:\n> - BITPOS key bit start：从start+1个字节开始查找，直到尾部\n> - BITPOS key bit start end：从start+1字节开始到end+1字节之间查找\n\n#### bitop\n作用：位操作\n语法：`BITOP operation destkey key [key ...]`\n对一个或多个保存二进制位的字符串`key`进行位操作，并将结果保存到`destkey`上。`operation`可以是`AND 、 OR 、 NOT 、 XOR`这四种操作中的任意一种。\n\n> - BITOP AND destkey key [key ...]： 对一个或多个 key 求逻与，并将结果保存到 destkey\n> - BITOP OR destkey key [key ...] ：对一个或多个 key 求逻辑或，并将结果保存到 destkey\n> - BITOP XOR destkey key [key ...] ：对一个或多个 key 求逻辑异或，并将结果保存到 destkey\n> - BITOP NOT destkey key ： 对给定 key 求逻辑非，并将结果保存到 destkey\n\n除了`NOT`操作之外，其他操作都可以接受一个或多个`key`作为输入，当`BITOP`处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0，空的`key`也被看作是包含 0 的字符串序列。如果要使用`BITOP`，建议读取到客户端再进行位计算。\n\n#### BITFIELD\n作用：可以在一次调用中同时对多个位范围进行操作。\t\n\n以下是`BITFIELD`命令支持的子命令语法：\n\n> - GET <type> <offset> : 返回指定的二进制位范围。\n> - SET <type> <offset> <value> : 对指定的二进制位范围进行设置，并返回它的旧值。\n> - INCRBY <type> <offset> <increment> : 对指定的二进制位范围执行加法操作，并返回它的旧值。用户可以通过向 increment 参数传入负值来实现相应的减法操作。\n\n除了以上三个子命令之外， 还有一个子命令， 它可以改变之后执行的`INCRBY`子命令在发生溢出情况时的行为：\n> - OVERFLOW [WRAP|SAT|FAIL]\n\n当被设置的二进制位范围值为整数时， 用户可以在类型参数的前面添加`i`来表示有符号整数， 或者使用`u`来表示无符号整数。 比如说，我们可以使用`u8`来表示8位长的无符号整数， 也可以使用`i16`来表示16位长的有符号整数。\n`BITFIELD`命令最大支持64位长的有符号整数以及63位长的无符号整数， 其中无符号整数的63位长度限制是由于Redis协议目前还无法返回64位长的无符号整数而导致的。\n\n下面对位于偏移量 100 的 8 位长有符号整数执行加法操作， 并获取位于偏移量 0 上的 4 位长无符号整数：\n```java\n> BITFIELD mykey INCRBY i8 100 1 GET u4 0\n1) (integer) 1\n2) (integer) 0\n```\n### 其他应用场景\n#### 用户在线状态\n只需要一个key，然后用户id为偏移量offset，如果在线就设置为1，不在线就设置为0。如果数据量过多的，可以按用户ID进行分片。\n\n#### 统计活跃用户\n使用时间天作为缓存的key，然后用户id为offset，如果当日活跃过就设置为1。之后通过`bitOp AND`进行二进制计算算出在某段时间内用户的活跃情况\n\n### 参考资料\n- [Redis实战篇（二）基于Bitmap实现用户签到功能](https://www.cnblogs.com/liang24/p/14449835.html)\n- [一看就懂系列之 详解redis的bitmap在亿级项目中的应用](https://blog.csdn.net/u011957758/article/details/74783347)","tags":["Redis","签到"],"categories":["Redis"]},{"title":"基于Redis HyperLogLog实现UV统计功能","url":"/2022/02/08/基于Redis-HyperLogLog实现UV统计功能/","content":"\n### 背景\n最近项目里需要计算每个商品的综合打分分数，以此来作为每个商品的畅销分数，来近实时统计每个商品的畅销排名。这其中需要统计近12个小时每个浏览商品的UV值来作为其中的一个计算项。\n\n### 选用Redis HyperLogLog原因\n因同1个用户的反复操作只统计1次，首先想到就是利用Redis Set结构来进行去重计算。目前商品总数接近10W，DAU接近500W，且因为是近实时，所以每分钟为每个浏览商品生成一个key-`uv:{goodsId}:{当前时间戳(分钟)}`。我们粗略估算下每分钟每个用户大概浏览10个不同的商品，高峰期大约有100W用户同时在线这样子，那么每小时占用的内存为：10`*`60`*`100W `*` 8byte = 460MB。如果用HyperLogLog算法，占用的内存为：10`*`60 `*` 12k = 7MB，远小于使用Set结构来存储。但是HyperLogLog统计结果会存在误差，标准误差大约在0.8%。考虑到可以接受一定的误差并且占用内存小，所以采用了HyperLogLog算法来统计UV。\n\n\n### HyperLogLog特性\nHyperLogLog(HLL) 是一种用于基数计数的概率算法，是基于LogLog(LLC)算法的优化和改进，在同样空间复杂度下，能够比LLC的基数估计误差更小。\n它具有以下特性：\n> - HyperLogLog使用极少的内存就能统计大量的数据，如Redis HyperLogLog，只需要12K内存就能统计2^64个数据，远比Hash结构的内存开销要少\n> - 计数存在一定的误差，误差率整体较低。标准误差为 0.81% \n> - 误差可以被设置辅助计算因子进行降低\n\n\n### HyperLogLog算法解析\n\nHyperLogLog算法来源于著名的伯努利试验。\n\n#### 伯努利试验\n伯努利试验是数学概率论中的一部分内容，它的典故来源于抛硬币，我们每次抛硬币出现正反面的概率各自是50%。试验过程如下：假设一直抛硬币，直到它出现正面为止，我们记录为一次完整的试验，这中间可能抛了一次就出现了正面，也可能抛了n次才出现正面。无论抛了多少次，只要出现了正面，就记录为一次试验。这个试验就是伯努利试验。\n\n进行`n`次伯努利试验，意味着会有`n`次的正面。假设每次伯努利试验所经历了的抛掷次数为`k`。第一次伯努利试验，次数设为`k1`，以此类推，第`n`次对应的是`kn`。\n在这`n`次伯努利试验中，必然会有一个最大的抛掷次数`k`，例如最多的抛了12次才出现正面，那么称这个为`k_max`，代表抛了最多的次数。\n伯努利试验容易得出有以下结论：\n\n> - n 次伯努利过程的投掷次数都不大于 k_max\n> - n 次伯努利过程，至少有一次投掷次数等于 k_max\n\n最终结合极大似然估算的方法，发现在n和k_max中存在估算关联：`n = 2^(k_max)` 。\n\n例如：\n> - 第一次试验: 抛了3次才出现正面，此时 k=3，n=1\n> - 第二次试验: 抛了2次才出现正面，此时 k=2，n=2\n> - 第三次试验: 抛了6次才出现正面，此时 k=6，n=3\n> - 第n次试验：抛了12次才出现正面，此时我们估算，n = 2^12\n\n当试验次数很小的时候，就会出现误差很大的情况，如上面的三次试验。\n\n#### 估算优化\n##### LogLog算法\nLogLog的算法是通过增加试验轮次，再取k_max平均数进行估算。我们以3组试验为一轮估算，然后进行100轮或者更多轮次的试验，然后再取每轮的`k_max`累加，再取平均数，即: `(k_max_1 + ... + k_max_m)/m`，最终再估算出n。下面就是LogLog的估算公式：\n![](LogLog算法.png)\n\n上面公式的`DVLL`对应的就是n，`constant`是修正因子，它的具体值是不定的，可以根据实际情况而分支设置。`m`代表的是试验的轮数。头上有一横的`R`就是平均数：`(k_max_1 + ... + k_max_m)/m`。\n\n##### HyperLogLog算法\n而HyperLogLog和LogLog的区别就是，它采用的不是平均数，而是调和平均数。下面是调和平均数的计算方式，`∑` 是累加符号。\n![](调和平均数.png)\n\n调和平均数比平均数的好处就是不容易受到大的数值的影响。下面举个例子：\n> - A的是1000/月，B的30000/月，求平均工资:\n> - 采用平均数的方式就是： (1000 + 30000) / 2 = 15500\n> - 采用调和平均数的方式就是： 2/(1/1000 + 1/30000) ≈ 1935.484\n明显地，调和平均数比平均数的效果是要更好的。\n\n### HyperLogLog应用\n那么在实际过程中，我们是怎么利用HyperLogLog来实现UV统计的。当我们输入一个userId时，会经过以下的几个步骤：\n\n#### 转二进制\n通过`hash`函数，将userId转为二进制形式，例如输入5，便转为：101。套入伯努利试验，0代表了硬币反面，1代表了硬币正面。如果一个数据最终被转化了 10010000，那么从右往左，从低位往高位看，首次出现1的时候，就是正面。\n那么基于上面的公式：`n = 2^(k_max)`，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验。那么也就可以根据多个存入的数据中，转换成二进制后的出现了 1 的最大的位置 k_max 来估算存入了多少数据。 \n\n\n#### 分桶\n分桶就是分多少轮。在一个长度为L，单位为bit的大数组S中 ，将S平均分为m组。m组对应多少轮，然后每组所占有的比特个数是平均的，为 P。则：\n`L = S.length`\n`L = m * p`\n以 K 为单位，S 占用的内存 = L / 8 / 1024\n以Redis HyperLogLog为例：m=16834，p=6，L=16834 * 6，占用内存为=16834 * 6 / 8 / 1024 = 12K\n> -   第0组     第1组                       .... 第16833组\n> - [000 000] [000 000] [000 000] [000 000] .... [000 000]\n\n这 6 个 bit 自然是无法容纳桶中所有元素的，它记录的是桶中*元素数量的对数值，即对应上面提到的k_max*。\n当每一个元素到来时，它会散列到其中一个桶，以一定的概率影响这个桶的计数值。因为是概率算法，所以单个桶的计数值并不准确，但是将所有的桶计数值进行调合均值累加起来，结果就会非常接近真实的计数值。\n\n#### 存储过程\n以前文提到的UV统计为例，首先我们需要将用户ID进行一次二进制转换，即：\n\n> - hash(id) = 二进制数字\n\n每一个二进制数字为一次伯努利试验。\n然后，计算这个二进制数字所处桶的位置，即分桶。我们假设用二进制数字的前多少位（从右往左，低位往高位看）转为10进制后，其值就对应于所在桶的标号。假设用低两位来计算桶下标志，此时有一个用户ID对应的二进制数是：1001011000011。它的所在桶下标为：`11(2) = 1*2^1 + 1*2^0 = 3`，处于第3个桶，即第3轮中。\n\n计算出桶号后，剩下的二进制串是：10010110000，从低位到高位看，第一次出现 1 的位置是 5 。也就是说，此时第3个桶或第3轮的试验中，k_max = 5，注意这里取的是首次1的位置index值。\n5 对应的二进制是：101，又因为每个桶有 p 个比特位。当 p>=3 时，便可以将 101 存进去。\n当然存进去之前，会比较新的index是否比原index大。是，则替换。否，则不变。 \n\n模仿上面的流程，多个不同的用户 id，就被分散到不同的桶中去了，且每个桶有其 k_max。当要统计UV时候，就是一次估算。最终结合所有桶中的 k_max，代入估算公式，便能得出估算值。\n![](HyperLoglog算法.png)\n\n\n### 偏差修正\n\n在估算的计算公式中，constant 变量不是一个定值，它会根据实际情况而被分支设置，例如下面的样子。\n\n假设：m为分桶数，p是m的以2为底的对数。\n![](偏差修正.png)\n\n```java\n// m 为桶数\nswitch (p) {\n   case 4:\n       constant = 0.673 * m * m;\n   case 5:\n       constant = 0.697 * m * m;\n   case 6:\n       constant = 0.709 * m * m;\n   default:\n       constant = (0.7213 / (1 + 1.079 / m)) * m * m;\n}\n\n```\n\n### Redis HyperLogLog的原理\n在Redis的实现中，设有 16384 个桶，即：`2^14 = 16384`，每个桶有 6 位，每个桶可以表达的最大数字是：`2^5+2^4+...+1 = 63` ，二进制为： `111 111` 。\n在存入时，value 会被 hash 成 64 位二进制数字，前 14 位用来分桶，前 14 位的二进制转为 10 进制就是桶标号。假设一个字符串的前 14 位是：00 0000 0000 0010，其十进制值为 2。那么转化后会放到编号为 2 的桶。\n\n对于剩下的50 位，找出首次出现1位置的index值，然后将该index转换为二进制。\n极端情况下，出现 1 的位置，是在第 50 位，即位置是 50。此时 index = 50。此时先将 index 转为 2 进制，它是：110010 。\n每个桶是 6 bit 组成的，刚好 110010可以被桶中去了。\n如果出现不同的 value，会被设置到同一个桶的，即前 14 位值是一样的，但是后面出现 1 的位置不一样。那么比较新的 index 是否比原 index 大。是，则替换。否，则不变。\n\nRedis HyperLogLog中每一个 key 都对应了 16384 个桶，每个桶有一个k_max。其中value 被转为 64 位二进制，64 位转为十进制就是：`2^64`，HyperLogLog 仅用了：`16384 * 6 /8 / 1024 = 12K` 存储空间就能统计多达 `2^64` 个数。\n\n\n但是在计数比较小的时候，大多数桶的计数值都是零。如果12k字节里面太多的字节都是零，那么这个空间是可以适当节约一下的。Redis在计数值比较小的情况下采用了稀疏存储，稀疏存储的空间占用远远小于 12k 字节。相对于稀疏存储的就是密集存储，密集存储会恒定占用 12k 字节。\n\n#### 密集存储结构\n不论是稀疏存储还是密集存储，Redis 内部都是使用bit位图来存储 HyperLogLog 所有桶的计数值。\n密集存储的结构非常简单，就是连续 16384 个 6bit 串成的bit位图。\n![](分桶bit图.png)\n那么给定一个桶编号，如何获取它的 6bit 计数值呢？这 6bit 可能在一个字节内部，也可能会跨越字节边界。我们需要对这一个或者两个字节进行适当的移位拼接才可以得到计数值。\n\n假设桶的编号为idx，这个 6bit 计数值的起始字节位置偏移用 offset_bytes表示，它在这个字节内部的起始比特位置偏移用 offset_bits 表示。\n```java\noffset_bytes = (idx * 6) / 8\noffset_bits = (idx * 6) % 8\n```\n比如 bucket 2 的字节偏移是 1，也就是第 2 个字节。它的位偏移是4，也就是第 2 个字节的第 5 个位开始是 bucket 2 的计数值。需要注意的是字节位序是左边低位右边高位。\n![](HyperLogLog字节位.png)\n\n如果 offset_bits 小于等于 2，那么这 6bit 在一个字节内部，可以直接使用下面的表达式得到计数值 val\n![](密集存储1.png)\n```java\nval = buffer[offset_bytes] >> offset_bits  # 向右移位\n```\n如果 offset_bits 大于 2，那么就会跨越字节边界，这时需要拼接两个字节的位片段。\n\n![](密集存储2.jpg)\n```java\n# 低位值\nlow_val = buffer[offset_bytes] >> offset_bits\n# 低位个数\nlow_bits = 8 - offset_bits\n# 拼接，保留低6位\nval = (high_val << low_bits | low_val) & 0b111111\n```\n\n#### 稀疏存储结构\n\n稀疏存储适用于很多计数值都是零的情况。下图表示了一般稀疏存储计数值的状态。\n![](稀疏存储1.png)\n当多个连续桶的计数值都是0时，Redis 使用了一个字节来表示接下来有多少个桶的计数值都是零：00xxxxxx。前缀两个零表示接下来的 6bit 整数值加 1 就是零值计数器的数量，注意这里要加 1 是因为数量如果为0是没有意义的。比如 00010101表示连续 22 个零值计数器。\n\n6bit 最多只能表示连续 64 个零值计数器，所以 Redis 又设计了连续多个多于 64 个的连续零值计数器，它使用两个字节来表示：01xxxxxx yyyyyyyy，后面的 14bit 可以表示最多连续 16384 个零值计数器。这意味着 HyperLogLog 数据结构中 16384 个桶的初始状态，所有的计数器都是零值，可以直接使用 2 个字节来表示。\n\n如果连续几个桶的计数值非零，那就使用形如 1vvvvvxx 这样的一个字节来表示。中间 5bit 表示计数值，尾部 2bit 表示连续几个桶。\n它的意思是连续 （xx +1） 个计数值都是 （vvvvv + 1）。比如10101011表示连续4个计数值都是11。注意这两个值都需要加1，因为任意一个是零都意味着这个计数值为零，那就应该使用零计数值的形式来表示。\n注意计数值最大只能表示到32，而 HyperLogLog 的密集存储单个计数值用 6bit 表示，最大可以表示到 63。当稀疏存储的某个计数值需要调整到大于 32 时，Redis 就会立即转换 HyperLogLog 的存储结构，将稀疏存储转换成密集存储。\n![](稀疏存储2.png)\nRedis 为了方便表达稀疏存储，它将上面三种字节表示形式分别赋予了一条指令。\n\n> - ZERO:len 单个字节表示 00[len-1]，连续最多64个零计数值\n> - VAL:value,len 单个字节表示 1[value-1][len-1]，连续 len 个值为 value 的计数值\n> - XZERO:len 双字节表示 01[len-1]，连续最多16384个零计数值\n\n上图可以使用指令形式表示如下：\n![](稀疏存储3.png)\n\n#### 存储转换\n当计数值达到一定程度后，稀疏存储将会不可逆一次性转换为密集存储。转换的条件有两个，任意一个满足就会立即发生转换:\n\n- 任意一个计数值从 32 变成 33，因为VAL指令已经无法容纳，它能表示的计数值最大为 32\n- 稀疏存储占用的总字节数超过 3000 字节，这个阈值可以通过 hll_sparse_max_bytes 参数进行调整\n\n\n#### 计数缓存 \nHyperLogLog 表示的总计数值是由16384个桶的计数值进行调和平均后再基于因子修正公式计算得出来的。它需要遍历所有的桶进行计算才可以得到这个值，中间还涉及到很多浮点运算。这个计算量相对来说还是比较大的。\n所以 Redis 使用了一个额外的字段来缓存总计数值，这个字段有 64bit，最高位如果为 1 表示该值是否已经过期，如果为 0， 那么剩下的 63bit 就是计数值。\n\n当HyperLogLog中任意一个桶的计数值发生变化时，就会将计数缓存设为过期，但是不会立即触发计算。而是要等到用户显示调用`pfcount`指令时才会触发重新计算刷新缓存。\n缓存刷新在密集存储时需要遍历16384个桶的计数值进行调和平均，但是稀疏存储时没有这么大的计算量。也就是说只有当计数值比较大时才可能产生较大的计算量。另一方面如果计数值比较大，那么大部分`pfadd`操作根本不会导致桶中的计数值发生变化。\n\n这意味着在一个极具变化的 HLL 计数器中频繁调用`pfcount`指令可能会有少许性能问题。不过Redis作者在这方面做了仔细的压力的测试，发现这是无需担心的，`pfcount` 指令的平均时间复杂度就是 O(1)。\n\n\n#### 对象头\nHyperLogLog 除了需要存储 16384 个桶的计数值之外，它还有一些附加的字段需要存储，比如总计数缓存、存储类型。所以它使用了一个额外的对象头来表示。\n\n```c\nstruct hllhdr {\n    char magic[4];      /* 魔术字符串\"HYLL\" */\n    uint8_t encoding;   /* 存储类型 HLL_DENSE or HLL_SPARSE. */\n    uint8_t notused[3]; /* 保留三个字节未来可能会使用 */\n    uint8_t card[8];    /* 总计数缓存 */\n    uint8_t registers[]; /* 所有桶的计数器 */\n};\n```\n所以 HyperLogLog 整体的内部结构就是 HLL 对象头 加上 16384 个桶的计数值位图。它在 Redis 的内部结构表现就是一个字符串位图。你可以把 HyperLogLog 对象当成普通的字符串来进行处理。\n\n```shell\n127.0.0.1:6379> pfadd codehole python java golang\n(integer) 1\n127.0.0.1:6379> get codehole\n\"HYLL\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80C\\x03\\x84MK\\x80P\\xb8\\x80^\\xf3\"\n```\n但是不可以使用 HyperLogLog 指令来操纵普通的字符串，因为它需要检查对象头魔术字符串是否是 \"HYLL\"。\n\n```shell\n127.0.0.1:6379> set codehole python\nOK\n127.0.0.1:6379> pfadd codehole java golang\n(error) WRONGTYPE Key is not a valid HyperLogLog string value.\n```\n但是如果字符串以 \"HYLL\\x00\" 或者 \"HYLL\\x01\" 开头，那么就可以使用 HyperLogLog 的指令。\n\n```shell\n127.0.0.1:6379> set codehole \"HYLL\\x01whatmagicthing\"\nOK\n127.0.0.1:6379> get codehole\n\"HYLL\\x01whatmagicthing\"\n127.0.0.1:6379> pfadd codehole python java golang\n(integer) 1\n```\n也许你会感觉非常奇怪，这是因为 HyperLogLog 在执行指令前需要对内容进行格式检查，这个检查就是查看对象头的 magic 魔术字符串是否是 \"HYLL\" 以及 encoding 字段是否是 HLL_SPARSE=0 或者 HLL_DENSE=1 来判断当前的字符串是否是 HyperLogLog 计数器。如果是密集存储，还需要判断字符串的长度是否恰好等于密集计数器存储的长度。\n\n### Redis HyperLogLog命令\nRedis HyperLogLog常用的命令：\n> - pfadd key value #将 key 对应的一个 value 存入\n> - pfcount key #统计 key 的 value 有多少个\n\n\n### HyperLogLog缺点\n- 不能像Set一样减少元素\n- 不是精准的计数，有一定误差\n\n### 精准去重计算替补方案\n如果是准确的去重，肯定需要用到 set 集合。考虑到元素特别多，单个集合会特别大，所以将集合打散成 16384 个小集合。通过 hash 算法将这个元素分派到其中的一个小集合存储，同样的元素总是会散列到同样的小集合，这样总的计数就是所有小集合大小的总和。当然这里也可以全局的key(String结构)，来统计总的元素个数。当元素到来时，使用这种方式精确计数除了可以增加元素外，还可以减少元素。\n\n\n### 参考资料\n- [HyperLogLog 算法的原理讲解以及 Redis 是如何应用它的](https://juejin.cn/post/6844903785744056333)\n-[手动直观观察 LogLog 和 HyperLogLog 变化的网站](http://content.research.neustar.biz/blog/hll.html)","tags":["Redis","UV统计"],"categories":["Redis"]},{"title":"RocketMQ 消息堆积原因排查","url":"/2022/02/07/RocketMQ-消息堆积原因排查/","content":"\n### 现象\n春节期间，公司业务告警群一直在提示“XXX-TOPIC连续15分钟出现消息堆积”，而订阅该TOPIC的消费者会调用微信接口，给微信用户推送物流轨迹模板消息。整个消费者组由4个consumer实例组成，每个consumer实例开了20个线程去消费消息。\n\n### 错误日志\n登陆阿里云，在Group管理找到对应的消费者组，进入详情可以看到每个consumer实例的消费堆积情况。发现其中有个consumer实例确实有出现堆积情况。\n查看对应的消费堆栈日志如下：\n```java\nThread: RebalanceService\nTID: 61 STATE: TIMED_WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\njava.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)\njava.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.common.CountDownLatch2.await(CountDownLatch2.java:114)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.common.ServiceThread.waitForRunning(ServiceThread.java:116)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.consumer.RebalanceService.run(RebalanceService.java:46)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_6\nTID: 234 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_4\nTID: 221 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_1\nTID: 194 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_10\nTID: 241 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_15\nTID: 254 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_13\nTID: 251 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: RebalanceService\nTID: 43 STATE: TIMED_WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\njava.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)\njava.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.common.CountDownLatch2.await(CountDownLatch2.java:114)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.common.ServiceThread.waitForRunning(ServiceThread.java:116)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.consumer.RebalanceService.run(RebalanceService.java:46)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_8\nTID: 238 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_20\nTID: 265 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_5\nTID: 222 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_2\nTID: 206 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: RebalanceService\nTID: 54 STATE: TIMED_WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\njava.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)\njava.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.common.CountDownLatch2.await(CountDownLatch2.java:114)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.common.ServiceThread.waitForRunning(ServiceThread.java:116)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.consumer.RebalanceService.run(RebalanceService.java:46)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_11\nTID: 246 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_3\nTID: 211 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_14\nTID: 252 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_17\nTID: 262 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_7\nTID: 237 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_18\nTID: 263 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_19\nTID: 264 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_16\nTID: 259 STATE: RUNNABLE\njava.net.SocketInputStream.socketRead0(Native Method)\njava.net.SocketInputStream.socketRead(SocketInputStream.java:116)\njava.net.SocketInputStream.read(SocketInputStream.java:171)\njava.net.SocketInputStream.read(SocketInputStream.java:141)\nsun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:466)\nsun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:460)\nsun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:159)\nsun.security.ssl.SSLTransport.decode(SSLTransport.java:110)\nsun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1198)\nsun.security.ssl.SSLSocketImpl.readHandshakeRecord(SSLSocketImpl.java:1107)\nsun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:400)\nsun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:372)\norg.apache.http.conn.ssl.SSLConnectionSocketFactory.createLayeredSocket(SSLConnectionSocketFactory.java:394)\norg.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:353)\norg.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:134)\norg.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:353)\norg.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:380)\norg.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)\norg.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184)\norg.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:88)\norg.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)\norg.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184)\norg.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:82)\norg.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:107)\ncn.xx.xx.wechat.service.impl.WeChatBaseServiceImpl.getAccessTokenByGet(WeChatBaseServiceImpl.java:400)\ncn.xx.xx.wechat.service.impl.WeChatBaseServiceImpl.getAccessToken(WeChatBaseServiceImpl.java:315)\ncn.xx.xx.wechat.service.impl.WeChatBaseServiceImpl$$FastClassBySpringCGLIB$$8a7ed60.invoke(<generated>)\norg.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)\norg.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:749)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)\norg.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:56)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:47)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)\ncn.xx.xx.wechat.service.impl.WeChatBaseServiceImpl$$EnhancerBySpringCGLIB$$96efbc13.getAccessToken(<generated>)\ncn.xx.xx.wechat.service.impl.WeChatPublicBaseServiceImpl.sendPublicTemplate(WeChatPublicBaseServiceImpl.java:118)\ncn.xx.xx.wechat.service.impl.WeChatPublicBaseServiceImpl$$FastClassBySpringCGLIB$$fb68e6b7.invoke(<generated>)\norg.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)\norg.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:749)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)\norg.springframework.transaction.interceptor.TransactionInterceptor$$Lambda$831/432055812.proceedWithInvocation(Unknown Source)\norg.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:295)\norg.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:56)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:47)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)\ncn.xx.xx.wechat.service.impl.WeChatPublicBaseServiceImpl$$EnhancerBySpringCGLIB$$b1925954.sendPublicTemplate(<generated>)\ncn.xx.xx.wechat.MQ.rockermq.consumer.OrderTracePublicTemplateMessageConsumer.consume(OrderTracePublicTemplateMessageConsumer.java:34)\ncom.aliyun.openservices.ons.api.impl.rocketmq.ConsumerImpl$MessageListenerImpl.consumeMessage(ConsumerImpl.java:101)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.consumer.ConsumeMessageConcurrentlyService$ConsumeRequest.run(ConsumeMessageConcurrentlyService.java:423)\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\njava.util.concurrent.FutureTask.run(FutureTask.java:266)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_9\nTID: 240 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\nThread: RebalanceService\nTID: 30 STATE: TIMED_WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\njava.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)\njava.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.common.CountDownLatch2.await(CountDownLatch2.java:114)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.common.ServiceThread.waitForRunning(ServiceThread.java:116)\ncom.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.consumer.RebalanceService.run(RebalanceService.java:46)\njava.lang.Thread.run(Thread.java:748)\n\nThread: ConsumeMessageThread_12\nTID: 248 STATE: WAITING\nsun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\njava.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\njava.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\njava.lang.Thread.run(Thread.java:748)\n\n```\n\n### 原因 \n从上文的堆栈日志发现，只有**Thread: ConsumeMessageThread_16**是**RUNNABLE**，其余线程都是**WAITING、TIMED_WAITING**。从**ConsumeMessageThread_16**的日志可以看到，当前的线程阻塞在**java.net.SocketInputStream.socketRead0**，再往下的日志可以发现**cn.xx.xx.wechat.service.impl.WeChatBaseServiceImpl.getAccessTokenByGet(WeChatBaseServiceImpl.java:400)**，由此可能是因为网络延迟或微信服务器连接后没有响应造成一直阻塞等待读取，导致影响正常的消息消费速度。\n\n### 结论\n让运维同学重启该问题实例后，问题解决了。在使用HTTP连接时应该设置相关connect超时时间和Read超时时间，避免客户端与远程服务连接时出现长时间未连接成功或读写出现长时间阻塞，以致于影响到其他正常的业务。\n","tags":["RocketMQ","坑点"],"categories":["RocketMQ","坑点"]},{"title":"RocketMQ [TIMEOUT_CLEAN_QUEUE]broker busy异常","url":"/2022/01/25/RocketMQ-TIMEOUT-CLEAN-QUEUE-broker-busy异常/","content":"\n### 场景案例\n最近在使用阿里云RocketMQ发送分区消息的时候，偶尔会出现下面的异常\n```java\n+17\n[2022-01-23 20:28:38]\ncontent: \nCaused by: com.aliyun.openservices.shade.com.alibaba.rocketmq.client.exception.MQBrokerException: CODE: 2  DESC: [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 2006ms, size of queue: 681\n+18\n[2022-01-23 20:28:38]\ncontent: \nFor more information, please visit the url, http://rocketmq.apache.org/docs/faq/\n+19\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.MQClientAPIImpl.processSendResponse(MQClientAPIImpl.java:686)\n+20\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.MQClientAPIImpl.sendMessageSync(MQClientAPIImpl.java:461)\n+21\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.MQClientAPIImpl.sendMessage(MQClientAPIImpl.java:442)\n+22\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.MQClientAPIImpl.sendMessage(MQClientAPIImpl.java:404)\n+23\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendKernelImpl(DefaultMQProducerImpl.java:753)\n+24\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendSelectImpl(DefaultMQProducerImpl.java:1040)\n+25\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:949)\n+26\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:944)\n+27\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.shade.com.alibaba.rocketmq.client.producer.DefaultMQProducer.send(DefaultMQProducer.java:442)\n+28\n[2022-01-23 20:28:38]\ncontent: \n\tat com.aliyun.openservices.ons.api.impl.rocketmq.OrderProducerImpl.send(OrderProducerImpl.java:119)\n```\n\n### 原因\n\n通过关键字[TIMEOUT_CLEAN_QUEUE]可以快速定位到异常所在的类-BrokerFastFailure.java\n```java\npublic class BrokerFastFailure {\n    //省略了一部分代码\n    public void start() {\n        this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() {\n            @Override\n            public void run() {\n                if (brokerController.getBrokerConfig().isBrokerFastFailureEnable()) {\n                    cleanExpiredRequest();\n                }\n            }\n        }, 1000, 10, TimeUnit.MILLISECONDS);\n    }\n\n    private void cleanExpiredRequest() {\n        while (this.brokerController.getMessageStore().isOSPageCacheBusy()) {\n            try {\n                if (!this.brokerController.getSendThreadPoolQueue().isEmpty()) {\n                    final Runnable runnable = this.brokerController.getSendThreadPoolQueue().poll(0, TimeUnit.SECONDS);\n                    if (null == runnable) {\n                        break;\n                    }\n\n                    final RequestTask rt = castRunnable(runnable);\n                    rt.returnResponse(RemotingSysResponseCode.SYSTEM_BUSY, String.format(\"[PCBUSY_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: %sms, size of queue: %d\", System.currentTimeMillis() - rt.getCreateTimestamp(), this.brokerController.getSendThreadPoolQueue().size()));\n                } else {\n                    break;\n                }\n            } catch (Throwable ignored) {\n            }\n        }\n\t\t\n\t\t//清除发送队列中的失效请求\t\t\n        cleanExpiredRequestInQueue(this.brokerController.getSendThreadPoolQueue(),\n            this.brokerController.getBrokerConfig().getWaitTimeMillsInSendQueue());\n\n\t\t//清除消费队列中的失效请求\t\t\n        cleanExpiredRequestInQueue(this.brokerController.getPullThreadPoolQueue(),\n            this.brokerController.getBrokerConfig().getWaitTimeMillsInPullQueue());\n\n\t\t//清除心跳队列中的失效请求\t\t\n        cleanExpiredRequestInQueue(this.brokerController.getHeartbeatThreadPoolQueue(),\n            this.brokerController.getBrokerConfig().getWaitTimeMillsInHeartbeatQueue());\n\n\t\t//清除事务队列中的失效请求\n        cleanExpiredRequestInQueue(this.brokerController.getEndTransactionThreadPoolQueue(), this\n            .brokerController.getBrokerConfig().getWaitTimeMillsInTransactionQueue());\n    }\n\n    void cleanExpiredRequestInQueue(final BlockingQueue<Runnable> blockingQueue, final long maxWaitTimeMillsInQueue) {\n        while (true) {\n            try {\n                if (!blockingQueue.isEmpty()) {\n                    final Runnable runnable = blockingQueue.peek();\n                    if (null == runnable) {\n                        break;\n                    }\n                    final RequestTask rt = castRunnable(runnable);\n                    if (rt == null || rt.isStopRun()) {\n                        break;\n                    }\n\n                    final long behind = System.currentTimeMillis() - rt.getCreateTimestamp();\n                    if (behind >= maxWaitTimeMillsInQueue) {\n                        if (blockingQueue.remove(runnable)) {\n                            rt.setStopRun(true);\n                            rt.returnResponse(RemotingSysResponseCode.SYSTEM_BUSY, String.format(\"[TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: %sms, size of queue: %d\", behind, blockingQueue.size()));\n                        }\n                    } else {\n                        break;\n                    }\n                } else {\n                    break;\n                }\n            } catch (Throwable ignored) {\n            }\n        }\n    }\n    //省略了一部分代码\n}\n```\n上面开启了一个定时任务线程池，每隔10ms执行一次任务。如果发送队列的头元素等待时间超过该队列设置的最大等待时间（waitTimeMillsInSendQueue，默认为200ms），则丢弃该元素对象的任务，并对这个请求返回[TIMEOUT_CLEAN_QUEUE]broker busy异常信息。这里其中涉及到Broker快速机制。\n\n\n### broker快速失败原理\n![](快速失败机制.png)\n当Broker收到客户端的请求后会将消息先放入队列(SendThreadPoolQueue，默认容量为10000）。Broker 会专门使用一个线程池(SendMessageExecutor)去从队列中获取任务并执行消息写入请求，为了保证消息的顺序处理，该线程池默认线程个数为1。为了避免队列中存在过多无效超时的发送请求（消息发送端的默认超时时间为3s）， Broker 端快速失败机制，即开启一个定时调度线程，每隔10ms去检查发送队列中的头元素，如果头元素等待时间超过200ms就会启动快速失败，向客户端返回`[TIMEOUT_CLEAN_QUEUE]broker busy`，让客户端重试发送消息。\n\n#### 发送消息线程池线程个数为什么设置为1\n因为RocketMQ4.0.x 版本后默认使用自旋锁，这样能够减少CPU上下文切换，提高性能。自旋锁适合在并发低的时候使用，在多线程场景，即在并发高的时候就要使用可重入锁了。\n可以用过以下的参数来进行调整\n```java\n//默认\nsendMessageThreadPoolNums=1 \nuseReentrantLockWhenPutMessage=false\n\n//调整后\nsendMessageThreadPoolNums=32\nuseReentrantLockWhenPutMessage=true  \n```\n如果sendMessageThreadPoolNums > 1，在使用绝对顺序消息时，是无法保证消息的顺序的，这里会有多个线程处理一个队列的消息，顺序错乱。\n\n### 解决方案\n#### 调整broker参数\n调大broker的默认发送消息任务队列等待时长waitTimeMillsInSendQueue值(单位: ms)\n\n#### 消息重试\n从异常日志`com.aliyun.openservices.shade.com.alibaba.rocketmq.client.exception.MQBrokerException: CODE: 2`可以看出，\n可以在业务逻辑处理对MQ异常捕获，如果捕获到异常为MQBrokerException并且responseCode为2，则重发消息。这里只能手动重试，因为在MQBrokerException异常中，只有以下几种responseCode可以自动进行重试：\n```java\n    private final Set<Integer> retryResponseCodes = new CopyOnWriteArraySet<Integer>(Arrays.asList(\n            ResponseCode.TOPIC_NOT_EXIST,\n            ResponseCode.SERVICE_NOT_AVAILABLE,\n            ResponseCode.SYSTEM_ERROR,\n            ResponseCode.NO_PERMISSION,\n            ResponseCode.NO_BUYER_ID,\n            ResponseCode.NOT_IN_CURRENT_UNIT\n    ));\n```\n以上定义在DefaultMQProducer.java类中\n\n状态码映射\n> - RemotingSysResponseCode.SYSTEM_BUSY： 2\n> - ResponseCode.TOPIC_NOT_EXIST： 17\n> - ResponseCode.SERVICE_NOT_AVAILABLE： 14\n> - ResponseCode.SYSTEM_ERROR： 1\n> - ResponseCode.NO_PERMISSION： 16\n> - ResponseCode.NO_BUYER_ID： 204\n> - ResponseCode.NOT_IN_CURRENT_UNIT： 205\n\n我们可以在DefaultMQProducerImpl的sendDefaultImpl()方法看到对MQBrokerException异常的处理\n```java\n    private SendResult sendDefaultImpl(\n        Message msg,\n        final CommunicationMode communicationMode,\n        final SendCallback sendCallback,\n        final long timeout\n    ) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {\n        this.makeSureStateOK();\n        Validators.checkMessage(msg, this.defaultMQProducer);\n        final long invokeID = random.nextLong();\n        long beginTimestampFirst = System.currentTimeMillis();\n        long beginTimestampPrev = beginTimestampFirst;\n        long endTimestamp = beginTimestampFirst;\n        TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic());\n        if (topicPublishInfo != null && topicPublishInfo.ok()) {\n            ...\n            for (; times < timesTotal; times++) {\n                String lastBrokerName = null == mq ? null : mq.getBrokerName();\n                MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName);\n                if (mqSelected != null) {\n                    mq = mqSelected;\n                    brokersSent[times] = mq.getBrokerName();\n                    try {\n                       ...\n                    } catch (RemotingException e) {\n                        ...\n                        continue;\n                    } catch (MQClientException e) {\n                        ...\n                        continue;\n                    } catch (MQBrokerException e) {\n                       ....\n                        if (this.defaultMQProducer.getRetryResponseCodes().contains(e.getResponseCode())) {\n                            continue;\n                        } else {\n                            if (sendResult != null) {\n                                return sendResult;\n                            }\n\n                            throw e;\n                        }\n                    } catch (InterruptedException e) {\n                        ...\n                        throw e;\n                    }\n                } else {\n                    break;\n                }\n            }\n\n            if (sendResult != null) {\n                return sendResult;\n            }\n\n            ...\n        }\n    }\n```\n\n#### 存 + 定时器扫描\n这里的存可以是存在数据库或者redis等其他存储介质。只有当出现上述异常时，才进行存储，所以数据量相对会小很多，然后用xxl-job定时器定时扫描，重新发送消息。\n","tags":["RocketMQ","坑点"],"categories":["RocketMQ","坑点"]},{"title":"【转载】死锁日志解读","url":"/2022/01/22/【转载】死锁日志解读/【转载】死锁日志解读/","content":"\n下面是日志内容：\n```shell\n------------------------\nLATEST DETECTED DEADLOCK\n------------------------\n2017-09-09 22:34:13 7f78eab82700\n*** (1) TRANSACTION: #事务1\nTRANSACTION 462308399, ACTIVE 33 sec starting index read\nmysql tables in use 1, locked 1\nLOCK WAIT 2 lock struct(s), heap size 360, 1 row lock(s)\nMySQL thread id 3525577, OS thread handle 0x7f896cc4b700, query id 780039657 localhost root updating\ndelete from ty where a=5\n*** (1) WAITING FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 219 page no 4 n bits 72 index `idxa` of table `test`.`ty` trx id 462308399 lock_mode X waiting\n*** (2) TRANSACTION:\nTRANSACTION 462308398, ACTIVE 61 sec inserting, thread declared inside InnoDB 5000\nmysql tables in use 1, locked 1\n5 lock struct(s), heap size 1184, 4 row lock(s), undo log entries 2\nMySQL thread id 3525490, OS thread handle 0x7f78eab82700, query id 780039714 localhost root update\ninsert into ty(a,b) values(2,10)\n*** (2) HOLDS THE LOCK(S):\nRECORD LOCKS space id 219 page no 4 n bits 72 index `idxa` of table `test`.`ty` trx id 462308398 lock_mode X\n*** (2) WAITING FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 219 page no 4 n bits 72 index `idxa` of table `test`.`ty` trx id 462308398 lock_mode X locks gap before rec insert intention waiting\n*** WE ROLL BACK TRANSACTION (1)\n```\n下面分成：（1）TRANSACTION、（1）WAITING FOR THIS LOCK TO BE GRANTED、（2）TRANSACTION、（2）HOLDS THE LOCK(S)、（2）WAITING FOR THIS LOCK TO BE GRANTED、WE ROLL BACK TRANSACTION (1)\n1代表事务1，2代表事务2\n\n- **（1）TRANSACTION: #事务1 **\n **TRANSACTION 462308399, ACTIVE 33 sec starting index read** \n事务编号为 462308399 ，活跃33秒，starting index read 表示事务状态为根据索引读取数据。\n常见的其他状态:\n> - fetching rows 表示事务状态在row_search_for_mysql中被设置，表示正在查找记录。\n> - updating or deleting 表示事务已经真正进入了Update/delete的函数逻辑（row_update_for_mysql）\n> - thread declared inside InnoDB 说明事务已经进入innodb层。通常而言 不在innodb层的事务大部分是会被回滚的。\n\n**mysql tables in use 1**， 说明当前的事务使用一个表，**locked 1** 表示表上有一个表锁，对于DML语句为LOCK_IX\n**LOCK WAIT 2 lock struct(s), heap size 360, 1 row lock(s)**\nLOCK WAIT表示正在等待锁, 2 lock struct(s) 表示trx->trx_locks锁链表的长度为2，每个链表节点代表该事务持有的一个锁结构，包括表锁，记录锁以及auto_inc锁等。本案例中2locks 表示IX锁和lock_mode X(Next-key lock)\nheap size 360 表示事务分配的锁堆内存大小,一般没有什么具体的用处。\n1 row lock(s)表示当前事务持有的行记录锁/gap 锁的个数。\n\ndelete from ty where a=5 表示事务1在执行的sql \n\n- ** （1）WAITING FOR THIS LOCK TO BE GRANTED**\n**RECORD LOCKS space id 219 page no 4 n bits 72 index `idxa` of table `test`.`ty` trx id 462308399 lock_mode X waiting**\nRECORD LOCKS 表示记录锁,space id为219,page号4 ，n bits 72表示这个聚集索引记录锁结构上留有72个Bit位\n表示事务1 正在等待表 ty 上的 idxa 的 X 锁本案例中其实是Next-Key lock\n事务2的log 和上面分析类似\n\n- ** （2）TRANSACTION、HOLDS THE LOCK(S) **\n** RECORD LOCKS space id 219 page no 4 n bits 72 index `idxa` of table `test`.`ty` trx id 462308398 lock_mode X **\n显示了事务2 insert into ty(a,b) values(2,10)持有了a=5 的Lock mode X |LOCK_GAP ，不过我们从日志里面看不到 事务2 执行的 delete from  ty where  a=5;这点也是造成DBA 仅仅根据日志难以分析死锁的问题的根本原因。\n\n-  ** （2）WAITING FOR THIS LOCK TO BE GRANTED**\n** RECORD LOCKS space id 219 page no 4 n bits 72 index `idxa` of table `test`.`ty` trx id 462308398 lock_mode X locks gap before rec insert intention waiting **\n表示事务2的insert 语句正在等待插入意向锁 lock_mode X locks gap before rec insert intention waiting (LOCK_X + LOCK_REC_GAP )\n这里需要各位注意的是锁组合，类似lock_mode X waiting ,lock_mode X,lock_mode X locks gap before rec insert intention waiting 是我们分析死锁的核心重点。\n\n\n### 锁组合\n锁组合呢？\n首先我们要知道对于MySQL有两种常规锁模式\n> - LOCK_S（读锁，共享锁）\n> - LOCK_X（写锁，排它锁）\n最容易理解的锁模式，读加共享锁，写加排它锁。\n### 锁属性\n> - LOCK_REC_NOT_GAP        （锁记录）\n> - LOCK_GAP                （锁记录前的GAP）\n> - LOCK_ORDINARY           （同时锁记录+记录前的GAP 。传说中的Next Key锁）\n> - LOCK_INSERT_INTENTION   （插入意向锁，其实是特殊的GAP锁）\n锁的属性可以与锁模式任意组合。例如:\nlock->type_mode 可以是Lock_X 或者Lock_S \nlocks gap before rec    表示为gap锁：lock->type_mode & LOCK_GAP\nlocks rec but not gap   表示为记录锁，非gap锁：lock->type_mode & LOCK_REC_NOT_GAP\ninsert intention        表示为插入意向锁：lock->type_mode & LOCK_INSERT_INTENTION\nwaiting                 表示锁等待：lock->type_mode & LOCK_WAIT\n\n\n### 参考资料\n- [如何阅读死锁日志](http://blog.itpub.net/22664653/viewspace-2145133/)\n","tags":["MySQL","转载","死锁"],"categories":["MySQL","转载"]},{"title":"【转载】MySQL各类加锁过程","url":"/2022/01/22/【转载】MySQL各类加锁过程/","content":"\n### MySQL各类加锁过程\n\nMySQL里面大部分获取锁的过程\n代码在lock0lock.c的static enum db_err lock_rec_lock() 函数中，这个函数会显示，获取锁的过程，以及获取锁成功与否。\n\n#### 通过主键进行删除\n**表结构**\n```sql\nCREATE TABLE `t1` (\n `id` int(11) NOT NULL AUTO_INCREMENT,\n `name` varchar(10) NOT NULL DEFAULT '',\n PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\n### 执行语句 \ndelete from t1 where id = 10;\n```\n![](加锁1-1.jpeg)\n可以看到，对索引 PRIMARY 加锁，mode = 1027，1027是什么意思呢？1027 =  LOCK_REC_NOT_GAP + LOCK_X（非 gap 的记录锁且是 X 锁）\n**过程如下:**\n![](加锁1-2.jpeg)\n**结论：**\n根据主键 id 去删除数据，且没有其它索引的情况下，此 SQL 只需要在 id = 10 这条记录上对主键索引加 X 锁即可\n\n#### 通过唯一索引进行删除\n**表结构**\n```sql\nCREATE TABLE `t2` (\n `id` int(11) NOT NULL AUTO_INCREMENT,\n `name` varchar(10) NOT NULL DEFAULT '',\n PRIMARY KEY (`id`),\n UNIQUE KEY `uk_name` (`name`)\n) ;\n\n#构造数据\nINSERT INTO `t2` (`id`, `name`) VALUES\n (1,'M'),\n (2,'Y'),\n (3,'S'),\n (4,'Q'),\n (5,'L');\n  \n#测试sql语句\ndelete from t2 where name = \"Y\"\n```\n- 第一步：\n![](加锁2-1.jpeg)\n- 第二步：\n![](加锁2-2.jpeg)\n**过程如下:**\n![](加锁2-3.jpeg)\n**结论：**\n这个过程是先对唯一键 uk_name 加 X 锁，然后再对聚簇索引（主键索引）加 X 锁\n\n#### 通过普通索引进行删除\n**表结构**\n```sql\nCREATE TABLE `t3` (\n `id` int(11) NOT NULL AUTO_INCREMENT,\n `name` varchar(10) NOT NULL DEFAULT '',\n PRIMARY KEY (`id`),\n KEY `idx_name` (`name`) \n);\n\n#构造数据\nINSERT INTO `t3` (`id`, `name`) VALUES\n (1,'N'),\n (2,'G'),\n (3,'I'),\n (4,'N'),\n (5,'X');\n  \n#测试语句sql\ndelete from t3 where name = \"N\";\n```\n调试过程如图：\n![](加锁3-1.jpeg)\n**过程如下:**\n![](加锁3-2.jpeg)\n**结论：**\n通过普通索引进行更新时，会对满足条件的所有普通索引加 X 锁，同时会对相关的主键索引加 X 锁\n\n#### 不走索引进行删除\n**表结构**\n```sql\nCREATE TABLE `t4` (\n `id` int(11) NOT NULL AUTO_INCREMENT,\n `name` varchar(10) NOT NULL DEFAULT '',\n PRIMARY KEY (`id`)\n)\n\n#构造数据 \nINSERT INTO `t4` (`id`, `name`) VALUES\n (1,'M'),\n (2,'Y'),\n (3,'S'),\n (4,'Q'),\n (5,'L');\n\n#测试SQL  \ndelete from t4 where name = \"S\";\n```\n调试过程如图：\n![](加锁4-1.jpeg)\n![](加锁4-2.jpeg)\n**过程如下:**\n![](加锁4-3.jpeg)\n**结论：**\n不走索引进行更新时，sql 会走聚簇索引（主键索引）对全表进行扫描，因此每条记录，无论是否满足条件，都会被加上X锁。\n但是为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。\n\n#### 对唯一性索引插入\n**表结构**\n```sql\n# 构造数据\nCREATE TABLE `t5` (\n `id` int(11) NOT NULL AUTO_INCREMENT,\n `name` varchar(10),\n `level` int(11),\n PRIMARY KEY (`id`),\n UNIQUE KEY `uk_name` (`name`)\n);\nINSERT INTO `t5` (`name`, `level`) VALUES ('A',0);\n \n# 出现问题的sql语句如下，并发情况下就会出现死锁\nINSERT ignore INTO `t1` (`name`, `level`) VALUES ('A',0);\n```\n调试过程如图：\n![](加锁5-1.jpeg)\n\n**结论：**\n对唯一键 uk_name 加共享锁（S锁）\n\n### 参考资料\n- [初学者从源码理解MySQL死锁问题](https://www.jb51.net/article/161758.htm)\n","tags":["MySQL","转载"],"categories":["MySQL","转载"]},{"title":"后端获取不到headers中的值","url":"/2022/01/22/后端获取不到headers中的值/后端获取不到headers中的值/","content":"\n前些日子，在和前端联调H5页面接口时，让前端在headers添加access_token，但是后端接口一直获取不到access_token中的值。\n了解到当时前端在本地开发时，调用链路是这样：H5-->Nginx-->后端网关-->后端服务。\n这里的原因是由于服务器是通过nginx代理转发的，它不认下划线。\n所以要么改变参数名或者nginx增加配置\n```java\nunderscores_in_headers on; \n```\n\n","tags":["坑点"],"categories":["坑点"]},{"title":"MySQL中ON DUPLICATE KEY UPDATE使用总结","url":"/2022/01/22/MySQL中ON-DUPLICATE-KEY-UPDATE使用总结/","content":"\n### 场景\n假设有一张如下的表，用来汇总每个店主每天的销售额:\n```sql\nCREATE TABLE `shop_sale_amount_summary` (\n  `shop_sale_amount_summary_id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `version` varchar(50) NOT NULL DEFAULT '' COMMENT '下单日期(年月日)',\n  `sale_amount` decimal(20,2) NOT NULL DEFAULT '0.00' COMMENT '每日销售额',\n  `shop_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '店主id',\n  `is_delete` tinyint(4) NOT NULL DEFAULT '0' COMMENT '是否删除:0.未删除 1.删除',\n  `add_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',\n  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',\n  PRIMARY KEY (`shop_sale_amount_summary_id`),\n  UNIQUE KEY `uk_version_shop_id` (`version`, `shop_id`),\n) ENGINE=InnoDB AUTO_INCREMENT=1; \n```\n当一条销售额数据过来的时候，这时候就需要通过select查询判断一条记录存不存在，存在则update更新，不存在则insert新插入一条记录，这种方式容易出现并发问题，当然可以通过加分布式锁解决，但是处理数据效率不高。还有另外一种方式，通过直接insert一条记录，看看是否有异常`DuplicateKeyException`。若有该异常，则进行update，依赖于当前表唯一性索引`uk_version_shop_id`。接下来的方式，可以让你彻底解放双手，那就是使用MySQL的`INSERT ... ON DUPLICATE KEY UPDATE`语句，可以一步到位解决上面的问题。\n\n### 用法\n#### 语法格式\n```sql\nINSERT INTO shop_sale_amount_summary ( version, shop_id, sale_amount ) VALUES ( '20220122', 123, 90.12 ) \nON DUPLICATE KEY UPDATE version = VALUES( version ),\n\t\t\t\t\t\tshop_id = VALUES( shop_id ),\n\t\t\t\t\t\tsale_amount = IF( sale_amount + VALUES ( sale_amount ) >= 0, sale_amount + VALUES ( sale_amount ), sale_amount )\n           \n```\n当与表中现有记录的唯一索引或主键中发生冲突时，那么就会对该条记录进行更新，否则插入新的记录。\n上面的SQL代表对shopId = 123，version=20220122的销售额进行累加。因为有了id自增，所以是基于唯一索引`uk_version_shop_id`判断记录唯一性。\n\n> - VALUES(col_name) : 代表取当前insert语句中的插入值，比如:VALUES( version )表示取值'20220122'，VALUES( shop_id )表示取值123\n> - IF(判断条件,值1,值2)： 当判断条件=true时，取值1，false时，取值2\n\n\n### 注意事项\n- 因为该条语句是insert语句，不能带where条件\n- 如果是插入操作，受到影响行的值为1；如果更新操作，受到影响行的值为2；如果更新的数据和已有的数据一样（就相当于没变，所有值保持不变），受到影响的行的值为0\n- 使用的前提条件，要有主键索引（PRIMARY KEY）或唯一索引（UNIQUE KEY）\n- 会存在自增Id值跳跃比较大的问题，也会有自增id不连续问题。这是因为on duplicate key update，在update的时候，id也会自增1，但在上述的业务场景下，不影响使用\n- 在有可能并发事务执行相同的语句情况下不要使用该语句，可能导致产生death lock。而上述业务场景执行的前提，已经根据`uk_version_shop_id`做了分区串行处理，保证同一个uk_version_shop_id值的数据只会串行处理。\n\n### 弊端-死锁\n#### 原因\n\n![](死锁现象.png)\n\n更深入一层的原因是`lock_mode X locks gap before rec insert intention waiting`，事务1和事务2都互相持有相同的gap锁，都在等待对方释放gap锁。\n\n在MVCC中，当前读和快照读的区别:当前读每次需要加锁（可以使共享锁或者互斥锁）获取到最新的数据，而快照读是读取的是这个事务开始的时候那个快照，这个是通过undo log去进行实现的。在RR隔离级别下如果要读取那么就是当前读，那么其实就需要加上S锁。S锁是共享锁，X锁是互斥锁。一般来说X锁和S、X锁都互斥，S锁和S锁不互斥。\n\n使用下面命令，可以查看产生死锁的详细原因\n```java\nSHOW ENGINE INNODB STATUS\n```\n查找关键字`LATEST DETECTED DEADLOCK`，找到对应输出信息位置。\n\n#### 解决方法\n\n- select... for update，不靠谱，也有可能死锁。\n当并发事务执行都没select出记录，且where筛选条件落在同一个区间时，两个事务可获得同一区间的gap锁。此时再进行并发插入，其中一个会进入锁等待，待第二个session进行插入时，会出现互相等待，导致死锁。MySQL会根据事务权重选择一个事务进行回滚。\n\n- 修改数据隔离级别为RC级别，RC隔离级别下会用快照读，从而不会加S锁，也不会有gap锁\n\n\n### 参考资料\n- [Mysql on duplicate key update用法及优缺点](https://www.cnblogs.com/better-farther-world2099/articles/11737376.html)\n- [MySQL on duplicate key update bug报告](https://bugs.mysql.com/bug.php?id=52020%EF%BC%8C)\n- [select for update引发死锁分析](https://www.cnblogs.com/micrari/p/8029710.html)\n- [记一次神奇的Mysql死锁排查](https://mp.weixin.qq.com/s?__biz=MzA5Mjg2MDQ5NQ%3D%3D&idx=1&mid=2452509340&scene=21&sn=c2cbe9fc3b9c820c38e5177642ba4999#wechat_redirect)\n- [讲讲insert on duplicate key update 的死锁坑\n](https://blog.csdn.net/li563868273/article/details/105213266)\n\n\n\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"idea工程更新不了最新jar包","url":"/2022/01/22/idea工程更新不了最新jar包/","content":"前些天在使用IDEA做开发的时候，一直拉不下最新刚deploy上去的jar包，并且添加新的依赖也引入不了jar包，依赖一直报红。\n尝试用了下面两种方式都没成功\n> - 强制更新jar方式\n    mvn clean install -e -U\n\n> - 删除本地仓库缓存，再重新reimport还是没奏效。\n\n后面再次检查自己的IDEA maven设置，发现勾选了`work offline`选项\n![](maven-Settings.png)\n\n**work offline**：勾选上时不会走maven远程仓库下载的包，会使用本地的jar，如果本地jar缺失，会导入失败。\n另外，在开发的时候，`always update snapshots`选项也记得勾选上，作用跟在settings.xml配置里面，添加`<updatePolicy>always</updatePolicy>`是一样的。\nmaven会通过比较本地pom和远程pom的时间戳，拉取最新的快照版本。","tags":["坑点","工具"],"categories":["坑点"]},{"title":"Java 8的新特性","url":"/2021/02/12/Java-8的新特性/","content":"\n## 简介\nJava 8在语言、编译器、库、工具和JVM等多个方面，较之前的版本增加了十多个新特性。\n\n## Java语言的新特性\n### Lambda表达式和函数式接口\nLambda表达式（也称为闭包），它允许我们将函数当成参数传递给某个方法，或者把代码本身当作数据处理。最简单的Lambda表达式可由**逗号分隔的参数列表、->符号和语句块**组成，例如：\n\n```java\nArrays.asList( \"a\", \"b\", \"d\" ).forEach( e -> System.out.println( e ) );\n```\n\n你也可以显式指定该参数的类型，例如：\n\n```java\nArrays.asList( \"a\", \"b\", \"d\" ).forEach( ( String e ) -> System.out.println( e ) );\n```\n\n如果Lambda表达式需要更复杂的语句块，则可以使用花括号将该语句块括起来，类似于Java中的函数体，例如：\n\n```java\nArrays.asList( \"a\", \"b\", \"d\" ).forEach( e -> {\n    System.out.print( e );\n    System.out.print( e );\n} );\n```\n\nLambda表达式可以引用**类成员和局部变量（会将这些变量隐式地转换成final）**，例如下列两个代码块的效果完全相同：\n\n```java\nString separator = \",\";\nArrays.asList( \"a\", \"b\", \"d\" ).forEach( \n    ( String e ) -> System.out.print( e + separator ) );\n```\n和\n\n```java\nfinal String separator = \",\";\nArrays.asList( \"a\", \"b\", \"d\" ).forEach( \n    ( String e ) -> System.out.print( e + separator ) );\n\n```\n\nLambda表达式有返回值，返回值的类型也由编译器推理得出。如果Lambda表达式中的语句块只有一行，则可以不用使用return语句，下列两个代码片段效果相同：\n\n\n```java\nArrays.asList( \"a\", \"b\", \"d\" ).sort( ( e1, e2 ) -> e1.compareTo( e2 ) );\n```\n和\n\n```java\nArrays.asList( \"a\", \"b\", \"d\" ).sort( ( e1, e2 ) -> {\n    int result = e1.compareTo( e2 );\n    return result;\n} );\n```\n\nLambda的设计者们为了让现有的功能与Lambda表达式良好兼容，考虑了很多方法，于是产生了函数接口这个概念。\n函数接口指的是只有一个函数的接口，这样的接口可以隐式转换为Lambda表达式。java.lang.Runnable和java.util.concurrent.Callable是函数式接口的最佳例子。\n在实践中，函数式接口非常脆弱：只要某个开发者在该接口中添加一个函数，则该接口就不再是函数式接口进而导致编译失败。为了克服这种代码层面的脆弱性，并显式说明某个接口是函数式接口，Java 8 供了一个特殊的注解**@FunctionalInterface**（Java库中的所有相关接口都已经带有这个注解了），举个简单的函数式接口的定义：\n\n```java\n@FunctionalInterface\npublic interface Functional {\n    void method();\n}\n```\n\n不过有一点需要注意，默认方法和静态方法不会破坏函数式接口的定义，因此如下的代码是合法的。\n\n```java\n@FunctionalInterface\npublic interface FunctionalDefaultMethods {\n    void method();\n \n    default void defaultMethod() {            \n    }        \n}\n```\n\n### 接口的默认方法和静态方法\nJava 8使用两个新概念扩展了接口的含义：默认方法和静态方法。默认方法使得开发者可以在 不破坏二进制兼容性的前提下，往现存接口中添加新的方法，即不强制那些实现了该接口的类也同时实现这个新加的方法。\n\n默认方法和抽象方法之间的区别在于**抽象方法需要实现，而默认方法不需要**。接口提供的默认方法会被接口的实现类继承或者覆写，例子代码如下：\n```java\nprivate interface Defaulable {\n    default String notRequired() { \n        return \"Default implementation\"; \n    }        \n}\n \nprivate static class DefaultableImpl implements Defaulable {\n}\n \nprivate static class OverridableImpl implements Defaulable {\n    @Override\n    public String notRequired() {\n        return \"Overridden implementation\";\n    }\n\n```\n在上述代码中，Defaulable接口使用关键字default定义了一个默认方法notRequired()。DefaultableImpl类实现了这个接口，同时默认继承了这个接口中的默认方法；OverridableImpl类也实现了这个接口，但覆写了该接口的默认方法，并提供了一个不同的实现。\n\nJava 8带来的另一个有趣的特性是在接口中可以定义静态方法，例子代码如下：\n```java\nprivate interface DefaulableFactory {\n    // Interfaces now allow static methods\n    static Defaulable create( Supplier< Defaulable > supplier ) {\n        return supplier.get();\n    }\n}\n\npublic static void main( String[] args ) {\n    Defaulable defaulable = DefaulableFactory.create( DefaultableImpl::new );\n    System.out.println( defaulable.notRequired() );\n \n    defaulable = DefaulableFactory.create( OverridableImpl::new );\n    System.out.println( defaulable.notRequired() );\n}\n\n//输出结果\nDefault implementation\nOverridden implementation\n```\n由于JVM上的默认方法的实现在字节码层面提供了支持，因此效率非常高。默认方法允许在不打破现有继承体系的基础上改进接口。该特性在官方库中的应用是：给java.util.Collection接口添加新方法，如stream()、parallelStream()、forEach()和removeIf()等等。\n\n### 接口的默认方法和静态方法\n方法引用使得开发者可以直接引用**现存的方法、Java类的构造方法或者实例对象**。方法引用和Lambda表达式配合使用，使得java类的构造方法看起来紧凑而简洁，没有很多复杂的模板代码。\n通过下面的例子来讲解四种类型的方法引用的区别 ，Car类是不同方法引用的例子\n```java\npublic static class Car {\n    public static Car create( final Supplier< Car > supplier ) {\n        return supplier.get();\n    }              \n \n    public static void collide( final Car car ) {\n        System.out.println( \"Collided \" + car.toString() );\n    }\n \n    public void follow( final Car another ) {\n        System.out.println( \"Following the \" + another.toString() );\n    }\n \n    public void repair() {   \n        System.out.println( \"Repaired \" + this.toString() );\n    }\n}\n```\n第一种方法引用的类型是构造器引用，用于创建一个对象，语法是Class::new，或者更一般的形式：Class<T>::new。\n注意：这个构造器没有参数。\n\n```java\nfinal Car car = Car.create( Car::new );\n```\n\n第二种方法引用的类型是静态方法引用，语法是Class::static_method。注意：这个方法接受一个Car类型的参数。\n\n```java\ncars.forEach( Car::collide );\n```\n\n第三种方法引用的类型是某个类的成员方法的引用，语法是Class::method，注意，这个方法没有定义入参：\n```java\ncars.forEach( Car::repair );\n```\n\n第四种方法引用的类型是某个实例对象的成员方法的引用，语法是instance::method。注意：这个方法接受一个Car类型的参数：\n```java\nfinal Car police = Car.create( Car::new );\ncars.forEach( police::follow );\n```\n运行上述例子结果:\n```java\nCollided com.javacodegeeks.java8.method.references.MethodReferences$Car@7a81197d\nRepaired com.javacodegeeks.java8.method.references.MethodReferences$Car@7a81197d\nFollowing the com.javacodegeeks.java8.method.references.MethodReferences$Car@7a81197d\n```\n### 重复注解\nJava 8打破了这个限制，引入了重复注解的概念，允许在同一个地方多次使用同一个注解。\n在Java 8中使用@Repeatable注解定义重复注解，底层的技术仍然相同。可以利用下面的代码说明：\n```java\npublic class RepeatingAnnotations {\n    @Target( ElementType.TYPE )\n    @Retention( RetentionPolicy.RUNTIME )\n    public @interface Filters {\n        Filter[] value();\n    }\n \n    @Target( ElementType.TYPE )\n    @Retention( RetentionPolicy.RUNTIME )\n    @Repeatable( Filters.class )\n    public @interface Filter {\n        String value();\n    };\n \n    @Filter( \"filter1\" )\n    @Filter( \"filter2\" )\n    public interface Filterable {        \n    }\n \n    public static void main(String[] args) {\n        for( Filter filter: Filterable.class.getAnnotationsByType( Filter.class ) ) {\n            System.out.println( filter.value() );\n        }\n    }\n}\n```\n\n正如我们所见，这里的Filter类使用@Repeatable(Filters.class)注解修饰，而Filters是存放Filter注解的容器，编译器尽量对开发者屏蔽这些细节。这样，Filterable接口可以用两个Filter注解注释（这里并没有提到任何关于Filters的信息）。\n\n另外，反射API提供了一个新的方法：getAnnotationsByType()，可以返回某个类型的重复注解，例如Filterable.class.getAnnoation(Filters.class)将返回两个Filter实例，输出到控制台的内容如下所示：\n```java\nfilter1\nfilter2\n```\n\n### 更好的类型推断\nJava 8编译器在类型推断方面有很大的提升，在很多场景下编译器可以推导出某个参数的数据类型，从而使得代码更为简洁。例子代码如下：\n```java\npublic class Value< T > {\n    public static< T > T defaultValue() { \n        return null; \n    }\n \n    public T getOrDefault( T value, T defaultValue ) {\n        return ( value != null ) ? value : defaultValue;\n    }\n}\n```\n下列代码是Value<String>类型的应用：\n```java\npublic class TypeInference {\n    public static void main(String[] args) {\n        final Value< String > value = new Value<>();\n        value.getOrDefault( \"22\", Value.defaultValue() );\n    }\n```\n参数Value.defaultValue()的类型由编译器推导得出，不需要显式指明。在Java 7中这段代码会有编译错误，除非使用Value.<String>defaultValue()。\n\n### 拓宽注解的应用场景\nJava 8拓宽了注解的应用场景。现在，注解几乎可以使用在任何元素上：局部变量、接口类型、超类和接口实现类，甚至可以用在函数的异常定义上。\n```java\npublic class Annotations {\n    @Retention( RetentionPolicy.RUNTIME )\n    @Target( { ElementType.TYPE_USE, ElementType.TYPE_PARAMETER } )\n    public @interface NonEmpty {        \n    }\n \n    public static class Holder< @NonEmpty T > extends @NonEmpty Object {\n        public void method() throws @NonEmpty Exception {            \n        }\n    }\n \n    @SuppressWarnings( \"unused\" )\n    public static void main(String[] args) {\n        final Holder< String > holder = new @NonEmpty Holder< String >();        \n        @NonEmpty Collection< @NonEmpty String > strings = new ArrayList<>();        \n    }\n}\n```\nElementType.TYPE_USER和ElementType.TYPE_PARAMETER是Java 8新增的两个注解，用于描述注解的使用场景。\n\n## Java编译器的新特性\n### 参数名称\n为了在运行时获得Java程序中方法的参数名称，老一辈的Java程序员必须使用不同方法，例如Paranamer liberary。Java 8终于将这个特性规范化，在语言层面（使用反射API和Parameter.getName()方法）和字节码层面（使用新的javac编译器以及-parameters参数）提供支持。\n```java\n\npublic class ParameterNames {\n    public static void main(String[] args) throws Exception {\n        Method method = ParameterNames.class.getMethod( \"main\", String[].class );\n        for( final Parameter parameter: method.getParameters() ) {\n            System.out.println( \"Parameter: \" + parameter.getName() );\n        }\n    }\n}\n```\n在Java 8中这个特性是默认关闭的，因此如果不带-parameters参数编译上述代码并运行，则会输出如下结果：\n\n```java\nParameter: arg0\n```\n如果带-parameters参数，则会输出如下结果（正确的结果）：\n\n```java\nParameter: args\n```\n如果你使用Maven进行项目管理，则可以在maven-compiler-plugin编译器的配置项中配置-parameters参数：\n```java\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-compiler-plugin</artifactId>\n    <version>3.1</version>\n    <configuration>\n        <compilerArgument>-parameters</compilerArgument>\n        <source>1.8</source>\n        <target>1.8</target>\n    </configuration>\n</plugin>\n```\n## Java官方库的新特性\n### Optional\nOptional提供了一些有用的接口来避免显式的null检查。\n\n如果Optional实例持有一个非空值，则isPresent()方法返回true，否则返回false；Optional实例持有null，orElseGet()方法则可以接受一个lambda表达式生成的默认值；map()方法可以将现有的Opetional实例的值转换成新的值；orElse()方法与orElseGet()方法类似，但是在持有null的时候返回传入的默认值。\n```java\nOptional< String > fullName = Optional.ofNullable( null );\nSystem.out.println( \"Full Name is set? \" + fullName.isPresent() );        \nSystem.out.println( \"Full Name: \" + fullName.orElseGet( () -> \"[none]\" ) ); \nSystem.out.println( fullName.map( s -> \"Hey \" + s + \"!\" ).orElse( \"Hey Stranger!\" ) );\n```\n输出结果：\n```java\nFull Name is set? false\nFull Name: [none]\nHey Stranger!\n```\n再看下另一个简单的例子：\n```java\nOptional< String > firstName = Optional.of( \"Tom\" );\nSystem.out.println( \"First Name is set? \" + firstName.isPresent() );        \nSystem.out.println( \"First Name: \" + firstName.orElseGet( () -> \"[none]\" ) ); \nSystem.out.println( firstName.map( s -> \"Hey \" + s + \"!\" ).orElse( \"Hey Stranger!\" ) );\n```\n这个例子的输出是：\n```java\nFirst Name is set? true\nFirst Name: Tom\nHey Tom!\n```\n\n### Streams\n新增的Stream API（java.util.stream）将生成环境的函数式编程引入了Java库中。\n```java\nfinal Collection< Task > tasks = Arrays.asList(\n    new Task( Status.OPEN, 5 ),\n    new Task( Status.OPEN, 13 ),\n    new Task( Status.CLOSED, 8 ) \n);\n\nfinal long totalPointsOfOpenTasks = tasks\n    .stream()\n    .filter( task -> task.getStatus() == Status.OPEN )\n    .mapToInt( Task::getPoints )\n    .sum();\n \nSystem.out.println( \"Total points: \" + totalPointsOfOpenTasks );\n```\n首先，tasks集合被转换成steam表示；其次，在steam上的filter操作会过滤掉所有CLOSED的task；第三，mapToInt操作基于每个task实例的Task::getPoints方法将task流转换成Integer集合；最后，通过sum方法计算总和，得出最后的结果。\n\nSteam之上的操作可分为中间操作和晚期操作。\n\n>- 中间操作会返回一个新的steam——执行一个中间操作（例如filter）并不会执行实际的过滤操作，而是创建一个新的steam，并将原steam中符合条件的元素放入新创建的steam。\n>- 晚期操作（例如forEach或者sum），会遍历steam并得出结果或者附带结果；在执行晚期操作之后，steam处理线已经处理完毕，就不能使用了。在几乎所有情况下，晚期操作都是立刻对steam进行遍历。\n\nsteam的另一个价值是创造性地支持并行处理（parallel processing）。对于上述的tasks集合，我们可以用下面的代码计算所有任务的点数之和：\n```java\nfinal double totalPoints = tasks\n   .stream()\n   .parallel()\n   .map( task -> task.getPoints() ) // or map( Task::getPoints ) \n   .reduce( 0, Integer::sum );\n```\n对于一个集合，经常需要根据某些条件对其中的元素分组。利用steam提供的API可以很快完成这类任务，代码如下：\n\n```java\nfinal Map< Status, List< Task > > map = tasks\n    .stream()\n    .collect( Collectors.groupingBy( Task::getStatus ) );\n\n```\nSteam API不仅可以作用于Java集合，传统的IO操作（从文件或者网络一行一行得读取数据）可以受益于steam处理，这里有一个小例子：\n```java\nfinal Path path = new File( filename ).toPath();\ntry( Stream< String > lines = Files.lines( path, StandardCharsets.UTF_8 ) ) {\n    lines.onClose( () -> System.out.println(\"Done!\") ).forEach( System.out::println );\n}\n\n```\nStream的方法onClose 返回一个等价的有额外句柄的Stream，当Stream的close（）方法被调用的时候这个句柄会被执行。\n\n### Date/Time API(JSR 310)\nJava 8引入了新的Date-Time API(JSR 310)来改进时间、日期的处理。Java 8中新的时间和日期管理API深受Joda-Time影响，并吸收了很多Joda-Time的精华。新的java.time包包含了所有关于日期、时间、时区、Instant（跟日期类似但是精确到纳秒）、duration（持续时间）和时钟操作的类。新设计的API认真考虑了这些类的不变性（从java.util.Calendar吸取的教训），如果某个实例需要修改，则返回一个新的对象。\n\n我们接下来看看java.time包中的关键类和各自的使用例子。\n首先，Clock类使用时区来返回当前的纳秒时间和日期。Clock可以替代System.currentTimeMillis()和TimeZone.getDefault()。\n```java\nfinal Clock clock = Clock.systemUTC();\nSystem.out.println( clock.instant() );\nSystem.out.println( clock.millis() );\n\n//输出结果\n//2014-04-12T15:19:29.282Z\n//1397315969360\n```\n\n第二，关注下LocalDate和LocalTime类。LocalDate仅仅包含ISO-8601日历系统中的日期部分；LocalTime则仅仅包含该日历系统中的时间部分。这两个类的对象都可以使用Clock对象构建得到。\n```java\n// Get the local date and local time\nfinal LocalDate date = LocalDate.now();\nfinal LocalDate dateFromClock = LocalDate.now( clock );\n \nSystem.out.println( date );\nSystem.out.println( dateFromClock );\n \n// Get the local date and local time\nfinal LocalTime time = LocalTime.now();\nfinal LocalTime timeFromClock = LocalTime.now( clock );\n \nSystem.out.println( time );\nSystem.out.println( timeFromClock );\n```\n\n上述例子的输出结果如下：\n\n```java\n2014-04-12\n2014-04-12\n11:25:54.568\n15:25:54.568\n```\nLocalDateTime类包含了LocalDate和LocalTime的信息，但是不包含ISO-8601日历系统中的时区信息。\n\n```java\n// Get the local date/time\nfinal LocalDateTime datetime = LocalDateTime.now();\nfinal LocalDateTime datetimeFromClock = LocalDateTime.now( clock );\n \nSystem.out.println( datetime );\nSystem.out.println( datetimeFromClock );\n\n//输出结果\n//2014-04-12T11:37:52.309\n//2014-04-12T15:37:52.309\n```\n\n如果你需要特定时区的data/time信息，则可以使用ZoneDateTime，它保存有ISO-8601日期系统的日期和时间，而且有时区信息。下面是一些使用不同时区的例子：\n```java\n// Get the zoned date/time\nfinal ZonedDateTime zonedDatetime = ZonedDateTime.now();\nfinal ZonedDateTime zonedDatetimeFromClock = ZonedDateTime.now( clock );\nfinal ZonedDateTime zonedDatetimeFromZone = ZonedDateTime.now( ZoneId.of( \"America/Los_Angeles\" ) );\n \nSystem.out.println( zonedDatetime );\nSystem.out.println( zonedDatetimeFromClock );\nSystem.out.println( zonedDatetimeFromZone );\n```\n\n这个例子的输出结果是：\n```java\n2014-04-12T11:47:01.017-04:00[America/New_York]\n2014-04-12T15:47:01.017Z\n2014-04-12T08:47:01.017-07:00[America/Los_Angeles]\n```\n\n最后看下Duration类，它持有的时间精确到秒和纳秒。这使得我们可以很容易得计算两个日期之间的不同，例子代码如下：\n```java\n// Get duration between two dates\nfinal LocalDateTime from = LocalDateTime.of( 2014, Month.APRIL, 16, 0, 0, 0 );\nfinal LocalDateTime to = LocalDateTime.of( 2015, Month.APRIL, 16, 23, 59, 59 );\n \nfinal Duration duration = Duration.between( from, to );\nSystem.out.println( \"Duration in days: \" + duration.toDays() );\nSystem.out.println( \"Duration in hours: \" + duration.toHours() );\n```\n这个例子用于计算2014年4月16日和2015年4月16日之间的天数和小时数，输出结果如下：\n```java\nDuration in days: 365\nDuration in hours: 8783\n```\n### Nashorn JavaScript引擎\nJava 8提供了新的Nashorn JavaScript引擎，使得我们可以在JVM上开发和运行JS应用。Nashorn JavaScript引擎是javax.script.ScriptEngine的另一个实现版本，这类Script引擎遵循相同的规则，允许Java和JavaScript交互使用，例子代码如下：\n```java\nScriptEngineManager manager = new ScriptEngineManager();\nScriptEngine engine = manager.getEngineByName( \"JavaScript\" );\n \nSystem.out.println( engine.getClass().getName() );\nSystem.out.println( \"Result:\" + engine.eval( \"function f() { return 1; }; f() + 1;\" ) );\n```\n这个代码的输出结果如下：\n\n```java\njdk.nashorn.api.scripting.NashornScriptEngine\nResult: 2\n```\n### Base64\n对Base64编码的支持已经被加入到Java 8官方库中，这样不需要使用第三方库就可以进行Base64编码，例子代码如下：\n```java\nimport java.nio.charset.StandardCharsets;\nimport java.util.Base64;\n \npublic class Base64s {\n    public static void main(String[] args) {\n        final String text = \"Base64 finally in Java 8!\";\n \n        final String encoded = Base64\n            .getEncoder()\n            .encodeToString( text.getBytes( StandardCharsets.UTF_8 ) );\n        System.out.println( encoded );\n \n        final String decoded = new String( \n            Base64.getDecoder().decode( encoded ),\n            StandardCharsets.UTF_8 );\n        System.out.println( decoded );\n    }\n}\n```\n这个例子的输出结果如下：\n\n```java\nQmFzZTY0IGZpbmFsbHkgaW4gSmF2YSA4IQ==\nBase64 finally in Java 8!\n```\n\n新的Base64API也支持URL和MINE的编码解码。\n(Base64.getUrlEncoder() / Base64.getUrlDecoder(), Base64.getMimeEncoder() / Base64.getMimeDecoder())。\n\n### 并行数组\nJava8版本新增了很多新的方法，用于支持并行数组处理。最重要的方法是parallelSort()，可以显著加快多核机器上的数组排序。\n```java\nimport java.util.Arrays;\nimport java.util.concurrent.ThreadLocalRandom;\n \npublic class ParallelArrays {\n    public static void main( String[] args ) {\n        long[] arrayOfLong = new long [ 20000 ];        \n \n        Arrays.parallelSetAll( arrayOfLong, \n            index -> ThreadLocalRandom.current().nextInt( 1000000 ) );\n        Arrays.stream( arrayOfLong ).limit( 10 ).forEach( \n            i -> System.out.print( i + \" \" ) );\n        System.out.println();\n \n        Arrays.parallelSort( arrayOfLong );        \n        Arrays.stream( arrayOfLong ).limit( 10 ).forEach( \n            i -> System.out.print( i + \" \" ) );\n        System.out.println();\n    }\n}\n```\n上述这些代码使用parallelSetAll()方法生成20000个随机数，然后使用parallelSort()方法进行排序。这个程序会输出乱序数组和排序数组的前10个元素。上述例子的代码输出的结果是：\n```java\nUnsorted: 591217 891976 443951 424479 766825 351964 242997 642839 119108 552378 \nSorted: 39 220 263 268 325 607 655 678 723 793\n```\n### 并发性\n基于新增的lambda表达式和steam特性，为Java 8中的java.util.concurrent.ConcurrentHashMap类添加了新的方法来支持聚焦操作；另外，也为java.util.concurrentForkJoinPool类添加了新的方法来支持通用线程池操作。\n\nJava 8还添加了新的java.util.concurrent.locks.StampedLock类，用于支持基于容量的锁——该锁有三个模型用于支持读写操作（可以把这个锁当做是java.util.concurrent.locks.ReadWriteLock的替代者）。\n\n在java.util.concurrent.atomic包中也新增了不少工具类，列举如下：\nDoubleAccumulator、DoubleAdder、LongAccumulator、LongAdder\n\n## 新的Java工具\n### Nashorn引擎：jjs\njjs是一个基于标准Nashorn引擎的命令行工具，可以接受js源码并执行。例如，我们写一个func.js文件，内容如下：\n```java\nfunction f() { \n     return 1; \n}; \n \nprint( f() + 1 );\n```\n可以在命令行中执行这个命令：**jjs func.js**。\n\n### 类依赖分析器：jdeps\njdeps是一个相当棒的命令行工具，它可以展示包层级和类层级的Java类依赖关系，它以**.class文件、目录或者Jar文件**为输入，然后会把依赖关系输出到控制台。\n\n我们可以利用jedps分析下Spring Framework库，为了让结果少一点，仅仅分析一个JAR文件：org.springframework.core-3.0.5.RELEASE.jar。\n```java\njdeps org.springframework.core-3.0.5.RELEASE.jar\n```\n这个命令会输出很多结果，我们仅看下其中的一部分：依赖关系按照包分组，如果在classpath上找不到依赖，则显示\"not found\"。\n```java\norg.springframework.core-3.0.5.RELEASE.jar -> C:\\Program Files\\Java\\jdk1.8.0\\jre\\lib\\rt.jar\n   org.springframework.core (org.springframework.core-3.0.5.RELEASE.jar)\n      -> java.io                                            \n      -> java.lang                                          \n      -> java.lang.annotation                               \n      -> java.lang.ref                                      \n      -> java.lang.reflect                                  \n      -> java.util                                          \n      -> java.util.concurrent                               \n      -> org.apache.commons.logging                         not found\n      -> org.springframework.asm                            not found\n      -> org.springframework.asm.commons                    not found\n   org.springframework.core.annotation (org.springframework.core-3.0.5.RELEASE.jar)\n      -> java.lang                                          \n      -> java.lang.annotation                               \n      -> java.lang.reflect                                  \n      -> java.util\n```\n\n### JVM的新特性\n使用Metaspace（JEP 122）代替持久代（PermGen space）。在JVM参数方面，使用-XX:MetaSpaceSize和-XX:MaxMetaspaceSize代替原来的-XX:PermSize和-XX:MaxPermSize。\n\n### 参考资料\n- [Java 8的新特性—终极版](https://blog.csdn.net/yczz/article/details/50896975)\n\n\n\n","tags":["Java"],"categories":["Java"]},{"title":"TCP长链接及短链接","url":"/2019/04/11/TCP长链接及短链接/","content":"\nTCP/IP是个协议组，可分为三个层次：网络层、传输层和应用层。\n\n在网络层有IP协议、ICMP协议、ARP协议、RARP协议\n在传输层有TCP协议与UDP协议\n在应用层有FTP、HTTP、TELNET、SMTP、DNS等协议\n\n\n### 长连接\n\n在一个TCP连接上可以连续发送多个数据包，在TCP连接保持期间，如果没有数据包发送，需要双上检测包以维持此连接，一般需要自己做在线维持。\n\n大致过程为：\n连接→数据传输→保持连接(心跳)→数据传输→保持连接(心跳)→……→关闭连接； \n\n### 短连接\n通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接。比如http的，只是连接、请求、关闭，过程时间较短,服务器若是一段时间内没有收到请求即可关闭连接。\n大致过程为：\n连接→数据传输→关闭连接；\n\n\n###　什么时候用长连接，短连接\n长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。对于频繁请求资源的客户来说，较适用长连接。但长连接存在两个问题：１、存活功能周期太长；２、只单纯探测TCP连接的存活。在长连接的应用场景下，client端一般不会主动关闭他们之间的连接，client与server的连接如果一直不关闭，会导致客户端的连接越来越多。措施：1、可以关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致server端服务受损；2、另外可以限制每个客户端的最大长连接数。\n\n短连接对于服务器来说管理较为简单，存在的连接都是有用的连接，不需要额外的控制手段。但如果客户请求频繁，将在TCP的建立和关闭操作上浪费时间和带宽。 \n\n\n长连接适用于请求频繁、点对点的通讯，而且连接数不能太多情况。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。\n\n而像WEB网站的http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连接好。\n\n","tags":["网络协议"],"categories":["网络协议"]},{"title":"TCP协议详解","url":"/2019/04/11/TCP协议详解/","content":"\n### 简介\nTCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。TCP层是位于IP层之上，应用层之下的中间层。不同主机的应用层之间经常需要可靠的、像管道一样的连接，但是IP层不提供这样的流机制，而是提供不可靠的包交换。应用层向TCP层发送用于网间传输的、用8位字节表示的数据流，然后TCP把数据流分区成适当长度的报文段。之后TCP把结果包传给IP层，由它来通过网络将包传送给接收端实体的TCP层。\n\nTCP的特征：序列化+确认应答、超时重发、流量控制、拥塞控制等等。\n\nTCP/IP 中有两个具有代表性的传输层协议，分别是TCP、UDP。TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。\n\n### 特点\nTCP位于传输层，提供可靠的字节流服务（Byte Stream Service）。\n\n1. 字节流服务：为了方便传输，将大块数据分割以报文段（segment）为单位的数据包进行管理。应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。 \n\n- 当数据块太长时，TCP中的缓存可以将应用程序发来的数据块划分成若干个短部分再传送。\n- 当数据块太短时，例如应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。\n\n2. 可靠的传输服务：能够把数据准确可靠地传给对方。\n\n### 优缺点\n\n1. 优点：\n\n- 可靠、稳定性 \n- 传递数据前，会有三次握手建立连接 ；\n- 传递数据时，有确认、窗口、重传、拥塞控制；\n- 传递数据后，会断开连接节省系统资源；\n\n2. 缺点：\n\n- 传输慢，效率低，占用系统资源高： \n              传递数据前，建立连接需要耗时\n              传递数据时，确认、重传、拥塞等会消耗大量时间以及CPU和内存等硬件资源\n\n- 易被攻击 ：因为有确认机制，三次握手等机制，容易被人利用，实现DOS 、DDOS攻击\n\nTCP协议为了更容易传送大数据才把数据分割，而且TCP协议能够确认数据最终是否送达到对方。为了通过IP数据报实现可靠传输，需要考虑很多事情，例如数据破坏、丢包、重复以及分片顺序混乱等问题。\n\nTCP通过检验和、序列号、确认应答、重发控制、连接管理及窗口等机制实现可靠传输。\n\n### 可靠传输（序列号+确认应答）\n#### 确认应答ACK（Positive Acknowledgment）\n在TCP中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。此消息叫做确认应答ACK。\n![](ACK1.png)\nTCP通过肯定的确认回答（ACK）实现可靠的数据传输。当发送端将数据发出后等待对方的确认应答，若有应答则表示对方已成功接收。反之则数据丢失可能性大。\n![](ACK2.png)\n在一定时间内没有等待确认应答，发送端就可以认为数据已丢失，进行重发。因此即使丢包，仍然可以保证数据传输到对方。（注意：未收到应答不一定是数据丢失，可能是确认应答在途中丢失）\n\n#### 序列号\n此外，也有可能是其它原因导致发送端未收到确认应答，主机只需按照机制重发数据即可，但对于目标主机而言，它会收到相同的数据包，为此引入一种机制，能够识别是否已经接受数据和判断是否需要接收。\n\n上述这些确认应答处理、重发控制以及重复控制等功能都可以通过序列号实现。序列号是按顺序给发送数据的每一个字节（8位字节）都标上编号。**接收端查询接收数据TCP首部中的序列号和数据长度，将下一步应接收的序号作为确认应答返送回去**。\n![](序列号.png)\n\n综上，通过序列号和确认应答，TCP可以实现可靠传输。\n\n### 重发超时\n重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔，如果超过这个时间仍未收到确认应答，发送端将进行数据重发。TCP要保证所有的数据包都可以到达，所以，必需要有重传机制。\n\n> - 接收端给发送端的Ack确认只会确认最后一个连续的包\n\n发送端发了1,2,3,4,5一共五份数据，接收端收到了1，2，于是回ack 3，然后收到了4（注意此时3没收到），此时的TCP会怎么办？\n1. 超时重传机制\n\n发送端继续等待3，即使收到了4，也不会回复ack。当发送方发现收不到3的ack超时后，会重传3。一旦接收方收到3后，会ack 4，意味着3和4都收到了。此机制下有两种应对方法：\n\n- 仅重传timeout的包。也就是第3份数据。\n- 重传timeout后所有的数据，也就是第3，4，5这三份数据\n第一种会节省带宽，但是慢，第二种会快一点，但是会浪费带宽。但其实这两种方法都不太好，都需要等待timeout（timeout可能会很长）。\n2. 快速重传（Fast Retransmit ）机制\n\nTCP引入了一种叫Fast Retransmit 的算法，不以时间驱动，而以数据驱动重传。如果数据包没有连续到达，就ack最后那个可能被丢了的包，如果发送端连续收到3次相同的ack就重传。其好处是发送端不需要一直等待，直到timeout后再重传。\n![](快速重传.png)\n\n如上图，再举个例子，如果发送方发出了1，2，3，4，5份数据，第一份先到送了，于是就ack回2，结果2因为某些原因没收到，3到达了，于是还是ack回2，后面的4和5都到了，但是还是ack回2，因为2还是没有收到，于是发送端收到了三个ack=2的确认，知道了2还没有到，于是就马上重转2。然后，接收端收到了2，此时因为3，4，5都收到了，于是ack回6。\n\n虽然快速重传机制解决了timeout的问题，还遗留了之前提出的一个问题：是重传之前的一个还是重传所有数据包？对于上面的示例来说，是重传#2呢还是重传#2，#3，#4，#5呢？因为发送端并不清楚这连续的3个ack(2)是谁传回来的？也许发送端发了20份数据，是#6，#10，#20传来的。\n\n因此，快速重传机制仍然是有缺点的！\n\n3. SACK 方法\nSelective Acknowledgment (SACK)方法：需要在TCP头里加一个SACK的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版。参考下图：\n![](SACK.png)\n此方法是基于Fast Retransmit的算法上的优化，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到。\n\n但是！SACK会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。\n\n4. Duplicate SACK – 重复收到数据的问题\n主要使用了SACK来告诉发送方有哪些数据被重复接收了，D-SACK使用了SACK的第一个段来做标志：\n\n- 如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK\n- 如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK\n\nD-SACK方法的好处：\n\n- 可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。\n- 是不是自己的timeout太小了，导致重传。\n- 网络上出现了先发的包后到的情况（又称reordering）\n- 网络上是不是把我的数据包给复制了\n\n### 连接管理\n为了准确无误地将数据送达目标处，TCP协议采用了三次握手（three-way handshaking）策略。用TCP协议将数据包送出去后，TCP一定会向对方确认是否成功送达。若在握手过程中某个阶段莫名中断，TCP协议会再次以相同的顺序发送相同的顺序包。\n\n1. 三次握手过程\n\n定义：三次握手，是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。\n\n目的：是连接服务器指定端口，建立TCP连接,并同步连接双方的序列号和确认号并交换 TCP 窗口大小信息\n\n在socket编程中，客户端执行connect()时，将触发三次握手。\n\n![](三次握手.png)\n- 第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；\n\n- 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；\n\n- 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。\n完成三次握手，客户端与服务器开始传送数据。\n\n2. 四次挥手\n所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示：\n![](四次挥手.png)\n由于TCP连接时全双工的，因此每个方向都必须要单独进行关闭。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。\n\n当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。\n\n- 第一次挥手：主动关闭方发送一个FIN并进入FIN_WAIT1状态\n\n- 第二次挥手：被动关闭方接收到主动关闭方发送的FIN并发送ACK，此时被动关闭方进入CLOSE_WAIT状态；主动关闭方收到被动关闭方的ACK后，进入FIN_WAIT2状态\n\n- 第三次挥手：被动关闭方发送一个FIN并进入LAST_ACK状态\n\n- 第四次挥手：主动关闭方收到被动关闭方发送的FIN并发送ACK，此时主动关闭方进入TIME_WAIT状态，经过2MSL时间后关闭连接；被动关闭方收到主动关闭方的ACK后，关闭连接\n\n> - MSL是Maximum Segment Lifetime，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。\n\n#### 为什么建立连接是三次握手，而关闭连接却是四次挥手呢\n- 对于3次握手：主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。也就上图中的 x 和 y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。\n\n- 对于4次挥手：其实你仔细看是2次，因为TCP是全双工的，所以，发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。\n\n服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。\n\n而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。\n\n\n### 流控制（Flow Control）\n#### 滑动窗口协议\n1. 特征定义\n\n- TCP协议中使用\n- 维持发送方/接收方缓存区\n此缓存区主要用于解决网络传输的不可靠问题\n\n2. 提出问题\n\n如果没有滑动窗口协议，如何保证接收方能够收到正确有序的包？\n![](窗口协议.png)\n如上图所示，发送方发送包1，接收方确认包1，发送包2，确认包2，这样即可解决不可靠性问题。但同时此过程的问题十分明显：吞吐量低，必须要等接收方确认完后才能发送下一个包。试考虑，若能连发几个包，接收方可以同时确认，这样效率岂不更高？\n\n3. 简单改进\n\n在此问题上，出现了以下改进：发送方可以同时发多个包，接收方一起确认。\n![](窗口协议改进.png)\n\n4. 滑动窗口实现\n由此又衍生出一个问题，同时发包的数量多少才会是最优方案呢？例如发送方同时发送包1、2，在获得接收方确认包1消息后，能否不等包2确认信息，直接发送包3呢？\n\n这样很自然地思考到了“滑动窗口实现”。以下有16个数据包，发送方希望按照顺序发送，在接收方收到每个包后都逐一给予确认：\n![](滑动窗口实现.png)\n- 初始：（窗口为4到7） \n> - 1、2、3包已发送并且获取发送方Ack确认；\n> - 4、5、6、7包已发送但尚未获取发送方Ack确认；\n> - 8、9、10包待发送；\n> - 而11、12、13、14、15、16包未发送甚至都没有装入内存；\n\n- 正常：（窗口为5到9） \n> - 1、2、3、4包已发送并且获取发送方Ack确认；\n> - 5、6、7、8、9包已发送但尚未获取发送方Ack确认；\n> - 10、11包待发送；\n> - 而12、13、14、15、16包未发送甚至都没有装入内存；\n![](窗口滑动丢ACK.png)\n- 丢Ack：（窗口为5到11） \n> - 5、6、7、8、9包未收到Ack（丢Ack），在等待过程又发送了10、11包，此时窗口已满，无法读进包12，只能等待Ack。如果真的是丢包，始终无法收到Ack，此时超时重传机制会从包5开始重新发送。（注意，这里的Ack是按照顺序发送的！）\n\n- 重发： （窗口为9到15） \n> - 5、6、7、8包获取发送方Ack确认；\n> - 9、10、11、12、13包已发送但尚未获取发送方Ack确认；\n> - 13、14包待发送；\n> - 而16包未发送甚至都没有装入内存；\n\n\n为了增加线路的吞吐量，改进原版方案，令发送方同时发送包；为了衡量同时发送的数量达到吞吐量最优解，从而引进滑动窗口机制；为了解决丢包等不可靠性问题导致发送方无法收到接收方的Ack，又引进了重发机制。\n\n\n#### 解释流控制\n1. 出现的问题\n\n发送端根据自己的实际情况发送数据，但是接收端在处理别的事（可能正处于高负荷的状态无法接收任何数据），而且此数据包并无重要意义，这样导致此包丢失又会触发重发机制，令网络流量无端浪费。\n\n2. 解决方法\n\n为了防止此现象发生，TCP提供一种机制可以让发送端根据接收端的实际接收能力控制发送的数据量。这就是“控制流”。\n\n3. 具体操作\n\n接收端想发送端通知自己可以接收数据的大小，发送端发送时不会超过这个限度的数据，该大小限制被称为窗口大小。\n\nTCP首部中专门有一个字段用来通知窗口大小。接收端将自己可接收的缓冲区大小放入字段中并通知发送端。此值越大代表网络的吞吐量越高。\n\n当缓存区一旦面临数据溢出时，窗口大小的值也会随之被设置成一个更小的值发送给发送端，从而控制数据发送量。也就是说，发送端会根据接收端的指示，对发送数据量进行控制。这就形成了一个完整的TCP流控制。\n\n查看下图示例：\n![](窗口探测.png)\n如上图所示，当接收端收到从3001号开始的数据段后，缓冲区已满，需要暂时停止接收数据。之后在收到发送窗口更新通知后通信才得以继续进行。如果此窗口更新通知在传送途中丢失，可能导致无法继续通信。为避免此类问题产生，发送端主机会时不时发送一个叫做“窗口探测”的数据段，此数据段仅含一个字节以获取最新的窗口大小信息。\n\n#### Zero Window\n发送端可以发送数据动态修改“滑动窗口”的大小，注意其值是可以为0的！那这样是否意味着发送端就不发数据了？确实如此，接收端都已经表示自己无力接收了，因此不会再发，类似于“Window Closed”。\n\n解决这个问题，TCP使用了Zero Window Probe技术，缩写为ZWP。即发送端在窗口变成0后，会发ZWP的包给接收端，让接收端来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。\n\n注意：只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。\n\n\n### 拥塞控制（Congestion Control）\n\n有了TCP的窗口控制，收发端之间不再以一个数据段为单位发送确认应答，也能够连续发送大量数据包。但是刚开始通信就发送大量数据会引发其它问题。计算机网络处于一个共享的环境，因此有可能因为其他主机之间的通信使得网络拥堵，此时突然发送一个大量数据，可能导致整个网络瘫痪。\n\n拥塞控制主要是四个算法：\n\n- 慢启动\n- 拥塞避免\n- 拥塞发生\n- 快速恢复\n\n#### 慢启动（Slow Start）\n首先，为了在发送端调节待发送的数据量，定义了“拥塞窗口”的概念，在慢启动时将其设为1个数据段（IMSS）发送数据，之后每收到一次确认应答（ACK），拥塞窗口的值就加1。在发送数据段时，将拥塞窗口的大小与接收端通知的窗口大小做比较，以较小值为标准，发送比其还要小的数据量。\n\n根据以上机制，可有效减少通信开始时连续发包导致的网络拥堵，还可以避免网络拥塞的情况。\n慢启动的算法如下：(cwnd全称Congestion Window)\n\n- 连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。\n- 每当收到一个ACK，cwnd++; 呈线性上升\n- 每当过了一个RTT，cwnd = cwnd`*`2; 呈指数让升\n- 还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”\n\n所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。\n\n#### 拥塞避免算法（Congestion Avoidance）\n前面慢启动的算法第四步中的ssthresh（slow start threshold）是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：\n\n- 收到一个ACK时，cwnd = cwnd + 1/cwnd\n- 当每过一个RTT时，cwnd = cwnd + 1\n\n这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。\n\n#### 拥塞状态时的算法\n在讲解超时重传机制中提到TCP面临丢包时，有以下两个问题：\n\na)等到RTO 超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈：\n\n> sshthresh =  cwnd /2\n> cwnd 重置为 1\n> 进入慢启动过程\n\nb) Fast Retransmit算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时，TCP Tahoe的实现和RTO超时一样。TCP Reno的实现是：\n\n> cwnd = cwnd /2\n> sshthresh = cwnd\n> 进入快速恢复算法——Fast Recovery\n\n上面我们可以看到RTO超时后，sshthresh会变成cwnd的一半，这意味着，如果cwnd<=sshthresh时出现的丢包，那么TCP的sshthresh就会减了一半，然后等cwnd又很快地以指数级增涨爬到这个地方时，就会成慢慢的线性增涨。我们可以看到，TCP是怎么通过这种强烈地震荡快速而小心得找到网站流量的平衡点的。\n\n\n#### 快速恢复算法（Fast Recovery）\n快速重传和快速恢复算法一般同时使用。快速恢复算法是认为，你还有3个Duplicated Acks说明网络也不那么糟糕，所以没有必要像RTO超时那么强烈。 注意，正如前面所说，进入Fast Recovery之前，cwnd 和 sshthresh已被更新：\n> cwnd = cwnd /2\n> sshthresh = cwnd\n\n真正的Fast Recovery算法如下：\n\n- cwnd = sshthresh + 3 * MSS （3的意思是确认有3个数据包被收到了）\n- 重传Duplicated ACKs指定的数据包\n- 如果再收到 duplicated Acks，那么cwnd = cwnd +1\n- 如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。\n\n仔细思考一下你会发现上面这个算法也有问题：它依赖于3个重复的Acks。\n\n注意：3个重复的Acks并不代表只丢了一个数据包，很有可能不止一个。但此算法只会重传一个，而剩下的那些包只能等到RTO超时，从而导致一种可怕的现象：超时一个窗口就减半一下，多个超时会超成TCP的传输速度呈级数下降，而且也不会触发Fast Recovery算法了。\n\n\n### TCP和UDP的区别\n#### UDP（User Datagram Protocol）\n用户数据包协议，UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。即使是出现网络拥堵的情况下，UDP也无法进行流量控制等避免网络拥塞的行为，同样出现丢包情况，UDP也不负责重发，也没有当包的到达顺序混乱纠正功能。如果需要这些细节控制，只能交由UDP的应用程序去处理。（UDP有点类似于用户说啥就听啥的机制）。\n\n面向报文传输，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。\n\n- 若报文太长，则IP层需要分片，降低效率。\n- 若报文太短，浪费资源。\nUDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。即应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。\n\n因此它有以下特点：\n\n- 传输数据之前源端和终端不建立连接，当它想传送时就简单地去抓取来自应用程序的数据，并尽可能快的把它扔到网络上\n- 由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息\n- 在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制\n- 在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段\n- UDP信息包的标题很短，只有8个字节，相对于TCP的20个字节信息包的额外开销很小\n- 吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制\n- UDP是面向报文的。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小。\n\n优点\n\n- 传输速率快：传输数据前，不需要像TCP一样建立连接；传输数据时，没有确认、窗口、重传、拥塞控制等机制。\n- 较安全：由于没有了TCP的一些机制，被攻击者利用的漏洞就少了\n缺点\n\n- 不可靠，不稳定：由于没有了TCP的机制，在数据传输时如果网络不好，很可能丢包\n\n#### 区别\nTCP\t                  UDP\n\n面向字节流\t          面向报文\n\n一对一\t              可以一对一，一对多\n\n面向有链接的通信服务\t  面向无连接的通信服务\n\n速度快\t              速度慢\n\n提供可靠的通信传输\t  不可靠,会丢包\n\n保证数据包顺序\t      不保证\n\n有流量控制，拥塞控制\t  没有\n\n数据无边界\t          数据有边界\n\n报头至少20字节\t      报头8字节\n\n\n### 常见问题\n1. 为什么UDP比TCP快\n\n因为TCP中连接需要三次握手，断开连接需要四次握手，传输过程中还有拥塞控制，控制流量等机制。\n\n2. 为什么TCP比UDP可靠\n\nTCP是面向有连接的，建立连接之后才发送数据；而UDP则不管对方存不存在都会发送数据。\nTCP有确认机制，接收端每收到一个正确包都会回应给发送端。超时或者数据包不完整的话发送端会重传。UDP没有。因此可能丢包。\n\n3. 什么时候使用TCP\n\n当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。\n\n例如日常生活中使用TCP协议的应用如下： 浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输\n\n4. 什么时候应该使用UDP\n\n当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。\n\n比如日常生活中使用UDP协议的应用如下： QQ语音 QQ视频 TFTP\n\n5. TCP无边界，UDP有边界\n\nTCP无边界：客户端分多次发送数据给服务器，若服务器的缓冲区够大，那么服务器端会在客户端发送完之后一次性接收过来，所以是无边界的。\n\nUDP有边界：客户端每发送一次，服务器端就会接收一次，也就是说发送多少次就会接收多少次，因此是有边界的。\n\n6. 如果tcp建立连接时第三次握手失败，tcp会做何操作？\n当客户端收到服务端的SYN+ACK应答后，其状态变为ESTABLISHED，并会发送ACK包给服务端，准备发送数据了。如果此时ACK在网络中丢失，过了超时计时器后，那么Server端会重新发送SYN+ACK包，重传次数根据/proc/sys/net/ipv4/tcp_synack_retries来指定，默认是5次。如果重传指定次数到了后，仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。但是Client认为这个连接已经建立，如果Client端向Server写数据，Server端将以RST包响应，方能感知到Server的错误。\n\n当失败时服务器并不会重传ack报文，而是直接发送RTS报文段，进入CLOSED状态。这样做的目的是为了防止SYN洪泛攻击，即坏人伪造许多IP向server发送连接请求，从而将server的未连接队列塞满，浪费server的资源。\n\n7. 为什么需要第三次握手？ \n如果在client与server建立连接的过程中，由于网络不顺畅等原因造成的通信链路中存在着残留数据包。\n如果只有两次握手，那么server收到了client的SYN=1的请求连接数据包之后，便会分配资源并且向client发送一个确认位ACK回复数据包。\n当client与server建立连接，数据发送完毕并且关闭TCP连接之后，如果链路中的残留数据包才到达server，那么server就会认为client重新发送了一次连接申请，便会回复ACK包并且分配资源。并且一直等待client发送数据，这就会造成server的资源浪费。\n\n8. 三次握手有什么缺陷可以被黑客利用，用来对服务器进行攻击？ \n黑客仿造IP大量的向server发送TCP连接请求报文包，从而将server的半连接队列（上文所说的未连接队列，即server收到连接请求SYN之后将client加入半连接队列中）占满，从而使得server拒绝其他正常的连接请求。即拒绝服务攻击\n\n9. 怎么防范这种攻击？\n1、缩短服务器接收客户端SYN报文之后的等待连接时间，即SYN timeout时间，也就是server接收到SYN报文段，到最后放弃此连接请求的超时时间，将SYN timeout设置的更低，便可以成倍的减少server的负荷，但是过低的SYN timeout可能会影响正常的TCP连接的建立，一旦网络不通畅便可能导致client连接请求失败\n\n2、SYN cookie + SYN proxy 无缝集成（较好的解决方案）\n\n- SYN cookie：当server接收到client的SYN之后，不立即分配资源，而是根据client发送过来的SYN包计算出一个cookie值，这个cookie值用来存储server返回给client的SYN+ACK数据包中的初始序列号，当client返回第三次握手的ACK包之后进行校验，如果校验成功则server分配资源，建立连接。\n\n- SYN proxy代理，作为server与client连接的代理，代替server与client建立三次握手的连接，同时SYN proxy与client建立好了三次握手连接之后，确保是正常的TCP连接，而不是TCP泛洪攻击，那么SYN proxy就与server建立三次握手连接，作为代理（网关？）来连通client与server\n\n10. 为什么要四次挥手 \n前两次挥手是为了断开client至server的连接，后两次挥手是为了断开server至client的连接，如果没有第四次挥手，会出现如下状况：\n\n- server发送FIN数据包并携带ACK至client之后直接断开连接，如果client没有收到这个FIN数据包，那么client会一直处于等待关闭状态，这是为了确保TCP协议是面向连接安全有保证锝。\n- 上面解释了为什么不是三次挥手，同理，两次挥手也是不安全的。不能保证server与client都能正确关闭连接释放资源，而不会造成资源浪费。\n\n11. 四次挥手之后client为什么还要等待2MSL的时间才释放资源关闭连接？ \n- 如果client第四次挥手的确认报文段没有被server接收，那么server便会重发第三次挥手的FIN报文段，因此client要停留2MSL的时长来处理可能会重复收到的报文段。\n\n- 让之前建立的client-server通信过程中或者是挥手过程中由于网络不通畅产生的滞留报文段失效。如果不等待2MSL，那么建立新连接之后，可能会收到上一次连接的旧报文段，可能会造成混乱。\n\n12. 在浏览器输入一个URL按下回车后，其流程是？\n（1）进行寻址：若浏览器缓存中存有URL的对应IP，则直接查询IP；否则访问DNS（Domain Name System）进行寻址（Domain Name Resolution）。\n\n（2） DNS或者URL Cache返回网页服务器的IP地址。\n\n（3）浏览器与网页服务器进行三次握手建立TCP连接。由于是网页浏览服务，故连接到服务器的80端口。\n\n（4）浏览器与服务器建立HTTP会话（Session），接收来自服务器的HTTP数据。\n\n（5）浏览器解析HTTP数据，在本地窗口内渲染并显示网页。\n\n（6）当浏览器页面被关闭时，终止HTTP会话并关闭连接。\n\n13. 设计一个可靠的UDP，如何做？ \n“可靠”是指接收端能够将收到的数据情况反馈给发送端。因此完全可以参照可靠的传输协议—–TCP，引入ACK、Flow Cotrol、Congestion Control等模块。可靠的UDP核心在于反馈机制，以下是几种实现方式。\n（1）最朴素的ACK发送：发送端没发送一个数据包，都需要接收端返回ACK，一旦超时，发送端重新发送数据包，直到该数据包被接收端ACK。该方法效率不高，因为之后的所以数据包都有可能被当前数据包block，并且每次返回ACK增加了overHead。\n\n（2）Block/bit map ACK：\n\n发送端发送一批数据包，例如32个，编号是0`~`31.接收端发回的ACK中用32bit（4byte）的bit map表示收到哪些数据包，发送端再一次性重发所有未被收到的数据包。该方法能够更加充分地利用带宽，在发送端一次性传输更多数据，但缺点是发送、接收端需要更深的buffer来暂存传输的所有数据。\n\n（3）ACK last packet\n\n发送端可以在发送最后一个数据包时要求接收端反馈ACK，并重发丢失的数据包。好处是可以减少由ACK造成的 data overhead，但需要buffer暂存数据。\n\n最佳方法：\n\n事实上，可以结合方法2、3，在每一批数据包的最后一个置位request ACK flag，要求接收端返回bit map ACK。更进一步，可以根据丢包率及延迟，估计网络状态，动态调整bit map大小：网络状态好时，用更大的bit map，即同时发送更多数据。否则减少发送数据量。这种对网络状况的自适应相当于实现了Congestion Control。\n\n14. 实时视频会议应用应选择UDP还是TCP？\nTCP的重传机制特点，会增加延迟，所以不适合此场景。其次视频音频编码本身可以容忍数据出错甚至数据丢失，因此并不需要TCP进行可靠传输。当某一视频帧出现丢包，可以直接跳过。一旦出现网络堵塞情况，发送端应主动丢弃一部分数据，因为即使被发送到接收端也都“过期”了，不会被解码显示。\n\n不过即使采用UDP，也需要实现TCP某些模块，例如Flow Control、Congestion Control 来判断接收端的播放情况和网络情况，也需要反馈机制来判断接收端的接收状况。尽管当前场景不需要ACK每个数据包，但接收端可以反馈当前收到最新完整视频帧的序号，这样即使丢包，发送端可以接收端收到最新视频帧为基础，压缩后继的视频。\n\n15. 网络中常见的ping 命令是什么协议?\n“ping”命令来测试两台主机之间TCP/IP通信是否正常，其实“ping”命令的原理就是向对方主机发送UDP数据包，然后对方主机确认收到数据包，如果数据包是否到达的消息及时反馈回来，那么网络就是通的。\n\n ping.exe的原理是向指定的IP地址发送一定长度的数据包，若指定IP地址存在会返回同样大小的数据包，若在特定时间内没有返回，就是“超时”，即指定IP地址不存在。由于ping使用的ICMP协议，有些防火墙软件会平米ICMP协议，所以ping结果只能作为参考，ping不通不一定代表对方IP不存在。\n\nICMP协议: ICMP是“Internet Control Message Protocol”（Internet控制消息协议）的缩写。它是 \nTCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。\n\n16. 如何编写Socket套接字？\n如果你要编写的是一个服务程序，那么先调用socket()创建一个套接字，调用bind()绑定IP地址和端口，然后启动一个死循环，循环中调用accept()接受连接。对于每个接受的连接，可以启动多线程方式进行处理，在线程中调用send()、recv()发送和接收数据。\n如果你要编写的是一个客户端程序，那么就简单多了。先调用socket()创建一个套接字，然后调用connect()连接服务器，之后就是调用send()、recv()发送和接收数据了。\n\n服务器端程序编写：\n\n- 调用 ServerSocket(int port) 创建一个服务器端套接字，并绑定到指定端口上。\n- 调用 accept()，监听连接请求，则接收连接，返回通信套接字。\n- 调用Socket类的 getOutStream() 和 getInputStream()获取输出流和输入流，开始网络数据的发送和接收。\n- 关闭通信套接字 Socket.close()。\n\n客户端程序编写：\n\n- 调用 Socket() 创建一个流套接字，并连接到服务器端。\n- 调用Socket类的 getOutputStream()和 getInputStream()获取输出流和输入流，开始网络数据的发送和接收。\n- 关闭通信套接字 Socket.close()。\n\n17. 端口概念\n在网络技术中，端口（Port）大致有两种意思：\n\n一是物理意义上的端口，比如，ADSL MODEM、集线器、交换机、路由器用于连接其他网络设备的接口；\n二是逻辑意义上的端口，一般是指TCP/IP协议中的端口，端口号的范围为0～65535，比如用于浏览网页服务的80端口，用于FTP服务的21端口。\n\n下面将介绍两种常见的逻辑分类：\n\n（1）按端口号分布划分\n\n- 知名端口（Well-Known Ports）：即众所周知的端口号，范围为0～1023，这些端口号一般固定分配给一些服务。\n比如21端口分配给FTP服务，25端口分配给SMTP（简单邮件传输协议）服务，80端口分配给HTTP服务。\n\n- 动态端口（Dynamic Ports）：范围为1024～65535，这些端口号一般不固定分配给某个服务，也就是说许多服务都可以使用这些端口。只要运行的程序向系统提出访问网络的申请，那么系统就可以从这些端口号中分配一个供该程序使用。比如1024端口就是 \n分配给第一个向系统发出申请的程序。在关闭程序进程后，就会释放所占用的端口号。\n（2）按协议类型划分\n\n按协议类型划分，可以分为TCP、UDP、IP和ICMP（Internet控制消息协议）等端口。下面主要介绍TCP和UDP端口：\n\n- TCP端口：即传输控制协议端口，需要在客户端和服务器之间建立连接，这样可以提供可靠的数据传输。常见的包括FTP服务的21端口，Telnet服务的23端口，SMTP服务的25端口，以及HTTP服务的80端口等等。\n\n- UDP端口：即用户数据包协议端口，无须在客户端和服务器之间建立连接，安全性得不到保障。常见的有DNS服务的53端口，SNMP（简单网络管理协议）服务的161端口，QQ使用的8000和4000端口等等。\n\n\n### 参考资料\n- [TCP三次握手四次挥手总结（流程、常见问题、会发生的攻击、防范方法）](https://blog.csdn.net/scuzoutao/article/details/81774100)\n- [TCP的三次握手与四次挥手理解](https://blog.csdn.net/qq_38950316/article/details/81087809)\n- [深入浅出之 TCP协议（三次握手与四次挥手、超时重发、流量控制、拥塞控制、与UDP区别）](https://blog.csdn.net/ITermeng/article/details/77973279?locationNum=7&fps=1)","tags":["网络协议"],"categories":["网络协议"]},{"title":"BIO、NIO和AIO","url":"/2019/04/11/BIO、NIO和AIO/","content":"\n### 简介\nJava 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。比如在Linux 2.6以后，Java中NIO和AIO都是通过epoll来实现的，而在Windows上，AIO是通过IOCP来实现的。\n\n\n### IO过程\n所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。\n\n需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在\"干活\"，而且这个过程非常快，属于memory copy，带宽通常在1GB/s级别以上，可以理解为基本不耗时。\n\n以socket.read()为例子：\n\n传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。\n\n对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。\n\n最新的AIO(Async I/O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡到内存的过程也是异步的。\n\n换句话说，BIO里用户最关心“我要读”，NIO里用户最关心\"我可以读了\"，在AIO模型里用户更需要关注的是“读完了”。\n\nNIO一个重要的特点是：socket主要的读、写、注册和接收函数，**在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）**。\n\n### Linux的五种IO模型\n在Linux(UNIX)操作系统中，共有五种IO模型，分别是：阻塞IO模型、非阻塞IO模型、IO复用模型、信号驱动IO模型以及异步IO模型。\n\n#### 阻塞IO模型\n阻塞 I/O 是最简单的 I/O 模型，一般表现为进程或线程等待某个条件，如果条件不满足，则一直等下去。条件满足，则进行下一步操作。\n![](阻塞IO模型.png)\n应用进程通过系统调用 recvfrom 接收数据，但由于内核还未准备好数据报，应用进程就会阻塞住，直到内核准备好数据报，recvfrom 完成数据报复制工作，应用进程才能结束阻塞状态。\n\n#### 非阻塞IO模型\n应用进程与内核交互，目的未达到之前，不再一味的等着，而是直接返回。然后通过轮询的方式，不停的去问内核数据准备有没有准备好。如果某一次轮询发现数据已经准备好了，那就把数据拷贝到用户空间中。\n![](非阻塞IO.png)\n应用进程通过 recvfrom 调用不停的去和内核交互，直到内核准备好数据。如果没有准备好，内核会返回error，应用进程在得到error后，过一段时间再发送recvfrom请求。在两次发送请求的时间段，进程可以先做别的事情。\n\n#### 信号驱动IO模型\n应用进程在读取文件时通知内核，如果某个 socket 的某个事件发生时，请向我发一个信号。在收到信号后，信号对应的处理函数会进行后续处理。\n![](信号驱动模型.png)\n应用进程预先向内核注册一个信号处理函数，然后用户进程返回，并且不阻塞，当内核数据准备就绪时会发送一个信号给进程，用户进程便在信号处理函数中开始把数据拷贝的用户空间中。\n\n#### IO复用模型\n多个进程的IO可以注册到同一个管道上，这个管道会统一和内核进行交互。当管道中的某一个请求需要的数据准备好之后，进程再把对应的数据拷贝到用户空间中。\n![](IO复用.png)\n\nIO多路转接是多了一个select函数，多个进程的IO可以注册到同一个select上，当用户进程调用该select，select会监听所有注册好的IO，如果所有被监听的IO需要的数据都没有准备好时，select调用进程会阻塞。当任意一个IO所需的数据准备好之后，select调用就会返回，然后进程在通过recvfrom来进行数据拷贝。\n\n这里的IO复用模型，并没有向内核注册信号处理函数，所以，他并不是非阻塞的。进程在发出select后，要等到select监听的所有IO操作中至少有一个需要的数据准备好，才会有返回，并且也需要再次发送请求去进行文件的拷贝。\n\n#### 异步IO模型\n应用进程把IO请求传给内核后，完全由内核去操作文件拷贝。内核完成相关操作后，会发信号告诉应用进程本次IO已经完成。\n![](异步IO.png)\n用户进程发起aio_read操作之后，给内核传递描述符、缓冲区指针、缓冲区大小等，告诉内核当整个操作完成时，如何通知进程，然后就立刻去做其他事情了。当内核收到aio_read后，会立刻返回，然后内核开始等待数据准备，数据准备好以后，直接把数据拷贝到用户控件，然后再通知进程本次IO已经完成。\n\n#### 小结\n![](5种IO模型.png)\n阻塞IO模型、非阻塞IO模型、IO复用模型和信号驱动IO模型都是同步的IO模型。原因是，无论以上那种模型，真正的数据拷贝过程，都是同步进行的。\n信号驱动，内核是在数据准备好之后通知进程，然后进程再通过recvfrom操作进行数据拷贝。我们可以认为数据准备阶段是异步的，但是，数据拷贝操作是同步的。所以，整个IO过程也不能认为是异步的。\n\n\n### 相关概念\n#### 同步与异步\n\n- 同步： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。\n- 异步： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。\n\n同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过**回调等机制来通知**调用者其返回结果。\n\n#### 阻塞和非阻塞\n\n- 阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。\n- 非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。\n\n举个生活中简单的例子，你妈妈让你烧水，小时候你比较笨啊，在哪里傻等着水开（同步阻塞）。等你稍微再长大一点，你知道每次烧水的空隙可以去干点其他事，然后只需要时不时来看看水开了没有（同步非阻塞）。后来，你们家用上了水开了会发出声音的壶，这样你就只需要听到响声后就知道水开了，在这期间你可以随便干自己的事情，你需要去倒水了（异步非阻塞）。\n\n### BIO (Blocking I/O)\n同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。\nBIO通信（一请求一应答）模型图如下:\n![](BIO.png)\n采用 BIO 通信模型 的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在while(true) 循环中服务端会调用 accept() 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接。\n\n如果要让 BIO 通信模型 能够同时处理多个客户端请求，就必须使用多线程（主要原因是socket.accept()、socket.read()、socket.write() 涉及的三个主要函数都是同步阻塞的），也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的 一请求一应答通信模型 。我们可以设想一下如果这个连接不做任何事情的话就会造成不必要的线程开销，不过可以通过 线程池机制 改善，线程池还可以让线程的创建和回收成本相对较低。使用FixedThreadPool 可以有效的控制了线程的最大数量，保证了系统有限的资源的控制，实现了N(客户端请求数量):M(处理客户端请求的线程数量)的伪异步I/O模型（N 可以远远大于 M）\n\n#### 伪异步 IO\n为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化一一一后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M：线程池最大线程数N的比例关系，其中M可以远远大于N.通过线程池可以灵活地调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽。\n![](伪异步IO.png)\n\n采用线程池和任务队列可以实现一种叫做伪异步的 I/O 通信框架，它的模型图如上图所示。当有新的客户端接入时，将客户端的 Socket 封装成一个Task（该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理，JDK 的线程池维护一个消息队列和 N 个活跃线程，对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。\n\n伪异步I/O通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。不过因为它的底层仍然是同步阻塞的BIO模型，因此无法从根本上解决问题。\n\n#### 代码示例\n下面代码中演示了BIO通信（一请求一应答）模型。我们会在客户端创建多个线程依次连接服务端并向其发送\"当前时间+:hello world\"，服务端会为每个客户端线程创建一个线程来处理。\n客户端\n```java\n/**\n * \n * @author 闪电侠\n * @date 2018年10月14日\n * @Description:客户端\n */\npublic class IOClient {\n\n  public static void main(String[] args) {\n    // TODO 创建多个线程，模拟多个客户端连接服务端\n    new Thread(() -> {\n      try {\n        Socket socket = new Socket(\"127.0.0.1\", 3333);\n        while (true) {\n          try {\n            socket.getOutputStream().write((new Date() + \": hello world\").getBytes());\n            Thread.sleep(2000);\n          } catch (Exception e) {\n          }\n        }\n      } catch (IOException e) {\n      }\n    }).start();\n\n  }\n\n}\n```\n服务端\n```java\n/**\n * @author 闪电侠\n * @date 2018年10月14日\n * @Description: 服务端\n */\npublic class IOServer {\n\n  public static void main(String[] args) throws IOException {\n    // TODO 服务端处理客户端连接请求\n    ServerSocket serverSocket = new ServerSocket(3333);\n\n    // 接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理\n    new Thread(() -> {\n      while (true) {\n        try {\n          // 阻塞方法获取新的连接\n          Socket socket = serverSocket.accept();\n\n          // 每一个新的连接都创建一个线程，负责读取数据\n          new Thread(() -> {\n            try {\n              int len;\n              byte[] data = new byte[1024];\n              InputStream inputStream = socket.getInputStream();\n              // 按字节流方式读取数据\n              while ((len = inputStream.read(data)) != -1) {\n                System.out.println(new String(data, 0, len));\n              }\n            } catch (IOException e) {\n            }\n          }).start();\n\n        } catch (IOException e) {\n        }\n\n      }\n    }).start();\n\n  }\n\n}\n\n```\n#### 缺点\n不过，这个模型最本质的问题在于，严重依赖于线程。但线程是很\"贵\"的资源，主要表现在：\n\n1. 线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。\n2. 线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。\n\n3. 线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。\n\n4. 容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。\n\n#### 小结\n\n在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。\n\n\n### NIO (New I/O)\nNIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。\n\nNIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。\n\n#### 特性\n- NIO是基于块（Block）的，它以块为基本单位处理数据 （硬盘上存储的单位也是按Block来存储，这样性能上比基于流的方式要好一些）\n- 为所有的原始类型提供（Buffer）缓存支持\n- 增加通道（Channel）对象，作为新的原始 I/O 抽象\n- 支持锁（我们在平时使用时经常能看到会出现一些.lock的文件，这说明有线程正在使用这把锁，当线程释放锁时，会把这个文件删除掉，这样其他线程才能继续拿到这把锁）和内存映射文件的文件访问接口\n- 提供了基于Selector的异步网络I/O\n\n#### NIO与IO区别\n1. IO流是阻塞的，NIO流是不阻塞的\n\nJava NIO使我们可以进行非阻塞IO操作。比如说，单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到buffer中后，线程再继续处理数据。写数据也是一样的。另外，非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。\n\nJava IO的各种流是阻塞的。这意味着，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了\n\n2. IO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)\nBuffer是一个对象，它包含一些要写入或者要读出的数据。在NIO类库中加入Buffer对象，体现了新库与原I/O的一个重要区别。在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区，而 NIO 却是直接读到 Buffer 中进行操作。\n\n在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。**任何时候访问NIO中的数据，都是通过缓冲区进行操作**。\n\n最常用的缓冲区是 ByteBuffer,一个 ByteBuffer 提供了一组功能用于操作 byte 数组。除了ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean类型）都对应有一种缓冲区。\n\n3. Channel (通道)\nNIO 通过Channel（通道） 进行读写。\n\n通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。\n\n4. Selectors(选择器)\nNIO有选择器，而IO没有。\n\n选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。\n![](选择器.png)\n\n#### NIO 读数据和写数据方式\n通常来说NIO中的所有IO都是从 Channel（通道） 开始的。\n\n从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。\n从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。\n数据读取和写入操作图示：\n![](读取写入.png)\n所有的从通道中的读写操作，都要经过Buffer，而通道就是io的抽象，通道的另一端就是操纵的文件。\n\nNIO 包含下面几个核心的组件：\n- Channel(通道)\n- Buffer(缓冲区)\n- Selector(选择器)\n\n#### Buffer \nJava NIO Buffers用于和NIO Channel交互。 我们从Channel中读取数据到buffers里，从Buffer把数据写入到Channels；\n- Buffer本质上就是一块内存区；\n- 一个Buffer有三个属性是必须掌握的，分别是：capacity容量、position位置、limit限制。\nJava中Buffer的实现。基本的数据类型都有它对应的Buffer。\n\n下面是一个简单的例子：\n```java\npublic class Test {\n    public static void main(String[] args) throws Exception {\n        FileInputStream fin = new FileInputStream(new File(\n                \"d:\\\\temp_buffer.tmp\"));\n        FileChannel fc = fin.getChannel();\n        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n        fc.read(byteBuffer);\n        fc.close();\n        byteBuffer.flip();//读写转换\n    }\n}\n```\n从通道读取字节到ByteBuffer。当这个方法调用返回时，你不知道你所需的所有数据是否在缓冲区内。你所知道的是，该缓冲区包含一些字节，这使得处理有点困难。假设第一次 read(buffer)调用后，读入缓冲区的数据只有半行，例如，“Name:An”，你能处理数据吗？显然不能，需要等待，直到整行数据读入缓存，在此之前，对数据的任何处理毫无意义。所以，你怎么知道是否该缓冲区包含足够的数据可以处理呢？好了，你不知道。发现的方法只能查看缓冲区中的数据。其结果是，在你知道所有数据都在缓冲区里之前，你必须检查几次缓冲区的数据。这不仅效率低下，而且可以使程序设计方案杂乱不堪。\n\n##### Buffer重要参数 \nBuffer中有3个重要的参数：位置（position）、容量（capactiy）和上限（limit）\n![](buffer重要参数.png)\n这里要区别下容量和上限，比如一个Buffer有10KB，那么10KB就是容量，我将5KB的文件读到Buffer中，那么上限就是5KB。\n\n下面举个例子来理解下这3个重要的参数：\n```java\npublic static void main(String[] args) throws Exception {\n        ByteBuffer b = ByteBuffer.allocate(15); // 15个字节大小的缓冲区\n        System.out.println(\"limit=\" + b.limit() + \" capacity=\" + b.capacity()\n                + \" position=\" + b.position());\n        for (int i = 0; i < 10; i++) {\n            // 存入10个字节数据\n            b.put((byte) i);\n        }\n        System.out.println(\"limit=\" + b.limit() + \" capacity=\" + b.capacity()\n                + \" position=\" + b.position());\n        b.flip(); // 重置position\n        System.out.println(\"limit=\" + b.limit() + \" capacity=\" + b.capacity()\n                + \" position=\" + b.position());\n        for (int i = 0; i < 5; i++) {\n            System.out.print(b.get());\n        }\n        System.out.println();\n        System.out.println(\"limit=\" + b.limit() + \" capacity=\" + b.capacity()\n                + \" position=\" + b.position());\n        b.flip();\n        System.out.println(\"limit=\" + b.limit() + \" capacity=\" + b.capacity()\n                + \" position=\" + b.position());\n \n    }\n```\n整个过程如图：\n![](buffer1.png)\n此时position从0到10，capactiy和limit不变\n![](flip.png)\n该操作会重置position，通常，将buffer从写模式转换为读模式时需要执行此方法flip()操作不仅重置了当前的position为0，还将limit设置到当前position的位置 。\n\nlimit的意义在于，来确定哪些数据是有意义的，换句话说，从position到limit之间的数据才是有意义的数据，因为是上次操作的数据。所以flip操作往往是读写转换的意思。\n![](flip2.png)\n而Buffer中大多数的方法都是去改变这3个参数来达到某些功能的：\n```java\npublic final Buffer rewind()\n```\n将position置零，并清除标志位（mark）\n```java\npublic final Buffer clear()\n```\n将position置零，同时将limit设置为capacity的大小，并清除了标志mark\n```java\npublic final Buffer flip()\n```\n先将limit设置到position所在位置，然后将position置零，并清除标志位mark，通常在读写转换时使用\n\n#### 实例\n1. 使用NIO来复制文件\n```java\npublic static void nioCopyFile(String resource, String destination)\n            throws IOException {\n        FileInputStream fis = new FileInputStream(resource);\n        FileOutputStream fos = new FileOutputStream(destination);\n        FileChannel readChannel = fis.getChannel(); // 读文件通道\n        FileChannel writeChannel = fos.getChannel(); // 写文件通道\n        ByteBuffer buffer = ByteBuffer.allocate(1024); // 读入数据缓存\n        while (true) {\n            buffer.clear();\n            int len = readChannel.read(buffer); // 读入数据\n            if (len == -1) {\n                break; // 读取完毕\n            }\n            buffer.flip();\n            writeChannel.write(buffer); // 写入文件\n        }\n        readChannel.close();\n        writeChannel.close();\n    }\n```\n2. 文件映射到内存\n```java\npublic static void main(String[] args) throws Exception {\n        RandomAccessFile raf = new RandomAccessFile(\"C:\\\\mapfile.txt\", \"rw\");\n        FileChannel fc = raf.getChannel();\n        // 将文件映射到内存中\n        MappedByteBuffer mbb = fc.map(FileChannel.MapMode.READ_WRITE, 0,\n                raf.length());\n        while (mbb.hasRemaining()) {\n            System.out.print((char) mbb.get());\n        }\n        mbb.put(0, (byte) 98); // 修改文件\n        raf.close();\n    }\n```\n对MappedByteBuffer的修改就相当于修改文件本身，这样操作的速度是很快的。\n\n##### Buffer的选择\n通常情况下，操作系统的一次写操作分为两步：\n\n1. 将数据从用户空间拷贝到系统空间。\n2. 从系统空间往网卡写。\n\n同理，读操作也分为两步：\n1. 将数据从网卡拷贝到系统空间；\n2. 将数据从系统空间拷贝到用户空间。\n\n对于NIO来说，缓存的使用可以使用DirectByteBuffer和HeapByteBuffer。\n如果使用了DirectByteBuffer，一般来说可以减少一次系统空间到用户空间的拷贝。\n但Buffer创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能。\n\n如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer；反之可以用directBuffer。\n\n#### NIO是怎么解决掉线程的瓶颈并处理海量连接的\nNIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。\n\n并且由于线程的节约，连接数大的时候因为线程切换带来的问题也随之解决，进而为处理海量连接提供了可能。\n\n单线程处理I/O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I/O，无疑对效率会有更大的提高。\n\n仔细分析一下我们需要的线程，其实主要包括以下几种：\n\n1. 事件分发器，单线程选择就绪的事件。\n2. I/O处理器，包括connect、read、write等，这种纯CPU操作，一般开启CPU核心个线程就可以。\n3. 业务线程，在处理完I/O后，业务一般还会有自己的业务逻辑，有的还会有其他的阻塞I/O，如DB操作，RPC等。只要有阻塞，就需要单独的线程。\n\nJava的Selector对于Linux系统来说，有一个致命限制：同一个channel的select不能被并发的调用。因此，如果有多个I/O线程，必须保证：一个socket只能属于一个IoThread，而一个IoThread可以管理多个socket。\n\n另外连接的处理和读写的处理通常可以选择分开，这样对于海量连接的注册和读写就可以分发。虽然read()和write()是比较高效无阻塞的函数，但毕竟会占用CPU，如果面对更高的并发则无能为力。\n\n####  Channel\n在多线程网络编程中，为每一个客户端使用一个线程，如果客户端出现延时等异常，线程可能会被占用很长时间。因为数据的准备和读取都在这个线程中。此时，如果客户端数量众多，可能会消耗大量的系统资源。\n\nNIO有一个很大的特点就是：把数据准备好了再通知我。\n而Channel有点类似于流，一个Channel可以和文件或者网络Socket对应 \n![](channel.png)\nselector是一个选择器，它可以选择某一个Channel，然后做些事情。\n\n**一个线程可以对应一个selector，而一个selector可以轮询多个Channel，而每个Channel对应了一个Socket**\n\n与上面一个线程对应一个Socket相比，使用NIO后，一个线程可以轮询多个Socket。\n\n> - 当selector调用select()时，会查看是否有客户端准备好了数据。当没有数据被准备好时，select()会阻塞。平时都说NIO是非阻塞的，但是如果没有数据被准备好还是会有阻塞现象。\n\n当有数据被准备好时，调用完select()后，会返回一个SelectionKey，SelectionKey表示在某个selector上的某个Channel的数据已经被准备好了。只有在数据准备好时，这个Channel才会被选择。这样NIO实现了一个线程来监控多个客户端。\n\nselectNow()与select()的区别在于，selectNow()是不阻塞的，当没有客户端准备好数据时，selectNow()不会阻塞，将返回0，有客户端准备好数据时，selectNow()返回准备好的客户端的个数。\n\n#### Selector（选择器）介绍\n\nSelector 一般称 为选择器 ，当然你也可以翻译为 多路复用器 。它是Java NIO核心组件中的一个，用于检查一个或多个NIO Channel（通道）的状态是否处于可读、可写。如此可以实现单线程管理多个channels,也就是可以管理多个网络链接。\n使用Selector的好处在于：**使用更少的线程来就可以来处理通道了， 相比使用多个线程，避免了线程上下文切换带来的开销**。\n\n\n#### 代码示例\n客户端 IOClient.java 的代码不变，我们对服务端使用 NIO 进行改造。\n```java\n/**\n * \n * @author 闪电侠\n * @date 2019年2月21日\n * @Description: NIO 改造后的服务端\n */\npublic class NIOServer {\n  public static void main(String[] args) throws IOException {\n    // 1. serverSelector负责轮询是否有新的连接，服务端监测到新的连接之后，不再创建一个新的线程，\n    // 而是直接将新连接绑定到clientSelector上，这样就不用 IO 模型中 1w 个 while 循环在死等\n    Selector serverSelector = Selector.open();\n    // 2. clientSelector负责轮询连接是否有数据可读\n    Selector clientSelector = Selector.open();\n\n    new Thread(() -> {\n      try {\n        // 对应IO编程中服务端启动\n        ServerSocketChannel listenerChannel = ServerSocketChannel.open();\n        listenerChannel.socket().bind(new InetSocketAddress(3333));\n        listenerChannel.configureBlocking(false);\n        listenerChannel.register(serverSelector, SelectionKey.OP_ACCEPT);\n\n        while (true) {\n          // 监测是否有新的连接，这里的1指的是阻塞的时间为 1ms\n          if (serverSelector.select(1) > 0) {\n            Set<SelectionKey> set = serverSelector.selectedKeys();\n            Iterator<SelectionKey> keyIterator = set.iterator();\n\n            while (keyIterator.hasNext()) {\n              SelectionKey key = keyIterator.next();\n\n              if (key.isAcceptable()) {\n                try {\n                  // (1)\n                  // 每来一个新连接，不需要创建一个线程，而是直接注册到clientSelector\n                  SocketChannel clientChannel = ((ServerSocketChannel) key.channel()).accept();\n                  clientChannel.configureBlocking(false);\n                  clientChannel.register(clientSelector, SelectionKey.OP_READ);\n                } finally {\n                  keyIterator.remove();\n                }\n              }\n\n            }\n          }\n        }\n      } catch (IOException ignored) {\n      }\n    }).start();\n    new Thread(() -> {\n      try {\n        while (true) {\n          // (2) 批量轮询是否有哪些连接有数据可读，这里的1指的是阻塞的时间为 1ms\n          if (clientSelector.select(1) > 0) {\n            Set<SelectionKey> set = clientSelector.selectedKeys();\n            Iterator<SelectionKey> keyIterator = set.iterator();\n\n            while (keyIterator.hasNext()) {\n              SelectionKey key = keyIterator.next();\n\n              if (key.isReadable()) {\n                try {\n                  SocketChannel clientChannel = (SocketChannel) key.channel();\n                  ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n                  // (3) 面向 Buffer\n                  clientChannel.read(byteBuffer);\n                  byteBuffer.flip();\n                  System.out.println(\n                      Charset.defaultCharset().newDecoder().decode(byteBuffer).toString());\n                } finally {\n                  keyIterator.remove();\n                  key.interestOps(SelectionKey.OP_READ);\n                }\n              }\n\n            }\n          }\n        }\n      } catch (IOException ignored) {\n      }\n    }).start();\n\n  }\n}\n```\n为什么大家都不愿意用 JDK 原生 NIO 进行开发呢？从上面的代码中大家都可以看出来，是真的难用！除了编程复杂、编程模型难之外，它还有以下让人诟病的问题：\n- JDK 的 NIO 底层由 epoll 实现，该实现饱受诟病的空轮询 bug 会导致 cpu 飙升 100%\n- 项目庞大之后，自行实现的 NIO 很容易出现各类 bug，维护成本较高，上面这一坨代码我都不能保证没有 bug\n\n#### 小结\nNIO可让您只使用一个（或几个）单线程管理多个通道（网络连接或文件），但付出的代价是解析数据可能会比从一个阻塞流中读取数据更复杂。如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，实现NIO的服务器可能是一个优势。同样，如果你需要维持许多打开的连接到其他计算机上，如P2P网络中，使用一个单独的线程来管理你所有出站连接，可能是一个优势。\n\n最后总结一下到底NIO给我们带来了些什么：\n> - 事件驱动模型\n> - 避免多线程\n> - 单线程处理多任务\n> - 非阻塞I/O，I/O读写不再阻塞，而是返回0\n> - 基于block的传输，通常比基于流的传输更高效\n> - 更高级的IO函数，zero-copy\n> - IO多路复用大大提高了Java网络应用的可伸缩性和实用性\n\n### AIO (Asynchronous I/O)\nAIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。\n\nAIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。（除了 AIO 其他的 IO 类型都是同步的。\n\n#### 特点\n1. 读完了再通知我\n2. 不会加快IO，只是在读完后进行通知\n3. 使用回调函数，进行业务处理\n\n由于NIO的读写过程依然在应用线程里完成，所以对于那些读写过程时间长的，NIO就不太适合。\n而AIO的读写过程完成后才被通知，所以AIO能够胜任那些重量级，读写过程长的任务\n\n### 参考资料\n- [BIO,NIO,AIO 总结](https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/BIO-NIO-AIO.md)\n- [Java NIO：IO与NIO的区别 -阿里面试题](http://www.cnblogs.com/aspirant/p/8630283.html)\n- [高并发Java（8）：NIO和AIO](http://www.importnew.com/21341.html)\n- [漫话：如何给女朋友解释什么是Linux的五种IO模型？](https://mp.weixin.qq.com/s?__biz=Mzg3MjA4MTExMw==&mid=2247484746&idx=1&sn=c0a7f9129d780786cabfcac0a8aa6bb7&source=41#wechat_redirect)\n- [Java NIO浅析](https://zhuanlan.zhihu.com/p/23488863)","tags":["IO模型"],"categories":["IO模型"]},{"title":"线程知识汇总","url":"/2019/04/11/线程知识汇总/","content":"\n## CPU核心数、线程数的关系\n> CPU的核心数是指物理上，也就是硬件上存在着几个核心。比如，双核就是包括2个相对独立的CPU核心单元组，四核就包含4个相对独立的CPU核心单元组。\n> 线程数是一种逻辑的概念，简单地说，就是模拟出的CPU核心数。比如，可以通过一个CPU核心数模拟出2个线程的CPU。，也就是说，这个单核心的CPU被模拟成了一个类似双核心CPU的功能。对于一个CPU，线程数总是大于或等于核心数的。一个核心最少对应一个线程，但通过超线程技术，一个核心可以对应两个线程，也就是说它可以同时运行两个线程。 线程数越多，越有利于同时运行多个程序，因为线程数等同于在某个瞬间CPU能同时并行处理的任务数。在Java中可以通过`Runtime.getRuntime().availableProcessors()`获得操作系统的线程数。\n\n## 在CPU时间片轮转机制中设置多少毫秒是合理的？\n### 轮转法的基本原理：\n\n根据先来先服务的原则，将需要执行的所有进程按照到达时间的大小排成一个升序的序列。每次都给一个进程分配一个时间段，也可称为时间片，即该进程允许运行的时间。如果在时间片结束时，进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。调度程序所要做的就是维护一张就绪进程列表，当进程用完它的时间片后，它被移到队列的末尾。\n从一个进程切换到另一个进程是需要一定时间的，用于保存和装入寄存器值及内存映像，更新各种表格和队列等。假如进程切换（process switch），也称为上下文切换（context switch），需要5毫秒，时间片为20毫秒，则在做完20毫秒有用工作之后，CPU将花费５毫秒来进行进程切换。CPU时间的２０％将花费在管理开销上。\n通常状况下，一个系统中所有的进程将分配到的时间片长短并不是相等，尽管初始时间片基本相等（在Linux系统中，初始时间片也不相等，而是各自父进程的一半），系统通过测量进程处于[睡眠]和[正在运行]状态的时间长短来计算每个进程的交互性，交互性和每个进程预设的静态优先级（nice值）的叠加即是动态优先级，动态优先级按比例缩放就是要分配给那个进程时间片的长短。一般地，为了获得较快的响应速度，交互性强的进程（即趋向于IO消耗型）被分配的时间片要长于交互性弱的（趋向于处理器消耗型）进程。将时间片设为100毫秒通常是一个合理的数值。\n操作系统把CPU的时间片分配给用户进程，再由用户进程的管理器将时间分配给用户线程。那么，用户进程能得到的时间片即为所有用户线程共享。比如现有一进程有10个线程，则在系统调度执行时间上占用的时间片也是1。\n在多级反馈队列调度算法中，分配各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。\n\n### 进程的切换\n时间片够用：意思就是在该时间片内，进程可以运行至结束，进程运行结束之后，将进程从进程队列中删除，然后启动新的时间片\n时间片不够用：意思是在该时间片内，进程只能完成它的一部分任务，在时间片用完之后，将进程的状态改为等待状态，将进程放到进程队列的尾部，等待cpu的调用\n\n### 关于时间片大小的选择\n时间片过小，则进程频繁切换，会造成cpu资源的浪费\n时间片过大，则随着就绪队列中进程/线程数目的增加，轮转一次所耗费的总时间加长，即对每个进程/线程的响应速度放慢，甚至时间片大到让进程/线程足以完成其所有任务，轮转调度算法便退化为FCFS算法\n\n### 时间片大小的确定\n 一个较为可取的时间片的大小是略大于一次典型的交互所需时间，是大多数交互程序能在一个时间片内完成。\n1.系统对响应时间的要求：T(响应时间) = N(进程数目)`*`q(时间片)\n2.就绪队列中进程的数目：数目越多，时间片越小\n3.系统的处理能力：应当使用户输入通常在一个时间片内能处理完，否则使响应时间，平均周转时间和平均带权周转时间延长。\n\n### 进程调度算法\n常用的进程调度算法有先来先服务、时间片轮转、优先级调度和多级反馈调度算法。\n> 先来先服务（first come first service）。FCFS按照进程成为就绪状态的先后次序分配CPU时间片，即进程调度总是将就绪队列队首的进程投入运行。FCFS的特点是比较有利于长作业，而不利于短作业；有利于CPU繁忙作业，而不利于I/O繁忙的作业。FCFS算法主要用于宏观调度。\n\n> 时间片轮转。该算法主要用于微观调度。通过时间片轮转提高进程并发行和响应时间特性，从而提高资源利用率。时间片的长度可以从几毫秒到几百毫秒，选择的方法一般有如下两种：\n(1)、固定时间片。分配给每个进程相等的时间片，使所有进程都公平执行。\n(2)、可变时间片。根据进程不同的要求对时间片的大小实时修改。\n\n> 优先级调度。该算法是让每一个进程都拥有一个优先数，数值大的表示优先级高，系统在调度时总选择优先数大的占用CPU。优先级调度分为静态优先级和动态优先级。\n(1)、静态优先级。进程的优先级在创建时确定，直到进程终止都不会改变。通常根据以下因素确定优先级：进程类型、对资源的需求、用户要求；\n(2)、动态优先级。在创建进程时赋予一个优先级，在进程运行过程中还可以改变，以便获得更好的调度性能。例如，在就绪队列中，随着等待事件增长，优先级将提高。这样对于优先级低的进程在等待足够的时间后，其优先级提高到可被调度执行。进程每执行一个时间片就降低其优先级，从而当一个进程持续执行时，其优先级会降低到让出CPU。\n\n> 多级反馈调度。多级反馈队列算法是时间片轮转算法和优先级算法的综合。其优点照顾了短进程以提高系统吞吐量、缩短了平均周转时间；照顾I/O型进程以获得较好的I/O设备利用率和缩短响应时间；不必估计进程的执行时间，动态调节优先级。\n(1)、设置多个就绪队列。队列1，队列2，...，队列n分别赋予不同的优先级，队列1的优先级最大。每个队列执行时间片的长度不一样，优先级低的时间片越长，逐级加倍。\n(2)、新进程进入内存后，先投入队列1的末尾，按照FCFS算法调度；若在队列1的一个时间片内未能执行完，则降低投入到队列2末尾，同样按照FCFS算法调度；如此下去，当进程降低到最后的队列时，则按时间片轮转算法调度直到完成。\n(3)、仅当较高优先级的队列为空才调度较低优先级队列中的进程执行。如果进程执行时有新进程进入较高优先级的队列，则抢先执行新进程，并把被抢先的进程投入原队列的末尾。\n\n### 什么是进程？什么是线程？一个进程最多可以创建多少个线程？\n进程是系统中正在运行的一个程序，是程序运行的实例。进程是资源分配的基本单位。\n线程是CPU独立运行和独立调度的基本单位，程序执行的最小单元，是进程中的一个实体用来执行程序。\n\n区别：\n（1）进程具有独立的空间地址，一个进程崩溃后，在保护模式下不会对其它进程产生影响。\n（2）线程只是一个进程的不同执行路径，线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉。\n (3) 同一进程内的多个线程会共享部分状态，多个线程可以读写同一块内存（一个进程无法直接访问另一进程的内存）。\n\n\n查看系统中的进程上限:\n```linux\nulimit -u\n```\n创建一个线程会占用多少内存，这取决于分配给线程的调用栈大小，可以用`ulimit -s`命令来查看大小（一般常见的有10M或者是8M）。\n一个进程的虚拟内存是4G，在Linux32位平台下，内核分走了1G，留给用户用的只有3G，于是我们可以想到，创建一个线程占有了10M内存，总共有3G内存可以使用。于是可想而知，最多可以创建差不多300个左右的线程。\n\n因此，进程最多可以创建的线程数是根据分配给调用栈的大小，以及操作系统（32位和64位不同）共同决定的。\n\n###  用户单一进程同时可打开文件数量是多少？\n在linux平台上，无论是客户端程序还是服务器端程序，在进行高并发TCP连接处理时，最高的并发数量都要受到系统对用户单一进程同时可打开文件数量的限制(这是因为系统为每个TCP连接都要创建一个socket句柄，每个socket句柄同时也是一个文件句柄)。\n\n可使用ulimit命令查看系统允许当前用户进程打开的文件数限制：\n```linux\n ulimit -n\n```\n一般情况下是65535。\n这表示当前用户的每个进程最多允许同时打开1024个文件，这1024个文件中还得除去每个进程必然打开的标准输入，标准输出，标准错误，服务器监听socket，进程间通信的unix与socket等文件，那么剩下的可用于客户端socket连接的文件数就只有大概1024-10=1014个左右，也就是说缺省情况下，基于linux的通信程序最多允许同时1014个tcp并发连接。\n\n### 什么是并行，什么是并发？\n并发是多个事件在同一时间段执行，而并行是多个事件在同一时间点执行。\n并行：两个线程在两个CPU上同时执行。\n并发：两个线程交替在同一个CPU上执行。\n\n### 什么是同步，什么是异步，什么是堵塞，什么是非堵塞？\n同步和异步是针对应用程序和内核的交互而言的，同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。\n\n以银行取款为例：\n\n同步：自己亲自出马持银行卡到银行取钱（使用同步IO时，Java自己处理IO读写）；\n\n异步：委托一小弟拿银行卡到银行取钱，然后给你（使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS(银行卡和密码)，OS需要支持异步IO操作API）；\n\n阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式。\n\n阻塞：线程在执行中如果遇到（I/O 操作）如磁盘读写或网络通信，通常要耗费较长的时间，这时操作系统会剥夺这个线程的 CPU 控制权，使其暂停执行，同时将资源让给其他的工作线程，这种线程调度方式称为 阻塞。当 I/O 操作完毕时，操作系统将这个线程的阻塞状态解除，恢复其对CPU的控制权，令其继续执行。\n\n非阻塞方：当线程遇到 I/O 操作时，不会以阻塞的方式等待 I/O 操作的完成或数据的返回，而只是将 I/O 请求发送给操作系统，继续执行下一条语句。当操作系统完成 I/O 操作时，以事件的形式通知执行 I/O 操作的线程，线程会在特定时候处理这个事件。\n\n以银行取款为例：\n\n阻塞：ATM排队取款，你只能等待（使用阻塞IO时，Java调用会一直阻塞到读写完成才返回）；\n\n非阻塞：\n\n柜台取款，取个号，然后坐在椅子上做其它事，等号广播会通知你办理，没到号你就不能去，你可以不断问大堂经理排到了没有，大堂经理如果说还没到你就不能去（使用非阻塞IO时，如果不能读写Java调用会马上返回，当IO事件分发器通知可读写时再继续进行读写，不断循环直到读写完成）\n\n**区别**\n同步和异步仅仅是关注的消息如何通知的机制，而阻塞与非阻塞关注的是等待消息通知时的状态。\n\n同步与异步是对应的，它们是线程之间的关系，两个线程之间要么是同步的，要么是异步的。\n\n阻塞与非阻塞是对同一个线程来说的，在某个时刻，线程要么处于阻塞，要么处于非阻塞。\n\n阻塞是使用同步机制的结果，非阻塞则是使用异步机制的结果。\n\n阻塞模式下，一个线程只能处理一项任务，要想提高吞吐量必须通过多线程。\n\n非阻塞模式下，一个线程永远在执行计算操作，这个线程所使用的 CPU 核心利用率永远是 100%，I/O 以事件的方式通知。\n\n在阻塞模式下，多线程往往能提高系统吞吐量，因为一个线程阻塞时还有其他线程在工作，多线程可以让 CPU 资源不被阻塞中的线程浪费。\n\n而在非阻塞模式下，线程不会被 I/O 阻塞，永远在利用 CPU。多线程带来的好处仅仅是在多核 CPU 的情况下利用更多的核。\n\n\n### 实现线程的三种方式？\n> 继承Thread类、实现Runnable接口、实现Callable接口三种方式。\n> 1、Thread类： \n通过继承Thread类，并复写run()方法，调用Thread的start()方法启动线程。线程执行的就是自己定义的run()方法。Thread类原run()的 源码如下：\n```java\n @Override\n    public void run() {\n        if (target != null) {\n            target.run();\n        }\n    }\n```\n这种方式下，每个线程都有属于自己的run()方法，即每个线程独自运行自己的run()方法，没有实现资源共享。\n\n> 2、Runnable接口创建线程：\n定义Runnable接口的实现类，并重写接口的run()方法，创建该类的实例，将该实例作为Thread的target，最后调用Thread的start()方法启动线程。Thread的run()方法就会调用Runnable.run()。 \n在这种方式下，多个线程可以共享同一个target对象，适合多个相同线程来处理同一份资源的情况。\n\n> 3、Callable和Future创建线程：\n创建Callable接口的实现类，并重写接口的call()方法，该call()方法将作为线程执行体，并且有返回值。 \n创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call()方法的返回值。 \n使用FutureTask对象作为Thread对象的target，最后调用Thread的start()方法启动线程。\n\n\n### 线程的生命周期是什么？线程池的初始化的时候，池里面的线程处于生命周期的那个阶段？\nNEW、RUNNABLE、RUNNING、BLOCKED、DEAD\n![](线程状态.png)\n> - 新建状态（New）：当线程对象对创建后，即进入了新建状态，如：Thread t = new MyThread();\n\n> - 就绪状态（Runnable）：当调用线程对象的start()方法（t.start();），线程即进入就绪状态。处于就绪状态的线程，只是说明此线程已经做好了准备，随时等待CPU调度执行，并不是说执行了t.start()此线程立即就会执行；\n\n> - 运行状态（Running）：当CPU开始调度处于就绪状态的线程时，此时线程才得以真正执行，即进入到运行状态。注：就绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；\n\n> - 阻塞状态（Blocked）：处于运行状态中的线程由于某种原因，暂时放弃对CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被CPU调用以进入到运行状态。根据阻塞产生的原因不同，阻塞状态又可以分为三种：\n\n1. 等待阻塞 -- 运行状态中的线程执行wait()方法，使本线程进入到等待阻塞状态，释放对象锁；\n\n2. 同步阻塞 -- 线程在获取synchronized同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状态；\n\n3. 其他阻塞 -- 通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态，不释放对象锁。\n\n> - 死亡状态（Dead）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。\n\n线程池的初始化的时候是RUNNING，池里面的线程处于NEW状态。\n\n### ThreadPoolExecutor 如何判断空闲线程\nWorker\n```java\n public void run() {\n            runWorker(this);\n }\n        \nwhile (task != null || (task = getTask()) != null) {\n Runnable r = timed ?\n                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :\n                    workQueue.take();\n                if (r != null)\n                    return r;\n```\n添加工作线程并启动后，工作线程不断地从队列获取任务，\n当超时获取不到任务，超时标志设置为true, 下一次循环判断超时，返回null，\n则跳出工作循环，执行 processWorkerExit(w, completedAbruptly);\n打断空闲线程 interruptIdleWorkers t.interrupt();\n\n### 什么是线程组？\n线程组表示一个线程的集合。此外，线程组也可以包含其他线程组。线程组构成一棵树，在树中，除了初始线程组外，每个线程组都有一个父线程组。\n允许线程访问有关自己的线程组的信息，但是不允许它访问有关其线程组的父线程组或其他任何线程组的信息。\n\n如果t1线程不调用start方法的话并不会添加到mainGroup中,只有线程调用start()方法,线程运行起来才可以.  只能添加当前线程组活动的线程。\n在实例化各个线程的时候，如果不指定所属的线程组，则这些线程自动归到当前线程对象所属的线程组中，也就是说隐似的在一个线程组中添加了子线程。比如：在main方法中创建多个线程，如果不明确的设置所属线程组的话，则这些线程默认都属于main所在的线程组。\n其中main方法所在的线程组即是main，main线程的父级线程组即是jvm线程组system，可以在main中通过以下获取：\n```java\nThread.currentThread().getThreadGroup().getName()；\nThread.currentThread().getThreadGroup().getParent().getName()\n```\n作用：\n获得线程组之后，可以知道这个线程组中的哪些线程是运行着的，每条线程是什么,都可以获得到。可以批量管理线程或线程组对象，有效地对线程或线程组对象进行组织。\n\n从线程安全性的角度来看，ThreadGroup API非常弱。为了得到一个线程组中的活动线程列表，你必须调用enumerate方法，它有一个数组参数，并且数组的容量必须足够大，以便容纳所有的活动线程。activeCount方法返回一个线程组中活动线程的数量，但是，一旦这个数组进行了分配，并传递给了enumerate方法，就不保证原先得到的活动线程数仍是正确的。如果线程数增加了，而数组太小，enumerate方法就会悄然的忽略掉无法再数组中容纳的线程。\n\n### ThreadLocal是用来解决共享资源的多线程访问的问题吗？\n不是。ThreadLocal是用来解决同一个线程内共享资源的访问。\n\nThreadLocal 并不是为了解决线程安全问题，而是提供了一种将实例绑定到当前线程的机制，类似于隔离的效果，实际上自己在方法中 new 出来变量也能达到类似的效果。ThreadLocal 跟线程安全基本不搭边，绑定上去的实例也不是多线程公用的，而是每个线程 new 一份，这个实例肯定不是共用的，如果共用了，那就会引发线程安全问题。ThreadLocal 最大的用处就是用来把实例变量共享成全局变量，在程序的任何方法中都可以访问到该实例变量而已。网上很多人说 ThreadLocal 是解决了线程安全问题，其实是望文生义，两者不是同类问题。\n\n也就是说 ThreadLocal 的用法和我们自己 new 对象一样，然后将这个 new 的对象传递到各个方法中。但是到处传递的话，太麻烦了。这个时候，就应该用 ThreadLocal。\n\nThreadLocal 的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。\n\n### 每次使用完ThreadLocal，都调用它的remove()方法，为什么呢？\n清除线程ThreadLocalMap里所有key为null的value，防止内存泄露 。\n\n\n所以JDK建议将ThreadLocal变量定义成**private static**的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露。\nstatic的ThreadLocal变量是一个与线程相关的静态变量，即一个线程内，static变量是被各个实例共同引用的，但是不同线程内，static变量是隔开的。\n\n1 static 防止无意义多实例\n\n2 当static时，ThreadLocal ref生命延长－ThreadMap的key在线程生命期内始终有值－ThreadMap的value在线程生命期内不释放——故线程池下，static修饰TrheadLocal引用，必须（1）remove   或（2）手动  ThreadLocal ref ＝ null\n\n### volatile的作用？\nvolatile保持内存可见性和防止指令重排序。\n保持内存可见性:所有线程都能看到共享内存的最新状态。\n使用volatile变量能够保证:\n1. 每次读取前必须先从主内存刷新最新的值。\n2. 每次写入后必须立即同步回主内存当中。\n\n防止指令重排序: volatile关键字通过“内存屏障”来防止指令被重排序，参考DCL。\n基于保守策略的JMM内存屏障插入策略：\n\n- 在每个volatile写操作的前面插入一个StoreStore屏障。\n- 在每个volatile写操作的后面插入一个StoreLoad屏障。\n- 在每个volatile读操作的后面插入一个LoadLoad屏障。\n- 在每个volatile读操作的后面插入一个LoadStore屏障。\n\n### run方法是否可以抛出异常？如果抛出异常，线程的状态如何？\n可能抛出。\n1. Thread的run方法是不支持抛出任何检查型异常(checked exception--在编译期间出现的异常)的，也就是说一条线程内部发生的checked异常，必须也只能在内部用try-catch处理掉，不能往外抛，因为线程是一个独立运行的代码片段，它的问题不能影响到其他线程\n\n2. 它自身却可能因为一个运行时异常（RuntimeException）而被终止，导致这个线程的终结，而对于主线程和其他线程完全不受影响，且完全感知不到某个线程抛出的异常(也是说完全无法catch到这个异常)。\n比如在Thread的run方法中，调用String的Parse系列方法对非数字的字符进行解析，就可能会抛出NumberFormatException，这种JVM是按照如下方式处理的：\n- 首先看当前的线程，是否在start之前，通过调用setUncaughtExceptionHandler(UncaughtExceptionHandler, eh)，设置了UncaughtExceptionHandler；如果已经设置，则使用此ExceptionHandler来处理；\n\n- 否则，查看当前Thread所在的ThreadGroup，是否设置了UncaughtExceptionHandler；如果已经设置，则使用此ExceptionHandler来处理；\n\n- 否则，查看Thread层面是否设置了UncaughtExceptionHandler，Thread类的静态方法setDefaultUncaughtExceptionHandler进行设置；如果已经设置，则使用此ExceptionHandler来处理；\n\n- 如果上述UncaughtExceptionHandler都没有找到，那么JVM会直接在console中打印Exception的StackTrace信息。\n\nrun方法本身是没有throws关键字的，可以使用try-catch语句块捕获异常。\n\n\n### 什么是隐式锁？什么是显式锁？什么是无锁？\nSynchronized就是隐式锁，当调用Synchronized修饰的代码时，并不需要显示的加锁和解锁的过程，所以称之为隐式锁。\nReentrantLock、ReentrantReadWriteLock.ReadLock和ReentrantReadWriteLock.WriteLock就是显示锁，所有的加锁和解锁操作方法都是显示的，因而称为显示锁。 \nCAS就是无锁，当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，CAS操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。\n\n### 多线程之间是如何通信的？\n多线程之间通讯，其实就是多个线程在操作同一个资源，但是操作的动作不同。\n\n一、传统线程通信synchronized + wait + notify\n\nObject类的wait()、notify() 、notifyAll()三个方法必须由同步监视器对象来调用，分两种情况：\n\na)同步方法，该类默认实例（this）就是同步监视器，可以在同步方法中可以直接调用\n\nb)同步代码块，同步监视器是synchronized后括号里的对象，所以必须使用此对象调用这三个方法\n\n\n二、使用Condition控制线程通信lock + condition + await + signal\n\nLock代替同步方法或同步代码块，Condition替代同步监视器的功能。\n\n```java\nprivate final Lock lock = new ReentrantLock();\n\nprivate final Condition con =lock.newCondition();\n\nlock.lock(); \n  con.await();  \n  con.signalAll();  \nlock.unlock():\n```\n \n三、使用阻塞队列（BlockingQueue）控制线程通信\n\nBlockingQueue接口主要作为线程同步的工具。当生产者试图向BlockingQueue中放入元素，如果队列已满，则线程被阻塞；当消费者试图向BlockingQueue中取出元素时，若该队列已空，则线程被阻塞。\n\n四、利用volatile，volatile能保证所修饰的变量对于多个线程可见性，即只要被修改，其它线程读到的一定是最新的值。\n\n\n### Java的内存模型是什么？\n\nJMM规定了所有的变量都存储在主内存（Main Memory）中。每个线程还有自己的工作内存（Working Memory）,线程的工作内存中保存了该线程使用到的变量的主内存的副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量（volatile变量仍然有工作内存的拷贝，但是由于它特殊的操作顺序性规定，所以看起来如同直接在主内存中读写访问一般）。不同的线程之间也无法直接访问对方工作内存中的变量，线程之间值的传递都需要通过主内存来完成。\n\n这里的主内存、工作内存与Java内存区域的Java堆、栈、方法区不是同一层次内存划分。\n\nJava内存模型是围绕着并发编程中原子性、可见性、有序性这三个特征来建立的：\n1. 原子性（Atomicity）：一个操作不能被打断，要么全部执行完毕，要么不执行。\n2. 可见性：一个线程对共享变量做了修改之后，其他的线程立即能够看到（感知到）该变量这种修改（变化）。\n   除了volatile关键字能实现可见性之外，还有synchronized,Lock，final也是可以的。\n3. 有序性：Java提供了两个关键字volatile和synchronized来保证多线程之间操作的有序性,volatile关键字本身通过加入内存屏障来禁止指令的重排序，而synchronized关键字通过一个变量在同一时间只允许有一个线程对其进行加锁的规则来实现，在单线程程序中，不会发生“指令重排”和“工作内存和主内存同步延迟”现象，只在多线程程序中出现。\n\n### 什么是原子操作？生成对象的过程是不是原子操作？\n原子操作：一个操作不能被打断，要么全部执行完毕，要么不执行。\n\n生成对象的过程不是原子操作，它可以”抽象“为下面几条JVM指令：\n```java\nmemory = allocate();    //1：分配对象的内存空间\ninitInstance(memory);   //2：初始化对象\ninstance = memory;      //3：设置instance指向刚分配的内存地址\n```\n上面操作2依赖于操作1，但是操作3并不依赖于操作2，所以JVM可以以“优化”为目的对它们进行重排序，经过重排序后如下：\n```java\nmemory = allocate();    //1：分配对象的内存空间\ninstance = memory;      //3：设置instance指向刚分配的内存地址（此时对象还未初始化）\ninitInstance(memory);   //2：初始化对象\n```\n可以看到指令重排之后，操作 3 排在了操作 2 之前，即引用instance指向内存memory时，这段崭新的内存还没有初始化——即引用instance指向了一个\"被部分初始化的对象\"。此时，如果另一个线程调用getInstance方法，由于instance已经指向了一块内存空间，从而if条件判为false，方法返回instance引用，用户得到了没有完成初始化的“半个”单例。\n解决这个该问题，只需要将instance声明为volatile变量\n\n\n### CopyOnWrite机制是什么？\n写时复制。那么，什么是写入时复制思想呢？就是当有多个调用者同时去请求一个资源时(可以是内存中的一个数据)，当其中一个调用者要对资源进行修改，系统会copy一个副本给该调用者，让其进行修改；而其他调用者所拥有资源并不会由于该调用者对资源的改动而发生改变。\n\n\nCopyOnWriteArrayList，就是当我们往CopyOnWrite容器中添加元素时，不直接操作当前容器，而是先将容器进行Copy，然后对Copy出的新容器进行修改，修改后，再将原容器的引用指向新的容器，即完成了整个修改操作\n\nCopyOnWriteArrayList通过使用ReentrantLock锁来实现线程安全：\n```java\npublic class CopyOnWriteArrayList<E>   implements List<E>, RandomAccess, Cloneable, java.io.Serializable {    private static final long serialVersionUID = 8673264195747942595L;    //ReentrantLock锁，没有使用Synchronized\n    transient final ReentrantLock lock = new ReentrantLock();    //集合底层数据结构：数组（volatile修饰共享可见）\n    private volatile transient Object[] array;\n}\n\n```\nCopyOnWriteArrayList添加元素：在添加元素之前进行加锁操作，保证数据的原子性。在添加过程中，进行数组复制，修改操作，再将新生成的数组复制给集合中的array属性。最后，释放锁；\n\n由于array属性被volatile修饰，所以当添加完成后，其他线程就可以立刻查看到被修改的内容。\n```java\npublic boolean add(E e) {    final ReentrantLock lock = this.lock;    //加锁：\n    lock.lock();    try {        //获取集合中的数组：\n        Object[] elements = getArray();       \n        int len = elements.length;        \n        //数组复制：将此线程与其他线程对集合的操作区分开来，无论底层结构如何改变，本线程中的数据不受影响\n        Object[] newElements = Arrays.copyOf(elements, len + 1);        \n        //对新的数组进行操作：\n        newElements[len] = e;        //将原有数组指针指向新的数组对象：\n        setArray(newElements);     \n        return true;\n    } finally {        //释放锁：\n        lock.unlock();\n    }\n}\n\n```\n在add（）方法时已经加了锁，为什么还要进行数组复制呢?\n\n因为，在add（）时候加了锁，首先不会有多个线程同时进到add中去，这一点保证了数组的安全。当在一个线程执行add时，又进行了数组的复制操作，生成了一个新的数组对象，在add后又将新数组对象的指针指向了旧的数组对象指针，注意此时是指针的替换，原来旧的数组对象还存在。这样就实现了，添加方法无论如何操作数组对象，获取方法在获取到集合后，都不会受到其他线程添加元素的影响。\n\nCopyOnWriteArrayList保证了数据在多线程操作时的最终一致性。\n\n缺点也同样显著，那就是内存空间的浪费：因为在写操作时，进行数组复制，在内存中产生了两份相同的数组。如果数组对象比较大，那么就会造成频繁的GC操作，进而影响到系统的性能；\n\n### 什么是CAS?\nCAS是compare and swap的缩写，即我们所说的比较交换。\nCAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和A的值是一样的，那么就将内存里面的值更新成B。\n\n\n### 什么是AQS?\nAQS是AbstractQueuedSynchronizer的简称，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架。\n它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。\nAQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。\n\n### Fail-Fast机制是多线程原因造成的吗？\n是的。当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。\n例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件。\n\n迭代器在调用next()、remove()方法时都是调用checkForComodification()方法，该方法主要就是检测modCount == expectedModCount ? 若不等则抛出ConcurrentModificationException 异常，从而产生fail-fast机制。所以要弄清楚为什么会产生fail-fast机制我们就必须要用弄明白为什么modCount != expectedModCount ，他们的值在什么时候发生改变的。\n\nexpectedModCount 是在Itr中定义的：int expectedModCount = ArrayList.this.modCount;所以他的值是不可能会修改的，所以会变的就是modCount。\n\nArrayList中无论add、remove、clear方法只要是涉及了改变ArrayList元素的个数的方法都会导致modCount的改变。所以我们这里可以初步判断由于expectedModCount 得值与modCount的改变不同步，导致两者之间不等从而产生fail-fast机制。\n\n### 为什么要用线程池？常见的线程池有哪些？\n好处：\n1. 降低系统资源消耗，因为重复创建和销毁线程比较消耗系统性能；\n2. 提高响应速度，可以重复利用之前创建好的线程来执行任务；\n3. 实现对线程的管理，无限制的创建，不仅会消耗系统资源，有可能导致系统资源不足而产生阻塞的情况\n常见：\n1. newFixedThreadPool（固定大小的线程池），核心线程数和最大线程数一致，keepAliveTime为0，队列为LinkedBlockingQueue，适用于处理CPU密集型的任务\n2. newSingleThreadExecutor，核心线程数和最大线程数都为1，keepAliveTime为0，队列为LinkedBlockingQueue。SingleThreadExecutor适用于串行执行任务的场景，每个任务必须按顺序执行，不需要并发执行。\n3. newCachedThreadPool，核心线程数为0，且最大线程数为Integer.MAX_VALUE，可能会导致OOM，keepAliveTime为60，阻塞队列是SynchronousQueue。CachedThreadPool 用于并发执行大量短期的小任务。\n4. newScheduledThreadPool，最大线程数为Integer.MAX_VALUE，可能会导致OOM， 阻塞队列是DelayedWorkQueue，\n\n\n### 阻塞队列的常用方法？\nadd(E e):将元素e插入到队列末尾，如果插入成功，则返回true；如果插入失败（即队列已满），则会抛出异常；\n\nremove()：移除队首元素，若移除成功，则返回true；如果移除失败（队列为空），则会抛出异常；\n\noffer(E e)：将元素e插入到队列末尾，如果插入成功，则返回true；如果插入失败（即队列已满），则返回false；\n\npoll()：移除并获取队首元素，若成功，则返回队首元素；否则返回null；\n\npeek()：获取队首元素，若成功，则返回队首元素；否则返回null\n\nput(E e) 用来向队尾存入元素，如果队列满，则等待；\n\ntake() 用来从队首取元素，如果队列为空，则等待；\n\noffer(E e,long timeout, TimeUnit unit) 用来向队尾存入元素，如果队列满，则等待一定的时间，当时间期限达到时，如果还没有插入成功，则返回false；否则返回true；\n\npoll(long timeout, TimeUnit unit) 用来从队首取元素，如果队列空，则等待一定的时间，当时间期限达到时，如果取到，则返回null；否则返回取得的元素；\n\n方法\\处理方式  \t抛出异常\t   返回特殊值\t 一直阻塞\t超时退出\n\n插入方法\t        add(e)\t    offer(e)\t put(e)\t    offer(e,time,unit)\n\n移除方法     \tremove()\tpoll()\t     take()\t    poll(time,unit)\n\n检查方法\t       element()\tpeek()\t      不可用    \t不可用\n\n> - 抛出异常：是指当阻塞队列满时候，再往队列里插入元素，会抛出IllegalStateException(“Queue full”)异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常 。\n> - 返回特殊值：插入方法会返回是否成功，成功则返回true。移除方法，则是从队列里拿出一个元素，如果没有则返回null\n> - 一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里take元素，队列也会阻塞消费者线程，直到队列可用。\n> - 超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。\n\n一般情况下建议使用offer、poll和peek三个方法，不建议使用add和remove方法。因为使用offer、poll和peek三个方法可以通过返回值判断操作成功与否，而使用add和remove方法却不能达到这样的效果。\n\n### 堵塞队列的add，offer，put的区别？\n\nadd(E e):将元素e插入到队列末尾，如果插入成功，则返回true；如果插入失败（即队列已满），则会抛出异常；\n\noffer(E e)：将元素e插入到队列末尾，如果插入成功，则返回true；如果插入失败（即队列已满），则返回false；\n\nput方法用来向队尾存入元素，如果队列满，则等待；\n\n\n### 为什么数组比链表随机访问速度会快很多呢？\n1. 寻址操作次数链表要多一些。\n数组只需通过下标进行快速定位，找到第k个元素的地址，对其取地址就能获得该元素。\n链表要获得第k个元素，就要从第一个元素找起，多了多步寻址操作。\n\n2. CPU缓存会把一片连续的内存空间读入，因为数组结构是连续的内存地址，所以数组全部或者部分元素被连续存在CPU缓存里面。  而链表的节点是分散在堆空间里面的，这时候CPU缓存找不到的，只能是去多次读取内存。\n\n无论是在已知下标的情况下进入单个元素查询，还是整体遍历，数组都比链表存在明显优势。\n\n### 什么时候用定时器，什么时候用延时队列？\n延时任务有别于定时任务，定时任务往往是固定周期的，有明确的触发时间。而延时任务一般没有固定的开始时间，它常常是由一个事件触发的，而在这个事件触发之后的一段时间内触发另一个事件。也就是说，任务事件生成时并不想让消费者立即拿到，而是延迟一定时间后才接收到该事件进行消费。\n\n延迟任务相关的业务场景如下：\n\n场景一：在订单系统中，一个用户某个时刻下单之后通常有30分钟的时间进行支付，如果30分钟之内没有支付成功，那么这个订单将自动进行过期处理。\n场景二：用户某个时刻通过手机远程遥控家里的智能设备在指定的时间进行工作。这时就可以将用户指令发送到延时队列，当指令设定的时间到了再将指令推送到只能设备。\n\n1. 定时扫描\n所有的订单或者所有的命令一般都会存储在数据库中。我们会起一个线程定时去扫数据库或者一个数据库定时Job，找到那些超时的数据，直接更新状态，或者拿出来执行一些操作。这种方式很简单，不会引入其他的技术，开发周期短。\n如果数据量比较大，千万级甚至更多，插入频率很高的话，上面的方式在性能上会出现一些问题，查找和更新对会占用很多时间，轮询频率高的话甚至会影响数据入库。一种可以尝试的方式就是使用类似TBSchedule或Elastic-Job这样的分布式的任务调度加上数据分片功能，把需要判断的数据分到不同的机器上执行。\n如果数据量进一步增大，那扫数据库肯定就不行了。另一方面，对于订单这类数据，我们也许会遇到分库分表，那上述方案就会变得过于复杂，得不偿失。\n\n（1）消耗系统内存，由于定时任务一直在系统中占着进程，比较消耗内存\n\n（2）增加了数据库的压力，这个提现在两方面，一是长时间占着数据库的连接，二是查询基数大\n\n（3）存在较大的时间误差\n\n2. RabbitMQ延迟队列\nRabbitMQ延迟队列，主要是借助消息的TTL（Time to Live）和死信exchange（Dead Letter Exchanges）来实现。\n\n涉及到2个队列，一个用于发送消息，一个用于消息过期后的转发目标队列。\n注意：由于队列的先进先出特性，只有当过期的消息到了队列的顶端（队首），才会被真正的丢弃或者进入死信队列。所以在考虑使用RabbitMQ来实现延迟任务队列的时候，需要确保业务上每个任务的延迟时间是一致的。如果遇到不同的任务类型需要不同的延时的话，需要为每一种不同延迟时间的消息建立单独的消息队列。\n\n\n### 线程的阻塞与挂起有什么区别？\n（1）挂起是一种主动行为，因此恢复也应该要主动完成。而阻塞是一种被动行为，是在等待事件或者资源任务的表现，你不知道它什么时候被阻塞，也不清楚它什么时候会恢复阻塞。 \n\n（2）阻塞（pend）就是任务释放CPU，其他任务可以运行，一般在等待某种资源或者信号量的时候出现。挂起（suspend）不释放CPU。\n\n一般线程中的阻塞：\n\nA、线程执行了Thread.sleep(int millsecond);方法，当前线程放弃CPU，睡眠一段时间，然后再恢复执行\n\nB、线程执行一段同步代码，但是尚且无法获得相关的同步锁，只能进入阻塞状态，等到获取了同步锁，才能回复执行。\n\nC、线程执行了一个对象的wait()方法，直接进入阻塞状态，等待其他线程执行notify()或者notifyAll()方法。\n\nD、线程执行某些IO操作，因为等待相关的资源而进入了阻塞状态。比如说监听system.in，但是尚且没有收到键盘的输入，则进入阻塞状态。\n\n一般来说是不推荐使用suspend去挂起线程的,因为suspend在导致线程暂停的同时,并不会去释放任何锁资源。如果其他任何线程想要访问被它暂用的锁时,都会被牵连,导致无法正常继续运行，直到对应的线程上进行了resume操作。\n并且,如果resume操作意外的在suspend前执行了,那么被挂起的线程可能很难有机会被继续执行,更严重的是:它所占用的锁不会被释放,因此可能会导致整个系统工作不正常,而且,对于被挂起的线程,从它的线程状态上看,居然还是Runnable。\n如果在不合适的时候挂起线程（比如，锁定共享资源时），此时便可能会发生死锁条件——其他线程在等待该线程释放锁，但该线程却被挂起了，便会发生死锁。\n\n\n### sleep的时候，是否会释放已经获得到锁？\n不会释放锁\n\n### yield的作用是什么？\nThread.yield()方法的作用：暂停当前正在执行的线程，并执行其他线程。（可能没有效果）\n\nyield()让当前正在运行的线程回到可运行状态，以允许具有相同优先级的其他线程获得运行的机会。因此，使用yield()的目的是让具有相同优先级的线程之间能够适当的轮换执行。但是，实际中无法保证yield()达到让步的目的，因为，让步的线程可能被线程调度程序再次选中。\n\n### join的作用？\n让父线程等待子线程结束之后才能继续运行。\n当我们调用某个线程的这个方法时，这个方法会挂起调用线程，直到被调用线程结束执行，调用线程才会继续执行。\n\n###  sleep方法和yield方法的区别？\n1. sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会；\n2. 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（runable）状态；\n3. sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常；\n4. sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性。\n\nyield()方法对应了如下操作:先检测当前是否有相同的优先级的线程处于可运行状态，如果有则把执行权让给当前线程，如果没有就继续执行原来的线程。也就是说yield()遇到比自己小的就继续霸占执行权，如果遇到比自己大的或者同等级的，就把执行权让出来。\n\n### 什么时候会发生InterruptedException异常？\n1、java.lang.Object 类的 wait 方法\n2、java.lang.Thread 类的 sleep 方法\n3、java.lang.Thread 类的 join 方法\n\n当一个线程处于阻塞状态下（例如休眠）的情况下，调用了该线程的interrupt()方法，则会出现InterruptedException。\n每一个线程都有一个boolean类型的标志，此标志意思是当前的请求是否请求中断，默认为false。当一个线程A调用了线程B的interrupt方法时，那么线程B的是否请求的中断标志变为true。而线程B可以调用方法检测到此标志的变化。\n\n阻塞方法：如果线程B调用了阻塞方法，如果是否请求中断标志变为了true，那么它会取消阻塞，抛出InterruptedException异常。抛出异常的同时它会将线程B的是否请求中断标志置为false\n\n非阻塞方法：可以通过线程B的isInterrupted方法进行检测是否请求中断标志为true还是false，另外还有一个静态的方法interrupted方法也可以检测标志。但是静态方法它检测完以后会自动的将是否请求中断标志位置为false。例如线程A调用了线程B的interrupt的方法，那么如果此时线程B中用静态interrupted方法进行检测标志位的变化的话，那么第一次为true，第二次就为false。 interrupt() 只是设置线程B的中断状态。 在被中断线程B中运行的代码以后可以轮询中断状态，看看它是否被请求停止正在做的事情。中断状态可以通过 Thread.isInterrupted() 来读取，并且可以通过一个名为 Thread.interrupted() 的操作读取和清除。\n\n因此interrupt() 方法并不能立即中断线程，该方法仅仅告诉线程外部已经有中断请求，至于是否中断还取决于线程自己\n\n一种具有代表性的错误错误处理InterruptedException是“生吞”-- 捕捉它，然后什么也不做,然而这种方法忽略了这样一个事实：这期间可能发生中断，而中断可能导致应用程序丧失及时取消活动或关闭的能力。\n\n### 如何设计一个利用无锁来实现线程的安全？\nCAS+版本号\n\n### 隐式锁什么情况下会释放锁？\n1、当前线程的同步方法、代码块执行结束的时候释放\n\n2、当前线程在同步方法、同步代码块中遇到break 、 return 终于该代码块或者方法的时候释放。\n\n3、出现未处理的error或者exception导致异常结束的时候释放\n\n4、程序执行了 同步对象 wait 方法 ，当前线程暂停，释放锁\n\n注意：ReentrantLock 获取的锁，异常的时候也不会自动释放！ \n\n\n### 描述一下可重入的实现机制？\n作用：可重入锁可以避免线程死锁。\n\n可重入锁分公平锁和非公平锁：线程老老实实在同步队列排队机制的锁叫公平锁，在之前线程释放锁期间可以加塞的锁叫非公平锁，可重入锁的默认锁是非公平锁。\n\n重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁阻塞，该特性的实现需要解决以下两个问题：\n\n线程再次获取锁：锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。\n锁的最终释放。线程重复 n 次获取了锁，随后在第 n 次释放该锁后，其它线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于 0 时表示锁已经成功释放。\n\n\n### 什么是内存可见性？什么是寄存器可见性？\n一个线程对共享变量的修改,另一个线程可以立即看到,这称之为可见性\n\n当变量被volatile修饰之后，只要用到数据，直接从内存中读取，然后再在计算器中计算，最后返回给内存，这个时候变量就不在寄存器里面停留，就当寄存器不存在一样，这就称为内存可见性。\n\n数据从内存地址读取到寄存器里面，后面的计算过程中CPU就一直使用寄存器里面的值，即是内存地址上的值发生变化，CPU也不知道，而变量此时可以称为：寄存器可见性。\n\n### 什么是自旋？举例说明一下。自旋的后果是什么呢？\n如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。\n\n线程自旋是需要消耗cpu的，说白了就是让cpu在做无用功，如果一直获取不到锁，那线程也不能一直占用cpu自旋做无用功\n\n### notifyAll之后所有的线程都会在抢夺锁，如果抢夺失败怎么办？\nnotifyAll调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行，如果不成功则留在锁池等待锁被释放后再次参与竞争。\n\n### notify死锁分析\n先阐述两个概念：锁池和等待池\n\n> - 锁池:假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。\n> - 等待池:假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁后，进入到了该对象的等待池中。\n\n线程调用了对象的 wait()方法，便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。\nnotifyAll调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行，如果不成功则留在锁池等待锁被释放后再次参与竞争。\nnotify调用后，只会将等待池中的一个随机线程移到锁池。\n以生产者和消费者模式为例。\n\n假如只有一个生产者和消费者，所以等待池中始终只有一个线程，要么就是生产者唤醒消费者，要么消费者唤醒生产者，所以程序可以成功跑起来。\n假设两个消费者线程C1、C2，一个生产者线程P1。\n- C1，C2观察到缓存cache中无数据，进入等待池;\n- P1获取锁并设置cache数据，通过notify唤醒等待池中某个线程C1，假设C1被唤醒并放入锁池，然后P1释放锁、继续循环重新获取锁并因为检测到cache.size()==1而进入等待池；\n- 此时锁池中的线程为C1，C1会竞争到锁，从而消费数据，然后执行notify方法，并假设其notify方法会将C2从等待池移入锁池；\n- C2检测到cache为空，执行await()使自身进入锁池。因为自身的阻塞所以不能唤醒C1或P1，从而导致死锁！\n\n简单来说就是notify造成所有线程都在等待池中，notifyAll保证所有的线程进入到锁池中，可以去竞争锁。\n\n使用wait、notify的基本套路\n下面是effective java中推荐的标准写法：\n```java\nsynchronized (obj) {\n    while (<condition does not hold>)\n        obj.wait(timeout);\n    // Perform action appropriate to condition\n}\n```\n为什么要用while，改成if行不行，就像下面这样：\n```java\nsynchronized (obj) {\n    if (<condition does not hold>)\n        obj.wait(timeout);\n    // Perform action appropriate to condition\n}\n```\n\n我们将1.1和1.2代码中的while换成if，启动一个生产者，两个消费者线程，某个消费者线程会出现数组下标越界的异常，代码及原因分析如下：\n```java\npublic class WaitNotifyTest {\n    public static void main(String[] args) throws Exception {\n        List<Integer> cache = Lists.newArrayList();\n        new Thread(new Consumer(cache)).start();\n        new Thread(new Consumer(cache)).start();\n        Thread.sleep(1000);\n        new Thread(new Producer(cache)).start();\n    }\n}\n```\n\n消费者C1、C2发现cache为空，相继进入等待池；\nP1生产数据，放入cache并唤醒C1，同时自己进入等待池；\nC1消费数据，唤醒C2，C2从cache.wait()处开始执行，因为我们将while(cache.isEmpty())改成了if(cache.isEmpty())，C2不会再次检查cache是否为空，而是直接执行后续代码，这时cache的数据已经被C1消费完了，调用cache.get(0)产生数组下标越界！\n\n\n可以用Lock/Condition解决，两个Condition可以保证notify（signal）不同角色的线程\n\n### 什么是内存栅栏？\n内存屏障，也称内存栅栏（Memory Barrier）就是是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。简单来说内存屏障就是从本地或工作内存到主存之间的拷贝动作。\n\n内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。因此，对于敏感的程序块，写操作之后、读操作之前可以插入内存屏障。\n在多线程并发过程中，仅当写操作线程先跨越内存栅栏而读线程后跨越内存栅栏的情况下，写操作线程所做的变更才对其他线程可见。\n\n内存屏障可以被分为以下几种类型\n> - LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。\n> - StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。\n> - LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。\n> - StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。 \n\n### 什么是before-happen？\n如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。\n\nhappens-before原则定义如下：\n1. 如果一个操作happens-before(之前发生)另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。\n\n2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。\n\n相关的happens-before规则如下：\n1. 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；\n2. 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作；\n3. volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；\n4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；\n5. 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；\n6. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；\n7. 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；\n8. 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；\n\n\n### 常见的限流算法有哪些？\n1、令牌桶算法\n令牌桶算法是比较常见的限流算法之一，大概描述如下：\n1）、所有的请求在处理之前都需要拿到一个可用的令牌才会被处理；\n2）、根据限流大小，设置按照一定的速率往桶里添加令牌；\n3）、桶设置最大的放置令牌限制，当桶满时、新添加的令牌就被丢弃活着拒绝；\n4）、请求达到后首先要获取令牌桶中的令牌，拿着令牌才可以进行其他的业务逻辑，处理完业务逻辑之后，将令牌直接删除；\n5）、令牌桶有最低限额，当桶中的令牌达到最低限额的时候，请求处理完之后将不会删除令牌，以此保证足够的限流；\n\n漏桶算法\n\n漏桶作为计量工具（The Leaky Bucket Algorithm as a Meter）时，可以用于流量整形（Traffic Shaping）和流量控制（TrafficPolicing），漏桶算法的描述如下：\n\n1. 一个固定容量的漏桶，按照常量固定速率流出水滴\n\n2. 如果桶是空的，则不需流出水滴\n\n3. 可以以任意速率流入水滴到漏桶\n\n4. 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的\n\n　　有时候我们还使用计数器来进行限流，主要用来限制总并发数，比如数据库连接池、线程池、秒杀的并发数；只要全局总请求数或者一定时间段的总请求数设定的阀值则进行限流，是简单粗暴的总数量限流，而不是平均速率限流。\n\n令牌桶和漏桶对比：\n\n令牌桶是按照固定速率往桶中添加令牌，请求是否被处理需要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求；\n\n漏桶则是按照常量固定速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝；\n\n令牌桶限制的是平均流入速率（允许突发请求，只要有令牌就可以处理，支持一次拿3个令牌，4个令牌），并允许一定程度突发流量；\n\n漏桶限制的是常量流出速率（即流出速率是一个固定常量值，比如都是1的速率流出，而不能一次是1，下次又是2），从而平滑突发流入速率；\n\n令牌桶允许一定程度的突发，而漏桶主要目的是平滑流入速率；\n\n两个算法实现可以一样，但是方向是相反的，对于相同的参数得到的限流效果是一样的\n\n### synchronized锁的范围有哪些？\n代码块、实例方法、类方法\n\n### 为什么使用线程池技术？\n\n### 常见的创建线程池的三种方式是什么？各有什么特点？\n- newFixedThreadPool（固定大小的线程池）\n- newSingleThreadExecutor（单线程线程池）\n- newCachedThreadPool（可缓存线程的线程池）\n- newScheduledThreadPool\n\n### 可缓存的线程池中多少秒未使用的线程将被移除？\n60秒\n\n### 线程池内部的核心队列什么？\nArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务；\n\nLinkedBlockingQuene：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于 ArrayBlockingQueue\n\nSynchronousQuene：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于ArrayBlockingQuene；\n\nPriorityBlockingQuene：具有优先级的无界阻塞队列；\n\n### 线程池中控制线程创建数目的参数是什么？\ncorePoolsize、maximumPoolSize\n\n### 线程池在什么情况下需要丢弃处理？\n阻塞队列已经满了且工作线程数目已达到最大值\n\n### 线程池任务拒绝策略有哪些？\n1. 直接丢弃任务\n2. 丢弃任务，并报错（默认）\n3. 利用当前正在调用的线程来执行任务\n4. 将阻塞队列中最老的任务丢弃，并添加新的任务\n\n\n### 创建线程池常用的堵塞队列有哪些？\nArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务；\n\nLinkedBlockingQuene：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于 ArrayBlockingQueue\n\nSynchronousQuene：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于ArrayBlockingQuene；\n\nPriorityBlockingQuene：具有优先级的无界阻塞队列；\n\n\n### Future的主要功能是什么？\nFuture 是一种回调机制，简单的说是在事情结束前先将处理过程委任给执行线程。\n异步执行任务，等任务执行完会返回线程的执行结果。\nJDK5新增了Future接口，用于描述一个异步计算的结果。虽然 Future 以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的 CPU 资源，而且也不能及时地得到计算结果。\n\nFuture就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果等操作。\n\n\nFutrue提供了三种功能：\n1）判断任务是否完成；\n2）能够中断任务；\n3）能够获取任务执行结果。（最为常用的）\nCallable和Futrue的区别：Callable用于产生结果，Future用于获取结果\n### FutureTask的结构关系？FutureTask如何使用呢？\nFutureTask是一个可以返回任务执行结果的任务单元，通常在需要任务执行结果的场景中使用。\n\n- 需要计算并且要获得计算值的场景\n- 在搜索引擎中，在规定时间内获取搜索的结果，并将搜索结果返回给用户。（超时的任务将取消）\n\nFutureTask是Future接口的实现类也是唯一的实现类,FutureTask实现了RunnableFuture，即同时实现了Future接口及Runnable接口，可以很方便的在线程中被执行。\n```java\npublic class FutureTask<V> implements RunnableFuture<V> {\n    private Callable<V> callable; //任务执行的主体\n    private volatile int state; //任务执行的状态\n\n    public FutureTask(Callable<V> callable) {    \n        if (callable == null) \n            throw new NullPointerException();   \n        this.callable = callable;\n        this.state = NEW;  \n    }\n\n    public FutureTask(Runnable runnable, V result) { \n       this.callable = Executors.callable(runnable, result);\n       this.state = NEW;\n    }    \n\n    public run(){\n       /**省略部分代码**/\n        V result = callable.call();\n       /**省略部分代码**/\n    }\n}\n\n```\n可以看到在FutureTask中，真正执行的方法是其成员变量Callable，这也是为什么FutureTask和Callable一起被使用的原因\n```java\npublic class useFutureTask(){\n     public static void main(String[] args){\n          //建立一个简单的计算任务\n          Future<Integer> future =new FutureTask<>(()->{\n                Integer a=100;\n                Integer b=1000;\n                return a+b;\n          });\n          \n          //新建一个带缓存的线程池，并将任务放入线程池中执行\n          ExecutorService executor = Executors.newCachedThreadPool();\n          \n          executor.submit((FutureTask)future);\n\n          //获取任务计算结果\n          System.out.println(future.get());\n          \n          //记得关闭线程池，不然jvm虚拟机不会退出\n          executor.shutdown();\n     }\n}\n\n```\n\n### 参考资料\n- [volatile关键字的作用、原理](https://www.cnblogs.com/monkeysayhi/p/7654460.html)\n- [从一个死锁分析wait,notify,notifyAll](https://www.jianshu.com/p/45626f4e0fc1?from=timeline)\n- [使用RabbitMQ实现延迟任务](https://www.cnblogs.com/haoxinyue/p/6613706.html)\n- [延时任务队列的原理与实现总结](https://www.jianshu.com/p/a8c1458998aa)\n- [Java集合--线程安全(CopyOnWrite机制)](https://www.imooc.com/article/34600)\n- [浅析java内存模型--JMM(Java Memory Model)](https://www.cnblogs.com/lewis0077/p/5143268.html)\n- [深入分析 ThreadLocal 内存泄漏问题](http://www.importnew.com/22039.html)\n- [将ThreadLocal变量设置为private static的好处是啥？](https://www.zhihu.com/question/35250439)\n","tags":["线程"],"categories":["线程"]},{"title":"一致性hash及应用","url":"/2019/04/11/hash一致性及应用/","content":"\n### 简介\n一致性哈希算法是分布式系统中常用的算法。一致性哈希算法解决了普通余数Hash算法伸缩性差的问题，可以保证在上线、下线服务器的情况下尽量有多的请求命中原来路由到的服务器。\n\n\n### 为什么要使用一致性hash\n\n对于分布式缓存，不同机器上存储不同对象的数据。为了实现这些缓存机器的负载均衡，可以使用式子1来定位对象缓存的存储机器：\n```java\nm = hash(o) mod n ——式子1\n```\n\n其中，o为对象的名称，n为机器的数量，m为机器的编号，hash为一hash函数。\n![](架构图.png)\n上图的负载均衡器（load balancer）正是使用式子1来将客户端对不同对象的请求分派到不同的机器上执行，例如，对于对象o，经过式子1的计算，得到m的值为3，那么所有对对象o的读取和存储的请求都被发往机器3执行。\n\n式子1在大部分时候都可以工作得很好，然而，当机器需要扩容或者机器出现宕机的情况下，事情就比较棘手了。 \n当机器扩容，需要增加一台缓存机器时，负载均衡器使用的式子变成：\n```java\nm = hash(o) mod (n + 1) ——式子2\n```\n当机器宕机，机器数量减少一台时，负载均衡器使用的式子变成：\n```java\nm = hash(o) mod (n - 1) ——式子3\n```\n我们以机器扩容的情况为例，说明简单的取模方法会导致什么问题。假设机器由3台变成4台，对象o1由式子1计算得到的m值为2，由式子2计算得到的m值却可能为0，1，2，3（一个 3t + 2的整数对4取模，其值可能为0，1，2，3，读者可以自行验证），**大约有75%（3/4)的可能性出现缓存访问不命中的现象。随着机器集群规模的扩大，这个比例线性上升。当99台机器再加入1台机器时，不命中的概率是99%（99/100）。这样的结果显然是不能接受的，因为这会导致数据库访问的压力陡增，严重情况，还可能导致数据库宕机。**\n\n一致性hash算法正是为了解决此类问题的方法，它可以保证当机器增加或者减少时，对缓存访问命中的概率影响减至很小。\n\n\n### 一致性Hash性质\n考虑到分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的，尤其是在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其hash值（通常与系统中的节点数目有关），由于hash值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性hash就显得至关重要，良好的分布式cahce系统中的一致性hash算法应该满足以下几个方面：\n\n- 平衡性(Balance)\n平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。\n\n- 单调性(Monotonicity)\n单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。简单的哈希算法往往不能满足单调性的要求，如最简单的线性哈希：x = (ax + b) mod (P)，在上式中，P表示全部缓冲的大小。不难看出，当缓冲大小发生变化时(从P1到P2)，原来所有的哈希结果均会发生变化，从而不满足单调性的要求。哈希结果的变化意味着当缓冲空间发生变化时，所有的映射关系需要在系统内全部更新。而在P2P系统内，缓冲的变化等价于Peer加入或退出系统，这一情况在P2P系统中会频繁发生，因此会带来极大计算和传输负荷。单调性就是要求哈希算法能够应对这种情况。\n\n- 分散性(Spread)\n在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。\n\n- 负载(Load)\n负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。\n\n- 平滑性(Smoothness)\n平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。\n\n### 原理\n简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希空间环如下：\n![](哈希空间环.png)\n> - 整个空间按顺时针方向组织。0和232-1在零点中方向重合。\n下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将四台服务器使用ip地址哈希后在环空间的位置如下：\n![](四台服务器hash环.png)\n接下来使用如下算法定位数据访问到相应服务器：\n\n> - 将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。\n\n例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：\n![](数据hash环.png)\n根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。\n\n### 一致性Hash算法的容错性和可扩展性\n#### 容错性\n现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据**仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响**。\n![](节点失效.png)\n\n#### 可扩展性\n下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：\n![](增加节点.png)\n此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据**仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响**。\n\n综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。\n\n### Hash环的数据倾斜问题\n一致性哈希算法在服务节点太少时，容易**因为节点分布不均匀而造成数据倾斜问题**。例如系统中只有两台服务器，其环分布如下：\n![](数据倾斜.png)\n此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。\n为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制。\n> - 对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。\n\n具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：\n![](虚拟节点.png)\n\n同时数据定位算法不变，只是多了一步**虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上**。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。\n\n### 一致性hash算法的Java实现\n1. 不带虚拟节点的\n```java\npackage hash;\n \nimport java.util.SortedMap;\nimport java.util.TreeMap;\n \n/**\n * 不带虚拟节点的一致性Hash算法\n */\npublic class ConsistentHashingWithoutVirtualNode {\n \n\t//待添加入Hash环的服务器列表\n\tprivate static String[] servers = { \"192.168.0.0:111\", \"192.168.0.1:111\",\n\t\t\t\"192.168.0.2:111\", \"192.168.0.3:111\", \"192.168.0.4:111\" };\n \n\t//key表示服务器的hash值，value表示服务器\n\tprivate static SortedMap<Integer, String> sortedMap = new TreeMap<Integer, String>();\n \n\t//程序初始化，将所有的服务器放入sortedMap中\n\tstatic {\n\t\tfor (int i=0; i<servers.length; i++) {\n\t\t\tint hash = getHash(servers[i]);\n\t\t\tSystem.out.println(\"[\" + servers[i] + \"]加入集合中, 其Hash值为\" + hash);\n\t\t\tsortedMap.put(hash, servers[i]);\n\t\t}\n\t\tSystem.out.println();\n\t}\n \n\t//得到应当路由到的结点\n\tprivate static String getServer(String key) {\n\t\t//得到该key的hash值\n\t\tint hash = getHash(key);\n\t\t//得到大于该Hash值的所有Map\n\t\tSortedMap<Integer, String> subMap = sortedMap.tailMap(hash);\n\t\tif(subMap.isEmpty()){\n\t\t\t//如果没有比该key的hash值大的，则从第一个node开始\n\t\t\tInteger i = sortedMap.firstKey();\n\t\t\t//返回对应的服务器\n\t\t\treturn sortedMap.get(i);\n\t\t}else{\n\t\t\t//第一个Key就是顺时针过去离node最近的那个结点\n\t\t\tInteger i = subMap.firstKey();\n\t\t\t//返回对应的服务器\n\t\t\treturn subMap.get(i);\n\t\t}\n\t}\n\t\n\t//使用FNV1_32_HASH算法计算服务器的Hash值,这里不使用重写hashCode的方法，最终效果没区别\n\tprivate static int getHash(String str) {\n\t\tfinal int p = 16777619;\n\t\tint hash = (int) 2166136261L;\n\t\tfor (int i = 0; i < str.length(); i++)\n\t\t\thash = (hash ^ str.charAt(i)) * p;\n\t\thash += hash << 13;\n\t\thash ^= hash >> 7;\n\t\thash += hash << 3;\n\t\thash ^= hash >> 17;\n\t\thash += hash << 5;\n \n\t\t// 如果算出来的值为负数则取其绝对值\n\t\tif (hash < 0)\n\t\t\thash = Math.abs(hash);\n\t\treturn hash;\n\t\t}\n \n\tpublic static void main(String[] args) {\n\t\tString[] keys = {\"太阳\", \"月亮\", \"星星\"};\n\t\tfor(int i=0; i<keys.length; i++)\n\t\t\tSystem.out.println(\"[\" + keys[i] + \"]的hash值为\" + getHash(keys[i])\n\t\t\t\t\t+ \", 被路由到结点[\" + getServer(keys[i]) + \"]\");\n\t}\n}\n```\n2. 带虚拟节点的\n```java\npackage hash;\n \nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.SortedMap;\nimport java.util.TreeMap;\n \nimport org.apache.commons.lang.StringUtils;\n \n/**\n  * 带虚拟节点的一致性Hash算法\n  */\n public class ConsistentHashingWithoutVirtualNode {\n \n     //待添加入Hash环的服务器列表\n     private static String[] servers = {\"192.168.0.0:111\", \"192.168.0.1:111\", \"192.168.0.2:111\",\n             \"192.168.0.3:111\", \"192.168.0.4:111\"};\n     \n     //真实结点列表,考虑到服务器上线、下线的场景，即添加、删除的场景会比较频繁，这里使用LinkedList会更好\n     private static List<String> realNodes = new LinkedList<String>();\n     \n     //虚拟节点，key表示虚拟节点的hash值，value表示虚拟节点的名称\n     private static SortedMap<Integer, String> virtualNodes = new TreeMap<Integer, String>();\n             \n     //虚拟节点的数目，这里写死，为了演示需要，一个真实结点对应5个虚拟节点\n     private static final int VIRTUAL_NODES = 5;\n     \n     static{\n         //先把原始的服务器添加到真实结点列表中\n         for(int i=0; i<servers.length; i++)\n             realNodes.add(servers[i]);\n         \n         //再添加虚拟节点，遍历LinkedList使用foreach循环效率会比较高\n         for (String str : realNodes){\n             for(int i=0; i<VIRTUAL_NODES; i++){\n                 String virtualNodeName = str + \"&&VN\" + String.valueOf(i);\n                 int hash = getHash(virtualNodeName);\n                 System.out.println(\"虚拟节点[\" + virtualNodeName + \"]被添加, hash值为\" + hash);\n                 virtualNodes.put(hash, virtualNodeName);\n             }\n         }\n         System.out.println();\n     }\n     \n     //使用FNV1_32_HASH算法计算服务器的Hash值,这里不使用重写hashCode的方法，最终效果没区别\n     private static int getHash(String str){\n         final int p = 16777619;\n         int hash = (int)2166136261L;\n         for (int i = 0; i < str.length(); i++)\n             hash = (hash ^ str.charAt(i)) * p;\n         hash += hash << 13;\n         hash ^= hash >> 7;\n         hash += hash << 3;\n         hash ^= hash >> 17;\n         hash += hash << 5;\n         \n         // 如果算出来的值为负数则取其绝对值\n         if (hash < 0)\n             hash = Math.abs(hash);\n         return hash;\n     }\n     \n     //得到应当路由到的结点\n     private static String getServer(String key){\n        //得到该key的hash值\n         int hash = getHash(key);\n         // 得到大于该Hash值的所有Map\n         SortedMap<Integer, String> subMap = virtualNodes.tailMap(hash);\n         String virtualNode;\n         if(subMap.isEmpty()){\n            //如果没有比该key的hash值大的，则从第一个node开始\n            Integer i = virtualNodes.firstKey();\n            //返回对应的服务器\n            virtualNode = virtualNodes.get(i);\n         }else{\n            //第一个Key就是顺时针过去离node最近的那个结点\n            Integer i = subMap.firstKey();\n            //返回对应的服务器\n            virtualNode = subMap.get(i);\n         }\n         //virtualNode虚拟节点名称要截取一下\n         if(StringUtils.isNotBlank(virtualNode)){\n             return virtualNode.substring(0, virtualNode.indexOf(\"&&\"));\n         }\n         return null;\n     }\n     \n     public static void main(String[] args){\n         String[] keys = {\"太阳\", \"月亮\", \"星星\"};\n         for(int i=0; i<keys.length; i++)\n             System.out.println(\"[\" + keys[i] + \"]的hash值为\" +\n                     getHash(keys[i]) + \", 被路由到结点[\" + getServer(keys[i]) + \"]\");\n     }\n }\n```\n\n### 总结 \n一致性hash算法解决了分布式环境下机器增加或者减少时，简单的取模运算无法获取较高命中率的问题。通过虚拟节点的使用，一致性hash算法可以均匀分担机器的负载，解决数据倾斜问题。\n\n### 参考资料\n- [一致性哈希算法原理](https://www.cnblogs.com/lpfuture/p/5796398.html)\n- [一致性Hash(Consistent Hashing)原理剖析及Java实现](https://blog.csdn.net/suifeng629/article/details/81567777)","tags":["hash"],"categories":["hash"]},{"title":"线程池原理","url":"/2019/04/09/线程池原理/","content":"\n### 为什么要用线程池？\n使用线程池来管理线程，使用线程池管理线程主要有如下好处：\n\n1. 降低资源消耗。 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。\n\n2. 提升系统响应速度。通过复用线程，省去创建线程的过程，因此整体上提升了系统的响应速度；\n\n3. 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，有可能导致系统资源不足而产生阻塞的情况，还会降低系统的稳定性，因此，需要使用线程池来管理线程。\n\n### 线程池状态\n\n程池是有状态的，线程池的开启到关闭的过程就是线程池状态的一个流转的过程。\n线程池共有五种状态：\n![](线程池状态.png)\n\n|状态 \t    |含义|\n| ------    | ------ |\n| RUNNING\t| 运行状态，该状态下线程池可以接受新的任务，也可以处理阻塞队列中的任务,执行 shutdown 方法可进入 SHUTDOWN 状态,执行 shutdownNow 方法可进入 STOP 状态|\n| SHUTDOWN  | 待关闭状态，不再接受新的任务，继续处理阻塞队列中的任务,当阻塞队列中的任务为空，并且工作线程数为0时，进入 TIDYING 状态|\n| STOP\t    | 停止状态，不接收新任务，也不处理阻塞队列中的任务，并且会尝试结束执行中的任务, 当工作线程数为0时，进入 TIDYING 状态|\n| TIDYING\t| 整理状态，此时任务都已经执行完毕，并且也没有工作线程, 执行 terminated 方法后进入 TERMINATED 状态|\n| TERMINATED  | 终止状态，此时线程池完全终止了，并完成了所有资源的释放|\n\n\n### 如何创建线程池\n《阿里巴巴Java开发手册》中强制线程池**不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式**，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。\n\n> Executors 返回线程池对象的弊端如下：\n> - FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。\n> - CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。\n\n> 1. FixedThreadPool ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。\n\n> 2. SingleThreadExecutor： 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。\n\n> 3. CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n\n\nThreadPoolExecutor提供了构造函数:\n```java\nThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler)\n```\n\n### 重要属性\n#### 线程状态和工作线程数量\n首先线程池是有状态的，不同状态下线程池的行为是不一样的。\n\n另外线程池肯定是需要线程去执行具体的任务的，所以在线程池中就封装了一个内部类 Worker 作为工作线程，每个 Worker 中都维持着一个 Thread。\n\n线程池的重点之一就是控制线程资源合理高效的使用，所以必须控制工作线程的个数，所以需要保存当前线程池中工作线程的个数。\n\n看到这里，你是否觉得需要用两个变量来保存线程池的状态和线程池中工作线程的个数呢？但是在 ThreadPoolExecutor 中只用了一个 AtomicInteger 型的变量就保存了这两个属性的值，那就是 ctl。\n![](线程池状态及个数.png)\n\nctl 的高3位用来表示线程池的状态(runState)，低29位用来表示工作线程的个数(workerCnt)\n\n>  为什么要用3位来表示线程池的状态呢?\n>  原因是线程池一共有5种状态，而2位只能表示出4种情况，所以至少需要3位才能表示得了5种状态。\n\n#### 核心线程数和最大线程数\n\n核心线程数：corePoolSize 用来表示线程池中的核心线程的数量，也可以称为可闲置的线程数量。\n\n> 线程池新建线程的时候，如果当前线程总数小于corePoolSize，则新建的是核心线程，如果超过corePoolSize，则新建的是非核心线程 \n> 核心线程默认情况下会一直存活在线程池中，即使这个核心线程啥也不干(闲置状态)。 \n> 如果指定ThreadPoolExecutor的allowCoreThreadTimeOut这个属性为true，那么核心线程如果不干活(闲置状态)的话，超过一定时间(时长下面参数决定)，就会被销毁掉\n\n\n最大线程数：maximumPoolSize 用来表示线程池中最多能够创建的线程数量。\n\n> 最大线程数 = 核心线程数 + 非核心线程数\n\n现在我们有一个疑问，既然已经有了标识工作线程的个数的变量了，为什么还要有核心线程数、最大线程数呢？\n\n其实你这样想就能够理解了，创建线程是有代价的，不能每次要执行一个任务时就创建一个线程，但是也不能在任务非常多的时候，只有少量的线程在执行，这样任务是来不及处理的，而是应该创建合适的足够多的线程来及时的处理任务。随着任务数量的变化，当任务数明显很小时，原本创建的多余的线程就没有必要再存活着了，因为这时使用少量的线程就能够处理的过来了，所以说真正工作的线程的数量，是随着任务的变化而变化的。\n\n那核心线程数和最大线程数与工作线程个数的关系是什么呢？\n\n![](线程池核心线程数和最大线程数.png)\n工作线程的个数可能从0到最大线程数之间变化，当执行一段时间之后可能维持在 corePoolSize，但也不是绝对的，取决于核心线程是否允许被超时回收。\n\n#### 非核心线程存活时间-keepAliveTime \n一个非核心线程，如果不干活(闲置状态)的时长超过这个参数所设定的时长，就会被销毁掉。\n如果设置allowCoreThreadTimeOut = true，则会作用于核心线程。\n\n#### 创建线程的工厂\n线程该如何来创建呢？这个任务就交给了线程工厂 ThreadFactory 来完成。\n\n\n#### 缓存任务的阻塞队列\n当线程池接收到一个任务时，如果工作线程数没有达到corePoolSize，那么就会新建一个线程，并绑定该任务，**直到工作线程的数量达到 corePoolSize 前都不会重用之前的线程**。当工作线程数达到corePoolSize了，这时又接收到新任务时，会将任务存放在一个阻塞队列中等待核心线程去执行。如果队列满了，则新建非核心线程执行任务。\n\n> 为什么不直接创建更多的线程来执行新任务呢?\n原因是核心线程中很可能已经有线程执行完自己的任务了，或者有其他线程马上就能处理完当前的任务，并且接下来就能投入到新的任务中去，所以阻塞队列是一种缓冲的机制，给核心线程一个机会让他们充分发挥自己的能力。另外一个值得考虑的原因是，创建线程毕竟是比较昂贵的，不可能一有任务要执行就去创建一个新的线程。\n\n##### 常用的workQueue类型\n 1. **SynchronousQueue：**这个队列接收到任务的时候，会直接提交给线程处理，而不保留它。如果所有线程都在工作怎么办？那就新建一个线程来处理这个任务！所以为了保证不出现<线程数达到了maximumPoolSize而不能新建线程>的错误，使用这个类型队列的时候，maximumPoolSize一般指定成Integer.MAX_VALUE，即无限大。\n\n 2. **LinkedBlockingQueue：**这个队列接收到任务的时候，由于这个队列没有最大值限制，即所有超过核心线程数的任务都将被添加到队列中，这也就导致了maximumPoolSize的设定失效，因为总线程数永远不会超过corePoolSize。\n\n 3. **ArrayBlockingQueue：**可以限定队列的长度。\n\n 4. **DelayQueue：**队列内元素必须实现Delayed接口，这就意味着你传进去的任务必须先实现Delayed接口。这个队列接收到任务时，首先先入队，只有达到了指定的延时时间，才会执行任务\n\n\n### 拒绝策略\n如果是有界的阻塞队列，那就存在队列满的情况，也存在工作线程的数据已经达到最大线程数的时候。如果这时候再有新的任务提交时，显然线程池已经心有余而力不足了，因为既没有空余的队列空间来存放该任务，也无法创建新的线程来执行该任务了，所以这时我们就需要有一种拒绝策略，即 handler。\n\n拒绝策略是一个 RejectedExecutionHandler 类型的变量，用户可以自行指定拒绝的策略，如果不指定的话，线程池将使用默认的拒绝策略：抛出异常。\n\n> AbortPolicy： 直接拒绝所提交的任务，并抛出RejectedExecutionException异常；\n> CallerRunsPolicy：只用调用者所在的线程来执行任务；\n> DiscardPolicy：不处理直接丢弃掉任务；\n> DiscardOldestPolicy：丢弃掉阻塞队列中存放时间最久的任务，执行当前任务\n\n### 工作流程\n![](工作流程.png)\n整个过程可以拆分成以下几个部分：\n\n#### 提交任务\n当向线程池提交一个新的任务时，线程池有三种处理情况，分别是：创建一个工作线程来执行该任务、将任务加入阻塞队列、拒绝该任务。\n\n提交任务的过程也可以拆分成以下几个部分：\n\n- 当工作线程数小于核心线程数时，直接创建新的核心工作线程\n\n- 当工作线程数大于核心线程数时，就需要尝试将任务添加到阻塞队列中去\n\n- 如果能够加入成功，说明队列还没有满，那么需要做以下的二次验证来保证添加进去的任务能够成功被执行\n\n  1、验证当前线程池的运行状态，如果是非RUNNING状态，则需要将任务从阻塞队列中移除，然后拒绝该任务\n\n  2、验证当前线程池中的工作线程的个数，如果为0，则需要主动添加一个空工作线程来执行刚刚添加到阻塞队列中的任务\n\n- 如果加入失败，则说明队列已经满了，那么这时就需要创建新的“临时”工作线程来执行任务\n\n  1、 如果创建成功，则直接执行该任务\n\n  2、 如果创建失败，则说明工作线程数已经等于最大线程数了，则只能拒绝该任务了\n\n整个过程可以用下面这张图来表示：\n![](提交任务.png)\n\n#### 创建工作线程\n创建工作线程需要做一系列的判断，需要确保当前线程池可以创建新的线程之后，才能创建。\n\n首先，当线程池的状态是 SHUTDOWN 或者 STOP 时，则不能创建新的线程。\n\n另外，当线程工厂创建线程失败时，也不能创建新的线程。\n\n还有就是当前工作线程的数量与核心线程数、最大线程数进行比较，如果前者大于后者的话，也不允许创建。\n\n除此之外，会尝试通过 CAS 来自增工作线程的个数，如果自增成功了，则会创建新的工作线程，即 Worker 对象。\n\n然后加锁进行二次验证是否能够创建工作线程，最后如果创建成功，则会启动该工作线程。\n\n#### 启动工作线程\n当工作线程创建成功后，也就是 Worker 对象已经创建好了，这时就需要启动该工作线程，让线程开始干活了，Worker 对象中关联着一个 Thread，所以要启动工作线程的话，只要通过 worker.thread.start() 来启动该线程即可。\n\n启动完了之后，就会执行 Worker 对象的 run 方法，而不是 start()。因为 Worker 实现了 Runnable 接口，所以本质上 Worker 也是一个线程。\n\n通过线程 start 开启之后就会调用到 Runnable 的 run 方法，在 worker 对象的 run 方法中，调用了 runWorker(this) 方法，也就是把当前对象传递给了 runWorker 方法，让他来执行。\n\n#### 获取任务并执行\n在 runWorker 方法被调用之后，就是执行具体的任务了，首先需要拿到一个可以执行的任务，而 Worker 对象中默认绑定了一个任务，如果该任务不为空的话，那么就是直接执行。\n\n执行完了之后，就会去阻塞队列中获取任务来执行，而获取任务的过程，需要考虑当前工作线程的个数。\n\n- 如果工作线程数大于核心线程数，那么就需要通过 poll 来获取，因为这时需要对闲置的线程进行回收；\n\n- 如果工作线程数小于等于核心线程数，那么就可以通过 take 来获取了，因此这时所有的线程都是核心线程，不需要进行回收，前提是没有设置 allowCoreThreadTimeOut\n\n### ThreadPoolExecutor的execute方法\nexecute方法源码如下：\n```java\npublic void execute(Runnable command) {\n    if (command == null)\n        throw new NullPointerException();\n    /*\n     * clt记录着runState和workerCount\n     */\n    int c = ctl.get();\n    /*\n     * workerCountOf方法取出低29位的值，表示当前活动的线程数；\n     * 如果当前活动线程数小于corePoolSize，则新建一个线程放入线程池中；\n     * 并把任务添加到该线程中。\n     */\n    if (workerCountOf(c) < corePoolSize) {\n        /*\n         * addWorker中的第二个参数表示限制添加线程的数量是根据corePoolSize来判断还是maximumPoolSize来判断；\n         * 如果为true，根据corePoolSize来判断；\n         * 如果为false，则根据maximumPoolSize来判断\n         */\n        if (addWorker(command, true))\n            return;\n        /*\n         * 如果添加失败，则重新获取ctl值\n         */\n        c = ctl.get();\n    }\n    /*\n     * 如果当前线程池是运行状态并且任务添加到队列成功\n     */\n    if (isRunning(c) && workQueue.offer(command)) {\n        // 重新获取ctl值\n        int recheck = ctl.get();\n        // 再次判断线程池的运行状态，如果不是运行状态，由于之前已经把command添加到workQueue中了，\n        // 这时需要移除该command\n        // 执行过后通过handler使用拒绝策略对该任务进行处理，整个方法返回\n        if (! isRunning(recheck) && remove(command))\n            reject(command);\n        /*\n         * 获取线程池中的有效线程数，如果数量是0，则执行addWorker方法\n         * 这里传入的参数表示：\n         * 1. 第一个参数为null，表示在线程池中创建一个线程，但不去启动；\n         * 2. 第二个参数为false，将线程池的有限线程数量的上限设置为maximumPoolSize，添加线程时根据maximumPoolSize来判断；\n         * 如果判断workerCount大于0，则直接返回，在workQueue中新增的command会在将来的某个时刻被执行。\n         */\n        else if (workerCountOf(recheck) == 0)\n            addWorker(null, false);\n    }\n    /*\n     * 如果执行到这里，有两种情况：\n     * 1. 线程池已经不是RUNNING状态；\n     * 2. 线程池是RUNNING状态，但workerCount >= corePoolSize并且workQueue已满。\n     * 这时，再次调用addWorker方法，但第二个参数传入为false，将线程池的有限线程数量的上限设置为maximumPoolSize；\n     * 如果失败则拒绝该任务\n     */\n    else if (!addWorker(command, false))\n        reject(command);\n}\n```\n这里要注意一下addWorker(null, false);，也就是创建一个线程，但并没有传入任务，因为任务已经被添加到workQueue中了，所以worker在执行的时候，会直接从workQueue中获取任务。所以，在workerCountOf(recheck) == 0时执行addWorker(null, false);也是为了保证线程池在RUNNING状态下必须要有一个线程来执行任务。\n\nexecute方法的执行示意图：\n![](excute.png)\n\n#### addWorker方法\naddWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数 用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize，代码如下：\n```java\nprivate boolean addWorker(Runnable firstTask, boolean core) {\n    retry:\n    for (;;) {\n        int c = ctl.get();\n        // 获取运行状态\n        int rs = runStateOf(c);\n        \n        /*\n         * 这个if判断\n         * 如果rs >= SHUTDOWN，则表示此时不再接收新任务；\n         * 接着判断以下3个条件，只要有1个不满足，则返回false：\n         * 1. rs == SHUTDOWN，这时表示关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务\n         * 2. firsTask为空\n         * 3. 阻塞队列不为空\n         * \n         * 首先考虑rs == SHUTDOWN的情况\n         * 这种情况下不会接受新提交的任务，所以在firstTask不为空的时候会返回false；\n         * 然后，如果firstTask为空，并且workQueue也为空，则返回false，\n         * 因为队列中已经没有任务了，不需要再添加线程了\n         */\n        // Check if queue empty only if necessary.\n        if (rs >= SHUTDOWN &&\n            ! (rs == SHUTDOWN &&\n               firstTask == null &&\n               ! workQueue.isEmpty()))\n            return false;\n        for (;;) {\n            // 获取线程数\n            int wc = workerCountOf(c);\n            // 如果wc超过CAPACITY，也就是ctl的低29位的最大值（二进制是29个1），返回false；\n            // 这里的core是addWorker方法的第二个参数，如果为true表示根据corePoolSize来比较，\n            // 如果为false则根据maximumPoolSize来比较。\n            // \n            if (wc >= CAPACITY ||\n                wc >= (core ? corePoolSize : maximumPoolSize))\n                return false;\n            // 尝试增加workerCount，如果成功，则跳出第一个for循环\n            if (compareAndIncrementWorkerCount(c))\n                break retry;\n            // 如果增加workerCount失败，则重新获取ctl的值\n            c = ctl.get();  // Re-read ctl\n            // 如果当前的运行状态不等于rs，说明状态已被改变，返回第一个for循环继续执行\n            if (runStateOf(c) != rs)\n                continue retry;\n            // else CAS failed due to workerCount change; retry inner loop\n        }\n    }\n    boolean workerStarted = false;\n    boolean workerAdded = false;\n    Worker w = null;\n    try {\n        // 根据firstTask来创建Worker对象\n        w = new Worker(firstTask);\n        // 每一个Worker对象都会创建一个线程\n        final Thread t = w.thread;\n        if (t != null) {\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                // Recheck while holding lock.\n                // Back out on ThreadFactory failure or if\n                // shut down before lock acquired.\n                int rs = runStateOf(ctl.get());\n                // rs < SHUTDOWN表示是RUNNING状态；\n                // 如果rs是RUNNING状态或者rs是SHUTDOWN状态并且firstTask为null，向线程池中添加线程。\n                // 因为在SHUTDOWN时不会在添加新的任务，但还是会执行workQueue中的任务\n                if (rs < SHUTDOWN ||\n                    (rs == SHUTDOWN && firstTask == null)) {\n                    if (t.isAlive()) // precheck that t is startable\n                        throw new IllegalThreadStateException();\n                    // workers是一个HashSet\n                    workers.add(w);\n                    int s = workers.size();\n                    // largestPoolSize记录着线程池中出现过的最大线程数量\n                    if (s > largestPoolSize)\n                        largestPoolSize = s;\n                    workerAdded = true;\n                }\n            } finally {\n                mainLock.unlock();\n            }\n            if (workerAdded) {\n                // 启动线程\n                t.start();\n                workerStarted = true;\n            }\n        }\n    } finally {\n        if (! workerStarted)\n            addWorkerFailed(w);\n    }\n    return workerStarted;\n}\n\n```\n这里的t.start()这个语句，启动时会调用Worker类中的run方法，Worker本身实现了Runnable接口，所以一个Worker类型的对象也是一个线程。\n\n#### Worker类\n线程池中的每一个线程被封装成一个Worker对象，ThreadPool维护的其实就是一组Worker对象，看一下Worker的定义：\n```java\nprivate final class Worker\n        extends AbstractQueuedSynchronizer\n        implements Runnable\n{\n    /**\n     * This class will never be serialized, but we provide a\n     * serialVersionUID to suppress a javac warning.\n     */\n    private static final long serialVersionUID = 6138294804551838833L;\n    /** Thread this worker is running in.  Null if factory fails. */\n    final Thread thread;\n    /** Initial task to run.  Possibly null. */\n    Runnable firstTask;\n    /** Per-thread task counter */\n    volatile long completedTasks;\n    /**\n     * Creates with given first task and thread from ThreadFactory.\n     * @param firstTask the first task (null if none)\n     */\n    Worker(Runnable firstTask) {\n        setState(-1); // inhibit interrupts until runWorker\n        this.firstTask = firstTask;\n        this.thread = getThreadFactory().newThread(this);\n    }\n    /** Delegates main run loop to outer runWorker  */\n    public void run() {\n        runWorker(this);\n    }\n    // Lock methods\n    //\n    // The value 0 represents the unlocked state.\n    // The value 1 represents the locked state.\n    protected boolean isHeldExclusively() {\n        return getState() != 0;\n    }\n    protected boolean tryAcquire(int unused) {\n        if (compareAndSetState(0, 1)) {\n            setExclusiveOwnerThread(Thread.currentThread());\n            return true;\n        }\n        return false;\n    }\n    protected boolean tryRelease(int unused) {\n        setExclusiveOwnerThread(null);\n        setState(0);\n        return true;\n    }\n    public void lock()        { acquire(1); }\n    public boolean tryLock()  { return tryAcquire(1); }\n    public void unlock()      { release(1); }\n    public boolean isLocked() { return isHeldExclusively(); }\n    void interruptIfStarted() {\n        Thread t;\n        if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {\n            try {\n                t.interrupt();\n            } catch (SecurityException ignore) {\n            }\n        }\n    }\n}\n```\n\n### 线程池的关闭\n关闭线程池，可以通过shutdown和shutdownNow这两个方法。它们的原理都是遍历线程池中所有的线程，然后依次中断线程。shutdown和shutdownNow还是有不一样的地方：\n\n1. shutdownNow首先将线程池的状态设置为STOP,然后尝试停止所有的正在执行和未执行任务的线程，并返回等待执行任务的列表；\n\n2. shutdown只是将线程池的状态设置为SHUTDOWN状态，然后中断所有没有正在执行任务的线程\n\n可以看出shutdown方法会将正在执行的任务继续执行完，而shutdownNow会直接中断正在执行的任务。调用了这两个方法的任意一个，isShutdown方法都会返回true，当所有的线程都关闭成功，才表示线程池成功关闭，这时调用isTerminated方法才会返回true。\n\n### 线程池的监控\n通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用\n\n- getTaskCount：线程池已经执行的和未执行的任务总数；\n- getCompletedTaskCount：线程池已完成的任务数量，该值小于等于taskCount；\n- getLargestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过，也就是达到了maximumPoolSize；\n- getPoolSize：线程池当前的线程数量；\n- getActiveCount：当前线程池中正在执行任务的线程数量。\n\n通过这些方法，可以对线程池进行监控，在ThreadPoolExecutor类中提供了几个空方法，如beforeExecute方法，afterExecute方法和terminated方法，可以扩展这些方法在执行前或执行后增加一些新的操作，例如统计线程池的执行任务的时间等，可以继承自ThreadPoolExecutor来进行扩展。\n\n### 如何合理配置线程池参数\nCPU密集型任务配置尽可能少的线程数量，如配置Ncpu+1个线程的线程池。\n\nIO密集型任务则由于需要等待IO操作，线程并不是一直在执行任务，则配置尽可能多的线程，如2xNcpu。\n混合型的任务，如果可以拆分，则将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率，如果这两个任务执行时间相差太大，则没必要进行分解。我们可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。\n\n优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。\n\n执行时间不同的任务可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。\n\n依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，如果等待的时间越长CPU空闲时间就越长，那么线程数应该设置越大，这样才能更好的利用CPU。并且，阻塞队列最好是使用有界队列，如果采用无界队列的话，一旦任务积压在阻塞队列中的话就会占用过多的内存资源，甚至会使得系统崩溃。\n\n### 执行execute()方法和submit()方法的区别是什么呢？\n1)execute() 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；\n\n2)submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。\n\n### 那么什么是“非核心线程”呢？\n是不是先创建的线程就是核心线程，后创建的就是非核心线程呢？\n\n其实核心线程跟创建的先后没有关系，而是跟工作线程的个数有关，如果当前工作线程的个数大于核心线程数，那么所有的线程都可能是“非核心线程”，都有被回收的可能。\n\n一个线程执行完了一个任务后，会去阻塞队列里面取新的任务，在取到任务之前它就是一个闲置的线程。\n\n取任务的方法有两种，一种是通过 take() 方法一直阻塞直到取出任务，另一种是通过 poll(keepAliveTime，timeUnit) 方法在一定时间内取出任务或者超时，如果超时这个线程就会被回收，请注意核心线程一般不会被回收。\n\n那么怎么保证核心线程不会被回收呢？还是跟工作线程的个数有关，每一个线程在取任务的时候，线程池会比较当前的工作线程个数与核心线程数：\n\n- 如果工作线程数小于当前的核心线程数，则使用第一种方法取任务，也就是没有超时回收，这时所有的工作线程都是“核心线程”，他们不会被回收；\n\n- 如果大于核心线程数，则使用第二种方法取任务，一旦超时就回收，所以并没有绝对的核心线程，**只要这个线程没有在存活时间内取到任务去执行就会被回收**。\n\n核心线程一般不会被回收，但是也不是绝对的，如果我们设置了允许核心线程超时被回收的话，那么就没有核心线程这种说法了，所有的线程都会通过 poll(keepAliveTime, timeUnit) 来获取任务，一旦超时获取不到任务，就会被回收，一般很少会这样来使用，除非该线程池需要处理的任务非常少，并且频率也不高，不需要将核心线程一直维持着。\n\n### 为什是 run() 而不是 start()\n假设这里是调用的 Runnable 的 start 方法，那会发生什么事情。\n\n如果我们往一个核心、最大线程数为 2 的线程池里丢了 1000 个任务，那么它会额外的创建 1000 个线程，同时每个任务都是异步执行的，一下子就执行完毕了。\n\n从而没法做到由这两个 Worker 线程来调度这 1000 个任务，而只有当做一个同步阻塞的 run() 方法调用时才能满足这个要求。\n\n### 说说几种常见的线程池及使用场景\n- newFixedThreadPool（固定大小的线程池）\n- newSingleThreadExecutor（单线程线程池）\n- newCachedThreadPool（可缓存线程的线程池）\n- newScheduledThreadPool\n\n#### newFixedThreadPool\n```java\npublic static ExecutorService newFixedThreadPool(int nThreads) {\n    return new ThreadPoolExecutor(nThreads, nThreads,\n                                  0L, TimeUnit.MILLISECONDS,\n                                  new LinkedBlockingQueue<Runnable>());\n}\n```\n1. 线程池特点：\n- 核心线程数和最大线程数大小一样\n- keepAliveTime为0\n- 阻塞队列是LinkedBlockingQueue\n\n它是固定大小的线程池，其核心线程数和最大线程数大小一样。并且阻塞队列用的是LinkedBlockingQueue，也就是说线程最大数这个参数失效了基本，所以不会出现非核心线程的存在，所以也可以认为keepAliveTime参数是一个摆设。除非allowCoreThreadTimeOut方法的调用。\n\n2. 该线程池的工作机制是：\n- 线程数少于核心线程数，也就是设置的线程数时，新建线程执行任务\n- 线程数等于核心线程数后，将任务加入阻塞队列。**由于队列容量非常大(Integer.MAX_VALUE)，可以一直加加加。(当线程池中的任务比较特殊时，比如关于数据库的长时间的IO操作，可能导致OOM)**\n\n- 执行完任务的线程反复去队列中取任务执行\n\n3. 适用场景：\nFixedThreadPool 适用于处理CPU密集型的任务，确保CPU在长期被工作线程使用的情况下，尽可能的少的分配线程即可。一般Ncpu+1\n\n#### newSingleThreadExecutor\n```java\npublic static ExecutorService newSingleThreadExecutor() {\n    return new FinalizableDelegatedExecutorService\n        (new ThreadPoolExecutor(1, 1,\n                                0L, TimeUnit.MILLISECONDS,\n                                new LinkedBlockingQueue<Runnable>()));\n}\n```\n1. 线程池特点：\n- 核心线程数和最大线程数大小一样且都是1\n- keepAliveTime为0\n- 阻塞队列是LinkedBlockingQueue\n\n2. 该线程池的工作机制是：\n- 线程池中没有线程时，新建一个线程执行任务\n- 有一个线程以后，将任务加入阻塞队列，不停加加加。 也有能导致OOM。\n- 唯一的这一个线程不停地去队列里取任务执行\n\n3. 适用场景：\nSingleThreadExecutor适用于串行执行任务的场景，每个任务必须按顺序执行，不需要并发执行。\n\n#### newCachedThreadPool\n```java\npublic static ExecutorService newCachedThreadPool() {\n    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                  60L, TimeUnit.SECONDS,\n                                  new SynchronousQueue<Runnable>());\n}\n```\n1. 线程池特点：\n- 核心线程数为0，且最大线程数为Integer.MAX_VALUE，可能会导致OOM\n- 阻塞队列是SynchronousQueue\n\nSynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue。\n\n当提交任务的速度大于处理任务的速度时，每次提交一个任务，就必然会创建一个线程。极端情况下会创建过多的线程，耗尽 CPU 和内存资源。由于空闲 60 秒的线程会被终止，长时间保持空闲的 CachedThreadPool 不会占用任何资源。\n\n2. 该线程池的工作机制是：\n- 没有核心线程，直接向SynchronousQueue中提交任务\n- 如果有空闲线程，就去取出任务执行；如果没有空闲线程，就新建一个\n- 执行完任务的线程有60秒生存时间，如果在这个时间内可以接到新任务，就可以继续活下去，否则就拜拜\n\n3. 适用场景：\nCachedThreadPool 用于并发执行大量短期的小任务。\n\n#### newScheduledThreadPool\n```java\npublic static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {\n    return new ScheduledThreadPoolExecutor(corePoolSize);\n}\n\n\npublic ScheduledThreadPoolExecutor(int corePoolSize) {\n    super(corePoolSize, Integer.MAX_VALUE,\n          DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,\n          new DelayedWorkQueue());\n}\n\nprivate static final long DEFAULT_KEEPALIVE_MILLIS = 10L;\n```\n1. 线程池特点：\n\n- 最大线程数为Integer.MAX_VALUE，可能会导致OOM\n- 阻塞队列是DelayedWorkQueue\n\nScheduledThreadPoolExecutor 添加任务提供了另外两个方法：\n\n- scheduleAtFixedRate() ：按某种速率周期执行\n- scheduleWithFixedDelay()：在某个延迟后执行\n\n两种方法的内部实现都是创建了一个ScheduledFutureTask对象封装了任务的延迟执行时间及执行周期，并调用decorateTask()方法转成RunnableScheduledFuture对象，然后添加到延迟队列中。\nDelayQueue：中封装了一个优先级队列，这个队列会对队列中的ScheduledFutureTask 进行排序，两个任务的执行 time 不同时，time 小的先执行；否则比较添加到队列中的ScheduledFutureTask的顺序号 sequenceNumber ，先提交的先执行。\n\n2. 该线程池的工作机制是：\n- 调用上面两个方法添加一个任务\n- 线程池中的线程从 DelayQueue 中取任务\n- 然后执行任务\n\n具体执行步骤：\n\n- 线程从 DelayQueue 中获取 time 大于等于当前时间的 ScheduledFutureTask，DelayQueue.take()\n- 执行完后修改这个 task 的 time 为下次被执行的时间\n- 然后再把这个 task 放回队列中-DelayQueue.add()\n\n\n3. 适用场景：\nScheduledThreadPoolExecutor用于需要多个后台线程执行周期任务，同时需要限制线程数量的场景。\n\n### 单机上一个线程正在处理服务，如果忽然断电了怎么办（正在处理和阻塞队列里的请求怎么处理）\n阻塞队列持久化，正在处理事物控制。断电之后正在处理的回滚，日志恢复该次操作。服务器重启后阻塞队列中的数据再加载\n\n### 参考资料\n- [线程池，这一篇或许就够了](https://segmentfault.com/a/1190000009098623) \n- [线程池是怎样工作的？](https://mp.weixin.qq.com/s/jW9iAIha7_la3cQGouHz4g)\n- [https://www.jianshu.com/p/125ccf0046f3](https://www.jianshu.com/p/125ccf0046f3)\n- [关于线程池的面试题](https://www.jianshu.com/p/9710b899e749#1-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%94%A8%E4%BB%80%E4%B9%88%E7%94%A8)\n- [深入理解Java线程池：ThreadPoolExecutor](http://www.ideabuffer.cn/2017/04/04/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%EF%BC%9AThreadPoolExecutor/)\n\n","tags":["线程"],"categories":["线程"]},{"title":"MySQL主从复制","url":"/2019/04/08/MySQL主从复制/","content":"\n### 什么是主从复制\n　　主从复制，是用来建立一个和主数据库完全一样的数据库环境，称为从数据库；主数据库一般是准实时的业务数据库。\n\n### 主从复制的作用\n1. 做数据的热备，作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失。\n\n2. 架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。\n\n3. 读写分离，使数据库能支撑更大的并发。在报表中尤其重要。由于部分报表sql语句非常的慢，导致锁表，影响前台服务。如果前台使用master，报表使用slave，那么报表sql将不会造成前台锁，保证了前台速度。\n\n### 主从复制的形式\nmysql主从复制 灵活\n- 一主一从\n- 主主复制\n- 一主多从---扩展系统读取的性能，因为读是在从库读取的；\n- 多主一从---5.7开始支持\n- 联级复制\n\n![](主从架构.png)\n\n### 主从部署必要条件\n- 主库开启binlog日志（设置log-bin参数）\n- 主从server-id不同\n- 从库服务器能连通主库\n- 从库要配置master.info（CHANGE MASTER to...相当于配置密码文件和Master的相关信息）\n\n### 主从复制的原理\n\nbinlog输出线程：每当有从库连接到主库的时候，主库都会创建一个线程，然后发送binlog内容到从库。\n\n在从库里，当复制开始的时候，从库就会创建两个线程进行处理：\n\n从库I/O线程： 当START SLAVE语句在从库开始执行之后，从库创建一个I/O线程，该线程连接到主库并请求主库发送binlog里面的更新记录到从库上。从库I/O线程读取主库的binlog输出线程发送的更新并拷贝这些更新到relay log-中继日志。\n\n从库的SQL线程： 从库创建一个SQL线程，这个线程读取relay log的SQL语句并执行。\n\n可以知道，对于每一个主从复制的连接，都有三个线程。拥有多个从库的主库为每一个连接到主库的从库创建一个binlog输出线程，每一个从库都有它自己的I/O线程和SQL线程。\n主从复制如图：\n![](主从复制原理1.jfif)\n![](主从复制2.jfif)\n![](主从复制原理.png)\n具体步骤：\n1. 主库db的更新事件(update、insert、delete)被写到binlog\n\n2. 从库执行start slave命令开启主从复制开关，此时，从库的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change \nmaster命令指定的）之后开始发送binlog日志内容\n\n3. Master服务器接收到来自Slave服务器的IO线程的请求后，binlog dump 线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有binlog中的下一个指定更新位置。\n\n4. 当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（Mysql-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容\n\n\n5. Slave服务器端的SQL线程会实时检测本地Relay Log 中IO线程新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点\n\n\n#### 常见问题\n1. 联级复制\nA->B->C\nB中添加参数：\n```sql\nlog-slave-updates  #必须要有这个参数\nlog-bin = /data/3307/mysql-bin\nexpire_logs_days = 7 #相当于删除7天之后的日志\n```\nB将把A的binlog记录到自己的binlog日志中\n\n2. 复制出错处理—1062（主键冲突），1032（记录不存在）\n- 手动处理\n- 跳过复制错误：set global sql_slave_skip_counter=1\n\n### Mysql主从复制问题\nmysql主从复制存在的问题：\n1. 主库宕机后，数据可能丢失\n2. 主库写压力大，从库只有一个sql Thread，复制很可能延时\n\n解决方法：\n1. 半同步复制---解决数据丢失的问题\n2. 并行复制----解决从库复制延迟的问题\n\n#### 半同步复制\n正常的主从复制采用的是异步复制策略。过程如下：\n![](异步复制.png)\n\nmysql semi-sync（半同步复制）\n半同步复制：\n- 5.5集成到mysql，以插件的形式存在，需要单独安装\n- 确保事务提交后binlog至少传输到一个从库\n- 不保证从库应用完这个事务的binlog\n- 性能有一定的降低，响应时间会更长\n- 网络异常或从库宕机，卡主主库，直到超时或从库恢复\n![](半同步复制.png)\n假设有以下架构：\n```sql\nM --S1\n```\n介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。\n\n\n#### 并行复制\n- 并行是指从库多线程apply binlog\n- 库级别并行应用binlog，同一个库数据更改还是串行的(5.7版并行复制基于事务组)\n设置sql线程数为10\n```sql\nset global slave_parallel_workers=10;\n```\n\n### Mysql主从复制延迟问题原因及解决方法\n\n#### 一个主库的从库太多，导致复制延迟\n建议从库数量3-5 为宜，要复制的从节点数量过多，会导致复制延迟\n\n#### 慢SQL语句过多 \n假如一条SQL语句，执行时间是20秒，那么从库执行完毕，到从库上能查到数据也至少是20秒，这样就延迟20秒了 \nSQL语句的优化一般要作为常规工作不断的监控和优化，如果是单个SQL的写入时间长，可以修改后分多次写入，通过查看慢查询日志或show full processlist 命令找出执行时间长的查询语句\n\n#### 主从库之间的网络延迟\n主库的网卡、网线、连接的交换机等网络设备都可能成为复制的瓶颈，导致复制延迟，另外，跨公网主从复制很容易导致主库复制延迟。\n\n#### 主库读写压力大，导致复制延迟\n主库硬件要搞好一点，架构的前端要加buffer以及缓存层。通过read-only参数让从库只读访问 。\n> - 在my.cnf里[mysqld]模块下加read-only参数，然后重启数据库。\n```sql\n[mysqld]\nread-only\n```\n\n对于一致性要求高的可以读写都在主库上，对于读多的，可以在数据库上层添加缓存，面对高并发读。\n\n\n### 从库提升主库步骤\n1. 确保所有relay log全部更新完毕 \n在每个库执行\n```sql\nstop slave in_thread(sql线程)；\nshow processlit;\n``` \n直到看到Has read all relay log；表示从库更新都执行完毕；\n\n2. 登录从库提升为主库\nmysql主从复制中，需要将备库（从库）提升为主库，需要取消其从库角色，可以通过执行以下命令：\n```sql\nstop slave;\nreset slave all;\n```\nRESET SLAVE ALL是清除从库的同步复制信息，包括连接信息和二进制文件名、位置\n从库上执行这个命令后，使用show slave status将不会有输出\n\n3. 进到数据库数据目录，删除master.info relay-log.info\n```sql\ncd /data/3306/data\nrm -rf master.info relay-log.info\n```\n\n4. 开启binlog \n```sql\nvim /data/3306/my.cnf\nlog-bin = /data/3306/mysql-bin\n#如果存在log-slave-updates read-only等一定要注释掉它。\n/data/3306/mysql restart\n```\n到此为止，提升主库完毕\n\n5. 其他从库操作 \n```sql\nstop slave；\nCHANGE MASTER TO MASTER_HOST ='192.168.1.1'; #如果不同步，就指定位置点。\nstart slave；\nshow slave status\\G\n```\n\n### 参考资料\n\n- [mysql 主从复制原理](https://www.cnblogs.com/Aiapple/p/5792939.html)\n- [如何解决主从数据库同步延迟问题？](https://www.zhihu.com/question/20025096)\n- [MySQL主从复制原理、半同步操作步骤及原理](https://blog.csdn.net/abcdocker/article/details/71249760)\n- [主从复制](https://www.cnblogs.com/a8457013/p/7819018.html)\n\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL MVCC版本控制","url":"/2019/04/08/MySQL-MVCC版本控制/","content":"\n### 简介\nMVCC (MultiVersion Concurrency Control)，即多版本并发控制技术,它使得大部分支持行锁的事务引擎，不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来，只需要很小的开销,就可以实现非锁定读，从而大大提高数据库系统的并发性能。\n\n### 实现\nMVCC是通过保存某个时间点的数据快照来实现的。 不同存储引擎的MVCC。不同存储引擎的MVCC实现是不同的,典型的有乐观并发控制和悲观并发控制。\n\ninnodb MVCC主要是为Repeatable-Read事务隔离级别做的。在此隔离级别下，A、B客户端所示的数据相互隔离，互相更新不可见\n\ninnodb存储的最基本row中包含一些额外的存储信息 **DATA_TRX_ID，DATA_ROLL_PTR，DB_ROW_ID，DELETE BIT**。\n\n- 6字节的DATA_TRX_ID 标记了最新更新这条行记录的transaction id，每处理一个事务，其值自动+1\n\n- 7字节的DATA_ROLL_PTR 指向当前记录项的rollback segment的undo log记录，找之前版本的数据就是通过这个指针\n\n- 6字节的DB_ROW_ID，当由innodb自动产生聚集索引时，聚集索引包括这个DB_ROW_ID的值，否则聚集索引中不包括这个值.\nDELETE BIT位用于标识该记录是否被删除，这里的不是真正的删除数据，而是标志出来的删除。真正意义的删除是在commit的时候。\n\n![](MVCC.png)\n具体的执行过程:\n\nbegin->用排他锁锁定该行->记录redo log->记录undo log->修改当前行的值，写事务编号，回滚指针指向undo log中的修改前的行\n\n上述过程确切地说是描述了UPDATE的事务过程，其实undo log分insert和update undo log，因为insert时，原始的数据并不存在，所以回滚时把insert undo log丢弃即可，而update undo log则必须遵守上述过程。\n\n\n### SELECT\nInnodb检查每行数据，确保他们符合两个标准：\n\n1、InnoDB只查找版本早于当前事务版本的数据行(也就是数据行的版本必须小于等于事务的版本)，这确保当前事务读取的行都是事务之前已经存在的，或者是由当前事务创建或修改的行\n\n2、行的删除操作的版本一定是未定义的或者大于当前事务的版本号，确定了当前事务开始之前，行没有被删除\n\n符合了以上两点则返回查询结果。\n\n### INSERT\nInnoDB为每个新增行记录当前系统版本号（当前事务ID）作为版本号（DATA_TRX_ID）。\n\n### DELETE\nInnoDB为每个删除行的记录当前系统版本号（当前事务ID）作为行的删除ID （DELETE BIT）。\n\n### UPDATE\nInnoDB复制了新的一行，这个新行的版本号（DATA_TRX_ID）使用了当前事务ID，删除时间未定义。旧行数据版本号不变，并把旧行的DELETE BIT更新为当前事务ID。\n\n\n### 总结\n\n更新前建立undo log，根据各种策略读取时非阻塞就是MVCC，undo log中的行就是MVCC中的多版本，这个可能与我们所理解的MVCC有较大的出入，一般我们认为MVCC有下面几个特点：\n\n- 每行数据都存在一个版本，每次数据更新时都更新该版本\n- 修改时Copy出当前版本随意修改，各个事务之间无干扰\n- 保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback）\n就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道。\n\n而Innodb的实现方式是：\n\n- **事务以排他锁的形式修改原始数据**\n- 把修改前的数据存放于undo log，通过回滚指针与主数据关联\n- 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）\n\n\n二者最本质的区别是，当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ \n \nInnodb的实现真算不上MVCC，因为并没有实现核心的多版本共存，undo log中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。但理想的MVCC是难以实现的，当事务仅修改一行记录使用理想的MVCC模式是没有问题的，可以通过比较版本号进行回滚；但当事务影响到多行数据时，理想的MVCC据无能为力了。\n \n比如，如果Transaciton1执行理想的MVCC，修改Row1成功，而修改Row2失败，此时需要回滚Row1，但因为Row1没有被锁定，其数据可能又被Transaction2所修改，如果此时回滚Row1的内容，则会破坏Transaction2的修改结果，导致Transaction2违反ACID。\n \n理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二提交是目前这种场景保证一致性的唯一手段。二段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的MVCC难以真正在实际中被应用，Innodb只是借了MVCC这个名字，提供了读的非阻塞而已。\n\n\n### 参考资料\n- [【mysql】关于innodb中MVCC的一些理解](https://www.cnblogs.com/chenpingzhao/p/5065316.html)\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"悲观锁与乐观锁","url":"/2019/04/04/悲观锁与乐观锁/","content":"\n### 简介\n悲观锁： 共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。\n\n乐观锁：不会给数据上锁，每次去取数据的时候总认为不会有其他线程对数据进行修改，只是在更新时会判断其他线程在这之前有没有对数据进行修改，一般会使用版本号机制或CAS操作实现。简单来说就是每次不加锁而是假设没有并发冲突而去完成某项操作，如果因为并发冲突失败就重试，直到成功为止。乐观锁适用于多读的应用类型，这样可以提高吞吐量。\n\n\n### 适用场景\n乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。\n\n\n### 悲观锁问题\n1. 在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。\n2. 一个线程持有锁会导致其它所有需要此锁的线程挂起。\n3. 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。\n\n\n### 乐观锁的实现方式\n主要有两个步骤：冲突检测和数据更新。\n\n#### 版本号机制\n一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加1。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。\n\n\n#### CAS（Compare and Swap）\n不使用锁的情况下实现多线程之间的变量同步。也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数\n\n- 需要读写的内存值 V\n- 进行比较的值 A\n- 拟写入的新值 B\n\n当且仅当 V == A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。一般情况下是一个自旋操作，即不断的重试\n\n以 java.util.concurrent 中的 AtomicInteger 为例\n```java\npublic class AtomicInteger extends Number implements java.io.Serializable {  \n    private volatile int value; \n\n    public final int get() {  \n        return value;  \n    }  \n\n    public final int getAndIncrement() {  \n    \t//自旋\n        for (;;) {  \n            int current = get();  \n            int next = current + 1;  \n            if (compareAndSet(current, next))  \n                return current;  \n        }  \n    }  \n\n    public final boolean compareAndSet(int expect, int update) {  \n        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);  \n    }  \n}\n```\n在没有锁的机制下,字段value要借助volatile原语，保证线程间的数据是可见性。这样在获取变量的值的时候才能直接读取。\n getAndIncrement 采用了CAS操作，每次从内存中读取数据然后将此数据和 +1 后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。\n\n### 乐观锁问题\n\n#### ABA问题\n线程T1从内存位置V中取出A，这时候另一个线程T2也从内存中取出A，并且T2进行了一些操作变成了B，然后T2又将V位置的数据变成A，这时候线程T1进行CAS操作发现内存中仍然是A，然后T1操作成功。尽管线程T1的CAS操作成功，但可能存在潜藏的问题。\n如下所示：\n现有一个用单向链表实现的堆栈，栈顶为A，这时线程T1已经知道A.next为B，然后希望用CAS将栈顶替换为B：\n```java\nhead.compareAndSet(A,B);\n```\n![ABA1](ABA1.png)\n在T1执行上面这条指令之前，线程T2介入，将A、B出栈，再pushD、C、A，此时堆栈结构如下图，而对象B此时处于游离状态：\n![ABA2](ABA2.png)\n此时轮到线程T1执行CAS操作，检测发现栈顶仍为A，所以CAS成功，栈顶变为B，但实际上B.next为null，所以此时的情况变为：\n![ABA3](ABA3.png)\n其中堆栈中只有B一个元素，C和D组成的链表不再存在于堆栈中，平白无故就把C、D丢掉了。\n\n从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。\n```java\npublic boolean compareAndSet(\n               V      expectedReference,//预期引用\n\n               V      newReference,//更新后的引用\n\n              int    expectedStamp, //预期标志\n\n              int    newStamp //更新后的标志\n)\n```\n实际应用代码：\n```java\n private static AtomicStampedReference<Integer> atomicStampedRef = new AtomicStampedReference<Integer>(100, 0);\n\n  atomicStampedRef.compareAndSet(100, 101, stamp, stamp + 1);\n```\n\n#### 循环时间长开销大\n自旋CAS（不成功，就一直循环执行，直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。\n\n#### 只能保证一个共享变量的原子操作\n当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。\n\n### CAS与Synchronized的使用情景\n1. 对于资源竞争较少（线程冲突较轻，高并发读多）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。\n\n2. 对于资源竞争严重（线程冲突严重，高并发下对同一个变量写）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。\n\n> - 补充： synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。\n\n\n### CAS实现\n#### concurrent包的实现\nJava的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键,同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式：\n1. 首先，声明共享变量为volatile；　　\n\n2. 然后，使用CAS的原子条件更新来实现线程之间的同步；\n\n3. 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。\n\nAQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下：\n![concurrent包](concurrent包.png)\n\n\n#### JVM中的CAS（堆中对象的分配）\nJava调用new object()会创建一个对象，这个对象会被分配到JVM的堆中。那么这个对象到底是怎么在堆中保存的呢？\n\n首先，new object()执行的时候，这个对象需要多大的空间，其实是已经确定的，因为java中的各种数据类型，占用多大的空间都是固定的。那么接下来的工作就是在堆中找出那么一块空间用于存放这个对象。 \n在单线程的情况下，一般有两种分配策略：\n\n1. 指针碰撞：这种一般适用于内存是绝对规整的（内存是否规整取决于内存回收策略），分配空间的工作只是将指针像空闲内存一侧移动对象大小的距离即可。\n\n2. 空闲列表：这种适用于内存非规整的情况，这种情况下JVM会维护一个内存列表，记录哪些内存区域是空闲的，大小是多少。给对象分配空间的时候去空闲列表里查询到合适的区域然后进行分配即可。\n\n由于再给一个对象分配内存的时候不是原子性的操作，至少需要以下几步：查找空闲列表、分配内存、修改空闲列表等等，这是不安全的。解决并发时的安全问题也有两种策略：\n\n1. CAS：实际上虚拟机采用CAS配合上失败重试的方式保证更新操作的原子性，原理和上面讲的一样。\n\n2. TLAB：如果使用CAS其实对性能还是会有影响的，所以JVM又提出了一种更高级的优化策略：每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲区（TLAB），线程内部需要分配内存时直接在TLAB上分配就行，避免了线程冲突。只有当缓冲区的内存用光需要重新分配内存的时候才会进行CAS操作分配更大的内存空间。 \n虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来进行配置（**jdk5及以后的版本默认是启用TLAB的**）。\n\n\n### 参考资料\n- [Java并发问题--乐观锁与悲观锁以及乐观锁的一种实现方式-CAS](https://www.cnblogs.com/qjjazry/p/6581568.html)\n- [多线程与高并发基础一（超发--悲观锁，乐观锁）](https://blog.csdn.net/zsvole/article/details/79099498)","tags":["并发"],"categories":["并发"]},{"title":"Redis数据结构","url":"/2019/04/04/Redis数据结构/","content":"\n### 简介\nRedis常用的类型主要是 String、List、Hash、Set、ZSet 这5种。\n![redis类型](redis类型.png)\n\nRedis在互联网公司一般有以下应用:\n\n> - String：缓存、限流、计数器、分布式锁、分布式Session\n\n> - Hash：存储用户信息、用户主页访问量、组合查询\n\n> - List：微博关注人时间轴列表、简单队列\n\n> - Set：赞、踩、标签、好友关系\n\n> - Zset：排行榜\n\n### Redis的对象redisObject\n当我们执行set hello world命令时，会有以下数据模型：\n![redisObject](redisObject.png)\n\n- dictEntry：Redis给每个key-value键值对分配一个dictEntry，里面有着key和val的指针，next指向下一个dictEntry形成链表，这个指针可以将多个哈希值相同的键值对链接在一起，由此来解决哈希冲突问题(链地址法)。\n\n- sds：键key“hello”是以SDS（简单动态字符串）存储。\n\n- redisObject：值val“world”存储在redisObject中。实际上，redis常用5种类型都是以redisObject来存储的；而redisObject中的type字段指明了Value对象的类型，ptr字段则指向对象所在的地址。\n\nredisObject对象非常重要，Redis对象的类型、内部编码、内存回收、共享对象等功能，都需要redisObject支持。这样设计的好处是，可以针对不同的使用场景，对5种常用类型设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率。\n\n无论是dictEntry对象，还是redisObject、SDS对象，都需要内存分配器（如jemalloc）分配内存进行存储。jemalloc作为Redis的默认内存分配器，在减小内存碎片方面做的相对比较好。比如jemalloc在64位系统中，将内存空间划分为小、大、巨大三个范围；每个范围内又划分了许多小的内存块单位；当Redis存储数据时，会选择大小最合适的内存块进行存储。\n\n\n### redis数据结构\nRedis每个对象由一个redisObject结构表示，它的ptr指针指向底层实现的数据结构，而数据结构由encoding属性决定。比如我们执行以下命令得到存储“hello”对应的编码：\n\n![](数据结构.png)\n\n### String\n字符串对象的底层实现可以是int、raw、embstr。embstr编码是通过调用一次内存分配函数来分配一块连续的空间，而raw需要调用两次。\n\nint编码字符串对象和embstr编码字符串对象在一定条件下会转化为raw编码字符串对象。embstr：<=39字节的字符串。int：8个字节的长整型。raw：大于39个字节的字符串。\n\n\n#### 简单动态字符串（SDS）\n简单动态字符串（SDS），这种结构更像C++的String或者Java的ArrayList，长度动态可变：\n```C++\nstruct sdshdr {\n\t/* buf 中已占用空间的长度 */\n\n\tint len;\n\n\t/* buf 中剩余可用空间的长度 */\n\n\tint free;\n\n\t/* 数据空间 */\n\n\tchar buf; /* ’\\0’空字符结尾 */\n};\n```\n- get：sdsrange---O(n)\n- set：sdscpy—O(n)\n- create：sdsnew---O(1)\n- len：sdslen---O(1)\n\n#### SDS特性\n**常数复杂度获取字符串长度：**因为SDS在len属性中记录了长度，所以获取一个SDS长度时间复杂度仅为O(1)。\n\n**预空间分配：**如果对一个SDS进行修改，分为一下两种情况：\n\n1、SDS长度（len的值）小于1MB，那么程序将分配和len属性同样大小的未使用空间，这时free和len属性值相同。举个例子，SDS的len将变成15字节，则程序也会分配15字节的未使用空间，SDS的buf数组的实际长度变成15+15+1=31字节（额外一个字节用户保存空字符）。\n\n2、SDS长度（len的值）大于等于1MB，程序会分配1MB的未使用空间。比如进行修改之后，SDS的len变成30MB，那么它的实际长度是30MB+1MB+1byte。\n\n**杜绝缓冲区溢出：**使用C字符串的操作时，如果字符串长度增加（如strcat操作）而忘记重新分配内存，很容易造成缓冲区的溢出；而SDS由于记录了长度，相应的操作在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区溢出。\n\n\n### List\nList对象的底层实现是quicklist（快速列表，是ziplist 压缩列表 和linkedlist 双端链表 的组合）。Redis中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。\n```c\ntypedef struct listNode {\n\t/* 前置节点 */\n\n\tstruct listNode *prev;\n\n\t/* 后置节点 */\n\n\tstruct listNode *next;\n\n\t/* 节点的值 */\n\n\tvoid *value;\n} listNode;\n\ntypedef struct list {\n\t/* 表头节点 */\n\n\tlistNode *head;\n\n\t/* 表尾节点 */\n\n\tlistNode *tail;\n\n\t/* 节点值复制函数 */\n\n\tvoid *(*dup)(void *ptr);\n\n\t/* 节点值释放函数 */\n\n\tvoid (*free)( void *ptr );\n\n\t/* 节点值对比函数 */\n\n\tint (*match)( void *ptr, void *key );\n\n\t/* 链表所包含的节点数量 */\n\n\tunsigned long len;\n} list;\n```\n- rpush: listAddNodeHead ---O(1)\n\n- lpush: listAddNodeTail ---O(1)\n\n- push:listInsertNode ---O(1)\n\n- index : listIndex ---O(N)\n\n- pop:ListFirst/listLast ---O(1)\n\n- llen:listLength ---O(N)\n\n####  linkedlist（双端链表）\n\n![List](List.png)\n\n从图中可以看出Redis的linkedlist双端链表有以下特性：节点带有prev、next指针、head指针和tail指针，获取前置节点、后置节点、表头节点和表尾节点的复杂度都是O（1）。len属性获取节点数量也为O（1）。\n\n与双端链表相比，压缩列表可以节省内存空间，但是进行修改或增删操作时，复杂度较高；因此当节点数量较少时，可以使用压缩列表；但是节点数量多时，还是使用双端链表划算。\n\n#### ziplist（压缩列表）\n当一个列表键只包含少量列表项，且是小整数值或长度比较短的字符串时，那么redis就使用ziplist（压缩列表）来做列表键的底层实现。\n\nziplist是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块(而不是像双端链表一样每个节点是指针)组成的顺序型数据结构；具体结构相对比较复杂，有兴趣读者可以看 Redis 哈希结构内存模型剖析。在新版本中list链表使用 quicklist 代替了 ziplist和 linkedlist：\n\nquickList 是 zipList 和 linkedList 的混合体。它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。因为链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。\n\n\n![](ziplist.png)\nquicklist 默认的压缩深度是 0，也就是不压缩。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。为了进一步节约空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 算法压缩。\n\n### Hash\nHash对象的底层实现可以是ziplist（压缩列表）或者hashtable（字典或者也叫哈希表）。\n\nHash对象只有同时满足下面两个条件时，才会使用ziplist（压缩列表）：1.哈希中元素数量小于512个；2.哈希中所有键值对的键和值字符串长度都小于64字节。\n\nhashtable哈希表可以实现O(1)复杂度的读写操作，因此效率很高。\n![](hash.png)\nRedis也使用链地址法来解决键冲突。即每个哈希表节点都有一个next指针，多个哈希表节点用next指针构成一个单项链表，链地址法就是将相同hash值的对象组织成一个链表放在hash值对应的槽位。\n\nRedis中的字典使用hashtable作为底层实现的话，每个字典会带有两个哈希表，一个平时使用，另一个仅在rehash（重新散列）时使用。随着对哈希表的操作，键会逐渐增多或减少。为了让哈希表的负载因子维持在一个合理范围内，Redis会对哈希表的大小进行扩展或收缩（rehash），也就是将ht【0】里面所有的键值对分多次、渐进式的rehash到ht【1】里。\n\n### Set\nSet集合对象的底层实现可以是intset（整数集合）或者hashtable（字典或者也叫哈希表）。\n\nintset底层实现为有序，无重复数组保存集合元素。 intset这个结构里的整数数组的类型可以是16位的，32位的，64位的。如果数组里所有的整数都是16位长度的，如果新加入一个32位的整数，那么整个16的数组将升级成一个32位的数组。升级可以提升intset的灵活性，又可以节约内存，但不可逆。\n\n### ZSet\nZSet有序集合对象底层实现可以是ziplist（压缩列表）或者skiplist（跳跃表）。\n\n当一个有序集合的元素数量比较多或者成员是比较长的字符串时，Redis就使用skiplist（跳跃表）作为ZSet对象的底层实现。\n\nskiplist的查找时间复杂度是LogN，可以和平衡二叉树相当，但实现起来又比它简单。跳跃表(skiplist)是一种有序数据结构，它通过在某个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。\n","tags":["Redis"],"categories":["Redis"]},{"title":"分布式事务解决方案","url":"/2019/04/01/分布式事务解决方案/","content":"\n### 分布式事务\n分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。\n\n### CAP理论\n CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。\n\n- 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）\n- 可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）\n- 分区容忍性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。\n\n\n### BASE理论\nBASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写，**BASE是对CAP中一致性和可用性权衡的结果**，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，**采用适当的方式来使系统达到最终一致性（Eventual consistency）**。接下来我们着重对BASE中的三要素进行详细讲解。\n\n#### 基本可用\n基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用，以下两个就是“基本可用”的典型例子。\n\n> - 响应时间上的损失：正常情况下，一个在线搜索引擎需要0.5秒内返回给用户相应的查询结果，但由于出现异常（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1-2秒。\n\n> - 功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。\n\n#### 弱状态\n\n弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。\n\n#### 最终一致性\n最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。\n\n在实际工程实践中，最终一致性存在以下五类主要变种:\n1. 因果一致性\n如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。\n\n2. 读己之所写\n\n进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者而言，其读取到的数据一定不会比自己上次写入的值旧。因此，读己之所写也可以看作是一种特殊的因果一致性。\n\n3. 会话一致性\n会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。\n\n4. 单调读一致性\n单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。\n\n5. 单调写一致性\n\n  单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。\n\n以上就是最终一致性的五类常见的变种。事实上，最终一致性并不是只有那些大型分布式系统才设计的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多都会采用同步和异步方式来实现主备数据复制技术。在同步方式中，数据的复制通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么很显然，从备库中读取的数据将是旧的，因此就出现了不一致的情况。当然，无论是采用多次重试还是认为数据订正，关系型数据库还是能保证最终数据达到一致——这就是系统提供最终一致性保证的经典案例。\n\n\n总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性是相反的，**它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态**。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。\n\n### 酸碱平衡\n如果非要说酸碱，或者说酸碱平衡，那就是平衡于CAP理论。在不考虑分区的情况下，CA问题依然是系统设计的难点。\n![](酸碱平衡.png)\n可用性并不是简单的网络连通，服务可以访问，数据可以读取就是可用性，对于互联网业务，可用性是完整的用户体验，甚至会延伸到用户现实生活中（补偿）。有的系统必须容忍大规模可靠分布式系统中的数据不一致，其中原因就是为了在高并发条件下提高读写性能。\n\n必须容忍大规模可靠分布式系统中的数据不一致，有两个原因：在高并发条件下提高读写性能， 并要区分物理上导致的不一致和协议规定的不一致。\n\n节点已经宕机，副本无法访问（物理）\n\n法定数模型会使部分系统不可用的分区情况，即使节点已启动并运行（paxos协议）\n\n网络断开，节点孤立（物理）\n\n所以，保证不发生分区，CA也不是免费午餐：尽管保证了网络可靠性，尽量不发生分区，同时获得CA也不是一件简单的事情。\n\nCA系统才是真正的难点。\n\n\n### 数据一致性问题\n下面举一些常见例子。比如在更新数据的时候，先更新了数据库，后更新了缓存，一旦缓存更新失败，此时数据库和缓存数据会不一致。反过来，如果先更新缓存，再更新数据库，一旦缓存更新成功，数据库更新失败，数据还是不一致；\n\n比如数据库中的参照完整性，从表引用了主表的主键，对从表来说，也就是外键。当主表的记录删除后，从表是字段置空，还是级联删除。同样，当要创建从表记录时，主表记录是否要先创建，还是可以直接创建从表的记录；\n\n比如数据库中的原子性：同时修改两条记录，一条记录修改成功了，一条记录没有修改成功，数据就会不一致，此时必须回滚，否则会出现脏数据。\n\n比如数据库的Master-Slave异步复制，Master宕机切换到Slave，导致部分数据丢失，数据会不一致。\n\n发送方发送了消息1、2、3、4、5，因为消息中间件的不稳定，导致丢了消息4，接收方只收到了消息1、2、3、5，发送方和接收方数据会不一致。\n\n一致性问题分为了两大类：事务一致性和多副本一致性。这两类一致性问题基本涵盖了实践中所遇到的绝大部分场景。\n\n### 分布式事务问题\n在微服务时代，服务的粒度拆得更细，导致一个无法避免的问题：数据库的事务机制不管用了，因为数据库本身只能保证单机事务，对于分布式事务，只能靠业务系统解决。\n\n例如做一个服务，最初底下只有一个数据库，用数据库本身的事务来保证数据一致性。随着数据量增长到一定规模，进行了分库，这时数据库的事务就不管用了，如何保证多个库之间的数据一致性呢？\n\n凡是一个业务操作，需要调用多个服务，并且都是写操作的时候，就可能会出现有的服务调用成功，有的服务调用失败，导致只部分数据写入成功，也就出现了服务之间的数据不一致性。\n\n\n### 分布式事务协议\n常见的分布式事务协议分为两阶段提交和三阶段提交。\n\n#### 两阶段提交\n\n两阶段提交协议是协调所有分布式原子事务参与者，并决定提交或取消（回滚）的分布式算法。\n\n##### 协议参与者\n在两阶段提交协议中，系统一般包含两类机器（或节点）：一类为协调者（coordinator），通常一个系统中只有一个；另一类为事务参与者（participants，cohorts或workers），一般包含多个，在数据存储系统中可以理解为数据副本的个数。协议中假设每个节点都会记录写前日志（write-ahead log）并持久性存储，即使节点发生故障日志也不会丢失。协议中同时假设节点不会发生永久性故障而且任意两个节点都可以互相通信。\n![](2PC协议.png)\n\n##### 2PC执行\n1. 请求阶段（commit-request phase，或称表决阶段，voting phase）在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。\n即参与者能够执行事务的提交，先执行事务操作，然后返回YES，如果没有成功执行事务操作，就返回NO。\n\n2. 提交阶段（commit phase）在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行响应的操作。\n\n##### 2PC缺点\n\n1. 同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。\n\n2. 单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）\n\n3. 数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这会导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。\n\n##### 2PC无法解决的问题\n\n当协调者出错，同时参与者也出错时，两阶段无法保证事务执行的完整性。考虑协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。\n\n\n#### 三阶段提交\n三阶段提交协议在协调者和参与者中都**引入超时机制**，并且把两阶段提交协议的第一个阶段拆分成了两步：**询问，然后再锁资源，最后真正提交。3PC最关键要解决的就是协调者和参与者同时挂掉的问题**。\n\n三阶段提交有CanCommit、PreCommit、DoCommit三个阶段。在第一阶段，只是询问所有参与者是否可以执行事务操作，并不在本阶段执行事务操作。当协调者收到所有的参与者都返回YES时，在第二阶段才执行事务操作，然后在第三阶段在执行commit或者rollback。\n![](3PC协议.png)\n\n##### 3PC的执行\n1. CanCommit阶段**3PC的CanCommit阶段其实和2PC的准备阶段很像**。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。\n\n2. PreCommit阶段Coordinator根据Cohort的反应情况来决定是否可以继续事务的PreCommit操作。\n根据响应情况，有以下两种可能:\nA. 假如Coordinator从所有的Cohort获得的反馈都是Yes响应，那么就会进行事务的预执行：发送预提交请求。Coordinator向Cohort发送PreCommit请求，并进入Prepared阶段。事务预提交。**Cohort接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中**。响应反馈。如果Cohort成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。\n\nB. 假如有任何一个Cohort向Coordinator发送了No响应，或者等待超时之后，Coordinator都没有接到Cohort的响应，那么就中断事务：发送中断请求。Coordinator向所有Cohort发送abort请求。中断事务。Cohort收到来自Coordinator的abort请求之后（或超时之后，仍未收到Cohort的请求），执行事务的中断。\n\n3. DoCommit阶段\n\n该阶段进行真正的事务提交，也可以分为以下两种情况:\n\n(1)、执行提交\n\nA.发送提交请求。Coordinator接收到Cohort发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有Cohort发送doCommit请求。\nB.事务提交。Cohort接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。\nC.响应反馈。事务提交完之后，向Coordinator发送ACK响应。\nD.完成事务。Coordinator接收到所有Cohort的ACK响应之后，完成事务。\n\n(2)、中断事务\n\nCoordinator没有接收到Cohort发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。\n\n#### 缺点\n如果进入PreCommit后，Coordinator发出的是abort请求，假设只有一个Cohort收到并进行了abort操作，而其他对于系统状态未知的Cohort会根据3PC选择继续Commit，此时系统状态发生不一致性。\n\n#### 三阶段提交协议和两阶段提交协议的不同\n对于协调者(Coordinator)和参与者(Cohort)都设置了超时机制（在2PC中，只有协调者拥有超时机制，即如果在一定时间内没有收到cohort的消息则默认失败）。在2PC的准备阶段和提交阶段之间，插入预提交阶段，使3PC拥有CanCommit、PreCommit、DoCommit三个阶段。PreCommit是一个缓冲，保证了在最后提交阶段之前各参与节点的状态是一致的。\n\n#### 3PC为什么比2PC好？\n场景：协调者和参与者都挂的情况。\n第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。\n\n这种情况下，当新的协调者被选出来之后，他同样是询问所有的参与者的情况来觉得是commit还是roolback。这看上去和二阶段提交一样啊？他是怎么解决一致性问题的呢？\n\n看上去和二阶段提交的那种数据不一致的情况的现象是一样的，但仔细分析所有参与者的状态的话就会发现其实并不一样。我们假设挂掉的那台参与者执行的操作是commit。那么其他没挂的操作者的状态应该是什么？他们的状态要么是prepare-commit要么是commit。因为3PC的第三阶段一旦有机器执行了commit，那必然第一阶段大家都是同意commit。所以，这时，新选举出来的协调者一旦发现未挂掉的参与者中有人处于commit状态或者是prepare-commit的话，那就执行commit操作。否则就执行rollback操作。这样挂掉的参与者恢复之后就能和其他机器保持数据一致性了。\n\n如果挂掉的那台机器已经执行了commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行commit。如果挂掉的那个参与者执行了rollback，那么协调者和其他的参与者执行的肯定也是rollback操作。\n\n\n\n### 分布式事务解决方案汇总\n以支付宝为例，要把一笔钱从支付宝的余额转账到余额宝，支付宝的余额在系统A，背后有对应的DB1；余额宝在系统B，背后有对应的DB2；蚂蚁借呗在系统C，背后有对应的DB3，这些系统之间都要支持相关转账。所谓“转账”，就是转出方的系统里面账号要扣钱，转入方的系统里面账号要加钱，如何保证两个操作在两个系统中同时成功呢？\n\n### 2PC（底层数据库之间直接交互）\n#### 理论\n2PC是应用在两个数据库或两个系统之间。\n在MySQL Binlog和Redo  Log两个日志文件之间的数据一致性时，也用到了2PC的理论来解决。\n\n2PC有两个角色：事务协调者和事务参与者。具体到数据库的实现来说，每一个数据库就是一个参与者，调用方也就是协调者。2PC是指事务的提交分为两个阶段：\n\n- 阶段1：准备阶段。协调者向各个参与者发起询问，说要执行一个事务，各参与者可能回复YES、NO或超时。\n- 阶段2：提交阶段。如果所有参与者都回复的是YES，则事务协调者向所有参与者发起事务提交操作，即Commit操作，所有参与者各自执行事务，然后发送ACK。\n![](2PC提交.jpg)\n如果有一个参与者回复的是NO，或者超时了，则事务协调者向所有参与者发起事务回滚操作，所有参与者各自回滚事务，然后发送ACK。\n![](2PC回滚.jpg)\n所以，无论事务提交，还是事务回滚，都是两个阶段。\n\n#### 实现方式\n要实现2PC，所有参与者都要实现三个接口：Prepare、Commit、Rollback，这也就是XA协议，在Java中对应的接口是javax.transaction.xa.XAResource，通常的数据库也都实现了这个协议。开源的Atomikos也基于该协议提供了2PC的解决方案。\n#### 问题\n- 问题1：性能问题。在阶段1，锁定资源之后，要等所有节点返回，然后才能一起进入阶段2，不能很好地应对高并发场景。\n- 问题2：阶段1完成之后，如果在阶段2事务协调者宕机，则所有的参与者接收不到Commit或Rollback指令，将处于“悬而不决”状态。\n- 问题3：阶段1完成之后，在阶段2，事务协调者向所有的参与者发送了Commit指令，但其中一个参与者超时或出错了（没有正确返回ACK），则其他参与者提交还是回滚呢？ 也不能确定。\n\n为了解决2PC的问题，又引入了3PC。3PC存在类似宕机如何解决的问题。\n2PC除本身的算法局限外，还有一个使用上的限制，就是它主要用在两个数据库之间（数据库实现了XA协议）。但以支付宝的转账为例，是两个系统之间的转账，而不是底层两个数据库之间直接交互，所以没有办法使用2PC。\n\n不仅支付宝，其他业务场景基本都采用了微服务架构，不会直接在底层的两个业务数据库之间做一致性，而是在两个服务上面实现一致性。\n\n正因为2PC有诸多问题和不便，在实践中一般很少使用，而是采用下面要讲的各种方案。\n\n### 最终一致性（消息中间件）\n\n系统A收到用户的转账请求，系统A先自己扣钱，也就是更新DB1；然后通过消息中间件给系统B发送一条加钱的消息，系统B收到此消息，对自己的账号进行加钱，也就是更新DB2。\n\n![](最终一致性.jpg)\n这里面有一个关键的技术问题：\n\n> - 系统A给消息中间件发消息，是一次网络交互；更新DB1，也是一次网络交互。系统A是先更新DB1，后发送消息，还是先发送消息，后更新DB1？\n\n假设先更新DB1成功，发送消息网络失败，重发又失败，怎么办？又假设先发送消息成功，更新DB1失败。消息已经发出去了，又不能撤回，怎么办？或者消息中间件提供了消息撤回的接口，但是又调用失败怎么办？\n\n因为这是两次网络调用，两个操作不是原子的，无论谁先谁后，都是有问题的。\n\n\n#### 最终一致性的几种具体实现思路\n###### 同一事务\n将“发送加钱消息”这个**网络调用和更新DB1放在同一个事务里面**，如果发送消息失败，更新DB自动回滚。这样不就可以保证两个操作的原子性了吗？\n\n这个方案看似正确，其实是错误的，原因有两点：\n\n（1）网络的2将军问题：发送消息失败，发送方并不知道是消息中间件没有收到消息，还是消息已经收到了，只是返回response的时候失败了？\n\n如果已经收到消息了，而发送端认为没有收到，执行update DB的回滚操作，则会导致账户A的钱没有扣，账户B的钱却被加了。\n\n（2）把网络调用放在数据库事务里面，可能会因为网络的延时导致数据库长事务。严重的会阻塞整个数据库，风险很大。\n\n###### 非事务消息\n消息中间件实现最终一致性示意图如图所示。\n![](中间件最终一致性.jpg)\n1. 系统A增加一张消息表，系统A不再直接给消息中间件发送消息，而是把消息写入到这张消息表中。**把DB1的扣钱操作（表1）和写入消息表（表2）这两个操作放在一个数据库事务里**，保证两者的原子性。\n\n2. 系统A准备一个后台程序，源源不断地把消息表中的消息传送给消息中间件。如果失败了，也不断尝试重传。因为网络的2将军问题，系统A发送给消息中间件的消息网络超时了，消息中间件可能已经收到了消息，也可能没有收到。系统A会再次发送该消息，直到消息中间件返回成功。所以，系统A允许消息重复，但消息不会丢失，顺序也不会打乱。\n\n3. 通过上面的两个步骤，系统A保证了消息不丢失，但消息可能重复。系统B对消息的消费要解决下面两个问题：\n\n> 问题1：丢失消费。系统B从消息中间件取出消息（此时还在内存里面），如果处理了一半，系统B宕机并再次重启，此时这条消息未处理成功，怎么办？\n\n答案是通过消息中间件的ACK机制，凡是发送ACK的消息，系统B重启之后消息中间件不会再次推送；凡是没有发送ACK的消息，系统B重启之后消息中间件会再次推送。\n\n但这又会引发一个新问题，就是下面问题2的重复消费：即使系统B把消息处理成功了，但是正要发送ACK的时候宕机了，消息中间件以为这条消息没有处理成功，系统B再次重启的时候又会收到这条消息，系统B就会重复消费这条消息（对应加钱类的场景，账号里面的钱就会加两次）\n\n> 问题2：重复消费。除了ACK机制，可能会引起重复消费；系统A的后台任务也可能给消息中间件重复发送消息。\n可以使用数据库的唯一性索引和Redis的分布式锁实现幂等消费。\n\n但这种方案有一个缺点：系统A需要增加消息表，同时还需要一个后台任务，不断扫描此消息表，会导致消息的处理和业务逻辑耦合，额外增加业务方的开发负担。\n\n###### 事务消息 \n为了能通过消息中间件解决该问题，同时又不和业务耦合，RocketMQ提出了“事务消息”\n![](RocketMQ事务消息.jpg)\nRocketMQ不是提供一个单一的“发送”接口，而是把消息的发送拆成了两个阶段，Prepare阶段（消息预发送）和Confirm阶段（确认发送）。具体使用方法如下：\n\n步骤1：系统A调用Prepare接口，预发送消息。此时消息保存在消息中间件里，但消息中间件不会把消息给消费方消费，消息只是暂存在那。\n步骤2：系统A更新数据库，进行扣钱操作。\n步骤3：系统A调用Comfirm接口，确认发送消息。此时消息中间件才会把消息给消费方进行消费。\n\n显然，这里有两种异常场景：\n\n场景1：步骤1成功，步骤2成功，步骤3失败或超时，怎么处理？\n场景2：步骤1成功，步骤2失败或超时，步骤3不会执行。怎么处理？\n\n这就涉及RocketMQ的关键点：RocketMQ会定期（默认是1min）扫描所有的预发送但还没有确认的消息，回调给发送方，询问这条消息是要发出去，还是取消。发送方根据自己的业务数据，知道这条消息是应该发出去（DB更新成功了），还是应该取消（DB更新失败）。\n\n对比最终一致性的两种实现方案会发现，RocketMQ最大的改变其实是把“扫描消息表”这件事不让业务方做，而是让消息中间件完成。\n\n至于消息表，其实还是没有省掉。因为消息中间件要询问发送方事物是否执行成功，还需要一个“变相的本地消息表”，记录事务执行状态和消息发送状态。\n\n同时对于消费方，还是没有解决系统重启可能导致的重复消费问题，这只能由消费方解决。需要设计判重机制，实现消息消费的幂等。\n\n\n### 人工介入\n\n无论方案1，还是方案2，发送端把消息成功放入了队列中，但如果消费端消费失败怎么办？\n\n如果消费失败了，则可以重试，但还一直失败怎么办？是否要自动回滚整个流程？\n\n答案是人工介入。从工程实践角度来讲，这种整个流程自动回滚的代价是非常巨大的，不但实现起来很复杂，还会引入新的问题。比如自动回滚失败，又如何处理？\n\n对应这种发生概率极低的事件，采取人工处理会比实现一个高复杂的自动化回滚系统更加可靠，也更加简单。\n\n\n### TCC\n\n2PC通常用来解决两个数据库之间的分布式事务问题，比较局限。现在企业采用的是各式各样的SOA服务，更需要解决两个服务之间的分布式事务问题。\n\n为了解决SOA系统中的分布式事务问题，支付宝提出了TCC。TCC是Try、Confirm、Cancel三个单词的缩写，其实是一个应用层面的2PC协议，Confirm对应2PC中的事务提交操作，Cancel对应2PC中的事务回滚操作。\n![](TCC事务提交.jpg)\n（1）准备阶段：调用方调用所有服务方提供的Try接口，该阶段各调用方做资源检查和资源锁定，为接下来的阶段2做准备。\n（2）提交阶段：如果所有服务方都返回YES，则进入提交阶段，调用方调用各服务方的Confirm接口，各服务方进行事务提交。如果有一个服务方在阶段1返回NO或者超时了，则调用方调用各服务方的Cancel接口\n![](TCC事务回滚.jpg)\n这里有一个关键问题：TCC既然也借鉴2PC的思路，那么它是如何解决2PC的问题的呢？也就是说，在阶段2，调用方发生宕机，或者某个服务超时了，如何处理呢？\n\n答案是：不断重试！不管是Confirm失败了，还是Cancel失败了，都不断重试。这就要求Confirm和Cancel都必须是幂等操作。注意，这里的重试是由TCC的框架来执行的，而不是让业务方自己去做。\n\n下面以一个转账的事件为例，来说明TCC的过程。假设有三个账号A、B、C，通过SOA提供的转账服务操作。A、B同时分别要向C转30元、50元，最后C的账号+80元，A、B各减30元、50元。\n\n阶段1：分别对账号A、B、C执行Try操作，A、B、C三个账号在三个不同的SOA服务里面，也就是分别调用三个服务的Try接口。具体来说，就是账号A锁定30元，账号B锁定50元，检查账号C的合法性，比如账号C是否违法被冻结，账号C是否已注销。\n\n所以，在这个场景里面，对应的“扣钱”的Try操作就是“锁定”，对应的“加钱”的Try操作就是检查账号合法性，为的是保证接下来的阶段2扣钱可扣、加钱可加！\n\n阶段2：A、B、C的Try操作都成功，执行Confirm操作，即分别调用三个SOA服务的Confirm接口。A、B扣钱，C加钱。如果任意一个失败，则不断重试，直到成功为止。\n\n从案例可以看出，Try操作主要是为了“保证业务操作的前置条件都得到满足”，然后在Confirm阶段，因为前置条件都满足了，所以可以不断重试保证成功。\n\n### 事务状态表+调用方重试+接收方幂等\n同样以转账为例，介绍一种类似于TCC的方法。TCC的方法通过TCC框架内部来做，下面介绍的方法是业务方自己实现的。\n\n调用方维护一张事务状态表（或者说事务日志、日志流水），在每次调用之前，落盘一条事务流水，生成一个全局的事务ID。事务状态表的表结构如下：\n![](事务表结构.png)\n初始是状态1，每调用成功1个服务则更新1次状态，最后所有系统调用成功，状态更新到状态4，状态2、3是中间状态。当然，也可以不保存中间状态，只设置两个状态：Begin和End。事务开始之前的状态是Begin，全部结束之后的状态是End。如果某个事务一直停留在Begin状态，则说明该事务没有执行完毕。\n\n然后有一个后台任务，扫描状态表，在过了某段时间后（假设1次事务执行成功通常最多花费30s），状态没有变为最终的状态4，说明这条事务没有执行成功。于是重新调用系统A、B、C。保证这条流水的最终状态是状态4（或End状态）。当然，系统A、B、C根据全局的事务ID做幂等操作，所以即使重复调用也没有关系。\n\n补充说明：\n\n（1）如果后台任务重试多次仍然不能成功，要为状态表加一个Error状态，通过人工介入干预。\n（2）对于调用方的同步调用，如果部分成功，此时给客户端返回什么呢？\n答案是不确定，或者说暂时未知。只能告诉用户该笔钱转账超时，请稍后再来确认。\n（3）对于同步调用，调用方调用A或B失败的时候，可以重试三次。如果重试三次还不成功，则放弃操作，再交由后台任务后续处理。\n\n### 对账\n把上一节的方案扩展一下，岂止事务有状态，系统中的各种数据对象都有状态，或者说都有各自完整的生命周期，同时数据与数据之间存在着关联关系。我们可以很好地利用这种完整的生命周期和数据之间的关联关系，来实现系统的一致性，这就是“对账”。\n\n在前面，我们把注意力都放在了“过程”中，而在“对账”的思路中，将把注意力转移到“结果”中。什么意思呢？\n\n在前面的方案中，无论最终一致性，还是TCC、事务状态表，都是为了保证“过程的原子性”，也就是多个系统操作（或系统调用），要么全部成功，要么全部失败。\n\n但所有的“过程”都必然产生“结果”，过程是我们所说的“事务”，结果就是业务数据。一个过程如果部分执行成功、部分执行失败，则意味着结果是不完整的。从结果也可以反推出过程出了问题，从而对数据进行修补，这就是“对账”的思路！\n\n下面举几个对账的例子。\n\n案例1：电商网站的订单履约系统。一张订单从“已支付”，到“下发给仓库”，到“出仓完成”。假定从“已支付”到“下发给仓库”最多用1个小时；从“下发给仓库”到“出仓完成”最多用8个小时。意味着只要发现1个订单的状态过了1个小时之后还处于“已支付”状态，就认为订单下发没有成功，需要重新下发，也就是“重试”。同样，只要发现订单过了8个小时还未出仓，这时可能会发出报警，仓库的作业系统是否出了问题……诸如此类。\n\n这个案例跟事务的状态很类似：一旦发现系统中的某个数据对象过了一个限定时间生命周期仍然没有走完，仍然处在某个中间状态，就说明系统不一致了，要进行某种补偿操作（比如重试或报警）。\n\n更复杂一点：订单有状态，库存系统的库存也有状态，优惠系统的优惠券也有状态，根据业务规则，这些状态之间进行比对，就能发现系统某个地方不一致，做相应的补偿。\n\n案例2：微博的关注关系。需要存两张表，一张是关注表，一张是粉丝表，这两张表各自都是分库分表的。假设A关注了B，需要先以A为主键进行分库，存入关注表；再以B为主键进行分库，存入粉丝表。也就是说，一次业务操作，要向两个数据库中写入两条数据，如何保证原子性？\n\n案例3：电商的订单系统也是分库分表的。订单通常有两个常用的查询维度，一个是买家，一个是卖家。如果按买家分库，按卖家查询就不好做；如果按卖家分库，按买家查询就不好做。这种通常会把订单数据冗余一份，按买家进行分库分表存一份，按卖家再分库分表存一份。和案例2存在同样的问题：一个订单要向两个数据库中写入两条数据，如何保证原子性？\n\n如果把案例2、案例3的问题看作为一个分布式事务的话，可以用最终一致性、TCC、事务状态表去实现，但这些方法都太重，一个简单的方法是“对账”。\n\n因为两个库的数据是冗余的，可以先保证一个库的数据是准确的，以该库为基准校对另外一个库。\n\n对账又分为全量对账和增量对账：\n\n（1）全量对账。比如每天晚上运作一个定时任务，比对两个数据库。\n（2）增量对账。可以是一个定时任务，基于数据库的更新时间；也可以基于消息中间件，每一次业务操作都抛出一个消息到消息中间件，然后由一个消费者消费这条消息，对两个数据库中的数据进行比对（当然，消息可能丢失，无法百分之百地保证，还是需要全量对账来兜底）。\n\n总之，对账的关键是要找出“数据背后的数学规律”。有些规律比较直接，谁都能看出来，比如案例2、案例3的冗余数据库；有些规律隐含一些，比如案例1的订单履约的状态。找到了规律就可以基于规律进行数据的比对，发现问题，然后补偿。\n\n### 妥协方案：弱一致性+基于状态的补偿\n- “最终一致性”是一种异步的方法，数据有一定延迟；\n- TCC是一种同步方法，但TCC需要两个阶段，性能损耗较大；\n- 事务状态表也是一种同步方法，但每次要记事务流水，要更新事务状态，很烦琐，性能也有损耗；\n- “对账”也是一个事后过程。\n\n如果需要一个同步的方案，既要让系统之间保持一致性，又要有很高的性能，支持高并发，应该怎么处理呢？\n\n电商网站的下单至少需要两个操作：创建订单和扣库存。订单系统有订单的数据库和服务，库存系统有库存的数据库和服务。先创建订单，后扣库存，可能会创建订单成功，扣库存失败；反过来，先扣库存，后创建订单，可能会扣库存成功，创建订单失败。如何保证创建订单 + 扣库存两个操作的原子性，同时还要能抵抗线上的高并发流量？\n![](电商系统的下单场景.jpg)\n\n如果用最终一致性方案，因为是异步操作，如果库存扣减不及时会导致超卖，因此最终一致性的方案不可行；如果用TCC方案，则意味着一个用户请求要调用两次（Try和Confirm）订单服务、两次（Try和Confirm）库存服务，性能又达不到要求。如果用事务状态表，要写事务状态，也存在性能问题。\n\n既要满足高并发，又要达到一致性，鱼和熊掌不能兼得。可以利用业务的特性，采用一种弱一致的方案。\n\n对于该需求，有一个关键特性：对于电商的购物来讲，允许少卖，但不能超卖。比如有100件东西，卖给99个人，有1件没有卖出去，这是可以接受的；但如果卖给了101个人，其中1个人拿不到货，平台违约，这就不能接受。而该处就利用了这个特性，具体做法如下。\n\n#### 方案1：先扣库存，后创建订单\n有三种情况：\n1. 扣库存成功，提交订单成功，返回成功。\n2. 扣库存成功，提交订单失败，返回失败，调用方重试（此处可能会多扣库存）。\n3. 扣库存失败，不再提交订单，返回失败，调用方重试（此处可能会多扣库存）。\n\n#### 方案2：先创建订单，后扣库存\n也有三种情况：\n\n1. 提交订单成功，扣库存成功，返回成功。\n2. 提交订单成功，扣库存失败，返回失败，调用方重试（此处可能会多扣库存）。\n3. 提交订单失败，不再扣库存，调用方重试。\n\n无论方案1，还是方案2，只要最终保证库存可以多扣，不能少扣即可。\n\n但是，库存多扣了，数据不一致，怎么补偿呢？\n\n库存每扣一次，都会生成一条流水记录。这条记录的初始状态是“占用”，等订单支付成功后，会把状态改成“释放”。\n\n对于那些过了很长时间一直是占用，而不释放的库存，要么是因为前面多扣造成的，要么是因为用户下了单但没有支付。\n\n通过比对，得到库存系统的“占用又没有释放的库存流水”与订单系统的未支付的订单，就可以回收这些库存，同时把对应的订单取消。类似12306网站，过一定时间不支付，订单会取消，将库存释放。\n\n### 妥协方案：重试+回滚+报警+人工修复\n上文介绍了基于订单的状态 +库存流水的状态做补偿（或者说叫对账）。如果业务很复杂，状态的维护也很复杂，就可以采用下面这种更加妥协而简单的方法。\n\n按方案1，先扣库存，后创建订单。不做状态补偿，为库存系统提供一个回滚接口。创建订单如果失败了，先重试。如果重试还不成功，则回滚库存的扣减。如回滚也失败，则发报警，进行人工干预修复。\n\n总之，根据业务逻辑，通过三次重试或回滚的方法，最大限度地保证一致。实在不一致，就发报警，让人工干预。只要日志流水记录得完整，人工肯定可以修复！通常只要业务逻辑本身没问题，重试、回滚之后还失败的概率会比较低，所以这种办法虽然丑陋，但很实用。\n\n\n### 总结\n解决分布式事务问题，比较可靠的七种方法：两种最终一致性的方案，两种妥协办法(2PC、3PC)，两种基于状态 + 重试 + 幂等的方法（TCC，状态机+重试+幂等），还有一种对账方法。\n\n在实现层面，妥协和对账的办法最容易，最终一致性次之，TCC最复杂。\n\n### 参考资料\n\n- [实践丨分布式事务解决方案汇总：2PC、消息中间件、TCC、状态机+重试+幂等](https://mp.weixin.qq.com/s/7u5zfrLzk38tDwOfDEkuqw)\n- [深入分布式事务](https://mp.weixin.qq.com/s/YDbqZFcliHrILk9w0sCx8Q)\n- [[分布式]：深入理解分布式系统的2PC和3PC](https://blog.csdn.net/w372426096/article/details/80449695)\n\n\n","tags":["分布式"],"categories":["分布式"]},{"title":"MySQL 中的重做日志，回滚日志 ，以及二进制日志的简单总结","url":"/2019/03/29/MySQL-中的重做日志，回滚日志-，以及二进制日志的简单总结/","content":"\n### 简介\nMySQL中有六种日志文件，分别是：重做日志（redo log）、回滚日志（undo log）、二进制日志（binlog）、错误日志（errorlog）、慢查询日志（slow query log）、一般查询日志（general log），中继日志（relay log）。\n其中重做日志和回滚日志与事务操作息息相关，二进制日志也与事务操作有一定的关系，这三种日志，对理解MySQL中的事务操作有着重要的意义。\ninnodb事务日志包括redo log和undo log。redo log是重做日志，提供前滚操作，undo log是回滚日志，提供回滚操作。\nundo log不是redo log的逆向过程，其实它们都算是用来恢复的日志：\n1.redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。\n2.undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。\n\n### 前滚和回滚\n#### 前滚\n\n   未完全提交的事务，即该事务已经被执行commit命令了，只是现在该事务修改所对应的脏数据块中只有一部分被写到磁盘上的数据文件中，还有一部分已经被置为提交标记的脏块还在内存上，如果此时数据库实例崩溃了，则当数据库实例恢复时，就需要用前滚（这个机制）来完成事务的完全提交，即将先前那部分已经被置为提交标记且还在内存上的脏块写入到磁盘上的数据文件中。\n\n#### 回滚\n\n    未提交的事务，即该事务未被执行commit命令。但是此时，该事务修改的脏块中也有可能一部分脏块写入到数据文件中了。如果此时数据库实例崩溃了，则当数据库实例恢复时，就需要用回滚（这个机制）来将先前那部分已经写入到数据文件的脏块从数据文件上撤销掉。\n\n\n### 重做日志（redo log）\nredo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。\n\n#### 作用\n- 确保事务的持久性。\n- 防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。\n\n#### 内容\n物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。\n\n#### 什么时候产生\n事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。\n\n#### 什么时候释放\n当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。\n\n#### 对应的物理文件\n默认情况下，对应的物理文件位于数据库的data目录下的ib_logfile1&ib_logfile2。\n\n- innodb_log_group_home_dir：指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。\n- innodb_log_files_in_group：指定重做日志文件组中文件的数量，默认2\n关于文件的大小和数量，由一下两个参数配置\n- innodb_log_file_size：重做日志文件的大小。\n- innodb_mirrored_log_groups：指定了日志镜像文件组的数量，默认1\n\n#### redo log是什么时候写盘的？\n前面说了是在事物开始之后逐步写盘的。\n之所以说重做日志是在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存，\n原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M(这里设置的16M),Innodb存储引擎先将重做日志写入innodb_log_buffer中。\n![](innodb_log_buffer.jpg)\n\n然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘\n1，Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件。\n2，每个事务提交时会将重做日志刷新到重做日志文件。\n3，当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件\n由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是对于第一种方式，Innodb_log_buffer到重做日志文件是Master Thread线程的定时任务。\n因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。\n即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。\n这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。\n\n#### 参数设置 \nMySQL支持用户自定义在commit时如何将log buffer中的日志刷log file中。这种控制通过变量 innodb_flush_log_at_trx_commit 的值来决定。该变量有3种值：0、1、2，默认为1。但注意，这个变量只是控制commit动作是否刷新log buffer到磁盘。\n\n- 当设置为1的时候，事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file on disk中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。\n- 当设置为0的时候，事务提交时不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。\n- 当设置为2的时候，每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到log file on disk。\n\n在主从复制结构中，要保证事务的持久性和一致性，需要对日志相关变量设置为如下：\n\n- 如果启用了二进制日志，则设置sync_binlog=1，即每提交一次事务同步写到磁盘中。\n- 总是设置innodb_flush_log_at_trx_commit=1，即每提交一次事务都写到磁盘中。\n上述两项变量的设置保证了：每次提交事务都写入二进制日志和事务日志，并在提交时将它们刷新到磁盘中。\n\n\n- innodb_flush_log_at_trx_commit={0|1|2} # 指定何时将事务日志刷到磁盘，默认为1。\n0表示每秒将\"log buffer\"同步到\"os buffer\"且从\"os buffer\"刷到磁盘日志文件中。\n1表示每事务提交都将\"log buffer\"同步到\"os buffer\"且从\"os buffer\"刷到磁盘日志文件中。\n2表示每事务提交都将\"log buffer\"同步到\"os buffer\"但每秒才从\"os buffer\"刷到磁盘日志文件中。\n- innodb_log_buffer_size：# log buffer的大小，默认8M\n- innodb_log_file_size：#事务日志的大小，默认5M\n- innodb_log_files_group =2：# 事务日志组中的事务日志文件个数，默认2个\n- innodb_log_group_home_dir =./：# 事务日志组路径，当前目录表示数据目录\n- innodb_mirrored_log_groups =1：# 指定事务日志组的镜像组个数，但镜像功能好像是强制关闭的，所以只有一个log group。在MySQL5.7中该变量已经移除。\n\n\n### 回滚日志（undo log）\n#### 作用\n保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。\n\n在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。\n\nundo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。\n\n当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。\n\nundo log是采用段(segment)的方式来记录的，每个undo操作在记录的时候占用一个undo log segment。\n\n另外，undo log也会产生redo log，因为undo log也要实现持久性保护。\n#### 内容\n逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。\n\n####  什么时候产生\n事务开始之前，将当前的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性\n\n#### 什么时候释放\n当事务提交之后，undo log并不能立马被删除，\n而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。\n\n#### 对应的物理文件\nMySQL5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认的名称是ibdata，位于数据文件目录中。\nMySQL5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数\n如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。\n关于MySQL5.7之后的独立undo 表空间配置参数如下\ninnodb_undo_directory = /data/undospace/ –undo独立表空间的存放目录\ninnodb_undo_logs = 128 –回滚段为128KB\ninnodb_undo_tablespaces = 4 –指定有4个undo log文件\n\n如果undo使用的共享表空间，这个共享表空间中又不仅仅是存储了undo的信息，共享表空间的默认为与MySQL的数据目录下面，其属性由参数innodb_data_file_path配置。\n![](undo_log.jpg)\n\n#### 其他\nundo是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redo log的产生。\n默认情况下undo文件是保持在共享表空间的，也即ibdatafile文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的undo信息，全部保存在共享表空间中的。\n因此共享表空间可能会变的很大，默认情况下，也就是undo 日志使用共享表空间的时候，被“撑大”的共享表空间是不会也不能自动收缩的。\n因此，mysql5.7之后的“独立undo 表空间”的配置就显得很有必要了。\n\n#### delete/update操作的内部机制\n当事务提交的时候，innodb不会立即删除undo log，因为后续还可能会用到undo log，如隔离级别为repeatable read时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即undo log不能删除。\n\n但是在事务提交的时候，会将该事务对应的undo log放入到删除列表中，未来通过purge来删除。并且提交事务时，还会判断undo log分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的undo log页而浪费存储空间和性能。\n\n通过undo log记录delete和update操作的结果发现：(insert操作无需分析，就是插入行而已)\n\n- delete操作实际上不会直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。\n- update分为两种情况：update的列是否是主键列。\n如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。\n如果是主键列，update分两部执行：先删除该行，再插入一行目标行。\n\n### 二进制日志（binlog）\n#### 作用\n- 用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。\n- 用于数据库的基于时间点的还原。\n\n####  内容\n逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。\n但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，\n也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。\n在使用mysql binlog解析binlog之后一些都会真相大白。\n因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。\n\n#### 什么时候产生\n事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。\n这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。\n因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。\n这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。\n\n#### 什么时候释放\nbinlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。\n![](binlog1.jpg)\n对应的物理文件：\n配置文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定的最大的大小之后，进行滚动更新，生成新的日志文件。\n对于每个binlog日志文件，通过一个统一的index文件来组织。\n![](binlog2.jpg)\n\n#### 其他\n二进制日志的作用之一是还原数据库的，这与redo log很类似，也记录了innodb表的很多操作，也能实现重做的功能，但是两者有本质的不同\n\n- 作用不同：redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。\n\n- 内容不同：redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，可以简单认为记录的就是sql语句\n\n- 两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。\n\n- 恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog\n\n- 二进制日志是在存储引擎的上层产生的，不管是什么存储引擎，对数据库进行了修改都会产生二进制日志。而redo log是innodb层产生的，只记录该存储引擎中表的修改。并且二进制日志先于redo log被记录\n\n- 二进制日志只在每次事务提交的时候一次性写入缓存中的日志\"文件\"。而redo log在数据准备修改前写入缓存中的redo log中，然后才对缓存中的数据执行修改操作；而且保证在发出事务提交指令时，先向缓存中的redo log写入日志，写入完成后才执行提交动作\n\n\n关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，\nMySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。\n\n\n### 日志刷盘的规则\nlog buffer中未刷到磁盘的日志称为脏日志(dirty log)。\n\n在上面的说过，默认情况下事务每次提交的时候都会刷事务日志到磁盘中，这是因为变量 innodb_flush_log_at_trx_commit 的值为1。但是innodb不仅仅只会在有commit动作后才会刷日志到磁盘，这只是innodb存储引擎刷日志的规则之一。\n\n刷日志到磁盘有以下几种规则：\n\n1.发出commit动作时。已经说明过，commit发出后是否刷日志由变量 innodb_flush_log_at_trx_commit 控制。\n\n2.每秒刷一次。这个刷日志的频率由变量 innodb_flush_log_at_timeout 值决定，默认是1秒。要注意，这个刷日志频率和commit动作无关。\n\n3.当log buffer中已经使用的内存超过一半时。\n\n4.当有checkpoint时，checkpoint在一定程度上代表了刷到磁盘时日志所处的LSN位置。\n\n### 数据页刷盘的规则及checkpoint\n内存中(buffer pool)未刷到磁盘的数据称为脏数据(dirty data)。由于数据和日志都以页的形式存在，所以脏页表示脏数据和脏日志。\n不仅仅是日志需要刷盘，脏数据页也一样需要刷盘。\n\n在innodb中，数据刷盘的规则只有一个：checkpoint。但是触发checkpoint的情况却有几种。不管怎样，checkpoint触发后，会将buffer中脏数据页和脏日志页都刷到磁盘。\n\ninnodb存储引擎中checkpoint分为两种：\n\n- sharp checkpoint：在重用redo log文件(例如切换日志文件)的时候，将所有已记录到redo log中对应的脏数据刷到磁盘。\n- fuzzy checkpoint：一次只刷一小部分的日志到磁盘，而非将所有脏日志刷盘。有以下几种情况会触发该检查点：\n   1、 master thread checkpoint：由master线程控制，每秒或每10秒刷入一定比例的脏页到磁盘。\n   2、flush_lru_list checkpoint：从MySQL5.6开始可通过 innodb_page_cleaners 变量指定专门负责脏页刷盘的page cleaner线程的个数，该线程的目的是为了保证lru列表有可用的空闲页。\n   3、async/sync flush checkpoint：同步刷盘还是异步刷盘。例如还有非常多的脏页没刷到磁盘(非常多是多少，有比例控制)，这时候会选择同步刷到磁盘，但这很少出现；如果脏页不是很多，可以选择异步刷到磁盘，如果脏页很少，可以暂时不刷脏页到磁盘\n   4、dirty page too much checkpoint：脏页太多时强制触发检查点，目的是为了保证缓存有足够的空闲空间。too much的比例由变量 innodb_max_dirty_pages_pct 控制，MySQL 5.6默认的值为75，即当脏页占缓冲池的百分之75后，就强制刷一部分脏页到磁盘。\n\n由于刷脏页需要一定的时间来完成，所以记录检查点的位置是在每次刷盘结束之后才在redo log中标记的。\n\n> - MySQL停止时是否将脏数据和脏日志刷入磁盘，由变量innodb_fast_shutdown={ 0|1|2 }控制，默认值为1，即停止时只做一部分purge，忽略大多数flush操作(但至少会刷日志)，在下次启动的时候再flush剩余的内容，实现fast shutdown。\n\n###  innodb的恢复行为\n在启动innodb的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。\n\n因为redo log记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如二进制日志)要快很多。而且，innodb自身也做了一定程度的优化，让恢复速度变得更快。\n\n重启innodb时，checkpoint表示已经完整刷到磁盘上data page上的LSN，因此恢复时仅需要恢复从checkpoint开始的日志部分。例如，当数据库在上一次checkpoint的LSN为10000时宕机，且事务是已经提交过的状态。启动数据库时会检查磁盘中数据页的LSN，如果数据页的LSN小于日志中的LSN，则会从检查点开始恢复。\n\n还有一种情况，在宕机前正处于checkpoint的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度。这时候一宕机，数据页中记录的LSN就会大于日志页中的LSN，在重启的恢复过程中会检查到这一情况，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。\n\n另外，事务日志具有幂等性，所以多次操作得到同一结果的行为在日志中只记录一次。而二进制日志不具有幂等性，多次操作会全部记录下来，在恢复的时候会多次执行二进制日志中的记录，速度就慢得多。例如，某记录中id初始值为2，通过update将值设置为了3，后来又设置成了2，在事务日志中记录的将是无变化的页，根本无需恢复；而二进制会记录下两次update操作，恢复时也将执行这两次update操作，速度比事务日志恢复更慢。\n\n\n### binlog和事务日志的先后顺序及group commit\n如果事务不是只读事务，即涉及到了数据的修改，默认情况下会在commit的时候调用fsync()将日志刷到磁盘，保证事务的持久性。\n\n但是一次刷一个事务的日志性能较低，特别是事务集中在某一时刻时事务量非常大的时候。innodb提供了group commit功能，可以将多个事务的事务日志通过一次fsync()刷到磁盘中。\n\n因为事务在提交的时候不仅会记录事务日志，还会记录二进制日志，但是它们谁先记录呢？二进制日志是MySQL的上层日志，先于存储引擎的事务日志被写入。\n在MySQL5.6以前，当事务提交(即发出commit指令)后，MySQL接收到该信号进入commit prepare阶段；进入prepare阶段后，立即写内存中的二进制日志，写完内存中的二进制日志后就相当于确定了commit操作；然后开始写内存中的事务日志；最后将二进制日志和事务日志刷盘，它们如何刷盘，分别由变量 sync_binlog 和 innodb_flush_log_at_trx_commit 控制。\n\n但因为要保证二进制日志和事务日志的一致性，在提交后的prepare阶段会启用一个prepare_commit_mutex锁来保证它们的顺序性和一致性。但这样会导致开启二进制日志后group commmit失效，特别是在主从复制结构中，几乎都会开启二进制日志。\n\n在MySQL5.6中进行了改进。提交事务时，在存储引擎层的上一层结构中会将事务按序放入一个队列，队列中的第一个事务称为leader，其他事务称为follower，leader控制着follower的行为。虽然顺序还是一样先刷二进制，再刷事务日志，但是机制完全改变了：删除了原来的prepare_commit_mutex行为，也能保证即使开启了二进制日志，group commit也是有效的。\n\nMySQL5.6中分为3个步骤：flush阶段、sync阶段、commit阶段。\n\n![](事务.png)\n\n- flush阶段：向内存中写入每个事务的二进制日志。\n- sync阶段：将内存中的二进制日志刷盘。若队列中有多个事务，那么仅一次fsync操作就完成了二进制日志的刷盘操作。这在MySQL5.6中称为BLGC(binary log group commit)。\n- commit阶段：leader根据顺序调用存储引擎层事务的提交，由于innodb本就支持group commit，所以解决了因为锁 prepare_commit_mutex 而导致的group commit失效问题。\n在flush阶段写入二进制日志到内存中，但是不是写完就进入sync阶段的，而是要等待一定的时间，多积累几个事务的binlog一起进入sync阶段，等待时间由变量 binlog_max_flush_queue_time 决定，默认值为0表示不等待直接进入sync，设置该变量为一个大于0的值的好处是group中的事务多了，性能会好一些，但是这样会导致事务的响应时间变慢，所以建议不要修改该变量的值，除非事务量非常多并且不断的在写入和更新。\n\n进入到sync阶段，会将binlog从内存中刷入到磁盘，刷入的数量和单独的二进制日志刷盘一样，由变量 sync_binlog 控制。\n\n当有一组事务在进行commit阶段时，其他新事务可以进行flush阶段，它们本就不会相互阻塞，所以group commit会不断生效。当然，group commit的性能和队列中的事务数量有关，如果每次队列中只有1个事务，那么group commit和单独的commit没什么区别，当队列中事务越来越多时，即提交事务越多越快时，group commit的效果越明显。\n\n\n### 参考资料\n- [MySQL 中的重做日志，回滚日志 ，以及二进制日志的简单总结](www.cnblogs.com/wy123/p/8365234.html)\n- [前滚和回滚的区别](https://blog.csdn.net/haiross/article/details/17003543)\n- [详细分析MySQL事务日志(redo log和undo log)](https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html)\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"分布式ID生成方案","url":"/2019/03/29/分布式ID生成方案/","content":"\n### 分布式系统中我们对ID生成器要求又有哪些呢?\n\n- 全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。\n\n- 递增：比较低要求的条件为趋势递增，即保证下一个ID一定大于上一个ID，而比较苛刻的要求是连续递增，如1,2,3等等。\n\n- 高可用高性能：ID生成事关重大，一旦挂掉系统崩溃;高性能是指必须要在压测下表现良好，如果达不到要求则在高并发环境下依然会导致系统瘫痪。\n\n### UUID/GUID（通用唯一识别码）\nUUID是通用唯一识别码（Universally Unique Identifier)的缩写，开放软件基金会(OSF)。\n由以下几部分的组合：\n\n1、当前日期和时间\n2、时钟序列\n3、全局唯一的IEEE机器识别号（如果有网卡，从网卡获得，没有网卡以其他方式获得）\n\nUUID是由128位二进制组成，一般转换成十六进制，然后用String表示。\n\n示例UUID，长度为36的字符串：4cdbc040-657a-4847-b266-7e31d9e2c3d9\n\n#### 优点\n1、通过本地生成，没有经过网络I/O，性能较快\n\n2、能够保证独立性，程序可以在不同的数据库间迁移，效果不受影响。\n\n3、保证生成的ID不仅是表独立的，而且是库独立的，这点在你想切分数据库的时候尤为重要。\n\n#### 缺点\n\n1、UUID太长，通常以36长度的字符串表示，空间占用大。\n\n2、UUID无业务含义：很多需要ID能标识业务含义的地方不使用。\n\n3、不满足递增要求，对MySQL索引不利：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。\n\n#### 适用场景\nUUID的适用场景可以为不担心过多的空间占用，以及不需要生成有递增趋势的数字。在Log4j里面他在UuidPatternConverter中加入了UUID来标识每一条日志。\n\n### 数据库主键自增\n用数据库生成ID是最常见的方案。能够确保ID全数据库唯一。\n\nMySQL使用AUTO_INCREMENT、Oracle使用Sequence序列\n\n集群环境下，不同的库，设置不同的初始值，每次自增加100\n\nMySQL下修改起点和步长的方式\n```sql\n\n    set @@auto_increment_offset=1;  -- 设置起点\n\n    set @@auto_increment_increment=100; -- 设置步长为100\n\n    show variables like 'auto_inc%'; -- 查看参数\n```\n#### 优点\n简单方便，有序递增，方便排序和分页\n\n#### 缺点\n- 分库分表会带来问题，需要进行改造。\n\n- 并发性能不高，受限于数据库的性能。\n\n- 数据库宕机服务不可用。\n\n#### 适用场景\n根据上面可以总结出来，当数据量不多，并发性能不高的时候这个很适合，比如一些to B的业务，商家注册这些，商家注册和用户注册不是一个数量级的，所以可以数据库主键递增。如果对顺序递增强依赖，那么也可以使用数据库主键自增。\n\n#### 优化方案\n\n针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。比如：Master1 生成的是 1，4，7，10，Master2生成的是2,5,8,11 Master3生成的是 3,6,9,12。这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。\n\n### 基于Redis自增\nRedis的 incr(key)  API 用于将key的值进行递增，并返回增长数值。如果key不存在，则创建并赋值为0。\n\n利用Redis的特性：单线程原子操作、自增计数API、数据有效期机制 EX。\n示例：\n\n1、业务编码 + 地区 + 自增数值。 （9 020 00000000001）\n\n#### 优点\n\n1、性能比数据库好，能满足有序递增。\n\n2、拓展性强，可以方便的结合业务进行处理；\n\n3、利用Redis操作原子性的特性，保证在并发的时候不会重复；\n\n#### 缺点\n1、引入Redis就意味着引入其他第三方的依赖；\n\n2、增加一次网络开销；\n\n3、需要对Redis服务实现高可用；\n\n4、 由于redis是内存的KV数据库，即使有AOF和RDB，但是依然会存在数据丢失，有可能会造成ID重复。\n\n#### 适用场景\n由于其性能比数据库好，但是有可能会出现ID重复和不稳定，这一块如果可以接受那么就可以使用。也适用于到了某个时间，比如每天都刷新ID，那么这个ID就需要重置，通过(Incr Today)，每天都会从0开始加。\n\n### ZooKeeper生成ID\n实际业务中，除了分布式ID全局唯一之外，还有是否趋势/连续递增的要求。根据具体业务需求的不同，有两种可选方案。\n\n一是只保证全局唯一，不保证连续递增。二是既保证全局唯一，又保证连续递增。\n\n#### 基于ZooKeeper和本地缓存的方案\n基于zookeeper分布式ID实现方案有很多种，本方案只使用ZooKeeper作为分段节点协调工具。每台服务器首先从zookeeper缓存一段，如1-1000的id。\n\n此时zk上保存最大值1000，每次获取的时候都会进行判断，如果id小于本地最大值，即id<=1000，则更新本地的当前值，如果id大于本地当前值，比如说是1001，则会将从zk再获取下一个id数据段并在本地缓存。获取数据段的时候需要更新zk节点数据，更新的时候使用curator的分布式锁来实现。\n\n由于id是从本机获取，因此本方案的优点是性能非常好。缺点是如果多主机负载均衡，则会出现不连续的id，当然将递增区段设置为1也能保证连续的id，但是效率会受到很大影响。\n```java\nimport org.apache.curator.framework.CuratorFramework;\nimport org.apache.curator.framework.CuratorFrameworkFactory;\nimport org.apache.curator.framework.recipes.locks.InterProcessSemaphoreMutex;\nimport org.apache.curator.retry.ExponentialBackoffRetry;\nimport org.apache.zookeeper.CreateMode;\nimport org.apache.zookeeper.data.Stat;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.UnsupportedEncodingException;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\n/**\n * 根据开源项目mycat实现基于zookeeper的递增序列号\n * <p>\n * 只要配置好ZK地址和表名的如下属性\n * MINID 某线程当前区间内最小值\n * MAXID 某线程当前区间内最大值\n * CURID 某线程当前区间内当前值\n *\n * @author wangwanbin\n * @version 1.0\n * @time 2017/9/1\n */\npublic class ZKCachedSequenceHandler extends SequenceHandler {\n    protected static final Logger LOGGER = LoggerFactory.getLogger(ZKCachedSequenceHandler.class);\n    private static final String KEY_MIN_NAME = \".MINID\";// 1\n    private static final String KEY_MAX_NAME = \".MAXID\";// 10000\n    private static final String KEY_CUR_NAME = \".CURID\";// 888\n    private final static long PERIOD = 1000;//每次缓存的ID段数量\n    private static ZKCachedSequenceHandler instance = new ZKCachedSequenceHandler();\n\n    /**\n     * 私有化构造方法,单例模式\n     */\n    private ZKCachedSequenceHandler() {\n    }\n\n    /**\n     * 获取sequence工具对象的唯一方法\n     *\n     * @return\n     */\n    public static ZKCachedSequenceHandler getInstance() {\n        return instance;\n    }\n\n    private Map<String, Map<String, String>> tableParaValMap = null;\n\n    private CuratorFramework client;\n    private InterProcessSemaphoreMutex interProcessSemaphore = null;\n\n    public void loadZK() {\n        try {\n            this.client = CuratorFrameworkFactory.newClient(zkAddress, new ExponentialBackoffRetry(1000, 3));\n            this.client.start();\n        } catch (Exception e) {\n            LOGGER.error(\"Error caught while initializing ZK:\" + e.getCause());\n        }\n    }\n\n    public Map<String, String> getParaValMap(String prefixName) {\n        if (tableParaValMap == null) {\n            try {\n                loadZK();\n                fetchNextPeriod(prefixName);\n            } catch (Exception e) {\n                LOGGER.error(\"Error caught while loding configuration within current thread:\" + e.getCause());\n            }\n        }\n        Map<String, String> paraValMap = tableParaValMap.get(prefixName);\n        return paraValMap;\n    }\n\n    public Boolean fetchNextPeriod(String prefixName) {\n        try {\n            Stat stat = this.client.checkExists().forPath(PATH + \"/\" + prefixName + SEQ);\n\n            if (stat == null || (stat.getDataLength() == 0)) {\n                try {\n                    client.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT)\n                            .forPath(PATH + \"/\" + prefixName + SEQ, String.valueOf(0).getBytes());\n                } catch (Exception e) {\n                    LOGGER.debug(\"Node exists! Maybe other instance is initializing!\");\n                }\n            }\n            if (interProcessSemaphore == null) {\n                interProcessSemaphore = new InterProcessSemaphoreMutex(client, PATH + \"/\" + prefixName + SEQ);\n            }\n            interProcessSemaphore.acquire();\n            if (tableParaValMap == null) {\n                tableParaValMap = new ConcurrentHashMap<>();\n            }\n            Map<String, String> paraValMap = tableParaValMap.get(prefixName);\n            if (paraValMap == null) {\n                paraValMap = new ConcurrentHashMap<>();\n                tableParaValMap.put(prefixName, paraValMap);\n            }\n            long now = Long.parseLong(new String(client.getData().forPath(PATH + \"/\" + prefixName + SEQ)));\n            client.setData().forPath(PATH + \"/\" + prefixName + SEQ, ((now + PERIOD) + \"\").getBytes());\n            if (now == 1) {\n                paraValMap.put(prefixName + KEY_MAX_NAME, PERIOD + \"\");\n                paraValMap.put(prefixName + KEY_MIN_NAME, \"1\");\n                paraValMap.put(prefixName + KEY_CUR_NAME, \"0\");\n            } else {\n                paraValMap.put(prefixName + KEY_MAX_NAME, (now + PERIOD) + \"\");\n                paraValMap.put(prefixName + KEY_MIN_NAME, (now) + \"\");\n                paraValMap.put(prefixName + KEY_CUR_NAME, (now) + \"\");\n            }\n        } catch (Exception e) {\n            LOGGER.error(\"Error caught while updating period from ZK:\" + e.getCause());\n        } finally {\n            try {\n                interProcessSemaphore.release();\n            } catch (Exception e) {\n                LOGGER.error(\"Error caught while realeasing distributed lock\" + e.getCause());\n            }\n        }\n        return true;\n    }\n\n    public Boolean updateCURIDVal(String prefixName, Long val) {\n        Map<String, String> paraValMap = tableParaValMap.get(prefixName);\n        if (paraValMap == null) {\n            throw new IllegalStateException(\"ZKCachedSequenceHandler should be loaded first!\");\n        }\n        paraValMap.put(prefixName + KEY_CUR_NAME, val + \"\");\n        return true;\n    }\n\n    /**\n     * 获取自增ID\n     *\n     * @param sequenceEnum\n     * @return\n     */\n    @Override\n    public synchronized long nextId(SequenceEnum sequenceEnum) {\n        String prefixName = sequenceEnum.getCode();\n        Map<String, String> paraMap = this.getParaValMap(prefixName);\n        if (null == paraMap) {\n            throw new RuntimeException(\"fetch Param Values error.\");\n        }\n        Long nextId = Long.parseLong(paraMap.get(prefixName + KEY_CUR_NAME)) + 1;\n        Long maxId = Long.parseLong(paraMap.get(prefixName + KEY_MAX_NAME));\n        if (nextId > maxId) {\n            fetchNextPeriod(prefixName);\n            return nextId(sequenceEnum);\n        }\n        updateCURIDVal(prefixName, nextId);\n        return nextId.longValue();\n    }\n\n    public static void main(String[] args) throws UnsupportedEncodingException {\n        long startTime = System.currentTimeMillis();   //获取开始时间\n        final ZKCachedSequenceHandler sequenceHandler = getInstance();\n        sequenceHandler.loadZK();\n        new Thread() {\n            public void run() {\n                long startTime2 = System.currentTimeMillis();   //获取开始时间\n                for (int i = 0; i < 5000; i++) {\n                    System.out.println(\"线程1 \" + sequenceHandler.nextId(SequenceEnum.ACCOUNT));\n                }\n                long endTime2 = System.currentTimeMillis(); //获取结束时间\n                System.out.println(\"程序运行时间1： \" + (endTime2 - startTime2) + \"ms\");\n            }\n        }.start();\n        for (int i = 0; i < 5000; i++) {\n            System.out.println(\"线程2 \" + sequenceHandler.nextId(SequenceEnum.ACCOUNT));\n        }\n        long endTime = System.currentTimeMillis(); //获取结束时间\n        System.out.println(\"程序运行时间2： \" + (endTime - startTime) + \"ms\");\n    }\n}\n```\n\n\n#### 利用zk的永久自增节点策略实现持续递增ID\n使用zk的永久sequence策略创建节点，并获取返回值，然后删除前一个节点，这样既防止zk服务器存在过多的节点，又提高了效率；节点删除采用线程池来统一处理，提高响应速度。\n\n优点：能创建连续递增的ID。\n关键实现代码如下：\n```java\nimport com.zb.p2p.enums.SequenceEnum;\nimport org.apache.commons.pool2.PooledObject;\nimport org.apache.commons.pool2.PooledObjectFactory;\nimport org.apache.commons.pool2.impl.DefaultPooledObject;\nimport org.apache.commons.pool2.impl.GenericObjectPool;\nimport org.apache.commons.pool2.impl.GenericObjectPoolConfig;\nimport org.apache.curator.framework.CuratorFramework;\nimport org.apache.curator.framework.CuratorFrameworkFactory;\nimport org.apache.curator.retry.ExponentialBackoffRetry;\nimport org.apache.zookeeper.CreateMode;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.ArrayDeque;\nimport java.util.Iterator;\nimport java.util.Queue;\nimport java.util.concurrent.ConcurrentLinkedQueue;\nimport java.util.concurrent.CountDownLatch;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\n/**\n * 基于zk的永久型自增节点PERSISTENT_SEQUENTIAL实现\n * 每次生成节点后会使用线程池执行删除节点任务\n * Created by wangwanbin on 2017/9/5.\n */\npublic class ZKIncreaseSequenceHandler extends SequenceHandler implements PooledObjectFactory<CuratorFramework> {\n    protected static final Logger LOGGER = LoggerFactory.getLogger(ZKCachedSequenceHandler.class);\n    private static ZKIncreaseSequenceHandler instance = new ZKIncreaseSequenceHandler();\n    private static ExecutorService fixedThreadPool = Executors.newFixedThreadPool(1);\n    private GenericObjectPool genericObjectPool;\n    private Queue<Long> preNodes = new ConcurrentLinkedQueue<>();\n    private static String ZK_ADDRESS = \"\"; //192.168.0.65\n    private static String PATH = \"\";//  /sequence/p2p\n    private static String SEQ = \"\";//seq;\n\n    /**\n     * 私有化构造方法,单例模式\n     */\n    private ZKIncreaseSequenceHandler() {\n        GenericObjectPoolConfig config = new GenericObjectPoolConfig();\n        config.setMaxTotal(4);\n        genericObjectPool = new GenericObjectPool(this, config);\n    }\n\n    /**\n     * 获取sequence工具对象的唯一方法\n     *\n     * @return\n     */\n    public static ZKIncreaseSequenceHandler getInstance(String zkAddress, String path, String seq) {\n        ZK_ADDRESS = zkAddress;\n        PATH = path;\n        SEQ = seq;\n        return instance;\n    }\n\n    @Override\n    public long nextId(final SequenceEnum sequenceEnum) {\n        String result = createNode(sequenceEnum.getCode());\n        final String idstr = result.substring((PATH + \"/\" + sequenceEnum.getCode() + \"/\" + SEQ).length());\n        final long id = Long.parseLong(idstr);\n        preNodes.add(id);\n        //删除上一个节点\n        fixedThreadPool.execute(new Runnable() {\n            @Override\n            public void run() {\n                Iterator<Long> iterator = preNodes.iterator();\n                if (iterator.hasNext()) {\n                    long preNode = iterator.next();\n                    if (preNode < id) {\n                        final String format = \"%0\" + idstr.length() + \"d\";\n                        String preIdstr = String.format(format, preNode);\n                        final String prePath = PATH + \"/\" + sequenceEnum.getCode() + \"/\" + SEQ + preIdstr;\n                        CuratorFramework client = null;\n                        try {\n                            client = (CuratorFramework) genericObjectPool.borrowObject();\n                            client.delete().forPath(prePath);\n                            preNodes.remove(preNode);\n                        } catch (Exception e) {\n                            LOGGER.error(\"delete preNode error\", e);\n                        } finally {\n                            if (client != null)\n                                genericObjectPool.returnObject(client);\n                        }\n                    }\n                }\n            }\n        });\n        return id;\n    }\n\n    private String createNode(String prefixName) {\n        CuratorFramework client = null;\n        try {\n            client = (CuratorFramework) genericObjectPool.borrowObject();\n            String result = client.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT_SEQUENTIAL)\n                    .forPath(PATH + \"/\" + prefixName + \"/\" + SEQ, String.valueOf(0).getBytes());\n            return result;\n        } catch (Exception e) {\n            throw new RuntimeException(\"create zookeeper node error\", e);\n        } finally {\n            if (client != null)\n                genericObjectPool.returnObject(client);\n        }\n    }\n\n    public static void main(String[] args) {\n        ExecutorService executorService = Executors.newFixedThreadPool(1);\n        long startTime = System.currentTimeMillis();   //获取开始时间\n        final ZKIncreaseSequenceHandler sequenceHandler = ZKIncreaseSequenceHandler.getInstance(\"192.168.0.65\", \"/sequence/p2p\", \"seq\");\n        int count = 10;\n        final CountDownLatch cd = new CountDownLatch(count);\n        for (int i = 0; i < count; i++) {\n            executorService.execute(new Runnable() {\n                public void run() {\n                    System.out.printf(\"线程 %s %d \\n\", Thread.currentThread().getId(), sequenceHandler.nextId(SequenceEnum.ORDER));\n                    cd.countDown();\n                }\n            });\n        }\n        try {\n            cd.await();\n        } catch (InterruptedException e) {\n            LOGGER.error(\"Interrupted thread\",e);\n            Thread.currentThread().interrupt();\n        }\n        long endTime = System.currentTimeMillis(); //获取结束时间\n        System.out.println(\"程序运行时间： \" + (endTime - startTime) + \"ms\");\n\n    }\n\n    @Override\n    public PooledObject<CuratorFramework> makeObject() throws Exception {\n        CuratorFramework client = CuratorFrameworkFactory.newClient(ZK_ADDRESS, new ExponentialBackoffRetry(1000, 3));\n        client.start();\n        return new DefaultPooledObject<>(client);\n    }\n\n    @Override\n    public void destroyObject(PooledObject<CuratorFramework> p) throws Exception {\n\n    }\n\n    @Override\n    public boolean validateObject(PooledObject<CuratorFramework> p) {\n        return false;\n    }\n\n    @Override\n    public void activateObject(PooledObject<CuratorFramework> p) throws Exception {\n\n    }\n\n    @Override\n    public void passivateObject(PooledObject<CuratorFramework> p) throws Exception {\n\n    }\n}\n```\n\n### 雪花算法-Snowflake\n\nsnowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。\n![](雪花.png)\n\n- 1bit:一般是符号位，不做处理\n\n- 41bit:用来记录时间戳，这里可以记录69年，如果设置好起始时间比如今年是2018年，那么可以用到2089年，到时候怎么办？要是这个系统能用69年，我相信这个系统早都重构了好多次了。\n\n- 10bit:10bit用来记录机器ID，总共可以记录1024台机器，一般用前5位代表数据中心，后面5位是某个数据中心的机器ID\n\n- 12bit:循环位，用来对同一个毫秒之内产生不同的ID，12位可以最多记录4095个，也就是在同一个机器同一毫秒最多记录4095个，多余的需要进行等待下毫秒。\n\n上面四部分加起来是 64比特位 = 8字节 = Long 。（转换成字符串后长度最多19）。\n\n上面只是一个将64bit划分的标准，当然也不一定这么做，可以根据不同业务的具体场景来划分，比如下面给出一个业务场景：\n\n- 服务目前QPS10万，预计几年之内会发展到百万。\n\n- 当前机器三地部署，上海，北京，深圳都有。\n\n- 当前机器10台左右，预计未来会增加至百台。\n\n这个时候我们根据上面的场景可以再次合理的划分62bit,QPS几年之内会发展到百万，那么每毫秒就是千级的请求，目前10台机器那么每台机器承担百级的请求，为了保证扩展，后面的循环位可以限制到1024，也就是2^10，那么循环位10位就足够了。\n\n机器三地部署我们可以用3bit总共8来表示机房位置，当前的机器10台，为了保证扩展到百台那么可以用7bit 128来表示，时间位依然是41bit,那么还剩下64-10-3-7-41-1 = 2bit,还剩下2bit可以用来进行扩展。\n\n这个算法单机每秒内理论上最多可以生成1000`*`(2^12)，也就是409.6万个ID\n\n#### 代码实现\n```java\n/**\n * Twitter_Snowflake<br>\n * SnowFlake的结构如下(每部分用-分开):<br>\n * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 <br>\n * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0<br>\n * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截)\n * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69<br>\n * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId<br>\n * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号<br>\n * 加起来刚好64位，为一个Long型。<br>\n * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。\n */\npublic class SnowflakeIdWorker {\n\n    // ==============================Fields===========================================\n    /** 开始时间截 (2015-01-01) */\n    private final long twepoch = 1420041600000L;\n\n    /** 机器id所占的位数 */\n    private final long workerIdBits = 5L;\n\n    /** 数据标识id所占的位数 */\n    private final long datacenterIdBits = 5L;\n\n    /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */\n    private final long maxWorkerId = -1L ^ (-1L << workerIdBits);\n\n    /** 支持的最大数据标识id，结果是31 */\n    private final long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);\n\n    /** 序列在id中占的位数 */\n    private final long sequenceBits = 12L;\n\n    /** 机器ID向左移12位 */\n    private final long workerIdShift = sequenceBits;\n\n    /** 数据标识id向左移17位(12+5) */\n    private final long datacenterIdShift = sequenceBits + workerIdBits;\n\n    /** 时间截向左移22位(5+5+12) */\n    private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n\n    /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */\n    private final long sequenceMask = -1L ^ (-1L << sequenceBits);\n\n    /** 工作机器ID(0~31) */\n    private long workerId;\n\n    /** 数据中心ID(0~31) */\n    private long datacenterId;\n\n    /** 毫秒内序列(0~4095) */\n    private long sequence = 0L;\n\n    /** 上次生成ID的时间截 */\n    private long lastTimestamp = -1L;\n\n    //==============================Constructors=====================================\n    /**\n     * 构造函数\n     * @param workerId 工作ID (0~31)\n     * @param datacenterId 数据中心ID (0~31)\n     */\n    public SnowflakeIdWorker(long workerId, long datacenterId) {\n        if (workerId > maxWorkerId || workerId < 0) {\n            throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId));\n        }\n        if (datacenterId > maxDatacenterId || datacenterId < 0) {\n            throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId));\n        }\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n    }\n\n    // ==============================Methods==========================================\n    /**\n     * 获得下一个ID (该方法是线程安全的)\n     * @return SnowflakeId\n     */\n    public synchronized long nextId() {\n        long timestamp = timeGen();\n\n        //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常\n        if (timestamp < lastTimestamp) {\n            throw new RuntimeException(\n                    String.format(\"Clock moved backwards.  Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp));\n        }\n\n        //如果是同一时间生成的，则进行毫秒内序列\n        if (lastTimestamp == timestamp) {\n            sequence = (sequence + 1) & sequenceMask;\n            //毫秒内序列溢出\n            if (sequence == 0) {\n                //阻塞到下一个毫秒,获得新的时间戳\n                timestamp = tilNextMillis(lastTimestamp);\n            }\n        }\n        //时间戳改变，毫秒内序列重置\n        else {\n            sequence = 0L;\n        }\n\n        //上次生成ID的时间截\n        lastTimestamp = timestamp;\n\n        //移位并通过或运算拼到一起组成64位的ID\n        return ((timestamp - twepoch) << timestampLeftShift) //\n                | (datacenterId << datacenterIdShift) //\n                | (workerId << workerIdShift) //\n                | sequence;\n    }\n\n    /**\n     * 阻塞到下一个毫秒，直到获得新的时间戳\n     * @param lastTimestamp 上次生成ID的时间截\n     * @return 当前时间戳\n     */\n    protected long tilNextMillis(long lastTimestamp) {\n        long timestamp = timeGen();\n        while (timestamp <= lastTimestamp) {\n            timestamp = timeGen();\n        }\n        return timestamp;\n    }\n\n    /**\n     * 返回以毫秒为单位的当前时间\n     * @return 当前时间(毫秒)\n     */\n    protected long timeGen() {\n        return System.currentTimeMillis();\n    }\n\n    //==============================Test=============================================\n    /** 测试 */\n    public static void main(String[] args) {\n        SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0);\n        for (int i = 0; i < 1000; i++) {\n            long id = idWorker.nextId();\n            System.out.println(Long.toBinaryString(id));\n            System.out.println(id);\n        }\n    }\n}\n```\n#### 优点\n- 性能较优，速度快；\n\n- 无需第三方依赖，实现也很简单；\n\n- 可以根据实际情况调整和拓展算法，方便灵活；\n\n#### 缺点\n- 依赖机器时间，如果发生回拨会导致可能生成ID重复。业界使用一般是基于雪花算法进行拓展；\n\n### 适用场景\n\n当我们需要无序不能被猜测的ID，并且需要一定高性能，且需要long型，那么就可以使用我们雪花算法。比如常见的订单ID，用雪花算法别人就发猜测你每天的订单量是多少。\n\n#### 问题分析\n1、为什么bit位置利用了63位？\n因为long在java中占8字节，每字节8bit，一共64bit，其中有1个bit位是符号位不能用做生成ID，如果符号位也用来做ID中的1个bit为会导致ID出现负数，影响趋势递增特性。\n\n2、雪花算法需要用单例方式生成ID\n　　因为雪花算法会依赖上一次生成的ID的时间来判断是否需要对序列号进行增加的操作，如果不是单例，两个业务用两个对象同时获取ID，则可能会生成相同的ID\n\n3、机器位怎么取值？\n- 主机唯一标识\n   如果线上机器有唯一标识，可以采用这种方式。我们公司运维平台提供了每台机器的唯一标识，不过提供的数值比较大，所以更改了机器位长度为22位。当当的sharding-jdbc也有类似的方法。例如，机器的 HostName 为: dangdang-db-sharding-dev-01(公司名-部门名-服务名-环境名-编号)，会截取 HostName 最后的编号 01 作为机器位。\n\n- 可根据ip进行计算\n　如果能保证不同机房的机器ip不重复，可以利用ip来计算机器位，IP最大 255.255.255.255。而（255+255+255+255) < 1024，因此采用IP段数值相加即可生成机器位，不受IP位限制。不过这种方式也不是绝对ok，要根据自身情况在选择，比如10.0.5.2 与 10.0.2.5 计算出来也是相同的。使用这种IP生成机器位的方法,必须保证IP段相加不能重复\n\n#### 时钟回拨问题\n原因：\n第一：人为操作，在真实环境一般不会有那个傻逼干这种事情，所以基本可以排除。\n第二：由于有些业务等需要，机器需要同步时间服务器（在这个过程中可能会存在时间回拨，查了下我们服务器一般在10ms以内（2小时同步一次））。\n\n解决：\n雪花算法是强依赖我们的时间的，如果时间发生回拨，有可能会生成重复的ID，在我们上面的nextId中我们用当前时间和上一次的时间进行判断，如果当前时间小于上一次的时间那么肯定是发生了回拨，普通的算法会直接抛出异常,这里我们可以对其进行优化,一般分为两个情况:\n\n- 如果时间回拨时间较短，比如配置5ms以内，那么可以直接等待一定的时间，让机器的时间追上来。\n\n- 如果时间的回拨时间较长，我们不能接受这么长的阻塞等待，那么又有两个策略:\n\n1、直接拒绝，抛出异常，打日志，通知RD时钟回滚。\n\n2、利用扩展位，上面我们讨论过不同业务场景位数可能用不到那么多，那么我们可以把扩展位数利用起来了，比如当这个时间回拨比较长的时候，我们可以不需要等待，直接在扩展位加1。2位的扩展位允许我们有3次大的时钟回拨，一般来说就够了，如果其超过三次我们还是选择抛出异常，打日志。\n\n另外一种解决方案：\n由于是分布在各各机器自己上面，如果要几台集中的机器（并且不做时间同步），那么就基本上就不存在回拨可能性了（曲线救国也是救国，哈哈），但是也的确带来了新问题，各各结点需要访问集中机器，要保证性能，百度的uid-generator产生就是基于这种情况做的（每次取一批回来，很好的思想，性能也非常不错）https://github.com/baidu/uid-generator。\n\n\n通过上面的几种策略可以比较的防护我们的时钟回拨，防止出现回拨之后大量的异常出现。下面是修改之后的代码，这里修改了时钟回拨的逻辑:\n![](时钟回拨.png)\n\n\n\n#### ID逆运算\n如果线上出现ID重复，如何进行问题定位？对ID进行逆运算拿到ID的时间位、机器位、序号位。就可以进行下一步分析了。以上述生成的4198401为例\n\n1、ID生成时间\n\n时间位 =  ID /![](ID1.png) + from\n\n时间位 = 4198401 / ![](ID2.png) + 1422720000000 = 1422720000001\n与上述生成ID时用时间位相符\n\n注意:ID /![](ID1.png)  是整数\n\n2、ID生成的机器\n\n机器位 = (ID / ![](ID3.png)) % ![](ID4.png)\n\n机器位 = (4198401  / ![](ID5.png)) % ![](ID6.png) = (1025) % 1024 = 1\n与上述生成ID时用机器位数值相符\n\n3、序列号\nID % ![](ID3.png)\n\n序列号 = 4198401 % ![](ID5.png) = 4198401 % 1024 = 1\n与上述生成ID时用的序列号数值相符\n\n### 各方案对比\n![](各方案对比.png)\n\n### 参考资料\n- [分布式ID常见解决方案](https://mp.weixin.qq.com/s?__biz=MzAxNjM2MTk0Ng==&mid=2247484315&idx=1&sn=3a08d749aa77f4d97eac0f97e4080a2d&chksm=9bf4b32eac833a38968a839e801d1092dcbdf2e584efc3efc9ccfb76166b72ec0a1aca45f95e&scene=21#wechat_redirect)\n- [分布式、高并发ID生成策略](https://mp.weixin.qq.com/s/4rPm7_U3GG2SwYpLBgb8Gg)\n- [如果再有人问你分布式ID，这篇文章丢给他](https://mp.weixin.qq.com/s/KfoLFClRwDXlcTDmhCEdaQ)\n- [分布式唯一id：snowflake算法思考](https://mp.weixin.qq.com/s/WijbBrH_VWNTnCyWrL0IbA)\n- [分布式ID生成方法-细聊雪花算法](https://mp.weixin.qq.com/s/FN_IEbhPg0Jnuexkb0qKsw)\n- [搞懂分布式技术12：分布式ID生成方案](https://blog.csdn.net/a724888/article/details/80784533)","tags":["分布式"],"categories":["分布式"]},{"title":"Java中的阻塞队列","url":"/2019/03/29/Java中的阻塞队列/","content":"\n### 什么是阻塞队列？\n阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。\n这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。\n阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。\n\n\n阻塞队列提供了四种处理方法:\n\n方法\\处理方式  |抛出异常     |返回特殊值   |一直阻塞  |超时退出  \n---           |:--:        |:--:        |:--:      |---:\n插入方法       |add(e)      |offer(e)    |put(e)    |offer(e,time,unit)\n移除方法       |remove()    |poll()      |take()    |poll(time,unit)\n检查方法       |element()   |peek()      |不可用     |不可用\n\n- 抛出异常：是指当阻塞队列满时候，再往队列里插入元素，会抛出IllegalStateException(“Queue full”)异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常 。\n\n- 返回特殊值：插入方法会返回是否成功，成功则返回true。移除方法，则是从队列里拿出一个元素，如果没有则返回null\n\n- 一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里take元素，队列也会阻塞消费者线程，直到队列可用。\n\n- 超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。\n\n### Java里的阻塞队列\n\nJDK7提供了7个阻塞队列。分别是\n\n- ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。\n- LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。\n- PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。\n- DelayQueue：一个使用优先级队列实现的无界阻塞队列。\n- SynchronousQueue：一个不存储元素的阻塞队列。\n- LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。\n- LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。\n\n#### ArrayBlockingQueue\nArrayBlockingQueue是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。**通常情况下为了保证公平性会降低吞吐量**。我们可以使用以下代码创建一个公平的阻塞队列：\n```java\n\tArrayBlockingQueue fairQueue = new  ArrayBlockingQueue(1000,true);\n```\n访问者的公平性是使用可重入锁实现的，代码如下：\n```java\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n        if (capacity <= 0)\n            throw new IllegalArgumentException();\n        this.items = new Object[capacity];\n        lock = new ReentrantLock(fair);\n        notEmpty = lock.newCondition();\n        notFull =  lock.newCondition();\n}\n```\n#### LinkedBlockingQueue \n一个用链表实现的有界阻塞队列。此队列的默认和最大长度为 Integer.MAX_VALUE。此队列按照先进先出的原则对元素进行排序。\n\n#### PriorityBlockingQueue \n一个支持优先级的无界队列。默认情况下元素采取自然顺序排列，也可以通过比较器 comparator 来指定元素的排序规则。元素按照升序排列。 \n\n#### DelayQueue \n一个支持延时获取元素的无界阻塞队列。队列使用 PriorityQueue 来实现。队列中的元素必须实现 Delayed 接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。我们可以将 DelayQueue 运用在以下应用场景：\n\n- 缓存系统的设计：可以用 DelayQueue 保存缓存元素的有效期，使用一个线程循环查询 DelayQueue，一旦能从 DelayQueue  中获取元素时，表示缓存有效期到了。\n\n- 定时任务调度：使用 DelayQueue 保存当天将会执行的任务和执行时间，一旦从 DelayQueue 中获取到任务就开始执行，从比如 TimerQueue 就是使用 DelayQueue 实现的。 \n队列中的 Delayed 必须实现 compareTo 来指定元素的顺序。比如让延时时间最长的放在队列的末尾。实现代码如下：\n```java\npublic int compareTo(Delayed other) {\n           if (other == this) // compare zero ONLY if same object\n                return 0;\n            if (other instanceof ScheduledFutureTask) {\n                ScheduledFutureTask x = (ScheduledFutureTask)other;\n                long diff = time - x.time;\n                if (diff < 0)\n                    return -1;\n                else if (diff > 0)\n                    return 1;\n\t   else if (sequenceNumber < x.sequenceNumber)\n                    return -1;\n                else\n                    return 1;\n            }\n            long d = (getDelay(TimeUnit.NANOSECONDS) -\n                      other.getDelay(TimeUnit.NANOSECONDS));\n            return (d == 0) ? 0 : ((d < 0) ? -1 : 1);\n        }\n```\n1、如何实现 Delayed 接口\n\n我们可以参考 ScheduledThreadPoolExecutor 里 ScheduledFutureTask 类。这个类实现了 Delayed 接口。首先：在对象创建的时候，使用 time 记录前对象什么时候可以使用，代码如下：\n```java\nScheduledFutureTask(Runnable r, V result, long ns, long period) {\n            super(r, result);\n            this.time = ns;\n            this.period = period;\n            this.sequenceNumber = sequencer.getAndIncrement();\n}\n```\n然后使用 getDelay 可以查询当前元素还需要延时多久，代码如下：\n```java\npublic long getDelay(TimeUnit unit) {\n            return unit.convert(time - now(), TimeUnit.NANOSECONDS);\n        }\n```\n通过构造函数可以看出延迟时间参数 ns 的单位是纳秒，自己设计的时候最好使用纳秒，因为 getDelay 时可以指定任意单位，一旦以纳秒作为单位，而延时的时间又精确不到纳秒就麻烦了。使用时请注意当 time 小于当前时间时，getDelay 会返回负数。\n\n2、如何实现延时队列\n\n延时队列的实现很简单，当消费者从队列里获取元素时，如果元素没有达到延时时间，就阻塞当前线程。\n```java\nlong delay = first.getDelay(TimeUnit.NANOSECONDS);\n                    if (delay <= 0)\n                        return q.poll();\n                    else if (leader != null)\n                        available.await();\n```\n\n#### SynchronousQueue\n一个不存储元素的阻塞队列。每一个 put 操作必须等待一个 take 操作，否则不能继续添加元素。SynchronousQueue 可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景, 比如在一个线程中使用的数据，传递给另外一个线程使用，SynchronousQueue 的吞吐量高于 LinkedBlockingQueue 和 ArrayBlockingQueue。\n\n#### LinkedTransferQueue \n一个由链表结构组成的无界阻塞 TransferQueue 队列。相对于其他阻塞队列，LinkedTransferQueue 多了 tryTransfer 和 transfer 方法。\n\ntransfer 方法。如果当前有消费者正在等待接收元素（消费者使用 take() 方法或带时间限制的 poll() 方法时），transfer 方法可以把生产者传入的元素立刻 transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer 方法会将元素存放在队列的 tail 节点，并等到该元素被消费者消费了才返回。transfer 方法的关键代码如下：\n```java\nNode pred = tryAppend(s, haveData);\nreturn awaitMatch(s, pred, e, (how == TIMED), nanos);\n```\n第一行代码是试图把存放当前元素的 s 节点作为 tail 节点。第二行代码是让 CPU 自旋等待消费者消费元素。因为自旋会消耗 CPU，所以自旋一定的次数后使用 Thread.yield() 方法来暂停当前正在执行的线程，并执行其他线程。\n\ntryTransfer 方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回 false。和 transfer 方法的区别是 tryTransfer 方法无论消费者是否接收，方法立即返回。而 transfer 方法是必须等到消费者消费了才返回。\n\n对于带有时间限制的 tryTransfer(E e, long timeout, TimeUnit unit) 方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回 false，如果在超时时间内消费了元素，则返回 true。\n\n#### LinkedBlockingDeque \n一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其他的阻塞队列，LinkedBlockingDeque 多了 addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast 等方法，以 First 单词结尾的方法，表示插入，获取（peek）或移除双端队列的第一个元素。以 Last 单词结尾的方法，表示插入，获取或移除双端队列的最后一个元素。另外插入方法 add 等同于 addLast，移除方法 remove 等效于 removeFirst。但是 take 方法却等同于 takeFirst，不知道是不是 Jdk 的 bug，使用时还是用带有 First 和 Last 后缀的方法更清楚。\n\n在初始化 LinkedBlockingDeque 时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在“工作窃取”模式中。\n\n### 阻塞队列的实现原理\n如果队列是空的，消费者会一直等待，当生产者添加元素时候，消费者是如何知道当前队列有元素的呢？\n\n使用通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。通过查看 JDK 源码发现 ArrayBlockingQueue 使用了 Condition 来实现，代码如下：\n```java\nprivate final Condition notFull;\nprivate final Condition notEmpty;\n\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n        // 省略其他代码 \n        notEmpty = lock.newCondition();\n        notFull =  lock.newCondition();\n    }\n\npublic void put(E e) throws InterruptedException {\n        checkNotNull(e);\n        final ReentrantLock lock = this.lock;\n        lock.lockInterruptibly();\n        try {\n            while (count == items.length)\n                notFull.await();\n            insert(e);\n        } finally {\n            lock.unlock();\n        }\n}\n\npublic E take() throws InterruptedException {\n        final ReentrantLock lock = this.lock;\n        lock.lockInterruptibly();\n        try {\n            while (count == 0)\n                notEmpty.await();\n            return extract();\n  } finally {\n            lock.unlock();\n        }\n}\n\nprivate void insert(E x) {\n        items[putIndex] = x;\n        putIndex = inc(putIndex);\n        ++count;\n        notEmpty.signal();\n    }\n```\n当我们往队列里插入一个元素时，如果队列不可用，阻塞生产者主要通过 notFull.await()--> LockSupport.park(this); 来实现\n```java\npublic final void await() throws InterruptedException {\n            if (Thread.interrupted())\n                throw new InterruptedException();\n            Node node = addConditionWaiter();\n            int savedState = fullyRelease(node);\n            int interruptMode = 0;\n            while (!isOnSyncQueue(node)) {\n                LockSupport.park(this);\n                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n                    break;\n            }\n            if (acquireQueued(node, savedState) && interruptMode != THROW_IE)\n                interruptMode = REINTERRUPT;\n            if (node.nextWaiter != null) // clean up if cancelled\n                unlinkCancelledWaiters();\n            if (interruptMode != 0)\n\nreportInterruptAfterWait(interruptMode);\n        }\n```\n继续进入源码，发现调用 setBlocker 先保存下将要阻塞的线程，然后调用 unsafe.park 阻塞当前线程。\n```java\npublic static void park(Object blocker) {\n        Thread t = Thread.currentThread();\n        setBlocker(t, blocker);\n        unsafe.park(false, 0L);\n        setBlocker(t, null);\n    }\n```\nunsafe.park 是个 native 方法，代码如下：\n```java\npublic native void park(boolean isAbsolute, long time);\n\n```\npark 这个方法会阻塞当前线程，只有以下四种情况中的一种发生时，该方法才会返回。\n\n- 与 park 对应的 unpark 执行或已经执行时。注意：已经执行是指 unpark 先执行，然后再执行的 park。\n- 线程被中断时。\n- 如果参数中的 time 不是零，等待了指定的毫秒数时。\n- 发生异常现象时。这些异常事先无法确定。\n当队列满时，生产者往阻塞队列里插入一个元素，生产者线程会进入 WAITING (parking) 状态。我们可以使用 jstack dump 阻塞的生产者线程看到这点：\n```java\n\"main\" prio=5 tid=0x00007fc83c000000 nid=0x10164e000 waiting on condition [0x000000010164d000]\n   java.lang.Thread.State: WAITING (parking)\n        at sun.misc.Unsafe.park(Native Method)\n        - parking to wait for  <0x0000000140559fe8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)\n        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:324)\n        at blockingqueue.ArrayBlockingQueueTest.main(ArrayBlockingQueueTest.java:11)\n```\n\n\n\n### 参考资料\n- [聊聊并发（七）——Java中的阻塞队列](http://www.cnblogs.com/aspirant/p/8628779.html)","tags":["Java","并发"],"categories":["Java","并发"]},{"title":"对Cookie和Session的深入理解","url":"/2019/03/29/对Cookie和Session的深入理解/","content":"\n### 简介\nsession对象用于存储特定的用户会话所需的信息 。 Session对象的引入是为了弥补HTTP协议的不足。HTTP协议本身是无状态的。\ncookie分发是通过扩展HTTP协议来实现的，服务器通过在HTTP的响应头中加上一行特殊的指示以提示浏览器按照指示生成相应的cookie。\nCookie通过在客户端记录信息确定用户身份，Session通过在服务器端记录信息确定用户身份。\n\n### 机制\nsession机制是一种服务器端的机制，服务器使用一种类似于散列表（Hashcode）的结构来保存信息。\n当程序需要为某个客户端的请求创建一个session的时候，服务器首先检查这个客户端的请求里是否已包含了一个session标识- 称为session id，如果已包含一个session id则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（如果检索不到，可能会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。 保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发挥给服务器。\n\n由于cookie可以被人为的禁止，必须有其他机制以便在cookie被禁止时仍然能够把session id传递回服务器。经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面，附加方式也有两种，一种是作为URL路径的附加信息，表现形式为http://...../xxx;jsessionid=ByOK ... 99zWpBng!-145788764\n另一种是作为查询字符串附加在URL后面，表现形式为http://...../xxx?jsessionid=ByOK ... 99zWpBng!-145788764\n这两种方式对于用户来说是没有区别的，只是服务器在解析的时候处理的方式不同，采用第一种方式也有利于把session id的信息和正常程序参数区分开来。\n为了在整个交互过程中始终保持状态，就必须在每个客户端可能请求的路径后面都包含这个session id。\n\n### session生命周期\nsession是在客户端请求服务器自动创建的具有唯一ID的对象。其生存周期从用户第一次请求服务器开始，结束于session失效。\nsession失效有以下几种可能性：1、在服务器设定的时间内用户没有请求服务器。2、服务器主动运行session.invalidate()方法使其失效。\nrequest也是客户端请求服务器时服务器自动生成的对象，用于标志一次请求。其生存周期是客户端请求开始，到服务器返回结果结束。\n两者的区别1、记录的信息不同。2、生存周期不同。sesion的生存周期长于request。\n因此，session常用于报存不同页面的共享信息，如登陆信息等。\n\n\n### cookie 和session 的区别\n1、cookie数据存放在客户的浏览器上，\nsession数据放在服务器上\n2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗\n考虑到安全应当使用session\n3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能\n考虑到减轻服务器性能方面，应当使用COOKIE\n4、单个cookie在客户端的限制是3-4K，就是说一个站点在客户端存放的COOKIE不能大于限制。\n\n\n### 参考资料\n\n- [Cookie和Session详解](https://www.cnblogs.com/linguoguo/p/5106618.html)\n","tags":["Java"],"categories":["Java"]},{"title":"MySQL优化分析操作过程","url":"/2019/03/28/MySQL优化分析操作过程/","content":"\n### 使用explains（执行计划）优化慢查询\nMySQL的Explain命令用于查看执行效果，显示了mysql如何使用索引来处理select语句以及连接表。\n可以帮助选择更好的索引和写出更优化的查询语句。\nexplain的语法如下，在select语句前加上explain就可以：\n```sql\nEXPLAIN select id from USER_2 where  num is  null\n```\n![](explain.png)\n\n字段含义\ntable：显示这一行的数据是关于哪张表的\ntype：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL\npossible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句\nkey： 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MYSQL会选择优化不足的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MYSQL忽略索引\nkey_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好\nref：显示索引的哪一列被使用了，如果可能的话，是一个常数\nrows：MYSQL认为必须检查的用来返回请求数据的行数\nExtra：关于MYSQL如何解析查询的额外信息。\n\n通过explain的参数介绍，我们可以得知：\n1. 表的读取顺序(id)\n2. 数据读取操作的操作类型(type)\n3. 哪些索引被实际使用(key)\n4. 表之间的引用(ref)\n5. 每张表有多少行被优化器查询(rows)\n\n#### id字段\nselect 查询的序列号，包含一组可以重复的数字，表示查询中执行sql语句的顺序。一般有三种情况：\n第一种：id全部相同，sql的执行顺序是由上至下；\n第二种：id全部不同，sql的执行顺序是根据id大的优先执行；\n第三种：id既存在相同，又存在不同的。先根据id大的优先执行，再根据相同id从上至下的执行。\n\n#### select_type  字段\nselect 查询的类型，主要是用于区别普通查询，联合查询，嵌套的复杂查询\n- simple：简单的select 查询，查询中不包含子查询或者union\n- primary：查询中若包含任何复杂的子查询，最外层查询则被标记为primary\n- subquery：在select或where 列表中包含了子查询\n- derived：在from列表中包含的子查询被标记为derived（衍生）MySQL会递归执行这些子查询，把结果放在临时表里。\n- union：若第二个select出现在union之后，则被标记为union，若union包含在from子句的子查询中，外层select将被标记为：derived\n- union result：从union表获取结果的select\n\n#### Extra 字段\n- using filesort：说明 MySQL 会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。\n- using temporary：使用了临时表保存中间结果，MySQL 在对查询结果排序时使用临时表。常见于排序 order by 和分组查询 group by。\n- using index ：使用覆盖索引的时候就会出现\n- using where：在查找使用索引的情况下，需要回表去查询所需的数据\n- using index condition：查找使用了索引，但是需要回表查询数据\n- using index & using where：查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据\n- distinct：优化 distinct 操作，在找到第一匹配的元组后即停止找同样值的操作\n\nusing filesort、using temporary 这两项出现时需要注意下，这两项是十分耗费性能的。\n\n在使用 group by 的时候，虽然没有使用 order by，如果没有索引，是可能同时出现 using filesort，using temporary 的。\n\n因为 group by 就是先排序在分组，如果没有排序的需要，可以加上一个 order by NULL 来避免排序，这样 using filesort 就会去除，能提升一点性能。\n\n#### type 字段\n性能从最优到最差的排序：system > const > eq_ref > ref > range > index > all，保证查询至少达到range级别或者最好能达到ref\n- system：表只有一行记录（等于系统表），这是 const 类型的特例，平时不会出现。\n\n- const：如果通过索引依次就找到了，const 用于主键索引或者 unique 索引。因为只能匹配一行数据，所以很快。如果将主键置于 where 列表中，MySQL 就能将该查询转换为一个常量。\n\n- eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。\n\n- ref：非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而它可能会找到多个符合条件的行，所以它应该属于查找和扫描的混合体。\n\n- range：只检索给定范围的行，使用一个索引来选择行。key 列显示使用了哪个索引，一般就是在你的 where 语句中出现 between、<、>、in 等的查询。\n\n这种范围扫描索引比全表扫描要好，因为只需要开始于索引的某一点，而结束于另一点，不用扫描全部索引。\n\n- index：Full Index Scan ，index 与 ALL 的区别为 index 类型只遍历索引树，这通常比 ALL 快，因为索引文件通常比数据文件小。\n\n也就是说虽然 ALL 和 index 都是读全表，但 index 是从索引中读取的，而 ALL 是从硬盘读取的。\n\n- all：Full Table Scan，遍历全表获得匹配的行。\n\n唯一索引打印的type值是const。表示通过索引一次就可以找到。即找到值就结束扫描返回查询结果。\n普通索引打印的type值是ref。表示非唯一性索引扫描。找到值还要继续扫描，直到将索引文件扫描完为止。\n\n\n#### 纠正\n在 where 子句中对字段进行 null 值判断、in 和 not in、使用!=或<>操作符并不会出现索引失效情况(MySQL 5.6)。\n\n\n### 如何查看执行SQL的耗时\n使用`show profiles`分析sql性能。\nprofile默认是不打开的\n```sql\nshow variables like \"%pro%\";\n```\n可以看到profiling 默认是OFF的。\n\n开启profile，然后测试\n```sql\nset profiling=1;\n```\n先执行一遍SQL语句，然后执行`show profiles`就可以看到语句执行的耗时\n![](showProfile.png)\nduration：单位秒\n\n接着执行`SHOW profile FOR QUERY 3;` 查看时间具体花在哪些地方，3为查询语句的ID。\nPROFILE的结果我们主要关注两列：Status、Duration，前者表示的是PROFILE里的状态，它和PROCESSLIST的状态基本是一致的，后者是该状态的耗时。因此，我们最主要的是关注处于哪个状态耗时最久，这些状态中，哪些可以进一步优化。\n\n\n### 慢查询日志\n有时候如果线上请求超时，应该去关注下慢查询日志，慢查询的分析很简单，先找到慢查询日志文件的位置，然后利用 mysqldumpslow 去分析。\n\n查询慢查询日志信息可以直接通过执行 SQL 命令查看相关变量，常用的 SQL 如下：\n![](慢查询.png)\n\nmysqldumpslow 的工具十分简单，我主要用到的参数如下：\n\n-t：限制输出的行数，我一般取前十条就够了。\n\n-s：根据什么来排序默认是平均查询时间 at，我还经常用到 c 查询次数，因为查询次数很频繁但是时间不高也是有必要优化的，还有 t 查询时间，查看那个语句特别卡。\n\n-v：输出详细信息。\n\n例子：mysqldumpslow -v -s t -t 10 mysql_slow.log.2018-11-20-0500。\n\n\n### 查看 SQL 进程和杀死进程\n如果你执行了一个 SQL 的操作，但是迟迟没有返回，你可以通过查询进程列表看看它的实际执行状况。\n\n如果该 SQL 十分耗时，为了避免影响线上可以用 kill 命令杀死进程，通过查看进程列表也能直观的看下当前 SQL 的执行状态；如果当前数据库负载很高，在进程列表可能会出现，大量的进程夯住，执行时间很长。\n\n命令如下：\n```sql\n--查看进程列表\nSHOW PROCESSLIST;\n--杀死某个进程\nkill 183665\n```\n\n### MySQL 排序规则\n一般使用 `_bin `和 `_genera_ci`：\n\n- utf8_genera_ci：不区分大小写，ci 为 case insensitive 的缩写，即大小写不敏感。\n\n- utf8_general_cs：区分大小写，cs 为 case sensitive 的缩写，即大小写敏感，但是目前 MySQL 版本中已经不支持类似于_genera_cs 的排序规则，直接使用 utf8_bin 替代。\n\n- utf8_bin：将字符串中的每一个字符用二进制数据存储，区分大小写。\n\n那么，同样是区分大小写，utf8_general_cs 和 utf8_bin 有什么区别？\n\n- cs 为 case sensitive 的缩写，即大小写敏感；bin 的意思是二进制，也就是二进制编码比较。\n\nutf8_general_cs 排序规则下，即便是区分了大小写，但是某些西欧的字符和拉丁字符是不区分的，比如 ä=a，但是有时并不需要 ä=a，所以才有 utf8_bin。\n\n- utf8_bin 的特点在于使用字符的二进制的编码进行运算，任何不同的二进制编码都是不同的，因此在 utf8_bin 排序规则下：ä<>a。\n\n\n### 优化点\n1、尽可能把所有列定义为NOT NULL\n\n原因：\n\n· 索引NULL列需要额外的空间来保存，所以要占用更多的空间；\n\n· 进行比较和计算时要对NULL值做特别的处理\n\n2、使用TIMESTAMP（4个字节）或DATETIME类型（8个字节）存储时间\n\nTIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07。\n\nTIMESTAMP 占用4字节和INT相同，但比INT可读性高\n\n超出TIMESTAMP取值范围的使用DATETIME类型存储。\n\n经常会有人用字符串存储日期型的数据（不正确的做法）：\n\n· 缺点1：无法用日期函数进行计算和比较\n\n· 缺点2：用字符串存储日期要占用更多的空间\n\n3、同财务相关的金额类数据必须使用decimal类型\n\n· 非精准浮点：float,double\n\n· 精准浮点：decimal\n\nDecimal类型为精准浮点数，在计算时不会丢失精度。占用空间由定义的宽度决定，每4个字节可以存储9位数字，并且小数点要占用一个字节。可用于存储比bigint更大的整型数据、\n\n4、禁止使用SELECT * 必须使用SELECT <字段列表> 查询\n\n原因：\n\n· 消耗更多的CPU和IO以网络带宽资源\n\n· 无法使用覆盖索引\n\n· 可减少表结构变更带来的影响\n\n5、避免使用子查询，可以把子查询优化为join操作\n\n通常子查询在in子句中，且子查询中为简单SQL(不包含union、group by、order by、limit从句)时，才可以把子查询转化为关联查询进行优化。\n\n子查询性能差的原因：\n\n· 子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能 会受到一定的影响；\n\n· 特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大；\n\n· 由于子查询会产生大量的临时表也没有索引，所以会消耗过多的CPU和IO资源，产生大量的慢查询。\n\n### 参考资料\n- [开发人员不得不知的MySQL索引和查询优化](https://mp.weixin.qq.com/s/MOXH0uRbBliVKLNLMSEpIg)\n- [MySQL索引优化分析](https://mp.weixin.qq.com/s/xWy2SfaKt_25ROB_NLlQ3w)\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL索引原理","url":"/2019/03/27/MySQL索引原理/","content":"\n### 索引概念\n\n索引（Index）是帮助MySQL高效获取数据的数据结构。索引是对表中一列或多列的值进行排序的一种存储结构。\n索引也是表的组成部分，建立太多的索引将会影响更新和插入的速度，因为它需要同样更新每个索引项结构。\n\n在数据之外，数据库系统还维护着满足特定查找算法的数据结构。这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构就是索引。\n\n数据写入到mysql的时候，每行数据按照过来的先后顺序，顺序写入到磁盘。如果没有任何索引，我们查找某个值的时候，需要遍历整个磁盘进行查找，对于那些经常用于查找的列，我们可以为其创建索引，例如简单的二叉树。二叉树的节点的值是该列的值，同时有一个指针指向该值对应的磁盘的位置，通过二叉树很快定位到要查找的值，获取到磁盘上的对应的行的位置，从而很快取出这一行，比遍历整个磁盘要快得多。\n\n![](简单索引原理.png)\n\n### 创建索引的优势：\n1. 提高数据的检索速度，降低数据库IO成本：使用索引的意义就是通过缩小表中需要查询的记录的数目从而加快搜索的速度。\n2. 降低数据排序的成本，降低CPU消耗：索引之所以查的快，是因为先将数据排好序，若该字段正好需要排序，则真好降低了排序的成本。\n\n### 创建索引的劣势：\n1. 占用存储空间：索引实际上也是一张表，记录了主键与索引字段，一般以索引文件的形式存储在磁盘上。\n2. 降低更新表的速度：表的数据发生了变化，对应的索引也需要一起变更，从而降低的更新速度。否则索引指向的物理数据可能不对，这也是索引失效的原因之一。\n3. 优质索引创建难：索引的创建并非一日之功，也并非一直不变。需要频繁根据用户的行为和具体的业务逻辑去创建最佳的索引。\n\n### 为什么MySQL索引要用Hash、B+Tree，而不用二叉树、红黑树、BTree\n一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。\n这样的话，索引查找过程中就要产生磁盘I/O消耗。索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。\n\n#### 不用二叉树、红黑树的原因\n首先二叉树不是自平衡的，插入新节点时，二叉搜索树在最坏的情况下可能会变成一个链表（当所有节点按从小到大的顺序依次插入后），为O(n)。而红黑树恰恰优化了二叉树的缺点，使插入、删除节点时能自平衡。但红黑树还是有些问题：那就是数据量大的话，红黑树的深度会很深，也就是说深度不可控，而造成磁盘IO读写过于频繁，另外由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，IO读写次数就更多了，这样一来查找数据还是会很耗时。\n\n红黑树多用在内部排序，即全部在内存中的，C++的STL中map和set的内部实现就是红黑树，Java集合框架里TreeMap也是使用红黑树实现，\nB树多用在内存里放不下，大部分数据存储在外存上时。因为B树层数少，因此可以确保每次操作，读取磁盘的次数尽可能的少。\n\n#### 使用hash\n![](hash.png)\n相比较于红黑树，hash可以固定“深度”，且映射到磁盘存储引用，这样查找数据直接告诉磁盘数据在哪，查找数据也挺快的，但是 hash 还是有些不足：那就是不能范围查找。\n\nmemory引擎就是使用hash索引。\n\n#### 不用BTree的原因\n\n根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：\n\n每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。\n\nB-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。\n\n综上所述，用B-Tree作为索引结构效率是非常高的。\n\n但B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小。\n\nB+树相对B树的优点：\n\n1、B+树的所有Data域在叶子节点，所有关键字查询的路径长度相同，也让B+-tree的查询效率更加稳定。另外叶子节点增加一个指向相邻叶子节点的指针，遍历叶子节点就能获取全部数据，提高区间访问性能。\n\n2、非叶子节点不存储数据，一个页所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。\n结论：B+Tree 既减少查询次数又提供了很好的范围查询\n\n### Mysql 索引实现\n\n聚集索引： 索引 和 数据文件为同一个文件。\n非聚集索引： 索引 和 数据文件分开的索引。\nMyISAM 、 InnoDB 都使用B+Tree索引结构。但是底层索引存储不同，MyISAM 采用非聚集索引，而InnoDB采用聚集索引。 \n每个索引一个B+树， 一个B+树节点 = 一个物理Page（16K）\n\n#### MyISAM索引实现(非聚集)\n原理：采用非聚集索引，索引文件(.myi)和数据(.myd)文件分离，索引文件仅保存数据记录的指针地址。叶子节点data域存储指向数据记录的指针地址。\n\nMyISAM索引按照B+Tree搜索，如果指定的Key存在，则取出其data域的值，然后以data域值-数据指针地址去读取相应数据记录。\n辅助索引和主索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如下图在col1上建立主索引，在col2上建立辅助索引。\n\n![](MyISAM索引.png)\n采用MyISAM引擎创建的表产生3个文件： frm-表定义文件、 myi-索引文件、 myd-数据文件\n\n#### InnoDB索引实现(聚集)\n原理：采用聚集索引，数据和索引文件为一个idb文件，表数据文件本身就是主索引，相邻的索引临近存储。 \n\n叶节点data域保存了完整的数据记录（除主键id外其他列data）。 \n\n采用InnoDB引擎创建的表产生2个文件：frm -表定义、 ibd: innoDB数据&索引文件\n\n![](innodb索引1.png)\n在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。\n\n因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。\n\nInnoDB的所有辅助索引都引用主键作为data域。例如，图11为定义在Col3上的一个辅助索引：\n![](innod辅助索引.png)\n\n聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。\n\n\n#### 与MyISAM索引的不同\n1、InnoDB的数据文件本身就是索引文件\n2、InnoDB的辅助索引data域存储相应记录主键的值而不是地址\n\n### 索引查询实例流程\n1、索引精确查找:\n\n 确定定位条件, 找到根节点Page No, 根节点读到内存, 逐层向下查找, 读取叶子节点Page,通过 二分查找找到记录或未命中。\n （select * from user_info where id = 23）\n![](索引精确查找.png)\n\n2.索引范围查找：\n\n读取根节点至内存, 确定索引定位条件id=18, 找到满足条件第一个叶节点, 顺序扫描所有结果, 直到终止条件满足id < 22。\n（select * from user_info where id >= 18 and id < 22）\n![](索引范围查找.png)\n\n3、全表扫描：\n直接读取叶节点头结点， 顺序扫描， 返回符合条件记录， 到最终节点结束\n（select * from user_info where name = 'abc'）\n\n![](索引全表查找.png)\n\n4、二级索引查找：\n通过二级索引查出对应主键，拿主键回表查主键索引得到数据， 二级索引可筛选掉大量无效记录，提高效率\nCreate table table_x(int id primary key, varchar(64) name,key sec_index(name) \nSelect * from table_x where name = “d”;\n![](二级索引查找.png)\n\n### MySQL索引类型\nmysql的索引分为单列索引(全文索引，主键索引，唯一索引，普通索引)和组合索引。\n单列索引:一个索引只包含一个列，一个表可以有多个单列索引。\n组合索引:一个组合索引包含两个或两个以上的列。\n\n#### 普通索引\n建表时：INDEX IndexName(`字段名`(length)) \n\n建表后：CREATE INDEX IndexName ON `TableName`(`字段名`(length)) \n\n或ALTER TABLE TableName ADD INDEX IndexName(`字段名`(length))\n\n注意：如果字段数据是CHAR，VARCHAR类型，可以指定length，其值小于字段的实际长度，如果是BLOB和TEXT类型就必须指定length。\n这个length的用处是什么?\n\n有时候需要在长文本字段上建立索引，但这种索引会增加索引的存储空间以及降低索引的效率，这时就可以用到length，创建索引时用到length的索引，我们叫做前缀索引，前缀索引是选择字段数据的前n个字符作为索引，这样可以大大节约索引空间，从而提高索引效率。\n\n前缀索引是一种能使索引更小，更快的有效办法，但是MySql无法使用前缀索引做ORDER BY 和 GROUP BY以及使用前缀索引做覆盖扫描。\n\n#### 唯一索引\n要求字段所有的值是唯一的，这一点和主键索引一样，但是允许有空值。\n建表时：UNIQUE INDEX IndexName(`字段名`(length)) \n\n建表后：CREATE UNIQUE  INDEX IndexName ON `TableName`(`字段名`(length)) \n\n或ALTER TABLE TableName ADD UNIQUE  INDEX IndexName(`字段名`(length)）\n\n#### 主键索引\n一般在建表的时候自动创建，主键一般会设为 int 而且是 AUTO_INCREMENT自增类型的\n\n#### 全文索引\n假设字段的数据类型是长文本，文本字段上(text等)建立了普通索引，我们需要查找关键字的话，那么其条件只能是where column like '%xxxx%' ，但是，这样做就会让索引失效，这时就需要全文索引了。\n建表时：FULLTEXT INDEX IndexName(`字段名`(length)) \n\n建表后：CREATE FULLTEXT  INDEX IndexName ON `TableName`(`字段名`(length)) \n\n或ALTER TABLE TableName ADD FULLTEXT  INDEX IndexName(`字段名`(length)）\n\n使用：\nSELECT * FROM TableName\nWHERE MATCH(column1， column2) AGAINST(‘xxx′， ‘sss′， ‘ddd′)\n这条命令将把column1和column2字段里有xxx、sss和ddd的数据记录全部查询出来。\n\n#### 组合索引\n假设字段a，b都有索引，我们的查询条件是a=1，b=2查询过程是mysql会先挑选出符合a=1的结果集，再在这些结果集中挑选b=2的结果集，但是mysql并不会在查询a，b时都用到索引，只会用其中一个，这和我们的预期不一样，所以，我们要使用组合索引\n\n建表时：INDEX IndexName(`字段名`(length)，`字段名`(length)，........) \n\n建表后：CREATE INDEX IndexName ON `TableName`(`字段名`(length)，`字段名`(length)，........) \n\n或ALTER TABLE TableName ADD INDEX IndexName(`字段名`(length)，`字段名`(length)，........) \n\n在最左匹配原则中，有如下说明：\n> - 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整（按照索引列来检索匹配）。\n> - =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式\n\n\n### 索引失效（or、like%、类型转换、函数、表达式）\n1. 如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引\n\n\n2. mysql会按照联合索引从左往右进行匹配，直到遇到范围查询，如：>,<,between,like等就停止匹配，\na = 1 and b =2 and  c > 3 and d = 4，如果建立（a,b,c,d）顺序的索引，d是不会使用索引的。\n但如果联合索引是（a,b,d,c）的话，则a b d c都可以使用到索引，只是最终c是一个范围值。\n\n3. like查询以%开头\n4. 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引，也是发生类型转换\n5. 如果mysql估计使用全表扫描要比使用索引快,则不使用索引\n6. 索引列不能是表达式的一部分，也不能作为函数的参数，否则无法使用索引查询。下面是例子：\n```mysql\nSELECT * FROM user_test WHERE user_name = concat(user_name, 'fei');\n\n```\n\n### order by使用索引\norder by排序有两种排序方式：using filesort使用算法在内存中排序以及使用mysql的索引进行排序；我们在部分情况下希望的是使用索引。\n\n如果ID是单列索引，则order by会使用索引，如：\n```sql\nselect test_index where id = 3 order by id desc;\n\n```\n如果ID是单列索引，name不是索引或者name也是单列索引，则order by不会使用索引。\n```sql\n\t\nselect test_index where id = 3 order by name desc;\n```\n因为Mysql的一次查询只会从众多索引中选择一个索引，而这次查询中使用的是ID列索引，而不是name列索引。在这种场景下，如果想让order by也使用索引的话，就建立联合索引（id，name），这里需要注意最左前缀原则，不要建立这样的联合索引（name，id）。\n\n最后需要注意mysql对排序记录的大小有限制：max_length_for_sort_data 默认为1024；也就意味着如果需要排序的数据量大于1024，则order by不会使用索引，而是使用using filesort。\n\n\n### 索引创建的几个原则\n1、适合索引的列是出现在WHERE 子句中的列\n2、使用惟一索引\n  具有多个重复值的列，其索引效果最差，比如性别全是男的记录，对于MyISAM引擎来说，因为这时查找的时间就是T扫描整个索引表+T扫描整个表，那么耗时肯定过大了。对于InnoDB引擎来说，默认是有主键索引的，性别就相当于辅助索引了，这时每找到一个辅助索引节点就要去主键索引，也是相当于遍历辅助索引链表+整颗主键索引树。\n3、使用短索引\n    如果对串列进行索引，应该指定一个前缀长度，只要有可能就应该这样做。例如，如果有一个CHAR(200) 列，如果在前10 个或20 个字符内，多数值是惟一的，那么就不要对整个列进行索引。对前10 个或20 个字符进行索引能够节省大量索引空间，也可能会使查询更快。较小的索引涉及的磁盘I/O 较少，较短的值比较起来更快。更为重要的是，对于较短的键值，索引高速缓存中的块能容纳更多的键值，因此，MySQL也可以在内存中容纳更多的值。这增加 了找到行而不用读取索引中较多块的可能性\n4、不要过度索引\n   每个额外的索引都要占用额外的磁盘空间，并降低写操作的性能。在修改表的内容时，索引必须进行更新，有时可能需要重构，因此，索引越多，所花的时间越长。\n5、考虑在列上进行的比较类型\n    索引可用于“ <”、“ < = ”、“ = ”、“ > =”、“ > ”和BETWEEN 运算。\n6、尽量选择区分度高的列作为索引，区分度的公式是 `COUNT(DISTINCT col) / COUNT(*)`，表示字段不重复的比率，比率越大我们扫描的记录数就越少。\n\n### 什么时候不创建索引\n1、表记录太少\n如果一个表只有5条记录，采用索引去访问记录的话，那首先需访问索引表，再通过索引表访问数据表，一般索引表与数据表不在同一个数据块，这种情况下至少要往返读取数据块两次。而不用索引的情况下ORACLE会将所有的数据一次读出，处理速度显然会比用索引快。\n\n2、唯一性太差的字段\n如状态字段、类型字段。那些只存储固定几个值的字段，例如用户登录状态、消息的status等。\n这个涉及到了索引扫描的特性。例如：通过索引查找键值为A和B的某些数据，通过A找到某条相符合的数据，这条数据在X页上面，然后继续扫描，又发现符合A的数据出现在了Y页上面，那么存储引擎就会丢弃X页面的数据，然后存储Y页面上的数据，一直到查找完所有对应A的数据，然后查找B字段，发现X页面上面又有对应B字段的数据，那么他就会再次扫描X页面，等于X页面就会被扫描2次甚至多次。以此类推，所以同一个数据页可能会被多次重复的读取，丢弃，在读取，这无疑给存储引擎极大地增加了IO的负担。\n\nselect * from tb where gender='男'这种不仅需要扫描这个索引  而且去取有‘男’的数据块基本覆盖了整个表所涉及的数据块\n\n\n3、唯一性太差的字段\n\n当你为这个字段创建索引时候，当你再次更新这个字段数据时，数据库会自动更新他的索引，所以当这个字段更新太频繁地时候那么就是不断的更新索引。\n如果一个字段同一个时间段内被更新多次，那么不能为他建立索引。\n\n### 思考\n#### InnoDB索引为什么不建议使用过长的字段作为主键\n  因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大\n\n#### 为什么InnoDB表必须有主键，并且推荐使用整型的自增主键？\n\nInnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。\n\n![](innodb自增主键 1.png)\n如果表使用自增主键，那么每次插入新的记录，**记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上**。\n\n如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：\n![](innodb自增主键2.png)\n\n此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。\n\n\n#### 为什么非主键索引结构叶子节点存储的是主键值？\n1、节省空间\n根据主键就可以找到主键索引中对应的叶子节点，不用再多存储一份相同的数据。\n\n2、数据一致性\n如果主键索引结构和非主键索引结构都含有相同的数据，那么在更新数据的时候，就要同时更新两个索引结构\n\n\n#### 什么时候用MyISAM，什么时候用Innodb?\n主要区别：\n1).MyISAM是非事务安全型的，而InnoDB是事务安全型的。\n2).MyISAM锁的粒度是表级，而InnoDB支持行级锁定。\n3).MyISAM支持全文类型索引，而InnoDB不支持全文索引。\n4).MyISAM相对简单，所以在效率上要优于InnoDB，小型应用可以考虑使用MyISAM。\n5).MyISAM表是保存成文件的形式，在跨平台的数据转移中使用MyISAM存储会省去不少的麻烦。\n6).InnoDB表比MyISAM表更安全，可以在保证数据不会丢失的情况下，切换非事务表到事务表（alter table tablename type=innodb）。\n\n应用场景：\n1).MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询，那么MyISAM是更好的选择。\n2).InnoDB用于事务处理应用程序，具有众多特性，包括ACID事务支持。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能。\n\n\nINNODB的行级锁是有条件的。在where条件没有使用主键时，照样会锁全表。\n\n#### 主索引和辅助索引\n一个主文件仅有一个主索引，但可以有多个辅助索引\n\n#### 为什么MyISAM会比Innodb的查询速度快\nINNODB在做SELECT的时候，要维护的东西比MYISAM引擎多很多:\n1）数据块，INNODB要缓存，MYISAM只缓存索引块，  这中间还有换进换出的减少；\n \n\n2）innodb寻址要映射到块，再到行，MYISAM记录的直接是文件的OFFSET，定位比INNODB要快\n\n3）INNODB还需要维护MVCC一致；虽然你的场景没有，但他还是需要去检查和维护\nMVCC (Multi-Version Concurrency Control)多版本并发控制 \n\n注释：\nInnoDB：通过为每一行记录添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。但是InnoDB并不存储这些事件发生时的实际时间，相反它只存储这些事件发生时的系统版本号。这是一个随着事务的创建而不断增长的数字。每个事务在事务开始时会记录它自己的系统版本号。每个查询必须去检查每行数据的版本号与事务的版本号是否相同。让我们来看看当隔离级别是REPEATABLEREAD时这种策略是如何应用到特定的操作的：\n　　SELECT InnoDB必须每行数据来保证它符合两个条件：\n　　1、InnoDB必须找到一个行的版本，它至少要和事务的版本一样老(也即它的版本号不大于事务的版本号)。这保证了不管是事务开始之前，或者事务创建时，或者修改了这行数据的时候，这行数据是存在的。\n　　2、这行数据的删除版本必须是未定义的或者比事务版本要大。这可以保证在事务开始之前这行数据没有被删除\n\n#### myisam 和 innodb中count(*)查询快慢原理\n在myisam中count(*)查询,myisam引擎很容易获得总行数的统计。查询速度变得更快。因为myisam存储引擎已经存储了表的总行数。每次新增加一行,这个计数器就加1。也就是说，把表的总数缓存在索引中了。\n\n注意:\n\nmyisam存储引擎的表，count()速度快的也仅仅是不带where条件的count。这个想想容易理解的，因为你带了where限制条件，原来所以中缓存的表总数能够直接返回用吗？不能用。这个查询引擎也是需要根据where条件去表中扫描数据，进行统计返回的。\n\n针对Innodb表,尽量不执行 SELECT COUNT() 语句,因为Innodb表没有类似MyISAM那样的内部计数器来记录表记录总量,执行这个操作将会全表扫描,速度很慢。所以呢，表的行数越多，扫描的时间就越多。当你表行数还是小数量的时候体会不出速度差距。比如百万也感觉不出明显。上千万就会很明显速度差别了。\n\n#### 哪些列比较适合做索引\n用于索引的最好的备选数据列是那些出现在WHERE子句、join子句、ORDER BY或GROUP BY子句中的列。仅仅出现在SELECT关键字后面的输出数据列列表中的数据列不是很好的备选列\n\n在mysql中执行查询时，只能使用一个索引，如果我们在lname,fname,age上分别建索引,执行查询时，只能使用一个索引，mysql会选择一个最严格(获得结果集记录数最少)的索引。\n\n\n\n### 参考资料\n- [干货：mysql索引的数据结构](https://www.jianshu.com/p/1775b4ff123a)\n- [深入理解Mysql索引底层数据结构与算法](https://blog.csdn.net/caijunsen/article/details/83045985)\n- [MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)\n- [MYSQL-B+TREE索引原理](https://www.jianshu.com/p/486a514b0ded)\n- [MYSQL索引详解](https://blog.csdn.net/qq_36711757/article/details/80642931)\n- [MySQL索引优化](https://www.cnblogs.com/dongguacai/p/7238663.html)\n- [数据库索引的实现原理及查询优化](https://yq.aliyun.com/articles/38328?spm=a2c4e.11155435.0.0.5011772ejZLrnv)\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"B树与B+树","url":"/2019/03/27/B树与B-树/","content":"\n### 简介\nB树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的多路搜索树（并不是二叉的）。与自平衡二叉查找树不同，B-树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统。\nB树中的B代表平衡（balance），而不是二叉（binary）。\n\n\n### B树定义\nB树也称B-树,它是一颗多路平衡查找树。我们描述一颗B树时需要指定它的阶数，阶数表示了一个结点最多有多少个孩子结点，一般用字母m表示阶数。当m取2时，就是我们常见的二叉搜索树。\n\n一颗m阶的B树定义如下：\n\n1）每个结点最多有m-1个关键字。\n\n2）根结点最少可以只有1个关键字。\n\n3）非根结点至少有Math.ceil(m/2)-1个关键字。(向上取整)\n\n4）每个结点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。\n\n5）所有叶子结点都位于同一层，或者说根结点到每个叶子结点的长度都相同。\n\nB-Tree的节点是一个二元组[key, data]，key为记录的键值，data键key对应的数据。\n\n\n下图是一个M=4 阶的B树（阶代表一个节点子节点的数量）:\n![](4阶B树.png)\n\n> 在实际应用中的B树的阶数m都非常大（通常大于100），所以即使存储大量的数据，B树的高度仍然比较小。\n可以看到B树是2-3树的一种扩展，他允许一个节点有多于2个的元素。\n\n#### B树的插入\n\n插入操作是指插入一条记录，即（key, value）的键值对。如果B树中**已存在**需要插入的键值对，则用需要插入的value**替换**旧的value。若B树**不存在**这个key,则一定是在**叶子结点中进行插入**操作。\n\n操作步骤：\n1）根据要插入的key的值，找到叶子结点并插入。\n\n2）判断当前结点key的个数是否小于等于m-1（每个结点最多有m-1个关键字），若满足则结束，否则进行第3步。\n\n3）以结点中间的key为中心分裂成左右两部分，然后将这个中间的key插入到父结点中，这个key的左子树指向分裂后的左半部分，这个key的右子支指向分裂后的右半部分，然后将当前结点指向父结点，继续进行第3步。\n\n下面以5阶B树为例，介绍B树的插入操作，在5阶B树中，结点最多有4个key,最少有2个key\na）在空树中插入39\n![](B树插入-1.png)\n此时根结点就一个key，此时根结点也是叶子结点\n\nb）继续插入22，97和41\n![](B树插入-2.png)\n根结点此时有4个key\n\nc）继续插入53\n![](B树插入-3.png)\n插入后超过了最大允许的关键字个数4，所以以key值为41为中心进行分裂，结果如下图所示，分裂后当前结点指针指向父结点（关键字41这个结点），满足B树条件，插入操作结束。当阶数m为偶数时，需要分裂时就不存在排序恰好在中间的key，那么我们选择中间位置的前一个key或中间位置的后一个key为中心进行分裂即可。\n![](B树插入-4.png)\n\nd）依次插入13，21，40，同样会造成分裂，结果如下图所示。\n![](B树插入-5.png)\n\ne）依次插入30，27, 33 ；36，35，34 ；24，29，结果如下图所示。\n![](B树插入-6.png)\n\nf）插入key值为26的记录，插入后的结果如下图所示。\n![](B树插入-7.png)\n\n当前结点需要以27为中心分裂，并向父结点进位27，然后当前结点指向父结点，结果如下图所示。\n![](B树插入-8.png)\n\n进位后导致当前结点（即根结点）也需要分裂，分裂的结果如下图所示。\n![](B树插入-9.png)\n分裂后当前结点指向新的根，此时无需调整。\n\ng）最后再依次插入key为17,28,29,31,32的记录，结果如下图所示。\n![](B树插入-10.png)\n\n在实现B树的代码中，为了使代码编写更加容易，我们可以将结点中存储记录的数组长度定义为m而非m-1，这样方便底层的结点由于分裂向上层插入一个记录时，上层有多余的位置存储这个记录。同时，每个结点还可以存储它的父结点的引用，这样就不必编写递归程序。\n\n**一般来说，对于确定的m和确定类型的记录，结点大小是固定的，无论它实际存储了多少个记录。**但是分配固定结点大小的方法会存在浪费的情况，比如key为28,29所在的结点，还有2个key的位置没有使用，但是已经不可能继续在插入任何值了，因为这个结点的前序key是27,后继key是30，所有整数值都用完了。**所以如果记录先按key的大小排好序，再插入到B树中，结点的使用率就会很低，最差情况下使用率仅为50%。**\n\n####  B树的删除操作\n删除操作是指，根据key删除记录，如果B树中的记录中不存对应key的记录，则删除失败。\n\n1）如果当前需要删除的key位于非叶子结点上，则用后继key（这里的后继key均指后继记录的意思）覆盖要删除的key，然后在后继key所在的子支中删除该后继key。此时后继key一定位于叶子结点上。删除这个记录后执行第2步\n\n2）该结点key个数大于等于Math.ceil(m/2)-1，结束删除操作，否则执行第3步。\n\n3）如果兄弟结点key个数大于Math.ceil(m/2)-1，则父结点中的key下移到该结点，兄弟结点中的一个key上移，删除操作结束。\n\n否则，将父结点中的key下移与当前结点及它的兄弟结点中的key合并，形成一个新的结点。原父结点中的key的两个孩子指针就变成了一个孩子指针，指向这个新结点。然后当前结点的指针指向父结点，重复上第2步。\n\n有些结点它可能即有左兄弟，又有右兄弟，那么我们任意选择一个兄弟结点进行操作即可。\n\n下面以5阶B树为例，介绍B树的删除操作，5阶B树中，结点最多有4个key,最少有2个key\n\na）原始状态\n\n![](B树删除-1.png)\n\nb）在上面的B树中删除21，删除后结点中的关键字个数仍然大于等2，所以删除结束。\n![](B树删除-2.png)\n\nc）在上述情况下接着删除27。从上图可知27位于非叶子结点中，所以用27的后继替换它。从图中可以看出，27的后继为28，我们用28替换27，然后在28（原27）的右孩子结点中删除28。删除后的结果如下图所示。\n![](B树删除-3.png)\n删除后发现，当前叶子结点的记录的个数小于2，而它的兄弟结点中有3个记录，我们可以从兄弟结点中借取一个key。所以父结点中的28下移，兄弟结点中的26上移,删除结束。结果如下图所示。\n![](B树删除-4.png)\n\nd）在上述情况下接着32，结果如下图。\n![](B树删除-5.png)\n当删除后，当前结点中只key，而兄弟结点中也仅有2个key。所以只能让父结点中的30下移和这个两个孩子结点中的key合并，成为一个新的结点，当前结点的指针指向父结点。结果如下图所示。\n![](B树删除-6.png)\n当前结点key的个数满足条件，故删除结束。\n\ne）上述情况下，我们接着删除key为40的记录，删除后结果如下图所示。\n![](B树删除-7.png)\n同理，当前结点的记录数小于2，兄弟结点中没有多余key，所以父结点中的key下移，和兄弟（这里我们选择左兄弟，选择右兄弟也可以）结点合并，合并后的指向当前结点的指针就指向了父结点。\n![](B树删除-8.png)\n同理，对于当前结点而言只能继续合并了，最后结果如下所示。\n![](B树删除-9.png)\n合并后结点当前结点满足条件，删除结束。\n\n\n> B-树的自控制:\n> B树中每一个内部节点会包含一定数量的键值。通常，键值的数量被选定在d和2d之间。在实际中，键值占用了节点中大部分的空间。因数2将保证节点可以被拆分或组合。如果一个内部节点有2d个键值，那么添加一个键值给此节点的过程，将会拆分2d键值为2个d键值的节点，并把此键值添加给父节点。每一个拆分的节点需要最小数目的键值。相似地，如果一个内部节点和他的邻居两者都有d个键值，那么将通过它与邻居的合并来删除一个键值。删除此键值将导致此节点拥有d-1个键值;与邻居的合并则加上d个键值，再加上从邻居节点的父节点移来的一个键值。结果为完全填充的2d个键值。\n\n### B+树定义\nB+树的定义为关键字个数比孩子结点个数小1。\nB+树是对B树的一种变形树，它与B树的差异在于：\n\n1）B+树包含2种类型的结点：内部结点（也称索引结点）和叶子结点。根结点本身即可以是内部结点，也可以是叶子结点。根结点的关键字个数最少可以只有1个。\n\n2）B+树与B树最大的不同是内部结点不保存数据，只用于索引，所有数据（或者说记录）都保存在叶子结点中。\n\n3） m阶B+树表示了内部结点最多有m-1个关键字（或者说内部结点最多有m个子树），阶数m同时限制了叶子结点最多存储m-1个记录。\n\n4）内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。\n\n5）每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。\n\n如下图，是一个B+树:\n![](B+树.png)\n\n由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。\n\n#### B+树插入\n1）若为空树，创建一个叶子结点，然后将记录插入其中，此时这个叶子结点也是根结点，插入操作结束。\n\n2）针对叶子类型结点：根据key值找到叶子结点，向这个叶子结点插入记录。插入后，若当前结点key的个数小于等于m-1，则插入结束。否则将这个叶子结点分裂成左右两个叶子结点，左叶子结点包含前m/2个记录，右结点包含剩下的记录，将第m/2+1个记录的key进位到父结点中（父结点一定是索引类型结点），进位到父结点的key左孩子指针向左结点,右孩子指针向右结点。将当前结点的指针指向父结点，然后执行第3步。\n\n3）针对索引类型结点：若当前结点key的个数小于等于m-1，则插入结束。否则，将这个索引类型结点分裂成两个索引结点，左索引结点包含前(m-1)/2个key，右结点包含m-(m-1)/2个key，将第m/2个key进位到父结点中，进位到父结点的key左孩子指向左结点, 进位到父结点的key右孩子指向右结点。将当前结点的指针指向父结点，然后重复第3步。\n\n下面是一颗5阶B树的插入过程，5阶B数的结点最少2个key，最多4个key。\na）空树中插入5\n![](B+树插入-1.png)\n\nb）依次插入8，10，15\n![](B+树插入-2.png)\n\nc）插入16\n![](B+树插入-3.png)\n插入16后超过了关键字的个数限制，所以要进行分裂。在叶子结点分裂时，分裂出来的左结点2个记录，右边3个记录，中间key成为索引结点中的key，分裂后当前结点指向了父结点（根结点）。结果如下图所示。\n![](B+树插入-4.png)\n当然我们还有另一种分裂方式，给左结点3个记录，右结点2个记录，此时索引结点中的key就变为15。\n\nd）插入17\n\n![](B+树插入-5.png)\n\ne）插入18，插入后如下图所示\n\n![](B+树插入-6.png)\n\n当前结点的关键字个数大于5，进行分裂。分裂成两个结点，左结点2个记录，右结点3个记录，关键字16进位到父结点（索引类型）中，将当前结点的指针指向父结点。\n\n![](B+树插入-7.png)\n当前结点的关键字个数满足条件，插入结束。\n\n\nf）插入若干数据后\n![](B+树插入-8.png)\n\ng）在上图中插入7，结果如下图所示\n![](B+树插入-9.png)\n\n当前结点的关键字个数超过4，需要分裂。左结点2个记录，右结点3个记录。分裂后关键字7进入到父结点中，将当前结点的指针指向父结点，结果如下图所示。\n![](B+树插入-10.png)\n当前结点的关键字个数超过4，需要继续分裂。左结点2个关键字，右结点2个关键字，关键字16进入到父结点中，将当前结点指向父结点，结果如下图所示。\n![](B+树插入-11.png)\n当前结点的关键字个数满足条件，插入结束。\n\n#### B+树删除\n如果叶子结点中没有相应的key，则删除失败。否则执行下面的步骤\n\n1）删除叶子结点中对应的key。删除后若结点的key的个数大于等于Math.ceil(m-1)/2 – 1，删除操作结束,否则执行第2步。\n\n2）若兄弟结点key有富余（大于Math.ceil(m-1)/2 – 1），向兄弟结点借一个记录，同时用借到的key替换父结（指当前结点和兄弟结点共同的父结点）点中的key，删除结束。否则执行第3步。\n\n3）若兄弟结点中没有富余的key,则当前结点和兄弟结点合并成一个新的叶子结点，并删除父结点中的key（父结点中的这个key两边的孩子指针就变成了一个指针，正好指向这个新的叶子结点），将当前结点指向父结点（必为索引结点），执行第4步（第4步以后的操作和B树就完全一样了，主要是为了更新索引结点）。\n\n4）若索引结点的key的个数大于等于Math.ceil(m-1)/2 – 1，则删除操作结束。否则执行第5步\n\n5）若兄弟结点有富余，父结点key下移，兄弟结点key上移，删除结束。否则执行第6步\n\n6）当前结点和兄弟结点及父结点下移key合并成一个新的结点。将当前结点指向父结点，重复第4步。\n\n> 注意，通过B+树的删除操作后，索引结点中存在的key，不一定在叶子结点中存在对应的记录。\n\n下面是一颗5阶B树的删除过程，5阶B数的结点最少2个key，最多4个key。\n\na）初始状态\n\n![](B+树删除-1.png)\n\nb）删除22,删除后结果如下图\n![](B+树删除-2.png)\n删除后叶子结点中key的个数大于等于2，删除结束\n\nc）删除15，删除后的结果如下图所示\n![](B+树删除-3.png)\n删除后当前结点只有一个key,不满足条件，而兄弟结点有三个key，可以从兄弟结点借一个关键字为9的记录,同时更新将父结点中的关键字由10也变为9，删除结束。\n![](B+树删除-4.png)\n\nd）删除7，删除后的结果如下图所示\n\n![](B+树删除-5.png)\n\n当前结点关键字个数小于2，（左）兄弟结点中的也没有富余的关键字（当前结点还有个右兄弟，不过选择任意一个进行分析就可以了，这里我们选择了左边的），所以当前结点和兄弟结点合并，并删除父结点中的key，当前结点指向父结点。\n![](B+树删除-6.png)\n\n此时当前结点的关键字个数小于2，兄弟结点的关键字也没有富余，所以父结点中的关键字下移，和两个孩子结点合并，结果如下图所示。\n![](B+树删除-7.png)\n\n\n### B+树优点\nB+ 树的优点在于：\n\n1、由于B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子节点上关联的数据也具有更好的缓存命中率。\n\n2、B+树的叶子结点都是相链的，因此对整棵树的遍历只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。\n\n但是B树也有优点，其优点在于，由于B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。\n\n### B树与B+树区别\n1、更加高效的单元素查找\na、首先B+树的中间节点不存储实际数据，所以同样大小的磁盘页可以容纳更多的节点元素，如此一来，相同数量的数据下，B+树就相对来说要更加矮胖些，磁盘IO的次数更少。\n\nb、由于只有叶子节点才保存卫星数据，B+树每次查询都要到叶子节点；而B树每次查询则不一样，最好的情况是根节点，最坏的情况是叶子节点，没有B+树稳定。\n2、叶子节点形成有顺链表，范围查找性能更优\n比如说对于B树来说，查找3到8，B树需要不下５次的磁盘IO，每次查一个数都需要重复从根节点开始查找，查找的范围跨度越大，则磁盘IO的次数越多，性能越差。\n对于B+树来说，只需定位到３的叶子节点，然后通过链表指针，依次遍历得到元素5/6/8/9/11；如此一来，就不用像B树那样一个个元素进行查找。\n\n### 分析\n对于一颗节点为N度为M的子树，查找和插入需要logM-1N ~ logM/2N次比较。这个很好证明，对于度为M的B树，每一个节点的子节点个数为M/2 到 M-1之间，所以树的高度在logM-1N至logM/2N之间。\n\n这种效率是很高的，对于N=620000000000个节点，如果度为1024，则logM/2N <=4，即在620亿个元素中，如果这棵树的度为1024，则只需要小于4次即可定位到该节点，然后再采用二分查找即可找到要找的值。\n\n### 应用\nB树和B+广泛应用于文件存储系统以及数据库系统中。\n由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，因此为了提高效率，要尽量减少磁盘I/O，减少读写操作。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：\n\n当一个数据被用到时，其附近的数据也通常会马上被使用。\n\n由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。\n\n预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。\n\n文件系统及数据库系统的设计者利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：\n\n每次新建一个节点的同时，直接申请一个页的空间( 512或者1024)，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。\n\n#### B-Tree\nB-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree：\n![](3阶的B-Tree.png)\n\n每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17-35，P3指针指向的子树的数据范围为大于35。\n模拟查找关键字29的过程：\n\n1、根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】\n2、比较关键字29在区间（17,35），找到磁盘块1的指针P2。\n3、根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】\n4、比较关键字29在区间（26,30），找到磁盘块3的指针P2。\n5、根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】\n6、在磁盘块8中的关键字列表中找到关键字29。\n\n分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。\n\n\n#### B+Tree\nB+Tree是在B-Tree基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用B+Tree实现其索引结构。\n\n从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。\n评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。\n\nB+Tree相对于B-Tree有几点不同：\n\n1、非叶子节点只存储键信息。\n2、所有叶子节点之间都有一个链指针。\n3、数据记录都存放在叶子节点中。\n\n将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示： \n![](3阶B+Tree.png)\n\n通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对B+Tree进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。\n\n可能上面例子中只有22条数据记录，看不出B+Tree的优点，下面做一个推算：\n\nInnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为〖10〗^3）。也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * 10^3 = 10亿 条记录(1k键值可以作为一个单独的节点再分出1k个子节点)。\n\n实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2-4层。mysql的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1-3次磁盘I/O操作。\n\n数据库中的B+Tree索引可以分为聚集索引（clustered index）和辅助索引（secondary index）。上面的B+Tree示例图在数据库中的实现即为聚集索引，聚集索引的B+Tree中的叶子节点存放的是整张表的行记录数据。辅助索引与聚集索引的区别在于辅助索引的叶子节点并不包含行记录的全部数据，而是存储相应行数据的聚集索引键，即主键。当通过辅助索引来查询数据时，InnoDB存储引擎会遍历辅助索引找到主键，然后再通过主键在聚集索引中找到完整的行记录数据。\n\n### 为什么Mysql选择B+TREE索引? B+TREE索引有什么好处?\nB-/+Tree索引的性能优势： 一般使用磁盘I/O次数评价索引优劣。\n1.结合操作系统存储结构优化处理： mysql巧妙运用操作系统存储结构(一个节点分配到一个存储页中->尽量减少IO次数) & 磁盘预读(缓存预读->加速预读马上要用到的数据).\n\n2.B+Tree 单个节点能放更多的键（B+Tree内节点去掉了data域，因此可以拥有更大的出度），相同IO次数，检索出更多信息。\n\n3.B+TREE 只在叶子节点存储数据 & 所有叶子结点包含一个链指针 & 其他内层非叶子节点只存储索引数据。只利用索引快速定位数据索引范围，先定位索引再通过索引高效快速定位数据。\n\n\n### 参考资料\n\n- [【经典数据结构】B树与B+树](https://www.cnblogs.com/vincently/p/4526560.html)\n- [二叉查找树、平衡二叉树（AVLTree）和平衡多路查找树（B-Tree），B+树](https://blog.csdn.net/qq_21993785/article/details/80576642)\n- [什么是B+Tree](https://www.cnblogs.com/dongguacai/p/7241860.html)\n- [B树和B+树的插入、删除图文详解](https://www.01hai.com/note/av124483)","tags":["数据结构"],"categories":["数据结构"]},{"title":"CopyOnWriteArrayList实现原理及源码分析","url":"/2019/03/26/CopyOnWriteArrayList实现原理及源码分析/","content":"\n### 简介\n　CopyOnWriteArrayList是Java并发包中提供的一个并发容器，它是个线程安全且读操作无锁的ArrayList，写操作则通过创建底层数组的新副本来实现，是一种读写分离的并发策略，我们也可以称这种容器为\"写时复制器\"，Java并发包中类似的容器还有CopyOnWriteSet。\n\n### 原理\nCopyOnWriteArrayList容器允许并发读，读操作是无锁的，性能较高。至于写操作，比如向容器中添加一个元素，则首先将当前容器复制一份，然后在新副本上执行写操作，结束之后再将原容器的引用指向新容器。\n![](原理.png)\n\n### 优点\n读操作性能很高，因为无需任何同步措施，比较适用于读多写少的并发场景。Java的list在遍历时，若中途有别的线程对list容器进行修改，则会抛出ConcurrentModificationException异常。而CopyOnWriteArrayList由于其\"读写分离\"的思想，遍历和修改操作分别作用在不同的list容器，所以在使用迭代器进行遍历时候，也就不会抛出ConcurrentModificationException异常了。\n\n### 缺点\n一是内存占用问题，毕竟每次执行写操作都要将原容器拷贝一份，数据量大时，对内存压力较大，可能会引起频繁GC；二是无法保证实时性，Vector对于读写操作均加锁同步，可以保证读和写的强一致性。而CopyOnWriteArrayList由于其实现策略的原因，写和读分别作用在新老不同容器上，在写操作执行过程中，读不会阻塞但读取到的却是老容器的数据。\n### 源码分析\n\n#### add\n```java\npublic boolean add(E e) {\n        //ReentrantLock加锁，保证线程安全\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            //拷贝原容器，长度为原容器长度加一\n            Object[] newElements = Arrays.copyOf(elements, len + 1);\n            //在新副本上执行添加操作\n            newElements[len] = e;\n            //将原容器引用指向新副本\n            setArray(newElements);\n            return true;\n        } finally {\n            //解锁\n            lock.unlock();\n        }\n    }\n```\n添加的逻辑很简单，先将原容器copy一份，然后在新副本上执行写操作，之后再切换引用。当然此过程是要加锁的。\n\n#### remove\n```java\npublic E remove(int index) {\n        //加锁\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            E oldValue = get(elements, index);\n            int numMoved = len - index - 1;\n            if (numMoved == 0)\n                //如果要删除的是列表末端数据，拷贝前len-1个数据到新副本上，再切换引用\n                setArray(Arrays.copyOf(elements, len - 1));\n            else {\n                //否则，将除要删除元素之外的其他元素拷贝到新副本中，并切换引用\n                Object[] newElements = new Object[len - 1];\n                System.arraycopy(elements, 0, newElements, 0, index);\n                System.arraycopy(elements, index + 1, newElements, index,\n                                 numMoved);\n                setArray(newElements);\n            }\n            return oldValue;\n        } finally {\n            //解锁\n            lock.unlock();\n        }\n    }\n```\n将除要删除元素之外的其他元素拷贝到新副本中，然后切换引用，将原容器引用指向新副本。同属写操作，需要加锁。","tags":["Java","并发"],"categories":["Java","并发"]},{"title":"HashMap（JDK-1.7及1.8）","url":"/2019/03/26/HashMap（JDK-1-7及1-8）/","content":"\n### 简介\nHashMap是基于哈希表实现的键值对的集合，继承自AbstractMap并实现了Map接口的**非同步**实现。此实现提供所有可选的映射操作，并**允许使用null值和null键（存放在第一个哈希桶中）**。此类不保证映射的顺序，特别是它**不保证该顺序恒久不变（扩容）**。\n\nHashMap的特殊存储结构使得在获取指定元素的前需要经过哈希运算，得到目标元素在哈希表中的位置，然后再进行少量的比较即可得到元素，这使得HashMap的查找效率很高。\n\n![](map类结构图.png)\n\n简单来说，HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，**对于添加操作，其时间复杂度依然为O(1)，因为最新的Entry会插入链表头部**，只需要简单改变引用链即可，而对于查找操作来讲，此时就需要遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。\n\n### 特点\n- 底层实现是 链表数组，JDK 8 后又加了 红黑树\n- 实现了 Map 全部的方法\n- key 用 Set 存放，所以 key 不允许重复，key 对应的类需要重写 hashCode 和 equals 方法\n- 允许空键和空值（但空键只有一个，且放在第一位，下面会介绍）\n- 元素是无序的，而且顺序会不定时改变\n- 插入、获取的时间复杂度基本是 O(1)（前提是有适当的哈希函数，让元素分布在均匀的位置）\n- 遍历整个 Map 需要的时间与 桶(数组) 的长度成正比（因此初始化时 HashMap 的容量不宜太大）\n- 两个关键因子：初始容量、负载因子\n\n如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。\n### JDK1.7（数组+链表）\n#### 数据结构\n```java\npublic class HashMap<K,V>\n    extends AbstractMap<K,V>\n    implements Map<K,V>, Cloneable, Serializable\n{\n\t//默认初始容量\n    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16\n    //最大容量： 2^ 30 次方\n    static final int MAXIMUM_CAPACITY = 1 << 30;\n    //默认加载因子的大小：0.75，可不是随便的，结合时间和空间效率考虑得到的\n    static final float DEFAULT_LOAD_FACTOR = 0.75f;\n    static final Entry<?,?>[] EMPTY_TABLE = {};\n    //哈希表中的链表数组\n    transient Entry<K,V>[] table = (Entry<K,V>[]) EMPTY_TABLE;\n    //键值对的数量\n    transient int size;\n    //阈值，下次需要扩容时的值，等于 容量*加载因子\n    int threshold;\n    //哈希表的加载因子\n    final float loadFactor;\n    //当前 HashMap 修改的次数，这个变量用来保证 fail-fast 机制\n    transient int modCount;\n    //缓存的 键值对集合（另外两个视图：keySet 和 values 是在 AbstractMap 中声明的）\n    transient Set<Map.Entry<K,V>> entrySet;\n    static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE;\n    /**********部分代码省略**********/\n    static class Entry<K,V> implements Map.Entry<K,V> {\n        final K key;\n        V value;\n        Entry<K,V> next;\n        int hash; //对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算\n        /**********部分代码省略**********/\n    }\n    /**********部分代码省略**********/\n}\n```\nHashMap中主要存储着一个Entry的数组table，Entry就是数组中的元素，Entry实现了Map.Entry所以其实Entry就是一个key-value对，并且它持有一个指向下一个元素的引用，这样构成了链表。\n![](整体结构.png)\n#### 构造函数\n```java\n/**\n * Constructs an empty <tt>HashMap</tt> with the specified initial\n * capacity and load factor.\n *\n * @param  initialCapacity the initial capacity\n * @param  loadFactor      the load factor\n * @throws IllegalArgumentException if the initial capacity is negative\n *         or the load factor is nonpositive\n */\npublic HashMap(int initialCapacity, float loadFactor) {\n    if (initialCapacity < 0)\n        throw new IllegalArgumentException(\"Illegal initial capacity: \" +\n                                            initialCapacity);\n    if (initialCapacity > MAXIMUM_CAPACITY)\n        initialCapacity = MAXIMUM_CAPACITY;\n    if (loadFactor <= 0 || Float.isNaN(loadFactor))\n        throw new IllegalArgumentException(\"Illegal load factor: \" +\n                                            loadFactor);\n\n    this.loadFactor = loadFactor;\n    threshold = initialCapacity;\n    init();\n}\npublic HashMap(int initialCapacity) {\n    this(initialCapacity, DEFAULT_LOAD_FACTOR);\n}\npublic HashMap() {\n    this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);\n}\npublic HashMap(Map<? extends K, ? extends V> m) {\n    this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1,\n                    DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR);\n    inflateTable(threshold);\n\n    putAllForCreate(m);\n}\n```\n主要有两个参数，【initialCapacity】初始容量、【loadFactor】加载因子。这两个属性在类定义时候都赋有默认值分别为16和0.75。table数组默认值为EMPTY_TABLE，在添加元素的时候判断table是否为EMPTY_TABLE来调用inflateTable。在构造HashMap实例的时候默认【threshold】阈值等于初始容量。当构造方法的参数为Map时，调用inflateTable(threshold)方法对table数组容量进行扩充，扩充为原来的2倍：\n```java\n/**\n * Inflates the table.\n */\nprivate void inflateTable(int toSize) {\n    // Find a power of 2 >= toSize\n    int capacity = roundUpToPowerOf2(toSize);\n    //更新阈值\n    threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1);\n    table = new Entry[capacity];\n    initHashSeedAsNeeded(capacity);\n}\n//返回一个比初始容量大的最小的2的幂数,如果number为2的整数幂值那么直接返回，最小为1，最大为2^31。\nprivate static int roundUpToPowerOf2(int number) {\n    // assert number >= 0 : \"number must be non-negative\";\n    return number >= MAXIMUM_CAPACITY\n            ? MAXIMUM_CAPACITY\n            : (number > 1) ? Integer.highestOneBit((number - 1) << 1) : 1;\n}\n```\n\n#### HashMap的put方法\n```java\n//HashMap添加元素\npublic V put(K key, V value) {\n    //table没有初始化size=0，先调用inflateTable对table容器进行扩容\n    if (table == EMPTY_TABLE) {\n        inflateTable(threshold);\n    }\n    //在hashMap增加key=null的键值对\n    if (key == null)\n        return putForNullKey(value);\n    //计算key的哈希值\n    int hash = hash(key);\n    //计算在table数据中的bucketIndex\n    int i = indexFor(hash, table.length);\n    //遍历table[i]的链表，如果节点不为null，通过循环遍历链表的下一个元素\n    for (Entry<K,V> e = table[i]; e != null; e = e.next) {\n        Object k;\n        //找到对应的key，则将value进行替换\n        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {\n            V oldValue = e.value;\n            e.value = value;\n            e.recordAccess(this);\n            return oldValue;\n        }\n    }\n    //没有找到对应的key的Entry，则需要对数据进行modify,modCount加一\n    modCount++;\n    //将改key，value添加入table中\n    addEntry(hash, key, value, i);\n    return null;\n}\nprivate V putForNullKey(V value) {\n        for (Entry<K,V> e = table[0]; e != null; e = e.next) {\n            if (e.key == null) {\n                V oldValue = e.value;\n                e.value = value;\n                e.recordAccess(this);\n                return oldValue;\n            }\n        }\n        modCount++;\n        addEntry(0, null, value, 0);\n        return null;\n   }\n//添加Entry\nvoid addEntry(int hash, K key, V value, int bucketIndex) {\n    //当前map中键值对数量大于于阈值，而且当前桶的索引位置不为null。则需要对桶进行扩容\n    if ((size >= threshold) && (null != table[bucketIndex])) {\n        //对桶进行扩容\n        resize(2 * table.length);\n        //重新计算hash值\n        hash = (null != key) ? hash(key) : 0;\n        //重新计算当前需要插入的桶的位置\n        bucketIndex = indexFor(hash, table.length);\n    }\n    //在bucketIndex位置创建Entry\n    createEntry(hash, key, value, bucketIndex);\n}\n//创建Entry\nvoid createEntry(int hash, K key, V value, int bucketIndex) {\n    //找到当前桶的当前链表的头节点\n    Entry<K,V> e = table[bucketIndex];\n    //新创建一个Entry将其插入在桶的bucketIndex位置的链表的头部\n    table[bucketIndex] = new Entry<>(hash, key, value, e);\n    size++;\n}\nfinal int hash(Object k) {\n    int h = hashSeed;\n    if (0 != h && k instanceof String) {\n        return sun.misc.Hashing.stringHash32((String) k);\n    }\n\n    h ^= k.hashCode();\n\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n    h ^= (h >>> 20) ^ (h >>> 12);\n    return h ^ (h >>> 7) ^ (h >>> 4);\n}\n//找到当前的hash在桶的分布节点位置\nstatic int indexFor(int h, int length) {\n    // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\";\n    return h & (length-1);\n}\n\n```\n整体流程：\n1、判断table[]哈希表是否为空，若为空，则按当前的阈值threshold对哈希表进行初始化（inflateTable(threshold)），设置为大于当前阈值的最小2次幂数。\n\n2、判断key是否为空，若为空，则调用putForNullKey()在table[0]上设置新的 value，同时返回旧的value。\n在putForNullKey()的执行逻辑为先判断table[0]上是否已经存在值，若存在就直接替换，返回旧值。若不存在则表明需要新加一个节点到链表上，此时需要先判断，当前的size是否已超过阈值，超过则先进行扩容，并重新计算key的hash值以及重新定位在哈希表的位置。若没超过，则插入一个新节点到table[0]链表的头部，size++。\n\n3、若插入的key非空，先计算key的hash值，然后定位到具体的哈希表的位置，如table[i]。循环table[i]上的链表，根据key的hash值（不是hashCode）和equals方法比较链表上是否已存在key对应的Entry。若存在则更新对应的Entry上的value，同时返回旧值。若链表上不存在key对应的Entry，则表明需要新加一个节点到链表上，此时需要先判断，当前的size是否已超过阈值，超过则先进行扩容，并重新计算key的hash值以及重新定位在哈希表的位置。若没超过，则插入一个新节点到table[i]链表的头部，size++。\n\n注意：\n> - 若发生覆盖行为，则返回key对应的旧值。\n\n#### HashMap的扩容\n当HashMap中的元素越来越多的时候，因为数组的长度是固定的，所以**hash冲突的几率也就越来越高，桶的节点处的链表就越来越长，这个时候查找元素的时间复杂度相应的增加**。为了提高查询的效率，就要对HashMap的数组进行扩容（这是一个常用的操作，数组扩容这个操作也会出现在ArrayList中。），而在HashMap数组扩容之后，最消耗性能的地方就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。\n\n```java\n//HashMap扩容\nvoid resize(int newCapacity) {\n    //引用备份\n    Entry[] oldTable = table;\n    //原来桶的长度\n    int oldCapacity = oldTable.length;\n    //判断是否已经扩容到极限\n    if (oldCapacity == MAXIMUM_CAPACITY) {\n        threshold = Integer.MAX_VALUE;\n        return;\n    }\n    //根据容器大小创新的建桶\n    Entry[] newTable = new Entry[newCapacity];\n    //\n    transfer(newTable, initHashSeedAsNeeded(newCapacity));\n    //重置桶的引用\n    table = newTable;\n    //重新计算阈值\n    threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);\n}\n//用于初始化hashSeed参数.\n//其中hashSeed用于计算key的hash值，它与key的hashCode进行按位异或运算。\n//这个hashSeed是一个与实例相关的随机值，主要用于解决hash冲突。\nfinal boolean initHashSeedAsNeeded(int capacity) {\n    boolean currentAltHashing = hashSeed != 0;\n    boolean useAltHashing = sun.misc.VM.isBooted() &&\n            (capacity >= Holder.ALTERNATIVE_HASHING_THRESHOLD);\n    boolean switching = currentAltHashing ^ useAltHashing;\n    if (switching) {\n        hashSeed = useAltHashing\n            ? sun.misc.Hashing.randomHashSeed(this)\n            : 0;\n    }\n    return switching;\n}\n//桶中数据的迁移\nvoid transfer(Entry[] newTable, boolean rehash) {\n    //新的痛长\n    int newCapacity = newTable.length;\n    for (Entry<K,V> e : table) {\n        //遍历桶的每一个节点的链表\n        while(null != e) {\n            Entry<K,V> next = e.next;\n            //重新计算哈希值\n            if (rehash) {\n                e.hash = null == e.key ? 0 : hash(e.key);\n            }\n            //找到当前Entry在新桶中的位置\n            int i = indexFor(e.hash, newCapacity);\n            //将Entry添加在当桶中的bucketIndex处的链表的头部\n            e.next = newTable[i];\n            //将产生的新链表赋值为桶的bucketIndex处\n            newTable[i] = e;\n            //遍历当前链表的下一个节点\n            e = next;\n        }\n    }\n}\n```\n整体过程：\n1、判断当前容量是否达到最大值（Integer.MAX_VALUE），若是则直接返回，不进行扩容，否则创建新的桶。\n2、transfer()将旧桶上的数据移到新桶上，重新计算阈值。\n转移过程：遍历桶的每一个节点的链表，定位当前节点在新桶上的位置，利用头插法将节点转移到新的桶上。\n\n![](1.7扩容.webp)\n\n所有Entry的hash值是不需要重新计算的。因为hash值与（length - 1）取的总是hash值的二进制右边底位，扩容一次向左多取一位二进制，取值互不影响。\n在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。\n![](1.7扩容例子.png)\n可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。\n\n#### HashMap的get方法\n```java\n//HashMap的get方法\npublic V get(Object key) {\n    //获取key为null的value\n    if (key == null)\n        return getForNullKey();\n    //获取key对应的Entry实例\n    Entry<K,V> entry = getEntry(key);\n\n    return null == entry ? null : entry.getValue();\n}\nprivate V getForNullKey() {\n        for (Entry<K,V> e = table[0]; e != null; e = e.next) {\n            if (e.key == null)\n                return e.value;\n        }\n        return null;\n    }\n\n//获取Entry\nfinal Entry<K,V> getEntry(Object key) {\n    if (size == 0) {\n        return null;\n    }\n    //计算key的hash值\n    int hash = (key == null) ? 0 : hash(key);\n    //根据hash调用indexFor方法找到当前key对应的桶的index，遍历该节点对应的链表\n    for (Entry<K,V> e = table[indexFor(hash, table.length)];\n         e != null;\n         e = e.next) {\n        Object k;\n        //判断当前Entry的hash、key的hash和Entry的key、key是否相等\n        if (e.hash == hash &&\n            ((k = e.key) == key || (key != null && key.equals(k))))\n            return e;\n    }\n    return null;\n}\n```\n整体过程：\n1、若key为空，则直接在哈希表table[0]的链表上遍历，得到key为null的Entry并返回value，若没有得到相应的Entry，直接返回null\n2、若key非空，则先计算key对应的哈希值，定位key在哈希桶上的位置，然后遍历该位置上的链表。根据key的hash值和equal找到对应的Entry，返回Entry上的value，否则返回null。\n\n\n#### HashMap的keySet\n我们遍历hashmap时的方法如下:\n```java\n  Iterator<String> map = map.keySet().iterator();\n        while(map.hasNext()){\n            System.out.println(map.next());\n    }\n```\n\n\n```java\n public Set<K> keySet() {\n        Set<K> ks = keySet;\n        return (ks != null ? ks : (keySet = new KeySet()));\n    }\n```\n往后一直追溯到：\n```java\n private final class KeyIterator extends HashIterator<K> {\n        public K next() {\n            return nextEntry().getKey();\n        }\n    }\n```\n当我们在增强for循环时会调用该next()方法，它指向的是nextEntry().getKey()，Entry中不仅存放了key，value，也存放了next，指向下一个Entry对象，我们知道，HashMap的数据层实现是数组+链表，nextEntry会先遍历链表，然后再继续遍历下一个数组位置的链表，直至全部遍历完成，其部分源码如下：\n```java\nif ((next = e.next) == null) {\n    Entry[] t = table;\n    while (index < t.length && (next = t[index++]) == null)\n        ;\n}\n```\nkeySet()方法返回一个内部引用，并指向一个内部类对象，该内部类重写了迭代器方法，当在增强for循环时才调用，并从外部类的table中取值。\n\n\n\n### JDK1.8 以及所做的改进\n#### 数据结构\n在java8中Entry改名为Node，因为在Java8中Entry不仅有链表形式还有树型结构，对应的类为TreeNode。同时增加了以下成员变量：\n```java\n//链表切换为红黑树的阈值\nstatic final int TREEIFY_THRESHOLD = 8;\n//红黑树切花为链表的阈值\nstatic final int UNTREEIFY_THRESHOLD = 6;\n//红黑树上的节点个数满足时对整个桶进行扩容\nstatic final int MIN_TREEIFY_CAPACITY = 64;\n//红黑树\nstatic final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {\n    TreeNode<K,V> parent;  // red-black tree links\n    TreeNode<K,V> left;\n    TreeNode<K,V> right;\n    TreeNode<K,V> prev;    // needed to unlink next upon deletion\n    boolean red;\n    /*************部分代码省略*****************/\n}\n//获取key的hashCode,并进行二次hash。二次hash只是将hashcode的高16位于第16位进行异或\nstatic final int hash(Object key) {\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n//resize时hash冲突使用的是红黑树\nfinal Node<K,V>[] resize() {\n    /*************部分代码省略*****************/\n}\n```\n#### 定位桶位置算法\n在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。这样可以避免只靠低位数据来计算哈希时导致的冲突，计算结果由高低位结合决定，可以避免哈希值分布不均匀。\n![](1.8hash.png)\n```java\nstatic final int hash(Object key) {   \n     int h;\n     // h = key.hashCode() 为第一步 取hashCode值\n     // h ^ (h >>> 16)  为第二步 高位参与运算\n     return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n```\n取key的hashCode值、高位运算、取模运算。JDK1.8没有indexFor()方法，将具体的实现放到了put方法中。\n\n#### 对Null key的处理\n在hash方法中做处理，统一返回hash值为0，并参与后面的正常运算过程，也是存储在第一个桶的位置。\n```java\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n```\n\n#### put\n![](1.8put.png)\n①.判断table是否为null或table.length是否为null，是则执行resize()进行扩容；\n\n②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；\n\n③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；\n\n④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；\n\n⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；\n\n⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。\n```java\npublic V put(K key, V value) {  \n    //hash()方法在上面已经出现过了，就不贴了  \n    return putVal(hash(key), key, value, false, true);  \n}  \n  \nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,  \n               boolean evict) {  \n    Node<K, V>[] tab;  \n    Node<K, V> p;  \n    int n, i;  \n    // 步骤①：tab为空则创建  \n    if ((tab = table) == null || (n = tab.length) == 0)  \n        n = (tab = resize()).length;  \n    // 步骤②：计算index，并对null做处理  \n    if ((p = tab[i = (n - 1) & hash]) == null)  \n        tab[i] = newNode(hash, key, value, null);  \n    else {  \n        Node<K, V> e;  \n        K k;  \n        // 步骤③：节点key存在，直接覆盖value  \n        if (p.hash == hash &&  \n                ((k = p.key) == key || (key != null && key.equals(k))))  \n            e = p;  \n            // 步骤④：判断该链为红黑树  \n        else if (p instanceof TreeNode)  \n            e = ((TreeNode<K, V>) p).putTreeVal(this, tab, hash, key, value);  \n            // 步骤⑤：该链为链表  \n        else {  \n            for (int binCount = 0; ; ++binCount) {  \n                if ((e = p.next) == null) {  \n                    p.next = newNode(hash, key, value, null);  \n                    //链表长度大于8转换为红黑树进行处理 TREEIFY_THRESHOLD = 8  \n                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st  \n                        treeifyBin(tab, hash);  \n\n                    break;  \n                }  \n                // key已经存在直接覆盖value  \n                if (e.hash == hash &&  \n                        ((k = e.key) == key || (key != null && key.equals(k))))  \n                    break;  \n                p = e;  \n            }  \n        }  \n        if (e != null) { // existing mapping for key  \n            V oldValue = e.value;  \n            if (!onlyIfAbsent || oldValue == null)  \n                e.value = value;  \n            afterNodeAccess(e);  \n            return oldValue;  \n        }  \n    }  \n    ++modCount;  \n    // 步骤⑥：超过最大容量 就扩容  threshold：单词解释--阈(yu)值,不念阀(fa)值！顺便学下语文咯。  \n    if (++size > threshold)  \n        resize();  \n    afterNodeInsertion(evict);  \n    return null;  \n}  \n```\n注意：\n1.7先扩容完，再加上新的节点，而1.8是加上新节点后，再扩容。\n1.7使用inflateTable来初始化数组，1.8统一使用resize()，扩容也是它。\n1.7链表采用头插法，1.8链表采用尾插法。\n\n#### 扩容\n```java\n  final Node<K,V>[] resize() {\n    //复制一份当前的数据\n    Node<K,V>[] oldTab = table;\n    //保存旧的元素个数、阈值\n    int oldCap = (oldTab == null) ? 0 : oldTab.length;\n    int oldThr = threshold;\n    int newCap, newThr = 0;\n    if (oldCap > 0) {\n        if (oldCap >= MAXIMUM_CAPACITY) {\n            threshold = Integer.MAX_VALUE;\n            return oldTab;\n        }\n        //新的容量为旧的两倍\n        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&\n                 oldCap >= DEFAULT_INITIAL_CAPACITY)\n            //如果旧容量小于等于 16，新的阈值就是旧阈值的两倍\n            newThr = oldThr << 1; // double threshold\n    }\n    //如果旧容量为 0 ，并且旧阈值>0，说明之前创建了哈希表但没有添加元素，初始化容量等于阈值\n    else if (oldThr > 0) // initial capacity was placed in threshold\n        newCap = oldThr;\n    else {               // zero initial threshold signifies using defaults\n        //旧容量、旧阈值都是0，说明还没创建哈希表，容量为默认容量，阈值为 容量*加载因子\n        newCap = DEFAULT_INITIAL_CAPACITY;\n        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n    }\n    //如果新的阈值为 0 ，就得用 新容量*加载因子 重计算一次\n    if (newThr == 0) {\n        float ft = (float)newCap * loadFactor;\n        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?\n                  (int)ft : Integer.MAX_VALUE);\n    }\n    //更新阈值\n    threshold = newThr;\n    //创建新链表数组，容量是原来的两倍\n    @SuppressWarnings({\"rawtypes\",\"unchecked\"})\n        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];\n    table = newTab;\n    //接下来就得遍历复制了\n    if (oldTab != null) {\n        for (int j = 0; j < oldCap; ++j) {\n            Node<K,V> e;\n            if ((e = oldTab[j]) != null) {\n                //旧的桶置为空\n                oldTab[j] = null;\n                //当前 桶只有一个元素，直接赋值给对应位置\n                if (e.next == null)\n                    newTab[e.hash & (newCap - 1)] = e;\n                else if (e instanceof TreeNode)\n                    //如果旧哈希表中这个位置的桶是树形结构，就要把新哈希表里当前桶也变成树形结构\n                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);\n                else { //保留旧哈希表桶中链表的顺序\n                    Node<K,V> loHead = null, loTail = null;\n                    Node<K,V> hiHead = null, hiTail = null;\n                    Node<K,V> next;\n                    //do-while 循环赋值给新哈希表\n                    do {\n                        next = e.next;\n                        // 原索引\n                        if ((e.hash & oldCap) == 0) {\n                            if (loTail == null)\n                                loHead = e;\n                            else\n                                loTail.next = e;\n                            loTail = e;\n                        }\n                        // 原索引+oldCap\n                        else {\n                            if (hiTail == null)\n                                hiHead = e;\n                            else\n                                hiTail.next = e;\n                            hiTail = e;\n                        }\n                    } while ((e = next) != null);\n                    // 原索引放到bucket里\n                    if (loTail != null) {\n                        loTail.next = null;\n                        newTab[j] = loHead;\n                    }\n                    // 原索引+oldCap放到bucket里\n                    if (hiTail != null) {\n                        hiTail.next = null;\n                        newTab[j + oldCap] = hiHead;\n                    }\n                }\n            }\n        }\n    }\n    return newTab;\n}\n```\n在JDK1.8中发生hashmap扩容时，遍历hashmap每个bucket里的链表，每个链表可能会被拆分成两个链表，不需要移动的元素置入loHead为首的链表，需要移动的元素置入hiHead为首的链表，然后分别分配给老的buket和新的buket。\n\n扩容过程中几个关键的点：\n\n- 新初始化哈希表时，容量为默认容量，阈值为 容量`*`加载因子\n- 已有哈希表扩容时，容量、阈值均翻倍\n- 如果之前这个桶的节点类型是树，需要把新哈希表里当前桶也变成树形结构\n- 复制给新哈希表中需要重新索引（rehash），这里采用的计算方法是 e.hash & (newCap - 1)，等价于 e.hash % newCap\n\n1. 在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&（这里就是为什么扩容的时候为啥一定必须是2的多少次幂的原因所在，因为如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞）（hash值 & length-1）\n\n2. 在JDK1.8的时候直接用了JDK1.7的时候计算的规律，也就是扩容前的原始位置+扩容的大小值=JDK1.8的计算方式，而不再是JDK1.7的那种异或的方法。但是这种方式就相当于只需要判断Hash值的新增参与运算的位是0还是1就直接迅速计算出了扩容后的储存方式。\n\n这里用到的是(e.hash & oldCap)，它有两种结果，一个是0，一个是oldCap，\n\n比如oldCap=8,hash是3，11，19，27时，(e.hash & oldCap)的结果是0，8，0，8。这样3，19组成新的链表，index为3；而11，27组成新的链表，新分配的index为3+8；\n\nJDK1.7中重写hash是(e.hash & newCap-1)，也就是3，11，19，27对16取余，也是3，11，3，11，和上面的结果一样，但是index为3的链表是19，3，index为3+8的链表是\n\n27，11，也就是说1.7中经过resize后数据的顺序变成了倒叙，而1.8没有改变顺序。\n扩容后，新数组中的链表顺序依然与旧数组中的链表顺序保持一致！\n\n![](扩容方式.png)\n#### get\n```java\npublic V get(Object key) {\n    Node<K,V> e;\n    //还是先计算 哈希值\n    return (e = getNode(hash(key), key)) == null ? null : e.value;\n}\n\nfinal Node<K,V> getNode(int hash, Object key) {\n    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;\n    //tab 指向哈希表，n 为哈希表的长度，first 为 (n - 1) & hash 位置处的桶中的头一个节点\n    if ((tab = table) != null && (n = tab.length) > 0 &&\n        (first = tab[(n - 1) & hash]) != null) {\n        //如果桶里第一个元素就相等，直接返回\n        if (first.hash == hash &&\n            ((k = first.key) == key || (key != null && key.equals(k))))\n            return first;\n        //否则就得慢慢遍历找\n        if ((e = first.next) != null) {\n            if (first instanceof TreeNode)\n                //如果是树形节点，就调用树形节点的 get 方法\n                return ((TreeNode<K,V>)first).getTreeNode(hash, key);\n            do {\n                //do-while 遍历链表的所有节点\n                if (e.hash == hash &&\n                    ((k = e.key) == key || (key != null && key.equals(k))))\n                    return e;\n            } while ((e = e.next) != null);\n        }\n    }\n    return null;\n}\n\n```\n查找 方法比较简单:\n\n先计算哈希值;\n然后再用 (n - 1) & hash 计算出桶的位置;\n在桶里的链表进行遍历查找。\n\n### 思考\n\n#### 1.7和1.8hash算法的不同\nJDK1.7用了9次扰动处理=4次位运算+5次异或，而JDK1.8只用了2次扰动处理=1次位运算+1次异或。\n\n#### 为什么哈希表的长度是2次幂\n首先，capacity 为 2的整数次幂的话，计算桶的位置 h&(capacity-1) 就相当于对 capacity 取模，提升了计算效率；\n\n其次，capacity 为 2 的整数次幂的话，为偶数，这样 capacity-1 为奇数，奇数的最后一位是 1，这样便保证了 h&(capacity-1) 的最后一位可能为 0，也可能为 1（这取决于h的值），即与后的结果可能为偶数，也可能为奇数，这样便可以保证散列的均匀性；\n\n而如果 capacity 为奇数的话，很明显 capacity-1 为偶数，它的最后一位是 0，这样 h&(capacity-1) 的最后一位肯定为 0，即只能为偶数，这样任何 hash 值都只会被散列到数组的偶数下标位置上，这便浪费了近一半的空间。\n\n\n#### 1.7HashMap扩容时出现死循环原因及1.8是怎么改进的\n先看下1.7的扩容方法\n```java\n\nvoid transfer(Entry[] newTable, boolean rehash) {\n        int newCapacity = newTable.length;\n　　　　　//for循环中的代码，逐个遍历链表，重新计算索引位置，将老数组数据复制到新数组中去（数组不存储实际数据，所以仅仅是拷贝引用而已）\n        for (Entry<K,V> e : table) {\n            while(null != e) {\n                Entry<K,V> next = e.next;\n                if (rehash) {\n                    e.hash = null == e.key ? 0 : hash(e.key);\n                }\n                int i = indexFor(e.hash, newCapacity);\n　　　　　　　　　 //将当前entry的next链指向新的索引位置,newTable[i]有可能为空，有可能也是个entry链，如果是entry链，直接在链表头部插入。\n                e.next = newTable[i];\n                newTable[i] = e;\n                e = next;\n            }\n        }\n    }\n```\n当thread1执行到`Entry next = e.next;`这一行时，thread2已完成对HashMap的扩容，结果如下图。\n![](死循环1.jpg)\n注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。\nthread1被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。\n![](死循环2.png)\ne.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。\n![](死循环3.png)\n\n根本原因就是**扩容重建时链表中形成了环,导致后续get时在环里打转造成死循环**。\n为什么会形成环?\ntable这个Entry数组是线程共享的,而next,e是线程私有的。现在假设线程1在运行完后挂起了,然后线程2也去做重建并且完成了。线程1恢复运行时entry状态的变化可能已经被刷新到主存了(线程相关的happends-before规则),这样当前entry的状态就和 next,e 期待的不同,就会导致错误的行为。\n\nJDK1.8声明两对指针，维护两个链表依次在末端添加新的元素。（在多线程操作的情况下，无非是第二个线程重复第一个线程一模一样的操作），解决了多线程死循环问题，但仍是非线程安全的，多线程时可能会造成数据丢失问题。\n\n#### 1.8hash的实现吗？为什么要这样实现？\n通过hashCode()的高位与底位进行异或，主要是从速度、功效、质量来考虑的，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。\n\n#### HashMap 中 equals() 和 hashCode() 有什么作用？\nHashMap 的添加、获取时需要通过 key 的 hashCode() 进行 hash()，然后计算下标 ( n-1 & hash)，从而获得要找的同的位置。\n\n当发生冲突（碰撞）时，利用 key.equals() 方法去链表或树中去查找对应的节点。\n\n#### keySet、valueEntry、EntrySet \nHashMap 三个视图返回的迭代器都是 fail-fast 的：如果在迭代时使用非迭代器方法修改了 map 的内容、结构，迭代器就会报 ConcurrentModificationException 的错。\n\n\n### 参考资料\n\n- [迟到一年HashMap解读](https://www.jianshu.com/p/cb1d024bdcc5)\n- [Java 8系列之重新认识HashMap](https://zhuanlan.zhihu.com/p/21673805)\n- [Java 集合深入理解（16）：HashMap 主要特点和关键方法源码解读](https://blog.csdn.net/u011240877/article/details/53351188#4hashmap-%E4%B8%AD%E7%9A%84%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0-hash)\n- [HashMap中keySet()底层调用解析](https://blog.csdn.net/u013370551/article/details/77113154)\n- [Hashmap的结构，1.7和1.8有哪些区别，史上最深入的分析](https://blog.csdn.net/qq_36520235/article/details/82417949)\n- [JDK1.8 不一样的HashMap](https://www.imooc.com/article/71730?block_id=tuijian_wz)","tags":["Java"],"categories":["Java"]},{"title":"ConcurrentMap(1.7和1.8)","url":"/2019/03/25/ConcurrentMap-1-7和1-8/","content":"\n### Unsafe类和内存屏障简介\n不论是在jdk1.7还是jdk1.8版本中ConcurrentHashMap中使用的最为核心也是最为频繁的就是Unsafe类中的各种native本地方法。所以这里有必要先介绍一下其中用的最多的几个Unsafe类中的核心方法。主要的几个方法是Unsafe.putObjectVolatile(obj,long,obj2)、 Unsafe.getObjectVolatile、 Unsafe.putOrderedObject等。\n```c\nvoid sun::misc::Unsafe::putObjectVolatile (jobject obj, jlong offset, jobject value)\n　　{\n　　write_barrier ();\n　　volatile jobject *addr = (jobject *) ((char *) obj + offset);\n　　*addr = value;\n　　}\n\nvoid sun::misc::Unsafe::putObject (jobject obj, jlong offset, jobject value)\n　　{\n　　jobject *addr = (jobject *) ((char *) obj + offset);\n　　*addr = value;\n　　}//用于和putObjectVolatile进行对比\n\njobject sun::misc::Unsafe::getObjectVolatile (jobject obj, jlong offset)\n　　{\n　　volatile jobject *addr = (jobject *) ((char *) obj + offset);\n　　jobject result = *addr;\n　　read_barrier ();\n　　return result;\n　　}\n\nvoid sun::misc::Unsafe::putOrderedObject (jobject obj, jlong offset, jobject value)\n　　{\n　　volatile jobject *addr = (jobject *) ((char *) obj + offset);\n　　*addr = value;\n　　}\n\n```\n在上述Unsafe几个方法的源代码中，可以看到有write_barrier和read_barrier这两个内存屏障，这两个就是对应的硬件中的写屏障和读屏障，java内存模型中使用的所谓的LoadLoad、LoadStore、StoreStore、StoreLoad这几个屏障就是基于这两个屏障实现的。写屏障的作用就是禁止了指令的重排序，并且配合C语言中的volatile关键字（C中的volatile关键字只能保证可见性不能保证有序性），个人理解就是通过添加内存屏障+C中的Volatile实现了类似Java中的Volatile关键字语义，即在putObjectVolatile方法中通过内存屏障保证了有序性，再通过volatile保证将对指定地址的操作是马上写入到共享的主存中而不是线程自身的本地工作内存中，这样配合下面的getObjectVolatile方法，就可以确保每次读取到的就是最新的数据。\n  对于getObjectVolatile而言，可以看到它在返回前加了read_barrier，这个读屏障的作用就是强制去读取主存中的数据而不是线程自己的本地工作内存，这样就确保了读取到的一定是最新的数据。\n  最后就是putOrderedObject，这个方法和putObjectVolatile的区别源码中在于没有加write_barrier，个人理解是这个方法只保证了更新数据的可见性，但是无法保证有序性，因为没有添加屏障可能会导致最终生成的汇编指令被重排序优化，不过在ConcurrentHashMap中使用到这个方法的地方主要是在put方法更新数据的时候用到了，而关于put是加锁了的，所以个人理解的是在依据加锁过的代码区域，用putOrderedObject比putObjectVolatile好在不需要添加屏障，因为只会有一个线程进行操作，从而允许进行指令优化重排序，从而性能会更好。\n\n\n\n### 简介\n　众所周知，哈希表是中非常高效，复杂度为O(1)的数据结构，在Java开发中，我们最常见到最频繁使用的就是HashMap和HashTable，但是在线程竞争激烈的并发场景中使用都不够合理。\n\n　　HashMap ：先说HashMap，HashMap是线程不安全的，在并发环境下，可能会形成环状链表（扩容时可能造成，具体原因自行百度google或查看源码分析），导致get操作时，cpu空转，所以，在并发环境中使用HashMap是非常危险的。\n\n　　HashTable ： HashTable和HashMap的实现原理几乎一样，差别无非是1.HashTable不允许key和value为null；2.HashTable是线程安全的。但是HashTable线程安全的策略实现代价却太大了，简单粗暴，get/put所有相关操作都是synchronized的，这相当于给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。\n\n![](HashTable.png)\nHashTable性能差主要是由于所有操作需要竞争同一把锁\n\n### 原理\n容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这样便可以有效地提高并发效率。这就是ConcurrentHashMap所采用的\"分段锁\"思想。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。\n![](分段锁.png)\n\n### 重要属性\nconcurrencyLevel：并行级别。默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是**不可以扩容的**。\n\ninitialCapacity：初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。\n\nloadFactor：负载因子，之前我们说了，Segment 数组不可以扩容，所以这个负载因子是给每个 Segment 内部使用的。\n\n### JDK1.7\nConcurrentHashMap的读取并发，因为在读取的大多数时候都没有用到锁定，所以读取操作几乎是完全的并发操作，而写操作锁定的粒度又非常细，比起之前又更加快速（这一点在桶更多时表现得更明显些）。只有在求size等操作时才需要锁定整个表。而在迭代时，ConcurrentHashMap使用了不同于传统集合的快速失败迭代器的另一种迭代方式，我们称为弱一致迭代器。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出 ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数据，iterator完成后再将头指针替换为新的数据，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证 了多个线程并发执行的连续性和扩展性，是性能提升的关键。\n\njdk1.7中采用Segment + HashEntry的方式进行实现，结构如下：\n![](1.7数据结构.png)\nConcurrentHashMap初始化时，计算出Segment数组的大小ssize和每个Segment中HashEntry数组的大小cap，并初始化Segment数组的第一个元素；其中ssize大小为2的幂次方，默认为16，cap大小也是2的幂次方，最小值为2，最终结果根据初始化容量initialCapacity进行计算。\n\n#### 源码分析\nConcurrentHashMap的主干是个Segment数组。\n\n```java\n final Segment<K,V>[] segments;\n```\nSegment继承了ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。在ConcurrentHashMap，一个Segment就是一个子哈希表，Segment里维护了一个HashEntry数组，并发环境下，对于不同Segment的数据进行操作是不用考虑锁竞争的。（就按默认的ConcurrentLeve为16来讲，理论上就允许16个线程并发执行）\n\n所以，对于同一个Segment的操作才需考虑线程同步，不同的Segment则无需考虑。\n\nSegment类似于HashMap，一个Segment维护着一个HashEntry数组\n\n```java\n transient volatile HashEntry<K,V>[] table;\n```\nHashEntry是目前我们提到的最小的逻辑处理单元了。一个ConcurrentHashMap维护一个Segment数组，一个Segment维护一个HashEntry数组。\n```java\nstatic final class HashEntry<K,V> {\n        final int hash;\n        final K key;\n        volatile V value;\n        volatile HashEntry<K,V> next;\n        //其他省略\n}    \n```\n我们说Segment类似哈希表，那么一些属性就跟我们之前提到的HashMap差不离，比如负载因子loadFactor，比如阈值threshold等等，看下Segment的构造方法。\n```java\nSegment(float lf, int threshold, HashEntry<K,V>[] tab) {\n            this.loadFactor = lf;//负载因子\n            this.threshold = threshold;//阈值\n            this.table = tab;//主干数组即HashEntry数组\n        }\n\n```\n我们来看下ConcurrentHashMap的构造方法\n```java\npublic ConcurrentHashMap(int initialCapacity,\n                               float loadFactor, int concurrencyLevel) {\n          if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)\n              throw new IllegalArgumentException();\n          //MAX_SEGMENTS 为1<<16=65536，也就是最大并发数为65536\n          if (concurrencyLevel > MAX_SEGMENTS)\n              concurrencyLevel = MAX_SEGMENTS;\n          //2的sshif次方等于ssize，例:ssize=16,sshift=4;ssize=32,sshif=5\n         int sshift = 0;\n         //ssize 为segments数组长度，根据concurrentLevel计算得出\n         int ssize = 1;\n         while (ssize < concurrencyLevel) {\n             ++sshift;\n             ssize <<= 1;\n         }\n        // 用默认值，concurrencyLevel 为 16，sshift 为 4\n        // 那么计算出 segmentShift 为 28，segmentMask 为 15，后面会用到这两个值\n         this.segmentShift = 32 - sshift;\n         this.segmentMask = ssize - 1;\n         if (initialCapacity > MAXIMUM_CAPACITY)\n             initialCapacity = MAXIMUM_CAPACITY;\n         //计算cap的大小，即Segment中HashEntry的数组长度，cap也一定为2的n次方.\n         // // initialCapacity 是设置整个 map 初始的大小，\n         // 这里根据 initialCapacity 计算 Segment 数组中每个位置可以分到的大小\n        // 如 initialCapacity 为 64，那么每个 Segment 或称之为\"槽\"可以分到 4 个\n         int c = initialCapacity / ssize;\n         if (c * ssize < initialCapacity)\n             ++c;\n         //默认 MIN_SEGMENT_TABLE_CAPACITY 是 2，这个值也是有讲究的，因为这样的话，对于具体的槽上，\n         // 插入一个元素不至于扩容，插入第二个的时候才会扩容\n         int cap = MIN_SEGMENT_TABLE_CAPACITY;\n         while (cap < c)\n             cap <<= 1;\n         //创建segments数组并初始化第一个Segment，其余的Segment延迟初始化\n         Segment<K,V> s0 =\n             new Segment<K,V>(loadFactor, (int)(cap * loadFactor),\n                              (HashEntry<K,V>[])new HashEntry[cap]);\n         Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];\n         // 往数组写入 segment[0]\n         UNSAFE.putOrderedObject(ss, SBASE, s0); \n         this.segments = ss;\n     }\n```\n\n初始化方法有三个参数，如果用户不指定则会使用默认值，initialCapacity为16，loadFactor为0.75（负载因子，扩容时需要参考），concurrentLevel为16。\n\n从上面的代码可以看出来,**Segment数组的大小ssize是由concurrentLevel来决定的，但是却不一定等于concurrentLevel，ssize一定是大于或等于concurrentLevel的最小的2的次幂**。比如：默认情况下concurrentLevel是16，则ssize为16；若concurrentLevel为14，ssize为16；若concurrentLevel为17，则ssize为32。为什么Segment的数组大小一定是2的次幂？其实主要是便于通过按位与的散列算法来定位Segment的index。\n\n当我们用 new ConcurrentHashMap() 无参构造函数进行初始化的，那么初始化完成后：\n\n- Segment 数组长度为 16，不可以扩容\n- Segment[i] 的默认大小为 2，负载因子是 0.75，得出初始阈值为 1.5，也就是以后插入第一个元素不会触发扩容，插入第二个会进行第一次扩容\n- 这里初始化了 segment[0]，其他位置还是 null，至于为什么要初始化 segment[0]，后面的代码会介绍\n- 当前 segmentShift 的值为 32 – 4 = 28，segmentMask 为 16 – 1 = 15，姑且把它们简单翻译为移位数和掩码\n\n#### segmentShift和segmentMask\nsegmentShift和segmentMask这两个全局变量的主要作用是用来定位Segment，int j =(hash >>> segmentShift) & segmentMask。\n\n　　segmentMask：段掩码，假如segments数组长度为16，则段掩码为16-1=15；segments长度为32，段掩码为32-1=31。这样得到的所有bit位都为1，可以更好地保证散列的均匀性\n\n　　segmentShift：2的sshift次方等于ssize，segmentShift=32-sshift。若segments长度为16，segmentShift=32-4=28;若segments长度为32，segmentShift=32-5=27。而计算得出的hash值最大为32位，无符号右移segmentShift，则意味着只保留高几位（其余位是没用的），然后与段掩码segmentMask位运算来定位Segment。\n\n\n#### put\nput 的主流程\n```java\npublic V put(K key, V value) {\n    Segment<K,V> s;\n    if (value == null)\n        throw new NullPointerException();\n    // 1. 计算 key 的 hash 值\n    int hash = hash(key);\n    // 2. 根据 hash 值找到 Segment 数组中的位置 j\n    //    hash 是 32 位，无符号右移 segmentShift(28) 位，剩下高 4 位，\n    //    然后和 segmentMask(15) 做一次与操作，也就是说 j 是 hash 值的前 4 位，也就是槽的数组下标\n    int j = (hash >>> segmentShift) & segmentMask;\n    // 刚刚说了，初始化的时候初始化了 segment[0]，但是其他位置还是 null，\n    // ensureSegment(j) 对 segment[j] 进行初始化\n    if ((s = (Segment<K,V>)UNSAFE.getObject          // nonvolatile; recheck\n         (segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment\n        s = ensureSegment(j);\n    // 3. 插入新值到 槽 s 中\n    return s.put(key, hash, value, false);\n}\n```\n　从源码看出，put的主要逻辑也就两步：\n1.定位segment并确保定位的Segment已初始化\n2.调用Segment的put方法。\n\n接下来定位到Segment上的put方法，Segment中的put方法是要加锁的。\n```java\nfinal V put(K key, int hash, V value, boolean onlyIfAbsent) {\n    //先尝试对segment加锁，如果直接加锁成功，那么node=null；如果加锁失败，则会调用scanAndLockForPut方法去获取锁，\n    //在这个方法中，获取锁后会返回对应HashEntry（要么原来就有要么新建一个）\n    HashEntry<K,V> node = tryLock() ? null :\n        scanAndLockForPut(key, hash, value);\n    V oldValue;\n    try {\n        //这里是一个优化点，由于table自身是被volatile修饰的，然而put这一块代码本身是加锁了的，所以同一时间内只会有一个线程操作这部分内容，\n        //所以不再需要对这一块内的变量做任何volatile修饰，因为变量加了volatile修饰后，变量无法进行编译优化等，会对性能有一定的影响\n        //故将table赋值给put方法中的一个局部变量，从而使得能够减少volatile带来的不必要消耗。\n        HashEntry<K,V>[] tab = table;\n        int index = (tab.length - 1) & hash;\n        //这里有一个问题：为什么不直接使用数组下标获取HashEntry，而要用entryAt来获取链表？\n        //这里结合网上内容个人理解是：由于Segment继承的是ReentrantLock，所以它是一个可重入锁，那么是否存在某种场景下，\n        //会导致同一个线程连续两次进入put方法，而由于put最终使用的putOrderedObject只是禁止了写写重排序无法保证内存可见性，\n        //所以这种情况下第二次put在获取链表时必须用entryAt中的volatile语义的get来获取链表，因为这种情况下下标获取的不一定是最新数据。\n        //不过并没有想到哪里会存在这种场景，有谁能想到的或者是我的理解有误请指出！\n        HashEntry<K,V> first = entryAt(tab, index);//先获取需要put的<k,v>对在当前这个segment中对应的链表的表头结点。\n\n        for (HashEntry<K,V> e = first;;) {//开始遍历first为头结点的链表\n            if (e != null) {//<1>\n                //e不为空，说明当前键值对需要存储的位置有hash冲突，直接遍历当前链表，如果链表中找到一个节点对应的key相同，\n                //依据onlyIfAbsent来判断是否覆盖已有的value值。\n                K k;\n                if ((k = e.key) == key ||\n                    (e.hash == hash && key.equals(k))) {\n                    //进入这个条件内说明需要put的<k,y>对应的key节点已经存在，直接判断是否更新并最后break退出循环。\n                    oldValue = e.value;\n                    if (!onlyIfAbsent) {\n                        e.value = value;\n                        ++modCount;\n                    }\n                    break;\n                }\n                e = e.next;//未进入上面的if条件中，说明当前e节点对应的key不是需要的，直接遍历下一个节点。\n            }\n            else {//<2>\n                //进入到这个else分支，说明e为空，对应有两种情况下e可能会为空，即：\n                // 1>. <1>中进行循环遍历，遍历到了链表的表尾仍然没有满足条件的节点。\n                // 2>. e=first一开始就是null（可以理解为即一开始就遍历到了尾节点）\n                if (node != null) //这里有可能获取到锁是通过scanAndLockForPut方法内自旋获取到的，这种情况下依据找好或者说是新建好了对应节点，node不为空\n                    node.setNext(first);\n                else// 当然也有可能是这里直接第一次tryLock就获取到了锁，从而node没有分配对应节点，即需要给依据插入的k,v来创建一个新节点\n                    node = new HashEntry<K,V>(hash, key, value, first);\n                int c = count + 1; //总数+1 在这里依据获取到了锁，即是线程安全的！对应了上述对count变量的使用规范说明。\n                if (c > threshold && tab.length < MAXIMUM_CAPACITY)//判断是否需要进行扩容\n                    //扩容是直接重新new一个新的HashEntry数组，这个数组的容量是老数组的两倍，\n                    //新数组创建好后再依次将老的table中的HashEntry插入新数组中，所以这个过程是十分费时的，应尽量避免。\n                    //扩容完毕后，还会将这个node插入到新的数组中。\n                    rehash(node);\n                else\n                    //数组无需扩容，那么就直接插入node到指定index位置，这个方法里用的是UNSAFE.putOrderedObject\n                    //网上查阅到的资料关于使用这个方法的原因都是说因为它使用的是StoreStore屏障，而不是十分耗时的StoreLoad屏障\n                    //给我个人感觉就是putObjectVolatile是对写入对象的写入赋予了volatile语义，但是代价是用了StoreLoad屏障\n                    //而putOrderedObject则是使用了StoreStore屏障保证了写入顺序的禁止重排序，但是未实现volatile语义导致更新后的不可见性，\n                    //当然这里由于是加锁了，所以在释放锁前会将所有变化从线程自身的工作内存更新到主存中。\n                    //这一块对于putOrderedObject和putObjectVolatile的区别有点混乱，不是完全理解，网上也没找到详细解答，查看了C源码也是不大确定。\n                    //希望有理解的人看到能指点一下，后续如果弄明白了再更新这一块。\n                    setEntryAt(tab, index, node);\n                ++modCount;\n                count = c;\n                oldValue = null;\n                break;\n            }\n        }\n    } finally {\n        unlock();\n    }\n    return oldValue;\n}\n\n```\n**注意：**\n1、setEntryAt()操作以实现对链头的延时写，以提升性能，因为此时并不需要将该更新写入到内存，而在锁退出后该更新自然会写入内存。\n2、如果scanAndLockForPut()操作返回了一个非空HashEntry，则表示在scanAndLockForPut()遍历key对应节点链时没有找到相应的节点。此时很多时候需要创建新的节点，因而它预创建HashEntry节点，所以不需要再创建，只需要更新它的next指针即可，这里使用setNext()实现延时写也时为了提升性能，因为当前修改并不需要让其他线程知道，在锁退出时修改自然会更新到内存中，如果采用直接赋值给next字段，由于next时volatile字段，会引起更新直接写入内存而增加开销。\n\n\n\n接下来，我们说一说其中几步关键的操作。\n1、**初始化槽: ensureSegment**\nConcurrentHashMap 初始化的时候会初始化第一个槽 segment[0]，对于其他槽来说，在插入第一个值的时候进行初始化。\n\n这里需要考虑并发，因为很可能会有多个线程同时进来初始化同一个槽 segment[k]，不过只要有一个成功了就可以。\n```java\nprivate Segment<K,V> ensureSegment(int k) {\n    final Segment<K,V>[] ss = this.segments;\n    long u = (k << SSHIFT) + SBASE; // raw offset\n    Segment<K,V> seg;\n    if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {\n        // 这里看到为什么之前要初始化 segment[0] 了，\n        // 使用当前 segment[0] 处的数组长度和负载因子来初始化 segment[k]\n        // 为什么要用“当前”，因为 segment[0] 可能早就扩容过了\n        Segment<K,V> proto = ss[0];\n        int cap = proto.table.length;\n        float lf = proto.loadFactor;\n        int threshold = (int)(cap * lf);\n \n        // 初始化 segment[k] 内部的数组\n        HashEntry<K,V>[] tab = (HashEntry<K,V>[])new HashEntry[cap];\n        if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))\n            == null) { // 再次检查一遍该槽是否被其他线程初始化了。\n \n            Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);\n            // 使用 while 循环，内部用 CAS，当前线程成功设值或其他线程成功设值后，退出\n            while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))\n                   == null) {\n                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))\n                    break;\n            }\n        }\n    }\n    return seg;\n}\n```\n总的来说，ensureSegment(int k) 比较简单，对于并发操作使用 CAS 进行控制。\n\n2、**获取写入锁: scanAndLockForPut**\n\n当put操作尝试加锁没成功时，它不是直接进入等待状态，而是调用了scanAndLockForPut()操作，该操作持续查找key对应的节点链中是已存在该机节点，如果没有找到已存在的节点，则**预创建一个新节点**，并且尝试n次，直到尝试次数操作限制，才真正进入等待状态，计所谓的自旋等待。**对最大尝试次数，目前的实现单核次数为1，多核为64**。\n\n下面我们来具体分析这个方法中是怎么控制加锁的。\n\n```java\nprivate HashEntry<K,V> scanAndLockForPut(K key, int hash, V value) {\n    HashEntry<K,V> first = entryForHash(this, hash);\n    HashEntry<K,V> e = first;\n    HashEntry<K,V> node = null;\n    int retries = -1; // negative while locating node\n \n    //如果尝试加锁失败，那么就对segment[hash]对应的链表进行遍历找到需要put的这个entry所在的链表中的位置，\n    //这里之所以进行一次遍历找到坑位，主要是为了通过遍历过程将遍历过的entry全部放到CPU高速缓存中，\n    //这样在获取到锁了之后，再次进行定位的时候速度会十分快，这是在线程无法获取到锁前并等待的过程中的一种预热方式。\n    while (!tryLock()) {\n        HashEntry<K,V> f; // to recheck first below\n        if (retries < 0) {\n        \t//e=null代表两种意思，第一种就是遍历链表到了最后，仍然没有发现指定key的entry；\n            //第二种情况是刚开始时确实通过entryForHash找到的HashEntry就是空的，即通过hash找到的table中对应位置链表为空\n            //当然这里之所以还需要对node==null进行判断，是因为有可能在第一次给node赋值完毕后，然后预热准备工作已经搞定，\n            //然后进行循环尝试获取锁，在循环次数还未达到<2>以前，某一次在条件<3>判断时发现有其它线程对这个segment进行了修改，\n        //那么retries被重置为-1，从而再一次进入到<1>条件内，此时如果再次遍历到链表最后时，因为上一次遍历时已经给node赋值过了，\n           //所以这里判断node是否为空，从而避免第二次创建对象给node重复赋值。\n            if (e == null) {\n                if (node == null) // speculatively create node\n                    // 进到这里说明数组该位置的链表是空的，没有任何元素\n                    // 当然，进到这里的另一个原因是 tryLock() 失败，所以该槽存在并发，不一定是该位置\n                    node = new HashEntry<K,V>(hash, key, value, null);\n                retries = 0;\n            }\n            else if (key.equals(e.key))\n                retries = 0;\n            else\n                // 顺着链表往下走\n                e = e.next;\n        }\n        // 重试次数如果超过 MAX_SCAN_RETRIES（单核1多核64），那么不抢了，进入到阻塞队列等待锁\n        //    lock() 是阻塞方法，直到获取锁后返回\n        else if (++retries > MAX_SCAN_RETRIES) {\n        \t// 尝试获取锁次数超过设置的最大值，直接进入阻塞等待，这就是所谓的有限制的自旋获取锁，\n            //之所以这样是因为如果持有锁的线程要过很久才释放锁，这期间如果一直无限制的自旋其实是对系统性能有消耗的，\n            //这样无限制的自旋是不利的，所以加入最大自旋次数，超过这个次数则进入阻塞状态等待对方释放锁并获取锁。\n            lock();\n            break;\n        }\n        else if ((retries & 1) == 0 &&\n                 // 这个时候是有大问题了，那就是有新的元素进到了链表，成为了新的表头\n                 //     所以这边的策略是，相当于重新走一遍这个 scanAndLockForPut 方法\n                 (f = entryForHash(this, hash)) != first) {\n            e = first = f; // re-traverse if entry changed\n            retries = -1;\n        }\n    }\n    return node;\n}\n```\n这个方法有两个出口，一个是 tryLock() 成功了，循环终止，另一个就是重试次数超过了 MAX_SCAN_RETRIES，进到 lock() 方法，此方法会阻塞等待，直到成功拿到独占锁。\n\n在这段逻辑中，它先获取key对应的节点链的头，然后持续遍历该链，如果节点链中不存在要插入的节点，则预创建一个节点，否则retries值自增，直到操作最大尝试次数而进入等待状态。这里需要注意最后一个else if中的逻辑：当在自旋过程中发现节点链的链头发生了变化，则更新节点链的链头，并重置retries值为－1，重新为尝试获取锁而自旋遍历。\n\n#### 扩容\n**segment 数组不能扩容**，扩容是 segment 数组某个位置内部的数组 HashEntry[] 进行扩容，扩容后，容量为原来的 2 倍。\n首先，我们要回顾一下触发扩容的地方，put 的时候，如果判断该值的插入会导致该 segment 的元素个数超过阈值，那么**先进行扩容，再插值**。\n```java\n/**\n * Doubles size of table and repacks entries, also adding the\n * given node to new table\n * 对数组进行扩容，由于扩容过程需要将老的链表中的节点适用到新数组中，所以为了优化效率，可以对已有链表进行遍历，\n * 对于老的oldTable中的每个HashEntry，从头结点开始遍历，找到第一个后续所有节点在新table中index保持不变的节点fv，\n * 假设这个节点新的index为newIndex，那么直接newTable[newIndex]=fv，即可以直接将这个节点以及它后续的链表中内容全部直接复用copy到newTable中\n * 这样最好的情况是所有oldTable中对应头结点后跟随的节点在newTable中的新的index均和头结点一致，那么就不需要创建新节点，直接复用即可。\n * 最坏情况当然就是所有节点的新的index全部发生了变化，那么就全部需要重新依据k,v创建新对象插入到newTable中。\n*/\nprivate void rehash(HashEntry<K,V> node) {\n    HashEntry<K,V>[] oldTable = table;\n    int oldCapacity = oldTable.length;\n    // 2 倍\n    int newCapacity = oldCapacity << 1;\n    threshold = (int)(newCapacity * loadFactor);\n    // 创建新数组\n    HashEntry<K,V>[] newTable =\n        (HashEntry<K,V>[]) new HashEntry[newCapacity];\n    // 新的掩码，如从 16 扩容到 32，那么 sizeMask 为 31，对应二进制 ‘000...00011111’\n    int sizeMask = newCapacity - 1;\n \n    // 遍历原数组，老套路，将原数组位置 i 处的链表拆分到 新数组位置 i 和 i+oldCap 两个位置\n    for (int i = 0; i < oldCapacity ; i++) {\n        // e 是链表的第一个元素\n        HashEntry<K,V> e = oldTable[i];\n        if (e != null) {\n            HashEntry<K,V> next = e.next;\n            // 计算应该放置在新数组中的位置，\n            // 假设原数组长度为 16，e 在 oldTable[3] 处，那么 idx 只可能是 3 或者是 3 + 16 = 19\n            int idx = e.hash & sizeMask;\n            if (next == null)   // 该位置处只有一个元素，那比较好办\n                newTable[idx] = e;\n            else { // Reuse consecutive sequence at same slot\n                // e 是链表表头\n                HashEntry<K,V> lastRun = e;\n                // idx 是当前链表的头结点 e 的新位置\n                int lastIdx = idx;\n \n                // 下面这个 for 循环会找到一个 lastRun 节点，这个节点之后的所有元素是将要放到一起的\n                for (HashEntry<K,V> last = next;\n                     last != null;\n                     last = last.next) {\n                    int k = last.hash & sizeMask;\n                    if (k != lastIdx) {\n                        lastIdx = k;\n                        lastRun = last;\n                    }\n                }\n                // 将 lastRun 及其之后的所有节点组成的这个链表放到 lastIdx 这个位置\n                newTable[lastIdx] = lastRun;\n                // 下面的操作是处理 lastRun 之前的节点，\n                //    这些节点可能分配在另一个链表中，也可能分配到上面的那个链表中\n                for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {\n                    V v = p.value;\n                    int h = p.hash;\n                    int k = h & sizeMask;\n                    HashEntry<K,V> n = newTable[k];\n                    newTable[k] = new HashEntry<K,V>(h, p.key, v, n);\n                }\n            }\n        }\n    }\n    // 将新来的 node 放到新数组中刚刚的 两个链表之一 的 头部\n    int nodeIndex = node.hash & sizeMask; // add the new node\n    node.setNext(newTable[nodeIndex]);\n    newTable[nodeIndex] = node;\n    table = newTable;\n}\n```\n它创建一个大原来两倍容量的数组，然后遍历原来数组以及数组项中的每条链，对每个节点重新计算它的数组索引，然后创建一个新的节点插入到新数组中，这里需要重新创建一个新节点而不是修改原有节点的next指针是为了在做rehash时可以保证其他线程的get遍历操作可以正常在原有的链上正常工作，有点copy-on-write思想。\n\n然而Doug Lea继续优化了这段逻辑，为了减少重新创建新节点的开销，这里做了两点优化：1，对只有一个节点的链，直接将该节点赋值给新数组对应项即可（之所以能这么做是因为Segment中数组的长度也永远是2的倍数，而将数组长度扩大成原来的2倍，那么新节点在新数组中的位置只能是相同的索引号或者原来索引号加原来数组的长度，因而可以保证每条链在rehash是不会相互干扰）；2，对有多个节点的链，先遍历该链找到第一个后面所有节点的索引值不变的节点p，然后只重新创建节点p以前的节点即可，此时新节点链和旧节点链同时存在，在p节点相遇，这样即使有其他线程在当前链做遍历也能正常工作。\n\n#### get\n```java\npublic V get(Object key) {\n    Segment<K,V> s; // manually integrate access methods to reduce overhead\n    HashEntry<K,V>[] tab;\n    int h = hash(key);//获取key对应hash值\n    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;//获取对应h值存储所在segments数组中内存偏移量\n    if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&\n        (tab = s.table) != null) {\n        //通过Unsafe中的getObjectVolatile方法进行volatile语义的读，获取到segments在偏移量为u位置的分段Segment，\n        //并且分段Segment中对应table数组不为空\n        for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile\n                 (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);\n             e != null; e = e.next) {//获取h对应这个分段中偏移量为xxx下的HashEntry的链表头结点，然后对链表进行 遍历\n            //###这里第一次初始化通过getObjectVolatile获取HashEntry时，获取到的是主存中最新的数据，但是在后续遍历过程中，有可能数据被其它线程修改\n            //从而导致其实这里最终返回的可能是过时的数据，所以这里就是ConcurrentHashMap所谓的弱一致性的体现，containsKey方法也一样！！！！\n            K k;\n            if ((k = e.key) == key || (e.hash == h && key.equals(k)))\n                return e.value;\n        }\n    }\n    return null;\n}\n\n```\n这个方法是弱一致性的，所以有可能会获取到过时的数据，如果业务场景要求获取数据的强一致性，不建议用这个。\n\nget 的时候在同一个 segment 中发生了 put 或 remove 操作。\n> - put 操作的线程安全性。\n初始化槽，这个我们之前就说过了，使用了 CAS 来初始化 Segment 中的数组。\n添加节点到链表的操作是插入到表头的，所以，如果这个时候 get 操作在链表遍历的过程已经到了中间，是不会影响的。\n\n当然，另一个并发问题就是 get 操作在 put 之后，需要保证刚刚插入表头的节点被读取，这个依赖于 setEntryAt 方法中使用的 UNSAFE.putOrderedObject。\n\n扩容。扩容是新创建了数组，然后进行迁移数据，最后面将 newTable 设置给属性 table。所以，如果 get 操作此时也在进行，那么也没关系，如果 get 先行，那么就是在旧的 table 上做查询操作；而 put 先行，那么 put 操作的可见性保证就是 table 使用了 volatile 关键字。\n\n> - remove 操作的线程安全性。\n如果 remove 先破坏了一个节点，分两种情况考虑。 1、如果此节点是头结点，那么需要将头结点的 next 设置为数组该位置的元素，table 虽然使用了 volatile 修饰，但是 volatile 并不能提供数组内部操作的可见性保证，所以源码中使用了 UNSAFE 来操作数组，请看方法 setEntryAt。2、如果要删除的节点不是头结点，它会将要删除节点的后继节点接到前驱节点中，这里的并发保证就是 next 属性是 volatile 的。\n\n#### remove\n```java\n/** \n         * Remove; match on key only if value null, else match both. \n         */  \n        final V remove(Object key, int hash, Object value) {  \n            if (!tryLock())  \n                scanAndLock(key, hash);  \n            V oldValue = null;  \n            try {  \n                HashEntry<K,V>[] tab = table;  \n                int index = (tab.length - 1) & hash;  \n                HashEntry<K,V> e = entryAt(tab, index);  \n                HashEntry<K,V> pred = null;  \n                while (e != null) {  \n                    K k;  \n                    HashEntry<K,V> next = e.next;  \n                    if ((k = e.key) == key ||  \n                        (e.hash == hash && key.equals(k))) {  \n                        V v = e.value;  \n                        if (value == null || value == v || value.equals(v)) {  \n                            if (pred == null)  \n                                setEntryAt(tab, index, next);  \n                            else  \n                                pred.setNext(next);  \n                            ++modCount;  \n                            --count;  \n                            oldValue = v;  \n                        }  \n                        break;  \n                    }  \n                    pred = e;  \n                    e = next;  \n                }  \n            } finally {  \n                unlock();  \n            }  \n            return oldValue;  \n        }\n```\n在JDK 1.6版本中，remove操作比较直观，它先找到key对应的节点链的链头（数组中的某个项），然后遍历该节点链，如果在节点链中找到key相等的节点，则为该节点之前的所有节点重新创建节点并组成一条新链，将该新链的链尾指向找到节点的下一个节点。这样如前面rehash提到的，同时有两条链存在，即使有另一个线程正在该链上遍历也不会出问题。\n\n然而Doug Lea又挖掘到了新的优化点，在1.7中，他不再重新创建一条新的链，而是只在当起缓存中将链中找到的节点移除。当移除的是链头则更新数组项的值，否则更新找到节点的前一个节点的next指针。这也是HashEntry中next指针没有设置成final的原因。当然remove操作如果第一次尝试获得锁失败也会如put操作一样先进入自旋状态，这里的scanAndLock和scanAndLockForPut类似，只是它不做预创建节点的步骤。\n\n\n#### size实现\n因为ConcurrentHashMap是可以并发插入数据的，所以在准确计算元素时存在一定的难度，一般的思路是统计每个Segment对象中的元素个数，然后进行累加，但是这种方式计算出来的结果并不一样的准确的，因为在计算后面几个Segment的元素个数时，已经计算过的Segment同时可能有数据的插入或则删除，在1.7的实现中，采用了如下方式：\n```java\n/**\n * 默认自旋次数，超过这个次数直接加锁，防止在size方法中由于不停有线程在更新map\n * 导致无限的进行自旋影响性能，当然这种会导致ConcurrentHashMap使用了这一规则的方法\n * 如size、clear是弱一致性的。\n */\nstatic final int RETRIES_BEFORE_LOCK = 2;\n\ntry {\n\t//无限for循环，结束条件就是任意前后两次遍历过程中modcount值的和是一样的，说明第二次遍历没有做任何变化\n    //这里就是前面介绍的为了防止由于有线程不断在更新map而导致每次遍历过程一直发现modCount和上一次不一样\n    //从而导致线程一直进行遍历验证前后两次modCount，为了防止这种情况发生，加了一个最多重复的次数限制，\n    //超过这个次数则直接强制对所有的segment进行加锁，不过这里需要注意如果出现这种情况，会导致本来要延迟创建的所有segment\n    //均在这个过程中被创建\n    for (;;) {\n        if (retries++ == RETRIES_BEFORE_LOCK) {\n            for (int j = 0; j < segments.length; ++j)\n                ensureSegment(j).lock(); // force creation\n        }\n        sum = 0L;\n        size = 0;\n        overflow = false;\n        for (int j = 0; j < segments.length; ++j) {\n            Segment<K,V> seg = segmentAt(segments, j);\n            if (seg != null) {\n                sum += seg.modCount;\n                int c = seg.count;\n                if (c < 0 || (size += c) < 0)\n                    overflow = true;\n            }\n        }\n        if (sum == last)\n            break;\n        last = sum;\n    }\n} finally {\n\t //由于只有在retries等于RETRIES_BEFORE_LOCK时才会执行强制加锁，并且由于是用的retries++，\n        //所以强制加锁完毕后，retries的值是一定会大于RETRIES_BEFORE_LOCK的，\n        //这样就防止正常遍历而没进行加锁时进行锁释放的情况\n    if (retries > RETRIES_BEFORE_LOCK) {\n        for (int j = 0; j < segments.length; ++j)\n            segmentAt(segments, j).unlock();\n    }\n}\n```\n\n先采用不加锁的方式，连续计算元素的个数，最多计算3次：\n1、如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；\n2、如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数；\n\n### 1.8\n1.8中放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，结构如下：\n![](1.8数据结构.png)\n\n#### 原理\n　在ConcurrentHashMap中通过一个Node<K,V>[]数组来保存添加到map中的键值对，而在同一个数组位置是通过链表和红黑树的形式来保存的。但是这个数组只有在第一次添加元素的时候才会初始化，否则只是初始化一个ConcurrentHashMap对象的话，只是设定了一个sizeCtl变量，这个变量用来判断对象的一些状态和是否需要扩容。\n\n   第一次添加元素的时候，默认初期长度为16，当往map中继续添加元素的时候，通过hash值跟数组长度取与来决定放在数组的哪个位置，如果出现放在同一个位置的时候，优先以链表的形式存放，在同一个位置的个数又达到了8个以上，如果数组的长度还小于64的时候，则会扩容数组。如果数组的长度大于等于64了的话，在会将该节点的链表转换成树。\n\n　　通过扩容数组的方式来把这些节点给分散开。然后将这些元素复制到扩容后的新的数组中，同一个链表中的元素通过hash值的数组长度位来区分，是还是放在原来的位置还是放到扩容的长度的相同位置去 。在扩容完成之后，如果某个节点的是树，同时现在该节点的个数又小于等于6个了，则会将该树转为链表。\n![](树转换1.png)\n这个时候因为数组的长度才为16，则不会转化为树，而是会进行扩容。扩容后数组大概是这样的：\n![](树转换2.png)\n如果数组扩张后长度达到64了，且继续在某个节点的后面添加元素达到8个以上的时候，则会出现转化为红黑树的情况。转化之后大概是这样：\n![](树转换3.png)\n\n#### 初始化\n```java\nprivate static final int MAXIMUM_CAPACITY = 1 << 30;\nprivate static final int DEFAULT_CAPACITY = 16;\nstatic final int TREEIFY_THRESHOLD = 8;\nstatic final int UNTREEIFY_THRESHOLD = 6;\nstatic final int MIN_TREEIFY_CAPACITY = 64;\nstatic final int MOVED     = -1; // 表示正在转移\nstatic final int TREEBIN   = -2; // 表示已经转换成树\nstatic final int RESERVED  = -3; // hash for transient reservations\nstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash\ntransient volatile Node<K,V>[] table;//默认没初始化的数组，用来保存元素\nprivate transient volatile Node<K,V>[] nextTable;//转移的时候用的数组\n/**\n     * 用来控制表初始化和扩容的，默认值为0，当在初始化的时候指定了大小，这会将这个大小保存在sizeCtl中，大小为数组的0.75\n     * 当为负的时候，说明表正在初始化或扩张，\n     *     -1表示初始化\n     *     -(1+n) n:表示活动的扩张线程\n     */\n    private transient volatile int sizeCtl;\npublic ConcurrentHashMap(int initialCapacity) {\n    if (initialCapacity < 0)\n        throw new IllegalArgumentException();\n    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?\n               MAXIMUM_CAPACITY :\n               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));\n    this.sizeCtl = cap;\n}\n```\n通过提供初始容量，计算了 sizeCtl，sizeCtl = 【 (1.5 * initialCapacity + 1)，然后向上取最近的 2 的 n 次方】。如 initialCapacity 为 10，那么得到 sizeCtl 为 16，如果 initialCapacity 为 11，得到 sizeCtl 为 32。\n在任何一个构造方法中，都没有对存储Map元素Node的table变量进行初始化。而是在第一次put操作的时候在进行初始化。\n\n#### put\n```java\n/*\n     *    单纯的额调用putVal方法，并且putVal的第三个参数设置为false\n     *  当设置为false的时候表示这个value一定会设置\n     *  true的时候，只有当这个key的value为空的时候才会设置\n     */\n    public V put(K key, V value) {\n        return putVal(key, value, false);\n    }\n\n    /*\n     * 当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了，\n     * 如果没有的话就初始化数组\n     *  然后通过计算hash值来确定放在数组的哪个位置\n     * 如果这个位置为空则直接添加，如果不为空的话，则取出这个节点来\n     * 如果取出来的节点的hash值是MOVED(-1)的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制\n     * 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来加锁，进行添加操作\n     *    然后判断当前取出的节点位置存放的是链表还是树\n     *    如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话，\n     *          则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾\n     *    如果是树的话，则调用putTreeVal方法把这个元素添加到树中去\n     *  最后在添加完成之后，会判断在该节点处共有多少个节点（注意是添加前的个数），如果达到8个以上了的话，\n     *  则调用treeifyBin方法来尝试将处的链表转为树，或者扩容数组\n     */\n    final V putVal(K key, V value, boolean onlyIfAbsent) {\n        if (key == null || value == null) throw new NullPointerException();//K,V都不能为空，否则的话跑出异常\n        int hash = spread(key.hashCode());    //取得key的hash值\n        int binCount = 0;    //用来计算在这个节点总共有多少个元素，用来控制扩容或者转移为树\n        for (Node<K,V>[] tab = table;;) {    //\n            Node<K,V> f; int n, i, fh;\n            if (tab == null || (n = tab.length) == 0)    \n                tab = initTable();    //第一次put的时候table没有初始化，则初始化table\n            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {    //通过哈希计算出一个表中的位置因为n是数组的长度，所以(n-1)&hash肯定不会出现数组越界\n                if (casTabAt(tab, i, null,        //如果这个位置没有元素的话，则通过cas的方式尝试添加，注意这个时候是没有加锁的\n                             new Node<K,V>(hash, key, value, null)))        //创建一个Node添加到数组中区，null表示的是下一个节点为空\n                    break;                   // no lock when adding to empty bin\n            }\n            /*\n             * 如果检测到某个节点的hash值是MOVED，则表示正在进行数组扩张的数据复制阶段，\n             * 则当前线程也会参与去复制，通过允许多线程复制的功能，一次来减少数组的复制所带来的性能损失\n             */\n            else if ((fh = f.hash) == MOVED)    \n                tab = helpTransfer(tab, f);\n            else {\n                /*\n                 * 如果在这个位置有元素的话，就采用synchronized的方式加锁，\n                 *     如果是链表的话(hash大于0)，就对这个链表的所有元素进行遍历，\n                 *         如果找到了key和key的hash值都一样的节点，则把它的值替换到\n                 *         如果没找到的话，则添加在链表的最后面\n                 *  否则，是树的话，则调用putTreeVal方法添加到树中去\n                 *  \n                 *  在添加完之后，会对该节点上关联的的数目进行判断，\n                 *  如果在8个以上的话，则会调用treeifyBin方法，来尝试转化为树，或者是扩容\n                 */\n                V oldVal = null;\n                synchronized (f) {\n                    if (tabAt(tab, i) == f) {        //再次取出要存储的位置的元素，跟前面取出来的比较\n                        if (fh >= 0) {                //取出来的元素的hash值大于0，当转换为树之后，hash值为-2\n                            binCount = 1;            \n                            for (Node<K,V> e = f;; ++binCount) {    //遍历这个链表\n                                K ek;\n                                if (e.hash == hash &&        //要存的元素的hash，key跟要存储的位置的节点的相同的时候，替换掉该节点的value即可\n                                    ((ek = e.key) == key ||\n                                     (ek != null && key.equals(ek)))) {\n                                    oldVal = e.val;\n                                    if (!onlyIfAbsent)        //当使用putIfAbsent的时候，只有在这个key没有设置值得时候才设置\n                                        e.val = value;\n                                    break;\n                                }\n                                Node<K,V> pred = e;\n                                if ((e = e.next) == null) {    //如果不是同样的hash，同样的key的时候，则判断该节点的下一个节点是否为空，\n                                    pred.next = new Node<K,V>(hash, key,        //为空的话把这个要加入的节点设置为当前节点的下一个节点\n                                                              value, null);\n                                    break;\n                                }\n                            }\n                        }\n                        else if (f instanceof TreeBin) {    //表示已经转化成红黑树类型了\n                            Node<K,V> p;\n                            binCount = 2;\n                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,    //调用putTreeVal方法，将该元素添加到树中去\n                                                           value)) != null) {\n                                oldVal = p.val;\n                                if (!onlyIfAbsent)\n                                    p.val = value;\n                            }\n                        }\n                    }\n                }\n                if (binCount != 0) {\n                    if (binCount >= TREEIFY_THRESHOLD)    //当在同一个节点的数目达到8个的时候，则扩张数组或将给节点的数据转为tree\n                        treeifyBin(tab, i);    \n                    if (oldVal != null)\n                        return oldVal;\n                    break;\n                }\n            }\n        }\n        addCount(1L, binCount);    //计数\n        return null;\n    }\n```\n\n只有在执行第一次put方法时才会调用initTable()初始化Node数组，实现如下：\n```java\n/**\n     * 初始化数组table，\n     * 如果sizeCtl小于0，说明别的数组正在进行初始化，则让出执行权\n     * 如果sizeCtl大于0的话，则初始化一个大小为sizeCtl的数组\n     * 否则的话初始化一个默认大小(16)的数组\n     * 然后设置sizeCtl的值为数组长度的3/4\n     */\n    private final Node<K,V>[] initTable() {\n        Node<K,V>[] tab; int sc;\n        while ((tab = table) == null || tab.length == 0) {    //第一次put的时候，table还没被初始化，进入while\n            if ((sc = sizeCtl) < 0)                            //sizeCtl初始值为0，当小于0的时候表示在别的线程在初始化表或扩展表\n                Thread.yield(); // lost initialization race; just spin\n            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {    //SIZECTL：表示当前对象的内存偏移量，sc表示期望值，-1表示要替换的值，设定为-1表示要初始化表了\n                try {\n                    if ((tab = table) == null || tab.length == 0) {\n                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;        //指定了大小的时候就创建指定大小的Node数组，否则创建指定大小(16)的Node数组\n                        @SuppressWarnings(\"unchecked\")\n                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];\n                        table = tab = nt;\n                        sc = n - (n >>> 2);\n                    }\n                } finally {\n                    sizeCtl = sc;            //初始化后，sizeCtl长度为数组长度的3/4\n                }\n                break;\n            }\n        }\n        return tab;\n    }\n```\n#### 扩容\n我们可以看到，在同一个节点的个数超过8个的时候，会调用treeifyBin方法来看看是扩容还是转化为一棵树，同时在每次添加完元素的addCount方法中，也会判断当前数组中的元素是否达到了sizeCtl的量，如果达到了的话，则会进入transfer方法去扩容。\n```java\n/**\n     * Replaces all linked nodes in bin at given index unless table is\n     * too small, in which case resizes instead.\n     * 当数组长度小于64的时候，扩张数组长度一倍，否则的话把链表转为树\n     */\n    private final void treeifyBin(Node<K,V>[] tab, int index) {\n        Node<K,V> b; int n, sc;\n        if (tab != null) {\n                System.out.println(\"treeifyBin方\\t==>数组长：\"+tab.length);\n            if ((n = tab.length) < MIN_TREEIFY_CAPACITY)    //MIN_TREEIFY_CAPACITY 64\n                tryPresize(n << 1);        // 数组扩容\n            else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {\n                synchronized (b) {    //使用synchronized同步器，将该节点出的链表转为树\n                    if (tabAt(tab, index) == b) {\n                        TreeNode<K,V> hd = null, tl = null;    //hd：树的头(head)\n                        for (Node<K,V> e = b; e != null; e = e.next) {\n                            TreeNode<K,V> p =\n                                new TreeNode<K,V>(e.hash, e.key, e.val,\n                                                  null, null);\n                            if ((p.prev = tl) == null)        //把Node组成的链表，转化为TreeNode的链表，头结点任然放在相同的位置\n                                hd = p;    //设置head\n                            else\n                                tl.next = p;\n                            tl = p;\n                        }\n                        setTabAt(tab, index, new TreeBin<K,V>(hd));//把TreeNode的链表放入容器TreeBin中\n                    }\n                }\n            }\n        }\n    }\n```\n用链表头部的TreeNode来构造一个TreeBin，在TreeBin容器中，将链表转化为红黑树。\n```java\nTreeBin(TreeNode<K,V> b) {\n            super(TREEBIN, null, null, null);    //创建的TreeBin是一个空节点，hash值为TREEBIN（-2）\n            this.first = b;\n            TreeNode<K,V> r = null;\n            for (TreeNode<K,V> x = b, next; x != null; x = next) {\n                next = (TreeNode<K,V>)x.next;\n                x.left = x.right = null;\n                if (r == null) {\n                    x.parent = null;\n                    x.red = false;\n                    r = x;\n                }//\n                else {\n                    K k = x.key;\n                    int h = x.hash;\n                    Class<?> kc = null;\n                    for (TreeNode<K,V> p = r;;) {//x代表的是转换为树之前的顺序遍历到链表的位置的节点，r代表的是根节点\n                        int dir, ph;\n                        K pk = p.key;\n                        if ((ph = p.hash) > h)    //\n                            dir = -1;\n                        else if (ph < h)\n                            dir = 1;\n                        else if ((kc == null &&\n                                  (kc = comparableClassFor(k)) == null) ||\n                                 (dir = compareComparables(kc, k, pk)) == 0)\n                            dir = tieBreakOrder(k, pk);    //当key不可以比较，或者相等的时候采取的一种排序措施\n                            TreeNode<K,V> xp = p;\n                        if ((p = (dir <= 0) ? p.left : p.right) == null) {//在这里判断要放的left/right是否为空，不为空继续用left/right节点来判断\n                            x.parent = xp;\n                            if (dir <= 0)\n                                xp.left = x;\n                            else\n                                xp.right = x;\n                            r = balanceInsertion(r, x); //每次插入一个元素的时候都调用balanceInsertion来保持红黑树的平衡\n                            break;\n                        }\n                    }\n                }\n            }\n            this.root = r;\n            assert checkInvariants(root);\n        }\n```\n\n可以看到当需要扩容的时候，调用的时候tryPresize方法，看看trePresize的源码\n```java\n/**\n     * 扩容表为指可以容纳指定个数的大小（总是2的N次方）\n     * 假设原来的数组长度为16，则在调用tryPresize的时候，size参数的值为16<<1(32)，此时sizeCtl的值为12\n     * 计算出来c的值为64,则要扩容到sizeCtl≥为止\n     *  第一次扩容之后 数组长：32 sizeCtl：24\n     *  第二次扩容之后 数组长：64 sizeCtl：48\n     *  第二次扩容之后 数组长：128 sizeCtl：94 --> 这个时候才会退出扩容\n     */\n    private final void tryPresize(int size) {\n            /*\n             * MAXIMUM_CAPACITY = 1 << 30\n             * 如果给定的大小大于等于数组容量的一半，则直接使用最大容量，\n             * 否则使用tableSizeFor算出来\n             * 后面table一直要扩容到这个值小于等于sizeCtrl(数组长度的3/4)才退出扩容\n             */\n        int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY :\n            tableSizeFor(size + (size >>> 1) + 1);\n        int sc;\n        while ((sc = sizeCtl) >= 0) {\n            Node<K,V>[] tab = table; int n;\n//            printTable(tab);    调试用的\n            /*\n             * 如果数组table还没有被初始化，则初始化一个大小为sizeCtrl和刚刚算出来的c中较大的一个大小的数组\n             * 初始化的时候，设置sizeCtrl为-1，初始化完成之后把sizeCtrl设置为数组长度的3/4\n             * 为什么要在扩张的地方来初始化数组呢？这是因为如果第一次put的时候不是put单个元素，\n             * 而是调用putAll方法直接put一个map的话，在putALl方法中没有调用initTable方法去初始化table，\n             * 而是直接调用了tryPresize方法，所以这里需要做一个是不是需要初始化table的判断\n             */\n            if (tab == null || (n = tab.length) == 0) {\n                n = (sc > c) ? sc : c;\n                if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {    //初始化tab的时候，把sizeCtl设为-1\n                    try {\n                        if (table == tab) {\n                            @SuppressWarnings(\"unchecked\")\n                            Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];\n                            table = nt;\n                            sc = n - (n >>> 2);\n                        }\n                    } finally {\n                        sizeCtl = sc;\n                    }\n                }\n            }\n            /*\n             * 一直扩容到的c小于等于sizeCtl或者数组长度大于最大长度的时候，则退出\n             * 所以在一次扩容之后，不是原来长度的两倍，而是2的n次方倍\n             */\n            else if (c <= sc || n >= MAXIMUM_CAPACITY) {\n                    break;    //退出扩张\n            }\n            else if (tab == table) {\n                int rs = resizeStamp(n);\n                /*\n                 * 如果正在扩容Table的话，则帮助扩容\n                 * 否则的话，开始新的扩容\n                 * 在transfer操作，将第一个参数的table中的元素，移动到第二个元素的table中去，\n                 * 虽然此时第二个参数设置的是null，但是，在transfer方法中，当第二个参数为null的时候，\n                 * 会创建一个两倍大小的table\n                 */\n                if (sc < 0) {\n                    Node<K,V>[] nt;\n                    if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                        sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||\n                        transferIndex <= 0)\n                        break;\n                    /*\n                     * transfer的线程数加一,该线程将进行transfer的帮忙\n                     * 在transfer的时候，sc表示在transfer工作的线程数\n                     */\n                    if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))\n                        transfer(tab, nt);\n                }\n                /*\n                 * 没有在初始化或扩容，则开始扩容\n                 */\n                else if (U.compareAndSwapInt(this, SIZECTL, sc,\n                                             (rs << RESIZE_STAMP_SHIFT) + 2)) {\n                        transfer(tab, null);\n                }\n            }\n        }\n    }\n```\n在tryPresize方法中，并没有加锁，允许多个线程进入，如果数组正在扩张，则当前线程也去帮助扩容。数组扩容的主要方法就是transfer方法。\n```java\n/**\n     * Moves and/or copies the nodes in each bin to new table. See\n     * above for explanation.\n     * 把数组中的节点复制到新的数组的相同位置，或者移动到扩张部分的相同位置\n     * 在这里首先会计算一个步长，表示一个线程处理的数组长度，用来控制对CPU的使用，\n     * 每个CPU最少处理16个长度的数组元素,也就是说，如果一个数组的长度只有16，那只有一个线程会对其进行扩容的复制移动操作\n     * 扩容的时候会一直遍历，知道复制完所有节点，没处理一个节点的时候会在链表的头部设置一个fwd节点，这样其他线程就会跳过他，\n     * 复制后在新数组中的链表不是绝对的反序的\n     */\n    private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {\n        int n = tab.length, stride;\n        if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)    //MIN_TRANSFER_STRIDE 用来控制不要占用太多CPU\n            stride = MIN_TRANSFER_STRIDE; // subdivide range    //MIN_TRANSFER_STRIDE=16\n        /*\n         * 如果复制的目标nextTab为null的话，则初始化一个table两倍长的nextTab\n         * 此时nextTable被设置值了(在初始情况下是为null的)\n         * 因为如果有一个线程开始了表的扩张的时候，其他线程也会进来帮忙扩张，\n         * 而只是第一个开始扩张的线程需要初始化下目标数组\n         */\n        if (nextTab == null) {            // initiating\n            try {\n                @SuppressWarnings(\"unchecked\")\n                Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];\n                nextTab = nt;\n            } catch (Throwable ex) {      // try to cope with OOME\n                sizeCtl = Integer.MAX_VALUE;\n                return;\n            }\n            nextTable = nextTab;\n            transferIndex = n;\n        }\n        int nextn = nextTab.length;\n        /*\n         * 创建一个fwd节点，这个是用来控制并发的，当一个节点为空或已经被转移之后，就设置为fwd节点\n         * 这是一个空的标志节点\n         */\n        ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);\n        boolean advance = true;    //是否继续向前查找的标志位\n        boolean finishing = false; // to ensure sweep(清扫) before committing nextTab,在完成之前重新在扫描一遍数组，看看有没完成的没\n        for (int i = 0, bound = 0;;) {\n            Node<K,V> f; int fh;\n            while (advance) {\n                int nextIndex, nextBound;\n                if (--i >= bound || finishing) {\n                    advance = false;\n                }\n                else if ((nextIndex = transferIndex) <= 0) {\n                    i = -1;\n                    advance = false;\n                }\n                else if (U.compareAndSwapInt\n                         (this, TRANSFERINDEX, nextIndex,\n                          nextBound = (nextIndex > stride ?\n                                       nextIndex - stride : 0))) {\n                    bound = nextBound;\n                    i = nextIndex - 1;\n                    advance = false;\n                }\n            }\n            if (i < 0 || i >= n || i + n >= nextn) {\n                int sc;\n                if (finishing) {        //已经完成转移\n                    nextTable = null;\n                    table = nextTab;\n                    sizeCtl = (n << 1) - (n >>> 1);    //设置sizeCtl为扩容后的0.75\n                    return;\n                }\n                if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {\n                    if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT) {\n                            return;\n                    }\n                    finishing = advance = true;\n                    i = n; // recheck before commit\n                }\n            }\n            else if ((f = tabAt(tab, i)) == null)            //数组中把null的元素设置为ForwardingNode节点(hash值为MOVED[-1])\n                advance = casTabAt(tab, i, null, fwd);\n            else if ((fh = f.hash) == MOVED)\n                advance = true; // already processed\n            else {\n                synchronized (f) {                //加锁操作\n                    if (tabAt(tab, i) == f) {\n                        Node<K,V> ln, hn;\n                        if (fh >= 0) {        //该节点的hash值大于等于0，说明是一个Node节点\n                                /*\n                                 * 因为n的值为数组的长度，且是power(2,x)的，所以，在&操作的结果只可能是0或者n\n                                 * 根据这个规则\n                                 *         0-->  放在新表的相同位置\n                                 *         n-->  放在新表的（n+原来位置）\n                                 */\n                            int runBit = fh & n; \n                            Node<K,V> lastRun = f;\n                            /*\n                             * lastRun 表示的是需要复制的最后一个节点\n                             * 每当新节点的hash&n -> b 发生变化的时候，就把runBit设置为这个结果b\n                             * 这样for循环之后，runBit的值就是最后不变的hash&n的值\n                             * 而lastRun的值就是最后一次导致hash&n 发生变化的节点(假设为p节点)\n                             * 为什么要这么做呢？因为p节点后面的节点的hash&n 值跟p节点是一样的，\n                             * 所以在复制到新的table的时候，它肯定还是跟p节点在同一个位置\n                             * 在复制完p节点之后，p节点的next节点还是指向它原来的节点，就不需要进行复制了，自己就被带过去了\n                             * 这也就导致了一个问题就是复制后的链表的顺序并不一定是原来的倒序\n                             */\n                            for (Node<K,V> p = f.next; p != null; p = p.next) {\n                                int b = p.hash & n;    //n的值为扩张前的数组的长度\n                                if (b != runBit) {\n                                    runBit = b;\n                                    lastRun = p;\n                                }\n                            }\n                            if (runBit == 0) {\n                                ln = lastRun;\n                                hn = null;\n                            }\n                            else {\n                                hn = lastRun;\n                                ln = null;\n                            }\n                            /*\n                             * 构造两个链表，顺序大部分和原来是反的\n                             * 分别放到原来的位置和新增加的长度的相同位置(i/n+i)\n                             */\n                            for (Node<K,V> p = f; p != lastRun; p = p.next) {\n                                int ph = p.hash; K pk = p.key; V pv = p.val;\n                                if ((ph & n) == 0)\n                                        /*\n                                         * 假设runBit的值为0，\n                                         * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同为0的节点)设置到旧的table的第一个hash计算后为0的节点下一个节点\n                                         * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点\n                                         */\n                                    ln = new Node<K,V>(ph, pk, pv, ln);\n                                else\n                                        /*\n                                         * 假设runBit的值不为0，\n                                         * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同不为0的节点)设置到旧的table的第一个hash计算后不为0的节点下一个节点\n                                         * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点\n                                         */\n                                    hn = new Node<K,V>(ph, pk, pv, hn);    \n                            }\n                            setTabAt(nextTab, i, ln);    \n                            setTabAt(nextTab, i + n, hn);\n                            setTabAt(tab, i, fwd);\n                            advance = true;\n                        }\n                        else if (f instanceof TreeBin) {    //否则的话是一个树节点\n                            TreeBin<K,V> t = (TreeBin<K,V>)f;\n                            TreeNode<K,V> lo = null, loTail = null;\n                            TreeNode<K,V> hi = null, hiTail = null;\n                            int lc = 0, hc = 0;\n                            for (Node<K,V> e = t.first; e != null; e = e.next) {\n                                int h = e.hash;\n                                TreeNode<K,V> p = new TreeNode<K,V>\n                                    (h, e.key, e.val, null, null);\n                                if ((h & n) == 0) {\n                                    if ((p.prev = loTail) == null)\n                                        lo = p;\n                                    else\n                                        loTail.next = p;\n                                    loTail = p;\n                                    ++lc;\n                                }\n                                else {\n                                    if ((p.prev = hiTail) == null)\n                                        hi = p;\n                                    else\n                                        hiTail.next = p;\n                                    hiTail = p;\n                                    ++hc;\n                                }\n                            }\n                            /*\n                             * 在复制完树节点之后，判断该节点处构成的树还有几个节点，\n                             * 如果≤6个的话，就转回为一个链表\n                             */\n                            ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :\n                                (hc != 0) ? new TreeBin<K,V>(lo) : t;\n                            hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :\n                                (lc != 0) ? new TreeBin<K,V>(hi) : t;\n                            setTabAt(nextTab, i, ln);\n                            setTabAt(nextTab, i + n, hn);\n                            setTabAt(tab, i, fwd);\n                            advance = true;\n                        }\n                    }\n                }\n            }\n        }\n    }\n```\n下面的两点一定要注意：\n\n　　　　·复制之后的新链表不是旧链表的绝对倒序。\n\n　　　　·在扩容的时候每个线程都有处理的步长，最少为16，在这个步长范围内的数组节点只有自己一个线程来处理\n\n\n#### size实现\n1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount，实现如下：\n```java\nif ((as = counterCells) != null ||\n    !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {\n    CounterCell a; long v; int m;\n    boolean uncontended = true;\n    if (as == null || (m = as.length - 1) < 0 ||\n        (a = as[ThreadLocalRandom.getProbe() & m]) == null ||\n        !(uncontended =\n          U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {\n        fullAddCount(x, uncontended);\n        return;\n    }\n    if (check <= 1)\n        return;\n    s = sumCount();\n}\n```\n1、初始化时counterCells为空，在并发量很高时，如果存在两个线程同时执行CAS修改baseCount值，则失败的线程会继续执行方法体中的逻辑，使用CounterCell记录元素个数的变化；\n\n2、如果CounterCell数组counterCells为空，调用fullAddCount()方法进行初始化，并插入对应的记录数，通过CAS设置cellsBusy字段，只有设置成功的线程才能初始化CounterCell数组，实现如下：\n```java\nelse if (cellsBusy == 0 && counterCells == as &&\n         U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {\n    boolean init = false;\n    try {                           // Initialize table\n        if (counterCells == as) {\n            CounterCell[] rs = new CounterCell[2];\n            rs[h & 1] = new CounterCell(x);\n            counterCells = rs;\n            init = true;\n        }\n    } finally {\n        cellsBusy = 0;\n    }\n    if (init)\n        break;\n}\n```\n3、如果通过CAS设置cellsBusy字段失败的话，则继续尝试通过CAS修改baseCount字段，如果修改baseCount字段成功的话，就退出循环，否则继续循环插入CounterCell对象；\n```java\nelse if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x))\n    break;\n```\n所以在1.8中的size实现比1.7简单多，因为元素个数保存baseCount中，部分元素的变化个数保存在CounterCell数组中，实现如下：\n```java\npublic int size() {\n    long n = sumCount();\n    return ((n < 0L) ? 0 :\n            (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :\n            (int)n);\n}\n \nfinal long sumCount() {\n    CounterCell[] as = counterCells; CounterCell a;\n    long sum = baseCount;\n    if (as != null) {\n        for (int i = 0; i < as.length; ++i) {\n            if ((a = as[i]) != null)\n                sum += a.value;\n        }\n    }\n    return sum;\n}\n```\n通过累加baseCount和CounterCell数组中的数量，即可得到元素的总个数；\n\n#### get\n```java\n/*\n     * 相比put方法，get就很单纯了，支持并发操作，\n     * 当key为null的时候回抛出NullPointerException的异常\n     * get操作通过首先计算key的hash值来确定该元素放在数组的哪个位置\n     * 然后遍历该位置的所有节点\n     * 如果不存在的话返回null\n     */\n    public V get(Object key) {\n    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;\n    int h = spread(key.hashCode());\n    if ((tab = table) != null && (n = tab.length) > 0 &&\n        (e = tabAt(tab, (n - 1) & h)) != null) {\n        // 判断头结点是否就是我们需要的节点\n        if ((eh = e.hash) == h) {\n            if ((ek = e.key) == key || (ek != null && key.equals(ek)))\n                return e.val;\n        }\n        // 如果头结点的 hash 小于 0，说明 正在扩容，或者该位置是红黑树\n        else if (eh < 0)\n            // 参考 ForwardingNode.find(int h, Object k) 和 TreeBin.find(int h, Object k)\n            return (p = e.find(h, key)) != null ? p.val : null;\n \n        // 遍历链表\n        while ((e = e.next) != null) {\n            if (e.hash == h &&\n                ((ek = e.key) == key || (ek != null && key.equals(ek))))\n                return e.val;\n        }\n    }\n    return null;\n}\n\n```\n\n#### 同步机制\nConcurrentHashMap是如果来做到并发安全，又是如何做到高效的并发的呢？\n\n首先是读操作，从源码中可以看出来，在get操作中，根本没有使用同步机制，也没有使用unsafe方法，所以读操作是支持并发操作的。\n\n1、那么写操作呢？\n\n　　分析这个之前，先看看什么情况下会引起数组的扩容，扩容是通过transfer方法来进行的。而调用transfer方法的只有trePresize、helpTransfer和addCount三个方法。\n\n这三个方法又是分别在什么情况下进行调用的呢？\n\n- tryPresize是在treeIfybin和putAll方法中调用，treeIfybin主要是在put添加元素完之后，判断该数组节点相关元素是不是已经超过8个的时候，如果超过则会调用这个方法来扩容数组或者把链表转为树。\n\n- helpTransfer是在当一个线程要对table中元素进行操作的时候，如果检测到节点的HASH值为MOVED的时候，就会调用helpTransfer方法，在helpTransfer中再调用transfer方法来帮助完成数组的扩容\n\n- addCount是在当对数组进行操作，使得数组中存储的元素个数发生了变化的时候会调用的方法。\n\n所以引起数组扩容的情况如下：\n\n- 只有在往map中添加元素的时候，在某一个节点的数目已经超过了8个，同时数组的长度又小于64的时候，才会触发数组的扩容。\n\n- 当数组中元素达到了sizeCtl的数量的时候，则会调用transfer方法来进行扩容\n\n　　\n那么在扩容的时候，可以不可以对数组进行读写操作呢？\n\n事实上是可以的。当在进行数组扩容的时候，如果当前节点还没有被处理（也就是说还没有设置为fwd节点），那就可以进行设置操作。\n如果该节点已经被处理了，则当前线程也会加入到扩容的操作中去。\n\n那么，多个线程又是如何同步处理的呢？\n\n在ConcurrentHashMap中，同步处理主要是通过Synchronized和unsafe两种方式来完成的。\n\n- 在取得sizeCtl、某个位置的Node的时候，使用的都是unsafe的方法，来达到并发安全的目的\n\n- 当需要在某个位置设置节点的时候，则会通过Synchronized的同步机制来锁定该位置的节点。\n\n- 在数组扩容的时候，则通过处理的步长和fwd节点来达到并发安全的目的，通过设置hash值为MOVED\n\n- 当把某个位置的节点复制到扩张后的table的时候，也通过Synchronized的同步机制来保证现程安全\n\n### 思考\n\n#### 在put中获取链表的头节点时，为什么不直接用tab[i]?\n```java\n         // 这个是 segment 内部的数组\n        HashEntry<K,V>[] tab = table;\n        // 再利用 hash 值，求应该放置的数组下标\n        int index = (tab.length - 1) & hash;\n        // first 是数组该位置处的链表的表头\n        HashEntry<K,V> first = entryAt(tab, index);\n```\n\n将volatile的table字段引用赋值给tab局部变量，为了保证每次读取的table中的数组项都是最新的值，因而调用entryAt()方法获取数组项的值而不是通过tab[index]方式直接获取（在put操作更新节点链时，它采用Unsafe.putOrderedObject()操作，此时它对链头的更新只局限与当前线程，为了保证接下来的put操作能够读取到上一次的更新结果，需要使用volatile的语法去读取节点链的链头）\nentryAt方法\n```java\nstatic final <K,V> HashEntry<K,V> entryAt(HashEntry<K,V>[] tab, int i) {\n        return (tab == null) ? null :\n            (HashEntry<K,V>) UNSAFE.getObjectVolatile\n            (tab, ((long)i << TSHIFT) + TBASE);\n    }\n```\nsetEntryAt方法\n```java\nstatic final <K,V> void setEntryAt(HashEntry<K,V>[] tab, int i,\n                                       HashEntry<K,V> e) {\n        UNSAFE.putOrderedObject(tab, ((long)i << TSHIFT) + TBASE, e);\n    }\n```\n\n#### 1.8synchronized用在哪些地方\n1、put的时候，如果在table[i]上有元素的话，就采用synchronized的方式加锁\n2、在transfer扩容的时候，使用synchronized重复对table[i]上的第一个元素加锁\n3、链表转树的过程也是一样\n\n\n\n### 参考资料\n- [ConcurrentHashMap实现原理及源码分析](https://www.cnblogs.com/chengxiao/p/6842045.html)\n- [谈谈ConcurrentHashMap1.7和1.8的不同实现](http://www.importnew.com/23610.html)\n- [ConcurrentHashMap1.7源码分析](https://blog.csdn.net/klordy_123/article/details/82933115)\n- [Java多线程 -- ConcurrentHashMap](https://blog.csdn.net/fw0124/article/details/43308193)\n- [Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析](http://www.importnew.com/28263.html)\n- [ConcurrentHashMap源码分析(1.8)](https://www.cnblogs.com/zerotomax/p/8687425.html#go6)\n\n\n","tags":["Java","并发"],"categories":["Java"]},{"title":"红黑树","url":"/2019/03/25/红黑树/","content":"\n### 二叉树查找树(BST)\n\n#### 常用性质\n\n1.左子树上所有结点的值均小于或等于它的根结点的值。\n\n2.右子树上所有结点的值均大于或等于它的根结点的值。\n\n3.左、右子树也分别为二叉排序树。\n\n4.在二叉树的第i层上最多有2i-1 个节点 。（i>=1）\n\n5.二叉树中如果深度为k(有k层),那么最多有2k-1个节点。(k>=1）\n\n6.若二叉树按照从上到下从左到右依次编号，则若某节点编号为k，则其左右子树根节点编号分别为2k和2k+1;\n\n7.二叉树分类：满二叉树，完全二叉树\n\n满二叉树：高度为h，由2^h-1个节点构成的二叉树称为满二叉树。\n完全二叉树：高度为h，最后一层至少有一个节点。\n\n#### 查询性能\n如果二叉排序树是平衡的，则n个节点的二叉排序树的高度为Log2(n+1),其查找效率为O(logN)，近似于**二分查找，查找的最大次数等同于树的高度**。如果二叉排序树完全不平衡，则其深度可达到n，查找效率为O(n)，退化为顺序查找。一般的，二叉排序树的查找性能在O(logN)到O(n)之间。因此，为了获得较好的查找性能，就要构造一棵平衡的二叉排序树。\n它的高度决定了它的查找效率。\n![](二叉树.png)\n如查找10。\n\n#### 插入\n那么在插入的时候也是利用该方法，一层一层比较，找到合适的位置插入。\n假设初始的二叉查找树只有三个节点，根节点值为9，左孩子值为8，右孩子值为12：\n![](BST插入-1.png)\n接下来我们依次插入如下五个节点：7,6,5,4,3。依照二叉查找树的特性，结果会变成什么样呢？\n![](BST插入-2.png)\n这时候的查找性能退化为顺序查找。\n**为了解决二叉树多次插入新节点导致的不平衡，引入了红黑树。**\n\n#### 删除\n删除操作的步骤如下：\n\n查找到要删除的节点。\n如果待删除的节点是叶子节点，则直接删除。\n如果待删除的节点不是叶子节点，则先找到待删除节点的中序遍历的后继节点，用该后继节点的值替换待删除的节点的值，然后删除后继节点。\n![](二叉树删除.png)\n\n#### BST存在的问题\nBST存在的主要问题是，数在插入的时候会导致树倾斜，不同的插入顺序会导致树的高度不一样，而树的高度直接的影响了树的查找效率。理想的高度是logN，最坏的情况是所有的节点都在一条斜线上，这样的树的高度为N。\n\n### 红黑树\n红黑树是一种自平衡的二叉查找树。在插入和删除的时候，会通过旋转操作将高度保持在logN。除了具备二叉树的性质，还具备：\n1.任何一个节点都有颜色，黑色或者红色\n2.根节点是黑色的\n3.父子节点之间不能出现两个连续的红节点\n4.任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等\n5.空节点被认为是黑色的\n6.新插入的节点，按照二叉树的规则合适的插入位置，并且为红色\n数据结构表示如下：\n```java\nclass  Node<T>{\n   public  T value;\n   public   Node<T> parent;\n   public   boolean isRed;\n   public   Node<T> left;\n   public   Node<T> right;\n}\n```\n\n下图中这棵树，就是一颗典型的红黑树：\n![](红黑树.png)\n红黑树保证从根到叶子的最长路径不会超过最短路径的两倍。\n\n#### 插入\n当红黑树插入新节点时，有可能会违背上面的规则，此时就需要调整。调整的策略有两种：1、变色；2、旋转——左旋和右旋\n\n变色：\n为了重新符合红黑树的规则，尝试把红色节点变为黑色，或者把黑色节点变为红色。\n\n新插入的节点是红色的，插入修复操作如果遇到**父节点的颜色为黑则修复操作结束**。也就是说，只有在父节点为红色节点的时候是需要插入修复操作的。\n\n插入修复操作分为以下的三种情况，而且新插入的节点的父节点都是红色的：\n\n- 叔叔节点也为红色。\n- 叔叔节点为空，且祖父节点、父节点和新节点处于一条斜线上。\n- 叔叔节点为空，且祖父节点、父节点和新节点不处于一条斜线上。\n\n##### case 1——叔叔节点也为红色\n将父节点和叔叔节点与祖父节点的颜色互换，这样就符合了RBTRee的定义。即维持了高度的平衡，修复后颜色也符合RBTree定义的第三条和第四条。下图中，操作完成后A节点变成了新的节点。如果A节点的父节点不是黑色的话，则继续做修复操作。\n![](RBT插入-1.png)\n\n##### case 2——叔叔节点为空，且祖父节点、父节点和新节点处于一条斜线上\n\n将B节点进行右旋操作，并且和父节点A互换颜色。通过该修复操作RBTRee的高度和颜色都符合红黑树的定义。如果B和C节点都是右节点的话，只要将操作变成左旋就可以了。\n![](RBT插入-2.png)\n\n##### case 3——叔叔节点为空，且祖父节点、父节点和新节点不处于一条斜线上\n将C节点进行左旋，这样就从case 3转换成case 2了，然后针对case 2进行操作处理就行了。case 2操作做了一个右旋操作和颜色互换来达到目的。如果树的结构是下图的镜像结构，则只需要将对应的左旋变成右旋，右旋变成左旋即可。\n\n![](RBT插入-3.png)\n\n\n#####  插入操作的总结\n插入后的修复操作是一个向root节点回溯的操作，一旦牵涉的节点都符合了红黑树的定义，修复操作结束。之所以会向上回溯是由于case 1操作会将父节点，叔叔节点和祖父节点进行换颜色，有可能会导致祖父节点不平衡(红黑树定义3)。这个时候需要对祖父节点为起点进行调节（向上回溯）。\n\n祖父节点调节后如果还是遇到它的祖父颜色问题，操作就会继续向上回溯，直到root节点为止，根据定义root节点永远是黑色的。在向上的追溯的过程中，针对插入的3种情况进行调节。直到符合红黑树的定义为止。直到牵涉的节点都符合了红黑树的定义，修复操作结束。\n\n如果上面的3种情况如果对应的操作是在右子树上，做对应的镜像操作就是了。\n\n#### 删除\n删除操作首先需要做的也是BST的删除操作，删除操作会删除对应的节点，如果是叶子节点就直接删除，如果是非叶子节点，会用对应的中序遍历的后继节点来顶替要删除节点的位置。删除后就需要做删除修复操作，使的树符合红黑树的定义，符合定义的红黑树高度是平衡的。\n\n删除修复操作在遇到被删除的节点是红色节点或者到达root节点时，修复操作完毕。\n\n删除修复操作是针对删除黑色节点才有的，当黑色节点被删除后会让整个树不符合RBTree的定义的第四条。需要做的处理是从兄弟节点上借调黑色的节点过来，如果兄弟节点没有黑节点可以借调的话，就只能往上追溯，将每一级的黑节点数减去一个，使得整棵树符合红黑树的定义。\n\n删除操作的总体思想是从兄弟节点借调黑色节点使树保持局部的平衡，如果局部的平衡达到了，就看整体的树是否是平衡的，如果不平衡就接着向上追溯调整。\n\n\n删除修复操作分为四种情况(删除黑节点后)：\n\n- 待删除的节点的兄弟节点是红色的节点。\n- 待删除的节点的兄弟节点是黑色的节点，且兄弟节点的子节点都是黑色的。\n- 待调整的节点的兄弟节点是黑色的节点，且兄弟节点的左子节点是红色的，右节点是黑色的(兄弟节点在右边)，如果兄弟节点在左边的话，就是兄弟节点的右子节点是红色的，左节点是黑色的。\n- 待调整的节点的兄弟节点是黑色的节点，且右子节点是是红色的(兄弟节点在右边)，如果兄弟节点在左边，则就是对应的就是左节点是红色的。\n\n##### 删除操作-case 1\n由于兄弟节点是红色节点的时候，无法借调黑节点，所以需要将兄弟节点提升到父节点，由于兄弟节点是红色的，根据RBTree的定义，兄弟节点的子节点是黑色的，就可以从它的子节点借调了。\n\ncase 1这样转换之后就会变成后面的case 2，case 3，或者case 4进行处理了。上升操作需要对C做一个左旋操作，如果是镜像结构的树只需要做对应的右旋操作即可。\n\n之所以要做case 1操作是因为兄弟节点是红色的，无法借到一个黑节点来填补删除的黑节点。\n\n![](RBT删除-1.png)\n\n##### 删除操作-case 2\ncase 2的删除操作是由于兄弟节点可以消除一个黑色节点，因为兄弟节点和兄弟节点的子节点都是黑色的，所以可以将兄弟节点变红，这样就可以保证树的局部的颜色符合定义了。这个时候需要将父节点A变成新的节点，继续向上调整，直到整颗树的颜色符合RBTree的定义为止。\n\ncase 2这种情况下之所以要将兄弟节点变红，是因为如果把兄弟节点借调过来，会导致兄弟的结构不符合RBTree的定义，这样的情况下只能是将兄弟节点也变成红色来达到颜色的平衡。当将兄弟节点也变红之后，达到了局部的平衡了，但是对于祖父节点来说是不符合定义4的。这样就需要回溯到父节点，接着进行修复操作。\n\n![](RBT删除-2.png)\n\n#####  删除操作-case 3\ncase 3的删除操作是一个中间步骤，它的目的是将左边的红色节点借调过来，这样就可以转换成case 4状态了，在case 4状态下可以将D，E节点都阶段过来，通过将两个节点变成黑色来保证红黑树的整体平衡。\n\n之所以说case-3是一个中间状态，是因为根据红黑树的定义来说，下图并不是平衡的，他是通过case 2操作完后向上回溯出现的状态。之所以会出现case 3和后面的case 4的情况，是因为可以通过借用侄子节点的红色，变成黑色来符合红黑树定义4.\n![](RBT删除-3.png)\n#####  删除操作-case 4\nCase 4的操作是真正的节点借调操作，通过将兄弟节点以及兄弟节点的右节点借调过来，并将兄弟节点的右子节点变成红色来达到借调两个黑节点的目的，这样的话，整棵树还是符合RBTree的定义的。\n\nCase 4这种情况的发生只有在待删除的节点的兄弟节点为黑，且子节点不全部为黑，才有可能借调到两个节点来做黑节点使用，从而保持整棵树都符合红黑树的定义。\n![](RBT删除-4.png)\n\n#####  删除操作的总结\n红黑树的删除操作是最复杂的操作，复杂的地方就在于当删除了黑色节点的时候，如何从兄弟节点去借调节点，以保证树的颜色符合定义。由于红色的兄弟节点是没法借调出黑节点的，这样只能通过选择操作让他上升到父节点，而由于它是红节点，所以它的子节点就是黑的，可以借调。\n\n对于兄弟节点是黑色节点的可以分成3种情况来处理，当所以的兄弟节点的子节点都是黑色节点时，可以直接将兄弟节点变红，这样局部的红黑树颜色是符合定义的。但是整颗树不一定是符合红黑树定义的，需要往上追溯继续调整。\n\n对于兄弟节点的子节点为左红右黑或者 (全部为红，右红左黑)这两种情况，可以先将前面的情况通过选择转换为后一种情况，在后一种情况下，因为兄弟节点为黑，兄弟节点的右节点为红，可以借调出两个节点出来做黑节点，这样就可以保证删除了黑节点，整棵树还是符合红黑树的定义的，因为黑色节点的个数没有改变。\n\n红黑树的删除操作是遇到删除的节点为红色，或者追溯调整到了root节点，这时删除的修复操作完毕。\n\n#### 红黑树总结\n整个红黑树的查找，插入和删除都是O(logN)的，原因就是整个红黑树的高度是logN，查找从根到叶，走过的路径是树的高度，删除和插入操作是从叶到根的，所以经过的路径都是logN。\n\n### 参考资料\n- [漫画：什么是红黑树？](https://juejin.im/post/5a27c6946fb9a04509096248#comment)\n- [红黑树深入剖析及Java实现](https://zhuanlan.zhihu.com/p/24367771)\n- [寻找红黑树的操作手册](https://www.jianshu.com/p/19f259fa9cec)\n\n","tags":["数据结构"],"categories":["数据结构"]},{"title":"zookeeper分布式锁及zookeeper集群单数原因","url":"/2019/03/25/zookeeper分布式锁及zookeeper集群单数原因/","content":"\n### 什么是分布式锁\n\n分布式锁一般用在分布式系统或者多个应用中，用来控制同一任务是否执行或者任务的执行顺序。在项目中，部署了多个tomcat应用，在执行定时任务时就会遇到同一任务可能执行多次的情况，我们可以借助分布式锁，保证在同一时间只有一个tomcat应用执行了定时任务。\n\n\n### 数据库锁\n\n1、基于MySQL锁表\n完全依靠数据库唯一索引来实现，当想要获得锁时，即向数据库中插入一条记录，释放锁时就删除这条记录\n这种方式存在以下问题：\n- 锁没有失效时间，解锁失败会导致死锁，其他线程无法再获取到锁，因为唯一索引insert都会返回失败\n- 只能是非阻塞锁，insert失败直接就报错了，无法进入队列进行重试\n- 不可重入，同一线程在没有释放锁之前无法再获取到锁\n\n2、采用乐观锁\n增加版本号,根据版本号来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败\n\n### 缓存锁\n采用setnx()，get()，getset()\n(1) 线程A setnx，值为超时的时间戳(t1)，如果返回true，获得锁。\n(2) 线程B用get 命令获取t1，与当前时间戳比较，判断是否超时，没超时false，如果已超时执行步骤3\n(3) 计算新的超时时间t2，使用getset命令返回t3(这个值可能其他线程已经修改过)，如果t1==t3,获得锁,如果t1!=t3说明锁被其他线程获取了\n(4) 获取锁后，处理完业务逻辑，再去判断锁是否超时，如果没超时删除锁，如果已超时，不用处理（防止删除其他线程的锁）\n\n### zk分布式锁\n\n   在获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点。客户端调用createNode方法在locker下创建临时顺序节点，然后调用getChildren(“locker”)来获取locker下面的所有子节点，注意此时不用设置任何Watcher。客户端获取到所有的子节点path之后，如果发现自己在之前创建的子节点序号最小，那么就认为该客户端获取到了锁。如果发现自己创建的节点并非locker所有子节点中最小的，说明自己还没有获取到锁，此时客户端需要找到比自己小的那个节点，然后对其调用exist()方法，同时对其注册事件监听器。之后，让这个被关注的节点删除，则客户端的Watcher会收到相应通知，此时再次判断自己创建的节点是否是locker子节点中序号最小的，如皋是则获取到了锁，如果不是则重复以上步骤继续获取到比自己小的一个节点并注册监听。\n\n```java\n/**\n * zk实现分布式锁\n */\n@Service\npublic class ZookeeperImproveLock implements Lock {\n    private static final String LOCK_PATH=\"/LOCK\";\n    private static final String ZOOKEEPER_IP_PORT=\"localhost:2181\";\n    private ZkClient client = new ZkClient(ZOOKEEPER_IP_PORT,1000,1000,new SerializableSerializer());\n    private CountDownLatch cdl;\n    private String beforePath; //当前请求的节点前一个节点\n    private String currentPath; //当前请求的节点\n\n//    判断有没有LOCK_PATH目录,没有则创建\n    public ZookeeperImproveLock(){\n        if(!this.client.exists(LOCK_PATH)){\n            this.client.createPersistent(LOCK_PATH);\n        }\n    }\n\n    @Override\n    //非阻塞时加锁\n    public boolean tryLock() {\n        try {\n//        如果currentpath为空则为第一次尝试加锁,第一次加锁赋值currentpath\n            if(currentPath==null||this.client.getChildren(LOCK_PATH).size() <=0){\n    //            创建一个临时顺序节点\n                currentPath = this.client.createEphemeralSequential (LOCK_PATH + '/',\"lock\");\n                System.out.println(\"创建一个临时节点--->\"+currentPath);\n            }\n            //获取所有临时节点并排序,临时节点名称为自增长的字符串,如:00000000400\n            List<String> children = this.client.getChildren(LOCK_PATH);\n            Collections.sort(children);\n            System.out.println(children.toString());\n            System.out.println(Thread.currentThread().getName()+ \"get0--->\"+ children.get(0));\n            System.out.println(Thread.currentThread().getName()+\"currentPath\"+ currentPath);\n            String realPath = LOCK_PATH+'/'+children.get(0);\n            System.out.println(Thread.currentThread().getName()+ \"real---\"+ realPath);\n            if(currentPath.equals(realPath)){\n                System.out.println(Thread.currentThread().getName()+\"成功啦--->\" + currentPath);\n                return true;\n            }else{\n                //如果当前节点在所有节点中排名不是第一,则获取前面的节点名称,并赋值给beforepath\n//                int wz = 0;\n//                if(children.contains(currentPath)){\n//                    wz = children.indexOf(currentPath);\n//                }\n                int wz = Collections.binarySearch(children,currentPath.substring(6));\n                beforePath = LOCK_PATH + '/' + children.get(wz-1);\n                System.out.println(Thread.currentThread().getName()+\"beforePath\"+ beforePath);\n            }\n        } catch (RuntimeException e) {\n            e.printStackTrace();\n        }\n        return false;\n    }\n\n    @Override\n    public void lock() {\n        if(!tryLock()){\n            System.out.println(\"获取锁不成功--->\" + currentPath);\n            waitForLock();\n            lock();\n        }else{\n            System.out.println(\"获得分布式锁--->\"+currentPath);\n        }\n    }\n\n    private void waitForLock() {\n        IZkDataListener listener = new IZkDataListener() {\n            @Override\n            public void handleDataChange(String s, Object o) throws Exception {\n\n            }\n\n            @Override\n            public void handleDataDeleted(String s) throws Exception {\n                if(cdl != null){\n                    System.out.println(\"countdown\" + currentPath);\n                    cdl.countDown();\n                }\n            }\n        };\n\n        //给排在前面的节点增加数据删除的watcher\n        this.client.subscribeDataChanges(beforePath,listener);\n\n        if(this.client.exists(beforePath)){\n            cdl = new CountDownLatch(1);\n            try {\n                cdl.await();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        this.client.unsubscribeDataChanges(beforePath,listener);\n    }\n\n    @Override\n    public void lockInterruptibly() throws InterruptedException {\n\n    }\n\n\n\n    @Override\n    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {\n        return false;\n    }\n\n    @Override\n    public void unlock() {\n        //删除当前临时节点\n        this.client.delete(currentPath);\n        System.out.println(\"删除当前锁---->\" + currentPath);\n    }\n\n    @Override\n    public Condition newCondition() {\n        return null;\n    }\n}\n\n```\n\n### Zookeeper集群为什么要是单数\n在zookeeper集群中，会有三种角色，leader、 follower、 observer分别对应着总统、议员、观察者。\n\n半数以上投票通过：可以这样理解。客户端的增删改操作无论访问到了哪台zookeeper服务器，最终都会被转发给leader服务器，再由leader服务器分给zookeeper集群中所有follower服务器去投票（投票指的是在内存中做增删改操作），半数投票通过就被认为操作可执行（commit），否则不可执行。\n\nobserver观察者服务器是针对于查询操作做负载的，observer与follower服务器最大的不同在于observer没有投票权，在客户端发起的增删改操中，leader服务器是不会把消息传递给observer服务器让其投票的。但是查询操作跟follower一样，客户端的查询到了observer服务器节点，observer服务器去访问leader服务器取最新的数据然后返回给客户端。\n\n### 原因\n1、容错\n由于在增删改操作中需要半数以上服务器通过，来分析以下情况。\n\n2台服务器，至少2台正常运行才行（2的半数为1，半数以上最少为2），正常运行1台服务器都不允许挂掉\n\n3台服务器，至少2台正常运行才行（3的半数为1.5，半数以上最少为2），正常运行可以允许1台服务器挂掉\n\n4台服务器，至少3台正常运行才行（4的半数为2，半数以上最少为3），正常运行可以允许1台服务器挂掉\n\n5台服务器，至少3台正常运行才行（5的半数为2.5，半数以上最少为3），正常运行可以允许2台服务器挂掉\n\n6台服务器，至少3台正常运行才行（6的半数为3，半数以上最少为4），正常运行可以允许2台服务器挂掉\n\n \n\n通过以上可以发现，3台服务器和4台服务器都最多允许1台服务器挂掉，5台服务器和6台服务器都最多允许2台服务器挂掉\n\n但是明显4台服务器成本高于3台服务器成本，6台服务器成本高于5服务器成本。这是由于半数以上投票通过决定的。\n\n2、防脑裂\n一个zookeeper集群中，可以有多个follower、observer服务器，但是必需只能有一个leader服务器。\n\n如果leader服务器挂掉了，剩下的服务器集群会通过半数以上投票选出一个新的leader服务器。\n\n集群互不通讯情况：\n\n一个集群3台服务器，全部运行正常，但是其中1台裂开了，和另外2台无法通讯。3台机器里面2台正常运行过半票可以选出一个leader。\n\n一个集群4台服务器，全部运行正常，但是其中2台裂开了，和另外2台无法通讯。4台机器里面2台正常工作没有过半票以上达到3，无法选出leader正常运行。\n\n一个集群5台服务器，全部运行正常，但是其中2台裂开了，和另外3台无法通讯。5台机器里面3台正常运行过半票可以选出一个leader。\n\n一个集群6台服务器，全部运行正常，但是其中3台裂开了，和另外3台无法通讯。6台机器里面3台正常工作没有过半票以上达到4，无法选出leader正常运行。\n\n \n\n通可以上分析可以看出，为什么zookeeper集群数量总是单出现，主要原因还是在于第2点，防脑裂，对于第1点，无非是正本控制，但是不影响集群正常运行。但是出现第2种裂的情况，zookeeper集群就无法正常运行了。\n\n\n\n\n\n\n\n","tags":["zookeeper","分布式"],"categories":["zookeeper","分布式"]},{"title":"ThreadLocal定义及内存泄漏","url":"/2019/03/25/ThreadLocal定义及内存泄漏/","content":"\n### 概述\nThreadLocal(线程局部变量) 的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。\n一个线程对应着一个ThreadLocalMap，一个ThreadLocalMap存储着<ThredLocal，Value<T>>的Entry。一个线程可以创建多个ThreadLocal，每个ThreadLocal对象代表当前线程范围内的一个共享变量。连续调用set()会更新ThreadLocal对象对应的值。所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。\n\nThreadLocal 也可以跟踪一个请求，从接收请求，处理请求，到返回请求，**只要线程不销毁**，就可以在线程的任何地方，调用这个参数。\n\n\n### ThreadLocal 实现原理\n![](原理图.png)\nThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。\n\n也就是说**ThreadLocal 本身并不存储值，它只是作为一个 key** 来让线程从 ThreadLocalMap 获取 value。值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。\nThreadLocalMap构造函数：\n```java\nThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {\n            table = new Entry[INITIAL_CAPACITY];\n            int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);\n            table[i] = new Entry(firstKey, firstValue);\n            size = 1;\n            setThreshold(INITIAL_CAPACITY);\n        }\n\n```\nEntry构造函数：\n```java\n static class Entry extends WeakReference<ThreadLocal<?>> {\n            /** The value associated with this ThreadLocal. */\n            Object value;\n\n            Entry(ThreadLocal<?> k, Object v) {\n                super(k);\n                value = v;\n            }\n        }\n```\n\n### ThreadLocal为什么肯定会内存泄漏\nThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap（数组）中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value永远无法回收，造成内存泄漏。\n\n其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。\n\n但是这些被动的预防措施并不能保证不会内存泄漏：\n\n- 使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏（参考ThreadLocal 内存泄露的实例分析）。\n- 分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。\n\n所以得出一个结论就是只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间不会被回收的，就发生了我们认为的内存泄露。最要命的是线程对象不被回收的情况，这就发生了真正意义上的内存泄露。比如使用线程池的时候，线程结束是不会销毁的，会再次使用的，就可能出现内存泄露。　　\n\n\n### ThreadLocal变量加不加static的区别\n加了static，类加载的时候，就会初始化该Threadlocal变量。之后的每个线程访问的时候，都是引用到同一个ThreadLocal变量。不加static的时候，每个线程访问的时候都会创建新的ThreadLocal变量实例，造成空间浪费。加不加static都会有内存泄漏，这个是ThreadLocal的特性造成。 \nstatic的ThreadLocal变量是一个与线程相关的静态变量，即一个线程内，static变量是被各个实例共同引用的，但是不同线程内，static变量是隔开的。定义为static的ThreadLocal，只要类不卸载，ThreadLocal变量永远不会被gc掉，故在线程生命周期内，当前ThreadLocalMap一直保持ThreadLocal的引用。\n\n### 为什么使用弱引用\n\n- key 使用强引用：ThreadLocal被设置为null，由于ThreadLocalMap持有ThreadLocal的强引用，如果没有手动删除Entry和ThreadLocalMap的关系，那么ThreadLocal不会被回收，导致内存泄漏。\n\n- key 使用弱引用：ThreadLocal被设置为null，由于ThreadLocalMap持有ThreadLocal的弱引用，如果没有手动删除Entry和ThreadLocalMap的关系，ThreadLocal仍会被回收！这时ThreadLocalMap中存在key为 null的Entry。如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。\n\n在我们调用ThreadLocal.set（）的时候，会做一个将Key== null 的元素清理掉的工作，具体做法是：\n> -  第一步：ThreadLocalMap 拿threadLocalHashCode与map长度减一相与，求出哈希表的位置 i 。\n> -  第二步：遍历Entry，如果找到key相等的，覆盖原值! 或者找到key==null的，将值set进去，并且将遍历时路过的key==null的元素和他的value都置为null,,释放内存。\n> -  第三步：最后一个if条件时，做rehash的动作，即:将Entry里的元素重新计算一下Hash值，放到合适的位置去，猜想是为了加快下次访问的速度。\n\n#### 总结\n比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，**如果都没有手动删除对应key的Entry，都会导致内存泄漏**，但是使用弱引用可以多一层保障：ThreadLocal实例没有外部强引用的情况下，在GC时可以正常回收ThreadLocal的内存，但对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。\n\n既然Key是弱引用，那么我们要做的事，就是在调用ThreadLocal的get()、set()方法时完成后再调用remove方法，将Entry节点和Map的引用关系移除，这样整个Entry对象在GC Roots分析后就变成不可达了，下次GC的时候就可以被回收。\n\n因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除key对应的Entry就会导致内存泄漏，而不是因为弱引用。\n\n### ThreadLocalMap Hash冲突怎么解决\nThreadLocalMap结构非常简单，没有next引用，也就是说ThreadLocalMap中解决Hash冲突的方式并非链表的方式，而是采用**线性探测**的方式，所谓线性探测，就是根据初始key的hashcode值确定元素在table数组中的位置，如果发现这个位置上已经有其他key值的元素被占用，则利用固定的算法寻找一定步长的下个位置，依次判断，直至找到能够存放的位置。\n\nThreadLocalMap解决Hash冲突的方式就是简单的步长加1或减1，寻找下一个相邻的位置。\n\n每个线程只存一个变量，这样的话所有的线程存放到map中的Key都是相同的ThreadLocal，如果一个线程要保存多个变量，就需要创建多个ThreadLocal，多个ThreadLocal放入Map中时会极大的增加Hash冲突的可能。\n\n\n### synchronized 与 ThreadLocal的区别\n\nThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。\n\n在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。\n\n而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。\n\n对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。\n\n### 总结\n\n总结：ThreadLocalMap内部Entry中key使用的是对ThreadLocal对象的弱引用，这为避免内存泄露是一个进步，因为如果是强引用，那么即使其他地方没有对ThreadLocal对象的引用，ThreadLocalMap中的ThreadLocal对象还是不会被回收，而如果是弱引用则这时候ThreadLocal引用是会被回收掉的，虽然对于的value还是不能被回收，这时候ThreadLocalMap里面就会存在key为null但是value不为null的entry项，虽然ThreadLocalMap提供了set,get,remove方法在一些时机下会对这些Entry项进行清理，但是这是不及时的，也不是每次都会执行的，所以一些情况下还是会发生内存泄露，所以在使用完毕后即使调用remove方法才是解决内存泄露的王道。\n\n\n- [ThreadLocal可能引起的内存泄露](http://www.cnblogs.com/onlywujun/p/3524675.html)\n- [ThreadLocal 与　static　变量](https://www.cnblogs.com/cuihongwei1988/p/5632344.html)\n- [ThreadLocal 定义，以及是否可能引起的内存泄露(threadlocalMap的Key是弱引用，用线程池有可能泄露)](https://www.cnblogs.com/aspirant/p/8991010.html)\n- [使用ThreadLocal不当可能会导致内存泄露](http://ifeve.com/%E4%BD%BF%E7%94%A8threadlocal%E4%B8%8D%E5%BD%93%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%AF%BC%E8%87%B4%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2/)\n- [ThreadLocal-面试必问深度解析](https://www.jianshu.com/p/98b68c97df9b)\n- [聊一聊 Spring 中的线程安全性](https://mp.weixin.qq.com/s/EqNiKIYnZ4VHiYHewx9UgA)\n- [ThreadLocal 内存泄露的实例分析](http://www.importnew.com/22046.html)","tags":["线程"],"categories":["线程"]},{"title":"Tomcat系统架构","url":"/2019/03/25/Tomcat系统架构/","content":"\n### Tomcat顶层架构\n在 tomcat中，最常见的配置就是 server.xml了，以下是一份简化过的 server.xml：\n```xml\n<Server port=\"8005\" shutdown=\"SHUTDOWN\">\n<!--APR library loader. Documentation at /docs/apr.html -->\n  <Listener SSLEngine=\"on\" className=\"org.apache.catalina.core.AprLifecycleListener\"/>\n  <!-- Prevent memory leaks due to use of particular java/javax APIs-->\n  <Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\"/>\n  <Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\"/>\n  <Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\"/>\n\n  <GlobalNamingResources>\n    <Resource auth=\"Container\" description=\"User database that can be updated and saved\" factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\" name=\"UserDatabase\" pathname=\"conf/tomcat-users.xml\" type=\"org.apache.catalina.UserDatabase\"/>\n  </GlobalNamingResources>\n\n  <!-- 服务Service -->\n  <Service name=\"Catalina\">\n    <!-- Http连接器，监听8080端口，负责建立Http连接 -->\n    <Connector connectionTimeout=\"20000\" port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\"/>\n    <Connector SSLEnabled=\"true\" clientAuth=\"false\" keystoreFile=\"conf/.keystore\" keystorePass=\"123456\" maxThreads=\"150\" port=\"8443\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" scheme=\"https\" secure=\"true\" sslProtocol=\"TLS\"/>\n   <!-- AJP连接器，监听8009端口，负责和其他的Http服务器建立连接 -->\n    <Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\"/>\n\n    <!-- 自带名为Catalina的Engine组件，它的默认虚拟主机为localhost -->\n    <Engine defaultHost=\"localhost\" name=\"Catalina\">\n    <!-- 定义的安全域，所有的虚拟主机都共享这个Realm -->\n      <Realm className=\"org.apache.catalina.realm.LockOutRealm\" />\n        <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/>\n      </Realm>\n\n      <!-- 名字为localhost的虚拟主机 -->\n      <Host appBase=\"webapps\" autoDeploy=\"true\" name=\"localhost\" unpackWARs=\"true\">\n      <!-- 访问日志阀，能够将客户的请求信息写到日志文件中 -->\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" pattern=\"%h %l %u %t \"%r\" %s %b\" prefix=\"localhost_access_log\" suffix=\".txt\"/>\n        <!-- 一个web项目，它的目录为appBase + docBase = webapps/ServletFramework -->\n        <Context docBase=\"ServletFramework\" path=\"/ServletFramework\" reloadable=\"true\" source=\"org.eclipse.jst.jee.server:ServletFramework\"/>\n      </Host>\n    </Engine>\n  </Service>\n</Server>\n\n```\n\nTomcat的顶层结构图（图A），如下：\n![](顶层架构.webp)\nTomcat中最顶层的容器是Server，代表着整个服务器，从上图中可以看出，一个Server可以包含至少一个Service，用于具体提供服务。\nService主要包含两个部分：Connector和Container。从上图中可以看出 Tomcat 的心脏就是这两个组件，他们的作用如下：\n> 1、Connector用于处理连接相关的事情，并提供Socket与Request和Response相关的转化; \n2、Container用于封装和管理Servlet，以及具体处理Request请求；\n\n一个Tomcat中只有一个Server，一个Server可以包含多个Service，一个Service只有一个Container，但是可以有多个Connectors，这是因为一个服务可以有多个连接，如同时提供Http和Https链接，也可以提供向相同协议不同端口的连接,示意图如下（Engine、Host、Context下边会说到）：\n\n![](逻辑架构.webp)\n\n多个Connector和一个Container就形成了一个Service，有了Service就可以对外提供服务了。整个Tomcat的生命周期由Server控制。\n\n### tomcat的启动过程\n\n我们使用 tomcat的时候，一般在 Linux服务器上都是使用 catalina.sh脚本来启动服务器的。一般启动的命令：\n\n./catalina.sh start\n\n这句脚本在执行什么呢？打开脚本，定位到start子命令的位置。\n catalina.sh启动tomcat是执行了 org.apache.catalina.startup.Bootstrap的 start()方法， start()方法启动了 Catalina类的线程。\n\n tomcat提供了 Bootstrap类作为服务器的命令处理器，由它创建 Catalina实例并根据外部传递的命令控制 Catalina的启动和关闭。 Bootstrap本身是一个单独的 JAR包被放到 $CATALINA_HOME/bin目录下面。\n \n\n#### 总结\n\n（1）Tomcat中只有一个Server，一个Server可以有多个Service，一个Service可以有多个Connector和一个Container； \n（2）Server掌管着整个Tomcat的生死大权； \n（4）Service 是对外提供服务的； \n（5）Connector用于接受请求并将请求封装成Request和Response来具体处理； \n（6）Container用于封装和管理Servlet，以及具体处理request请求；\n\n\n### Connector和Container的微妙关系\n\n一个请求发送到Tomcat之后，首先经过Service然后会交给我们的Connector，Connector用于接收请求并将接收的请求封装为Request和Response来具体处理，Request和Response封装完之后再交由Container进行处理，Container处理完请求之后再返回给Connector，最后在由Connector通过Socket将处理的结果返回给客户端，这样整个请求的就处理完了！\n\nConnector最底层使用的是Socket来进行连接的，Request和Response是按照HTTP协议来封装的，所以Connector同时需要实现TCP/IP协议和HTTP协议！\n\nConnector用于接受请求并将请求封装成Request和Response，然后交给Container进行处理，Container处理完之后在交给Connector返回给客户端。\n\n因此，我们可以把Connector分为四个方面进行理解：\n\n（1）Connector如何接受请求的？ \n（2）如何将请求封装成Request和Response的？ \n（3）封装完之后的Request和Response如何交给Container进行处理的？ \n（4）Container处理完之后如何交给Connector并返回给客户端的？\n\n首先看一下Connector的结构图（图B），如下所示：\n\n\n![](connector.webp)\nConnector就是使用ProtocolHandler来处理请求的，不同的ProtocolHandler代表不同的连接类型，比如：Http11Protocol使用的是普通Socket来连接的，Http11NioProtocol使用的是NioSocket来连接的。\n\n其中ProtocolHandler由包含了三个部件：Endpoint、Processor、Adapter。\n\n（1）Endpoint用来处理底层Socket的网络连接，Processor用于将Endpoint接收到的Socket封装成Request，Adapter用于将Request交给Container进行具体的处理。\n\n（2）Endpoint由于是处理底层的Socket网络连接，因此Endpoint是用来实现TCP/IP协议的，而Processor用来实现HTTP协议的，Adapter将请求适配到Servlet容器进行具体的处理。\n\n（3）Endpoint的抽象实现AbstractEndpoint里面定义的Acceptor和AsyncTimeout两个内部类和一个Handler接口。Acceptor用于监听请求，AsyncTimeout用于检查异步Request的超时，Handler用于处理接收到的Socket，在内部调用Processor进行处理。\n\n### Container\n\nContainer用于封装和管理Servlet，以及具体处理Request请求，在Connector内部包含了4个子容器，结构图如下（图C）：\n\n![](container.webp)\n\n4个子容器的作用分别是：\n\n（1）Engine：引擎，用来管理多个站点，一个Service最多只能有一个Engine； \n（2）Host：代表一个站点，也可以叫虚拟主机，通过配置Host就可以添加站点； \n（3）Context：代表一个应用程序，对应着平时开发的一套程序，或者一个WEB-INF目录以及下面的web.xml文件； \n（4）Wrapper：每一Wrapper封装着一个Servlet；\n\n下面找一个Tomcat的文件目录对照一下，如下图所示：\n![](webapp.webp)\n\nContext和Host的区别是Context表示一个应用，我们的Tomcat中默认的配置下webapps下的每一个文件夹目录都是一个Context，其中ROOT目录中存放着主应用，其他目录存放着子应用，而整个webapps就是一个Host站点。\n\n\n### Container如何处理请求的\nContainer处理请求是使用Pipeline-Value管道来处理的！\n\nPipeline-Value是责任链模式，责任链模式是指在一个请求处理的过程中有很多处理者依次对请求进行处理，每个处理者负责做自己相应的处理，处理完之后将处理后的请求返回，再让下一个处理着继续处理。\n但是！Pipeline-Value使用的责任链模式和普通的责任链模式有些不同！区别主要有以下两点：\n\n（1）每个Pipeline都有特定的Value，而且是在管道的最后一个执行，这个Value叫做BaseValue，BaseValue是不可删除的；\n（2）在上层容器的管道的BaseValue中会调用下层容器的管道。\n\n我们知道Container包含四个子容器，而这四个子容器对应的BaseValue分别在：StandardEngineValue、StandardHostValue、StandardContextValue、StandardWrapperValue。\n\nPipeline的处理流程图如下（图D）：\n\n![](pipeline.webp)\n\n（1）Connector在接收到请求后会首先调用最顶层容器的Pipeline来处理，这里的最顶层容器的Pipeline就是EnginePipeline（Engine的管道）；\n\n（2）在Engine的管道中依次会执行EngineValue1、EngineValue2等等，最后会执行StandardEngineValue，在StandardEngineValue中会调用Host管道，然后再依次执行Host的HostValue1、HostValue2等，最后在执行StandardHostValue，然后再依次调用Context的管道和Wrapper的管道，最后执行到StandardWrapperValue。\n\n（3）当执行到StandardWrapperValue的时候，会在StandardWrapperValue中创建FilterChain，并调用其doFilter方法来处理请求，这个FilterChain包含着我们配置的与请求相匹配的Filter和Servlet，其doFilter方法会依次调用所有的Filter的doFilter方法和Servlet的service方法，这样请求就得到了处理！\n\n（4）当所有的Pipeline-Value都执行完之后，并且处理完了具体的请求，这个时候就可以将返回的结果交给Connector了，Connector在通过Socket的方式将结果返回给客户端。\n\n\n### 总结\n- [四张图带你了解Tomcat系统架构--让面试官颤抖的Tomcat回答系列！](https://mp.weixin.qq.com/s/xhfYlTUNyWlImqZ7valfaw)\n- [面试必会必知：tomcat 启动设计原理](https://mp.weixin.qq.com/s/yEFsn_ZFFAEi7_yGnV6NBg)","tags":["Tomcat"],"categories":["Tomcat"]},{"title":"Java三种代理模式","url":"/2019/03/12/Java三种代理模式/","content":"\n###  简介\n代理(Proxy)是一种设计模式,提供了对目标对象另外的访问方式;即通过代理对象访问目标对象。这样做的好处是:可以在目标对象实现的基础上,增强额外的功能操作,即扩展目标对象的功能。\n\n这里使用到编程中的一个思想:不要随意去修改别人已经写好的代码或者方法,如果需改修改,可以通过代理的方式来扩展该方法。\n\n举个例子来说明代理的作用:假设我们想邀请一位明星,那么并不是直接连接明星,而是联系明星的经纪人,来达到同样的目的.明星就是一个目标对象,他只要负责活动中的节目,而其他琐碎的事情就交给他的代理人(经纪人)来解决.这就是代理思想在现实中的一个例子。\n![图例](图例.png)\n\n\n代理模式的关键点是:代理对象与目标对象。代理对象是对目标对象的扩展,并会调用目标对象。\n\n### 静态代理\n静态代理在使用时,需要定义接口或者父类,被代理对象与代理对象一起实现相同的接口或者是继承相同父类。\n\n#### 场景\n模拟保存动作,定义一个保存动作的接口:IUserDao.java,然后目标对象实现这个接口的方法UserDao.java,此时如果使用静态代理方式,就需要在代理对象(UserDaoProxy.java)中也实现IUserDao接口.调用的时候通过调用代理对象的方法来调用目标对象.\n\n需要注意的是,代理对象与目标对象要实现相同的接口,然后通过调用相同的方法来调用目标对象的方法.\n\n代码示例：\n1、接口:IUserDao.java\n```java\n/**\n* 接口\n*/\npublic interface IUserDao {\n   void save();\n}\n```\n2、目标对象:UserDao.java\n```java\n/**\n* 接口实现\n* 目标对象\n*/\npublic class UserDao implements IUserDao {\n   public void save() {\n       System.out.println(\"----已经保存数据!----\");\n   }\n}\n```\n3、代理对象:UserDaoProxy.java\n```java\n/**\n* 代理对象,静态代理\n*/\npublic class UserDaoProxy implements IUserDao{\n   //接收保存目标对象\n   private IUserDao target;\n   public UserDaoProxy(IUserDao target){\n       this.target=target;\n   }\n\n   public void save() {\n       System.out.println(\"开始事务...\");\n       target.save();//执行目标对象的方法\n       System.out.println(\"提交事务...\");\n   }\n}\n```\n4、测试类:App.java\n```java\n/**\n* 测试类\n*/\npublic class App {\n   public static void main(String[] args) {\n       //目标对象\n       UserDao target = new UserDao();\n\n       //代理对象,把目标对象传给代理对象,建立代理关系\n       UserDaoProxy proxy = new UserDaoProxy(target);\n\n       proxy.save();//执行的是代理的方法\n   }\n}\n```\n\n优点：\n 可以做到在不修改目标对象的功能前提下,对目标功能扩展.\n缺点:\n  因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多.同时,一旦接口增加方法,目标对象与代理对象都要维护.\n\n\n### 动态代理\n动态代理有以下特点:\n\n1.代理对象,不需要实现接口\n\n2.代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)\n\n3.动态代理也叫做:JDK代理,接口代理\n\n#### JDK中生成代理对象的API\n代理类所在包:java.lang.reflect.Proxy\n\nJDK实现代理只需要使用newProxyInstance方法,但是该方法需要接收三个参数,完整的写法是:\n```java\nstatic Object newProxyInstance(ClassLoader loader, \n            Class[] interfaces,InvocationHandler h )\n```\n注意该方法是在Proxy类中是静态方法,且接收的三个参数依次为:\n\n1、ClassLoader loader,:指定当前目标对象使用类加载器,获取加载器的方法是固定的\n2、Class[] interfaces,:目标对象实现的接口的类型,使用泛型方式确认类型\n3、InvocationHandler h:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入\n\n代码示例：\n接口类IUserDao.java以及接口实现类,目标对象UserDao是一样的,没有做修改.在这个基础上,增加一个代理工厂类(ProxyFactory.java),将代理类写在这个地方,然后在测试类(需要使用到代理的代码)中先建立目标对象和代理对象的联系,然后代用代理对象的中同名方法\n\n1、代理工厂类:ProxyFactory.java\n```java\n/**\n* 创建动态代理对象\n* 动态代理不需要实现接口,但是需要指定接口类型\n*/\npublic class ProxyFactory{\n\n   //维护一个目标对象\n   private Object target;\n   public ProxyFactory(Object target){\n       this.target=target;\n   }\n\n  //给目标对象生成代理对象\n   public Object getProxyInstance(){\n       return Proxy.newProxyInstance(\n               target.getClass().getClassLoader(),\n               target.getClass().getInterfaces(),\n               new InvocationHandler() {\n                   @Override\n                   public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n                       System.out.println(\"开始事务2\");\n                       //执行目标对象方法\n                       Object returnValue = method.invoke(target, args);\n                       System.out.println(\"提交事务2\");\n                       return returnValue;\n                   }\n               }\n       );\n   }\n\n}\n```\n2、测试类:App.java\n```java\n/**\n* 测试类\n*/\npublic class App {\n   public static void main(String[] args) {\n       // 目标对象\n       IUserDao target = new UserDao();\n       // 【原始的类型 class cn.itcast.b_dynamic.UserDao】\n       System.out.println(target.getClass());\n\n       // 给目标对象，创建代理对象\n       IUserDao proxy = (IUserDao) new ProxyFactory(target).getProxyInstance();\n       // class $Proxy0   内存中动态生成的代理对象\n       System.out.println(proxy.getClass());\n\n       // 执行方法   【代理对象】\n       proxy.save();\n   }\n}\n```\n\n代理对象不需要实现接口,但是目标对象一定要实现接口,否则不能用动态代理\n\n### Cglib代理\n上面的静态代理和动态代理模式都是要求目标对象是实现一个接口的目标对象,但是有时候目标对象只是一个单独的对象,并没有实现任何的接口,这个时候就可以使用以目标对象子类的方式类实现代理,这种方法就叫做:Cglib代理.\n\nCglib代理,也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展.\nJDK的动态代理有一个限制,就是使用动态代理的对象必须实现一个或多个接口,如果想代理没有实现接口的类,就可以使用Cglib实现.\nCglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接口.它广泛的被许多AOP的框架使用,例如Spring AOP和synaop,为他们提供方法的interception(拦截)\nCglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类.不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉.\n\n#### Cglib子类代理实现方法\n\n1、需要引入cglib的jar文件,但是Spring的核心包中已经包括了Cglib功能,所以直接引入spring-core-3.2.5.jar即可.\n2、引入功能包后,就可以在内存中动态构建子类\n3、代理的类不能为final,否则报错\n4、目标对象的方法如果为final/static,那么就不会被拦截,即不会执行目标对象额外的业务方法.\n\n代码示例:\n1、目标对象类:UserDao.java\n```java\n/**\n* 目标对象,没有实现任何接口\n*/\npublic class UserDao {\n\n   public void save() {\n       System.out.println(\"----已经保存数据!----\");\n   }\n}\n```\n2、Cglib代理工厂:ProxyFactory.java\n```java\n/**\n* Cglib子类代理工厂\n* 对UserDao在内存中动态构建一个子类对象\n*/\npublic class ProxyFactory implements MethodInterceptor{\n   //维护目标对象\n   private Object target;\n\n   public ProxyFactory(Object target) {\n       this.target = target;\n   }\n\n   //给目标对象创建一个代理对象\n   public Object getProxyInstance(){\n       //1.工具类\n       Enhancer en = new Enhancer();\n       //2.设置父类\n       en.setSuperclass(target.getClass());\n       //3.设置回调函数\n       en.setCallback(this);\n       //4.创建子类(代理对象)\n       return en.create();\n\n   }\n\n   @Override\n   public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {\n       System.out.println(\"开始事务...\");\n\n       //执行目标对象的方法\n       Object returnValue = method.invoke(target, args);\n\n       System.out.println(\"提交事务...\");\n\n       return returnValue;\n   }\n}\n```\n\n3、测试类:\n```java\n/**\n* 测试类\n*/\npublic class App {\n\n   @Test\n   public void test(){\n       //目标对象\n       UserDao target = new UserDao();\n\n       //代理对象\n       UserDao proxy = (UserDao)new ProxyFactory(target).getProxyInstance();\n\n       //执行代理对象的方法\n       proxy.save();\n   }\n}\n```\n\n在Spring的AOP编程中:\n\n如果加入容器的目标对象有实现接口,用JDK代理.\n如果目标对象没有实现接口,用Cglib代理.\n","tags":["Java","设计模式"],"categories":["Java","设计模式"]},{"title":"equals()和hashCode()的关系","url":"/2019/03/12/equals-和hashCode-的关系/","content":"\n### 简介\n\nJava的基类Object提供了一些方法，其中equals()方法用于判断两个对象是否相等，hashCode()方法用于计算对象的哈希码。equals()和hashCode()都不是final方法，都可以被重写(overwrite)。\n\n### equal()方法\nObject类中equals()方法实现如下：\n\n![Object.equals](Object.equals.png)\n通过该实现可以看出，Object类的实现采用了区分度最高的算法，即**只要两个对象不是同一个对象，那么equals()一定返回false**。\n当我们在重写equals()方法时，有以下事项是要遵守的：\n\n> - 自反性：x.equals(x)必须返回true\n\n> - 对称性：x.equals(y)与y.equals(x)的返回值必须相等\n\n> - 传递性：x.equals(y)为true，y.equals(z)也为true，那么x.equals(z)必须为true\n\n> - 一致性：如果对象x和y在equals()中使用的信息都没有改变，那么x.equals(y)值始终不变\n\n> - 非null：x不是null，y为null，则x.equals(y)必须为false\n\n### hashCode()方法\nObject的hashCode()方法实现如下：\n![Object.hashCode](Object.hashCode.png)\n\n可以看出，hashCode()是一个native方法，而且返回值类型是整形；实际上，该native方法将**对象在内存中的地址作为哈希码**返回，可以保证不同对象的返回值不同。\n\n与equals()方法类似，hashCode()方法可以被重写。重写时，应该注意以下事项：\n> - 如果对象在equals()中使用的信息都没有改变，那么hashCode()值始终不变。\n\n> - 如果两个对象使用equals()方法判断为相等，则hashCode()方法也应该相等。\n\n> - 如果两个对象使用equals()方法判断为不相等，则不要求hashCode()也必须不相等；但是开发人员应该认识到，不相等的对象产生不相同的hashCode可以提高哈希表的性能。\n\n#### hashCode的作用\n总的来说，hashCode()在哈希表中起作用，如HashSet、HashMap等。\n\n当我们向哈希表(如HashSet等)中添加对象object时，首先调用hashCode()方法计算object的哈希码，通过哈希码可以直接定位object在哈希表中的位置(一般是哈希码对哈希表大小取余)。如果该位置没有对象，可以直接将object插入该位置；如果该位置有对象(可能有多个，通过链表实现)，则调用equals()方法比较这些对象与object是否相等，如果相等，则不需要保存object；如果不相等，则将该对象加入到链表中。\n\n这也就解释了为什么equals()相等，则hashCode()必须相等。如果两个对象equals()相等，则它们在哈希表(如HashSet等)中只应该出现一次；如果hashCode()不相等，那么它们会被散列到哈希表的不同位置，哈希表中出现了不止一次。\n\n实际上，在JVM中，加载的对象在内存中包括三部分：对象头、实例数据、填充。其中，对象头包括指向对象所属类型的指针和MarkWord，而MarkWord中除了包含对象的GC分代年龄信息、加锁状态信息外，还包括了对象的hashcode；对象实例数据是对象真正存储的有效信息；填充部分仅起到占位符的作用, 原因是HotSpot要求对象起始地址必须是8字节的整数倍。\n\n### String中equals()和hashCode()的实现\n![String.equal](String.equal.png)\n![String.hashCode](String.hashCode.png)\n\n通过代码可以得知：\n\n- String的数据是final的，即**一个String对象一旦创建，便不能修改**；形如String s = “hello”; s = “world”;的语句，当s = “world”执行时，并不是字符串对象的值变为了”world”，而是新建了一个String对象，s引用指向了新对象。\n- String类将hashCode()的结果缓存为hash值，提高性能。\n- String对象equals()相等的条件是二者同为String对象，长度相同，且字符串值完全相同；不要求二者是同一个对象。\n- String的hashCode()计算公式为：s[0]*31^(n-1) + s[1]*31^(n-2) + … + s[n-1]\n\n#### 关于hashCode()计算过程中，为什么使用了数字31\n\n- 使用质数计算哈希码，由于质数的特性，它与其他数字相乘之后，计算结果唯一的概率更大，哈希冲突的概率更小。\n- 使用的质数越大，哈希冲突的概率越小，但是计算的速度也越慢；31是哈希冲突和性能的折中，实际上是实验观测的结果。\n- JVM会自动对31进行优化：31 * i == (i << 5) – i\n\n#### 如何重写hashCode方法\n重写hashCode需要遵守以下原则：\n\n1、如果重写了equals()方法，检查条件“两个对象使用equals()方法判断为相等，则hashCode()方法也应该相等”是否成立，如果不成立，则重写hashCode ()方法\n2、hashCode()方法不能太过简单，否则哈希冲突过多\n3、hashCode()方法不能太过复杂，否则计算复杂度过高，影响性能\n\n\n在《Effective Java》中提出了一种简单通用的hashCode算法：\nA、初始化一个整形变量，为此变量赋予一个非零的常数值，比如int result = 17;\n\nB、选取equals方法中用于比较的所有域（之所以只选择equals()中使用的域，是为了保证上述原则的第1条），然后针对每个域的属性进行计算：\n\n1) 如果是boolean值，则计算f ? 1:0；\n2) 如果是byte\\char\\short\\int,则计算(int)f；\n3) 如果是long值，则计算(int)(f ^ (f >>> 32))；\n4) 如果是float值，则计算Float.floatToIntBits(f)；\n5) 如果是double值，则计算Double.doubleToLongBits(f)，然后返回的结果是long,再用规则(3)去处理long,得到int；\n6) 如果是对象应用，如果equals方法中采取递归调用的比较方式，那么hashCode中同样采取递归调用hashCode的方式。否则需要为这个域计算一个范式，比如当这个域的值为null的时候，那么hashCode 值为0；\n7) 如果是数组，那么需要为每个元素当做单独的域来处理。java.util.Arrays.hashCode方法包含了8种基本类型数组和引用数组的hashCode计算，算法同上。\n\nC、最后，把每个域的散列码合并到对象的哈希码中。 \n\n实例说明：\n![Person](Person.png)\n![person.equal](person.equal.png)\n","tags":["Java"],"categories":["Java"]},{"title":"单例模式","url":"/2019/03/12/单例模式/","content":"\n### 简介\n单例模式即一个JVM内存中只存在一个类的对象实例\n![UML](UML.png)\n### 分类\n1、饿汉式\n\n类加载的时候就创建实例\n\n2、懒汉式\n\n使用的时候才创建实例\n\n当然还有其他的生成单例的方式，双重校验锁，枚举和静态内部类\n\n### 实践\n\n1、线程不安全，不可用\n```java\npublic class Singleton {  \n\n    private static Singleton instance;  \n\n    private Singleton (){}  \n\n  \n\n    public static Singleton getInstance() {  \n\n    if (instance == null) {  \n\n        instance = new Singleton();  \n\n    }  \n\n    return instance;  \n\n    }  \n\n} \n```\n\n\n2、线程安全，同步方法，效率低，不推荐\n```java\npublic class Singleton {  \n\n    private static Singleton instance;  \n\n    private Singleton (){}  \n\n    public static synchronized Singleton getInstance() {  \n\n    if (instance == null) {  \n\n        instance = new Singleton();  \n\n    }  \n\n    return instance;  \n\n    }  \n\n} \n```\n\n\n3、线程不安全，会产生多个实例，不可用\n```java\npublic class Singleton {\n\n    private static Singleton singleton;\n\n\tprivate Singleton() {}\n\n\n\n    public static Singleton getInstance() {\n\n        if (singleton == null) {\n\n            synchronized (Singleton.class) {\n\n                singleton = new Singleton();\n\n            }\n\n        }\n\n        return singleton;\n\n    }\n\n}\n```\n\n4、无线程安全问题，不能延迟加载，影响系统性能\n```java\n\npublic class Singleton {  \n\n    private static Singleton instance = new Singleton();  \n\n    private Singleton (){}  \n\n    public static Singleton getInstance() {  \n\n\t\treturn instance;  \n\n    }  \n\n} \n\n```\n\n5、双重校验锁，线程安全，推荐使用\n```java\npublic class Singleton {\n\n    private static volatile Singleton singleton;\n\n    private Singleton() {} //private类型禁止外界new创建\n\n\n\n    public static Singleton getInstance() {\n\n        if (singleton == null) {\n\n            synchronized (Singleton.class) {\n\n                if (singleton == null) {\n\n                    singleton = new Singleton();\n\n                }\n\n            }\n\n        }\n\n        return singleton;\n\n    }\n\n} \n```\n\n\n6、静态内部类，线程安全，主动调用时才实例化，延迟加载效率高，推荐使用\n```java\npublic class Singleton {  \n\n    private static class SingletonHolder {  \n\n\t\tprivate static final Singleton INSTANCE = new Singleton();  \n\n    }  \n\n    private Singleton (){}  //private类型禁止外界new创建\n\n    public static final Singleton getInstance() {  \n\n\t\treturn SingletonHolder.INSTANCE;  \n\n    }  \n\n} \n```\n7、枚举类型，无线程安全问题，避免反序列华创建新的实例，很少使用\n```java\npublic enum Singleton {  \n\n    INSTANCE;  \n\n    public void whateverMethod() {  \n\n    }  \n\n}\n```\n### 注意事项\n1、考虑多线程问题\n\n2、单例类构造方法要设置为private类型禁止外界new创建\n\nprivate Singleton() {}\n\n3、如果类可序列化，考虑反序列化生成多个实例问题，解决方案如下\n```java\nprivate Object readResolve() throws ObjectStreamException {  \n\n\t// instead of the object we're on, return the class variable INSTANCE  \n\n\treturn INSTANCE;  \n\n}  \n```\n### 使用场景\n1、工具类对象\n\n2、系统中只能存在一个实例的类\n\n3、创建频繁或又耗时耗资源且又经常用到的对象\n下面是单例模式在JDK的应用\n![runtime](runtime.png)\n\n另外，spring容器中的实例默认是单例饿汉式类型的，即容器启动时就实例化bean到容器中，当然也可以设置懒汉式defalut-lazy-init=\"true\"为延迟实例化，用到时再实例化。\n\n### 参考资料\n[设计模式之单例模式实践](https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247483742&idx=1&sn=9429b26871f19e4dafd1bf0c7ec0520e&chksm=eb538468dc240d7e968486dbdb7fa440b365ac81a3d9920013781776b601754b1a0659b92b70&scene=21#wechat_redirect)","tags":["Java","设计模式"],"categories":["Java","设计模式"]},{"title":"MySQL 解锁与锁表","url":"/2019/03/11/MYSQL 解锁与锁表/","content":"\n### Mysql三种锁机制\n\nMyISAM和MEMORY存储引擎采用的是表级锁（table-level locking）；\nBDB存储引擎采用的是页面锁（page-level locking），但也支持表级锁；\nInnoDB存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。\n\n> - 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。\n \n> - 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。\n \n> - 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。\n\n### 查询表级锁争用情况\n可以通过table_locks_waited和table_locks_immediate状态变量来分析系统上的表锁定情况，使用输入以下命令来获得。\n```sql\nshow status like 'table%';\n```\n> - table_locks_waited：表示表级锁争用而发生等待的次数（不能立即获取锁的次数，每等待一次锁值加1），此值高则说明存在较严重的表级锁竞争情况。\n> - table_locks_immediate：产生表级锁定的次数，表示可以立即获取锁的查询次数，每立即获取锁值加1\n\n### 查询行级锁争用情况\n\n可以通过innodb_row_lock状态变量来分析系统上的行锁竞争情况，使用输入以下命令来获得。\n```sql\nshow status like 'innodb_row_lock%';\n```\n> - innodb_row_lock_current_waits:当前正在等待锁定的数量\n> - innodb_row_lock_time:从系统启动到现在锁定总时间长度\n> - innodb_row_lock_time_avg:每次等待所花平均时间\n> - innodb_row_lock_time_max:从系统启动到现在等待最长的一次所花时间\n> - innodb_row_lock_time_waits:系统启动后到现在总共等待的次数\n\n对于这5个状态变量，比较重要的是：\n\n> - innodb_row_lock_time_avg （等待平均时长） \n> - innodb_row_lock_waits （等待总次数） \n> - innodb_row_lock_time（等待总时长） \n尤其是当等待次数很高，而且每次等待时长也不小的时候\n\n\n### 锁表\n\n#### 读锁\n锁定数据表，避免在备份过程中，表被更新\n```sql\nlock tables tbl_name read;\n```\n#### 写锁\n```sql\nlock tables tbl_name write;\n```\n\n### 解锁\n1、找到锁进程，然后kill id\n```sql\nshow processlist;\n\nkill <id>;\n```\n2、直接解锁\n```sql\nunlock tables;\n```\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL中的锁机制（表锁、行锁）","url":"/2019/03/11/MySQL中的锁机制（表锁、行锁）/","content":"\nMysql锁机制比较简单，但其最显著的特点是不同的存储引擎支持不同的所机制。\n大致上可分为以下3种锁：\n- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低\n- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度最高\n- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般\n\n### 表级锁（MyISAM）\nMysql表级锁有两种模式：表共享锁（Table Read Lock）和表独占写锁（Table Write Lock）\n- 对MyISAM的读操作，不会阻塞其他用户对同一表的`读请求`，但会阻塞对同一表的写请求\n- 对MyISAM的写操作，则会阻塞其他用户对同一表的读和写操作\n\nMyISAM表的读和写之间、写与写之间是串行的，读与读之间是并行的，即读写、写写互斥；当一个线程获得对一个表的写锁后，只有持有锁线程可以对表进行更新操作。其他线程的读、写操作都会等待直到锁被释放为止。\n\n#### 加锁过程\nMyISAM在执行查询语句（select）前，会自动给涉及的所有表加读锁，在执行更新操作（update、delete、insert）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此用户一般不需要直接使用`LOCK TABLE`命令给MyISAM表显示加锁。\n下面对MyISAM显示加锁的命令进行讲解\n```sql\nLOCK tables table_name read local\n```\n> local选项，其作用就是在满足MyISAM表并发插入条件的情况下，允许其他用户在表尾插入记录\n在用LOCK  tables给表显示加表锁时，必须同时取得所有涉及表的锁，并且MYSQL支持锁升级。也就是说，在执行LOCK TABLES后，只能访问显示加锁的这些表，不能访问加锁的表；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。其实，在自动加锁的情况下也基本如此，MYSQL一次性获得SQL语句所需要的全部锁。这也正是MyISAM表不会出现死锁（deadlock free）的原因。\n\n一次session使用LOCK TABLES命令给表加了读锁，这个session可以查询锁定表中的记录，但更新或访问其他表都会提示错误；同时，另外一个session可以查询表中的记录，但更新就会出现锁等待。当使用LOCK TABLES时，不仅需要一次锁定用到的所有表，而且，同一个表在SQL语句中出现多少次，就要通过与SQL语句中相同的别名锁多少次，否则也会出错。\n\n#### 并发锁\nMyISAM在读操作占主导的情况下是很高效的。可一旦出现大量的读写并发，同InnoDB相比，MyISAM的效率就会直线下降，而且，MyISAM和InnoDB的数据存储方式也有显著不同：通常，在MyISAM里，新数据会被附加到数据文件的结尾，可如果时常做一些UPDATE，DELETE操作之后，数据文件就不再是连续的，形象一点来说，就是数据文件里出现了很多洞洞，此时再插入新数据时，按缺省设置会先看这些洞洞的大小是否可以容纳下新数据，如果可以，则直接把新数据保存到洞洞里，反之，则把新数据保存到数据文件的结尾。之所以这样做是为了减少数据文件的大小，降低文件碎片的产生。但InnoDB里则不是这样，在InnoDB里，由于主键是cluster的，所以，数据文件始终是按照主键排序的，如果使用自增ID做主键，则新数据始终是位于数据文件的结尾。\n\n在一定条件下，MyISAM也支持查询和更新的并发进行。\nMyISAM存储引擎有一个系统变量concurrent_insert，专门用以控制其并发插入行为，其值分别可分为0、1、2。\n\n> - 当concurrent_insert设置为0时，不允许并发插入\n> - 当concurrent_insert设置为1时，如果MyISAM允许在一个读表的同时，另一个进程从表尾插入记录。这也是MySQL的默认设置。\n> - 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾插入记录，都允许在表尾并发插入记录。\n\n可以利用MyISAM存储引擎的并发插入特性，来解决应用中对同一表查询和插入锁争用。例如，将concurrent_insert系统变量为2，总是允许并发插入；同时，通过定期在系统空闲时段执行OPTIONMIZE TABLE语句来整理空间碎片，收到因删除记录而产生的中间空洞。\n\n#### MyISAM锁调度机制\n当一个进程请求某个MyISAM表的读锁，同时另一个进程也请求同一表的写锁时，写进程会先获得锁！这也正是MyISAM表不太适合于大量更新操作和查询操作应用的原因，大量的更新操作会造成查询很难获得读锁，从而可能永远阻塞。可以通过设置以下手段来调整\n\n> - 通过指定启动参数low_priority_updates，使MyISAM引擎默认给予读请求以优先的权利\n> - 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级\n\n另外，MYSQL也提供了一种折中得办法来调节读写冲突，即给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL变暂时将写请求的优先级降低，给读进程一定获得锁的机会。\n\n应用中应尽量避免出现长时间运行的查询操作，不要总想用一条SELECT语句来解决问题。因为这种看似巧妙的SQL语句，往往比较复杂，执行时间较长，在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解”，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。\n \n\n### 行级锁（InnoDB）\nInnoDB与MyISAM的最大不同有两点：1、支持事务；2、采用了行级锁。\n\n#### 事务及其ACID属性\n事务是由一组SQL语句组成的逻辑处理单元。事务具有ACID属性。\n> - 原子性（Actomicity）: 事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。\n> - 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持完整性；事务结束时，所有的内部数据结构（B树索引或双向链表）也都必须是正确的。\n> - 隔离性（isolation）： 数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的独立环境执行。这意味着事务处理过程中的中间状态对外部是不可见的。\n> - 持久性（Durable）： 事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。\n\n#### 并发事务带来的问题\n> - 更新丢失（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题，最后的更新覆盖了其他事务所作的更新。\n> - 脏读（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些脏的数据，并据此做了进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做脏读。\n　一句话：事务A读取到了事务B已经修改但尚未提交的数据，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求。 \n> - 不可重复读（Non-Repeatable Reads）： 一个事务在读取了某些数据后的某个时间，再次读取以前读取过的数据，却发现其读出的数据`已经发生了改变！`这种现象叫做不可重复读。\n一句话：事务A读取到了事务B已经提交的修改数据，不符合隔离性 \n> - 幻读（Phantom Reads）： 　一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务`插入了满足其查询条件的新数据或某些记录已经被删除了`，这种现象就称为“幻读”。一句话：事务A读取到了事务B提交的新增数据或事务B删除了数据，不符合隔离性\n\n#### 事务隔离级别\n要防止`更新丢失`，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决。因此，防止更新丢失应该是应用的责任。\n`脏读`，`不可重复读`和`幻读`，都是数据库一致性问题，必须由数据库提供一定的事务隔离机制来解决。\n数据库实现`事务隔离（isolation）`的方式，基本可分为以下两种（悲观锁和乐观锁）：\n- 悲观锁方式：一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改；\n- 乐观锁方式：不用加锁，通过一定机制生成一个数据请求时间点的一致性数据快照，并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度，好像是数据库可以提供同一个数据的多个版本，这种技术叫做数据多版本并发控制（ＭultiVersion Concurrency Control，简称MVCC或MCC），也称为多版本数据库。\n\n#### 4种隔离级别\n> - Serializable （串行化）：最严格的级别，事务串行执行，资源消耗最大；\n\n> - REPEATABLE READ（重复读） ：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但不能避免“幻读”，但是带来了更多的性能损失。\n\n> - READ COMMITTED （提交读）：大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读取”，但不能避免“幻读”和“不可重复读取”。该级别适用于大多数系统。\n\n> - Read Uncommitted（未提交读） ：事务中的修改，即使没有提交，其他事务也可以看得到，会导致“脏读”、“幻读”和“不可重复读取”。\n\n数据库的事务隔离级别越严格，并发副作用越小，但事务执行效率越差。因为事务隔离实质上就是使事务在一定程度上\"串行化\"执行。\n\n#### 数据库一致性问题\n> - 脏读：所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。\n\n也就是说，当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。\n\n> - 不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。\n\n也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。\n\n> - 幻读：事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。\n\n也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。\n\n不可重复读和幻读比较：\n两者有些相似，但是前者针对的是update或delete，后者针对的insert。\n\n\n#### 事务4种隔离级别比较\n\n| 隔离级别/读数据一致性及允许的并发副作用        | 读数据一致性      | 脏读    | 不可重复读  |  幻读 |\n| ------------- | -------------: | -------------: | -------------: | :-----:|\n| 未提交读（Read uncommitted）     | 最低级别，只能保证不读取物理上损坏的数据 | 是 | 是 | 是 |\n| 已提交读（Read committed）       | 语句级\t | 否 | 是 | 是 |\n| 可重复读（Repeatable read）      | 事务级 | 否 | 否 | 是 |\n| 可序列化（Serializable）         | 最高级别，事务级 | 否 | 否 | 否 |\n\nMysql查看事务隔离级别命令为\n```sql\nshow  VARIABLES like '%tx_isolation%'\n```\nOracle只提供Read committed（默认）和Serializable两个标准级别，另外还自己定义的Read only隔离级别：ＭySQL支持全部４个隔离级别，默认为REPEATABLE-READ。\n\n#### InnoDB的行锁模式及加锁方法\nInnoDB实现了以下两种类型的行锁\n> - 共享锁：又称为读锁，简称S锁，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。\n> - 排他锁：又称为写锁，简称X锁，顾名思义，排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。\n\n另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。\n\n> - 意向共享锁（IS）：事务打算给数据行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。\n> - 意向排他锁（IX）： 事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。\n\n#### InnoDB行锁模式兼容性列表\n\n| 当前锁模式/是否兼容/请求锁模式       | X     | IX    | S  |  IS |\n| ------------- | -------------: | -------------: | -------------: | :-----: |\n|       X     | 冲突 | 冲突 | 冲突 | 冲突 |\n|      IX     | 冲突 | 兼容 | 冲突 | 兼容 |\n|       S     | 冲突 | 冲突 | 兼容 | 兼容 |\n|      IS     | 冲突 | 兼容 | 兼容 | 兼容 |\n\n如果一个事务请求的锁模式与当前的锁兼容，Innodb就请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。\n意向锁是InnoDB自动加的，不需用户干预。对于update、delete和insert语句，innodb会自动给涉及数据行加排他锁；对于普通的select语句，innodb不会加任何锁。事务可以通过以下语句显示给记录集加共享锁和排他锁。\n共享锁（S）： select * from table_name where ... lock in share mode;\n排他锁（X）： select * from table_name where ... for update;\n 用select...in share mode获得共享锁，主要用在需要数据依存关系时确认某行记录是否存在，并确保没有人对这个记录进行update或者delete操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定记录后需要进行更新操作的应用，应该用select...for update方式获取排他锁。\n\n#### innodb实现行锁的方式\ninnodb行锁是通过索引上的索引项来实现的，Oracle是通过在数据中对相应数据行加锁来实现的，innodb行锁只有通过索引条件检索数据，innodb才会使用到行锁，否则，innodb将使用表锁！\n在实际应用中，要特别注意innodb行锁这一特性，不然可能会导致大量的锁冲突，从而影响并发性能。\n\n### 间隙锁（Next-Key锁）\n当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，innodb会给符合条件的已有数据索引项加锁；对于键值在条件范围内但不存在的记录，叫做间隙（GAP），innodb也会对这个间隙加锁。\n举例来说，假如emp表中只有101条记录，其中empid的值分别是1-101，下面的SQL：\n```sql\nselect * from emp where empid > 100 for update;\n```\n是一个范围条件的检索，innodb不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101的数据加锁，尽管这些数据不存在。\ninnodb使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求。如果不使用间隙锁，其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另一方面，是为了满足其恢复和复制的需要。\n很显然，在使用范围条件检索并锁定记录时，innodb这种加锁机制会阻塞符合条件范围内键值的并发插入。这种往往会造成严重的锁等待。因此，在实际开发中，尤其是并发插入比较多的应用，我们尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件！\n\n### 使用表锁的场景\n对于innodb表，在绝大部分情况下都应该使用行锁，因为事务和行锁是我们选择innodb表的理由。但在特殊的事务中，也可以考虑使用表锁。\n- 事务需要更新大部分或全部数据，表又比较大。如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。\n- 事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。\n\n在innodb下，使用表锁要注意以下两点：\n> - 使用lock tables虽然可以给innodb加表锁，但表锁不是innodb存储引擎管理的，而是由其上一层MySQL Server负责的，仅当autocommit=0、innodb_table_lock=1（默认设置）时，innodb层才能直到Mysql加的表锁，Mysql Server才能感知Innodb加的行锁，这种情况下，innodb才能自动识别涉及表锁的死锁，否则，innodb将无法自动检测并处理这种死锁。\n> - 在用lock tables对innodb锁时要注意，要将autocommit=0，否则MySQL不会给表加锁；事务结束前，不要用UNLOCAK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK产不能释放用LOCAK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁。\n\n### 死锁\n死锁的四个必要条件：\n> - 互斥条件(Mutual exclusion)：资源不能被共享，只能由一个进程使用。\n> - 请求与保持条件(Hold and wait)：已经得到资源的进程可以再次申请新的资源。\n> - 非剥夺条件(No pre-emption)：已经分配的资源不能从相应的进程中被强制地剥夺。\n> - 循环等待条件(Circular wait)：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源。\n\n\nMyISAM表锁是deadlock free的，因为MyISAM总是一次性获得所需要的全部锁。而在innodb中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了innodb发生死锁的可能性。\n发生死锁后，innodb一般都能自动检测到，并使一个事务释放锁并退回，另一个事务获得锁，继续完成事务。但在涉及外部锁的情况下，innodb并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodb_lock_wait_timeout来解决。需要说明的是，这个参数并不是只是用来解决死锁问题，，在并发访问比较高的情况下，如果大量事务因无法立即获取所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖垮数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。\n\n#### 导致死锁情况\n- 在应用中，如果不同的程序会并发存取多个表，应尽量约定按相同的顺序访问表，这样可以大大降低产生死锁的机会。如果两个session访问两个表的顺序不同，发生死锁的机会就非常高！但如果以相同的顺序来访问，死锁就可能避免。\n- 在程序按批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低死锁的可能性\n- 在事务中，如果要更新记录，应该直接申请足够级别的锁，排他锁，而不是应该先申请共享锁，更新时再申请排他锁，甚至死锁。\n- 在REPEATEABLE READ隔离级别下，如果两个线程同时对相同条件记录用SELECT...ROR UPDATE加排他锁，在没有符合该记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录。如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可以避免问题。\n- 当隔离级别为READ COMMITED时，如果两个线程都先执行SELECT...FOR UPDATE，判断是否存在符号条件记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现所等待，当第1个线程提交后，第2个线程会因主键出错，但是这个线程出错了，却会获得一个排他锁！这时如果有第3个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键异常，或者在遇到主键错误时，总是执行ROLLBACK释放获得的排他锁。\n 如果出现死锁，可以用SHOW ENGINE INNODB STATUS命令来确定最后一个死锁产生的原因和改进措施。\n\n\n### 总结\n\n对于MyISAM的表锁，主要有以下几点：\n- 共享读锁（S）之间是兼容的，但共享读锁（S）和排他写锁（X）之间，以及排他写锁（X）之间是互斥的，也就是读和写是串行的。\n- 在一定条件下，MyISAM允许查询和插入并发执行，我们可以利用这一点来解决应用中对同一表和插入的锁竞争问题。\n- MyISAM默认的锁调度机制是写有限，这不一定适合所有应用，用户可以通过设置LOW_PRIPORITY_UPDATES参数，或在INSERT、UPDATE、DELETE语句中指定LOW_PRIORITY选项来调节读写锁的争用。\n- 由于表锁的锁定粒度大，读写之间又是串行的，因此，如果更新操作较多，MyISAM表可能会出现严重的锁等待，可以考虑采用innodb表来减少锁冲突\n\n\n对于innodb表，主要有以下几点：\n- innodb的行锁是基于索引实现的，如果不通过索引访问数据，innodb会使用表锁\n- innodb锁冲突甚至死锁很难完全避免\n\n在了解InnoDB的锁特性后，用户可以通过设计和SQL调整等措施减少锁冲突和死锁，包括：\n- 尽量使用较低的隔离级别\n- 精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会。\n- 选择合理的事务大小，小事务发生锁冲突的几率也更小。\n- 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁。\n- 不同程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大减少死锁的机会。\n- 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响。\n- 不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁。\n- 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。\n\n\n### 参考资料\n- [通俗地解释脏读、不可重复读、幻读](https://blog.csdn.net/Somhu/article/details/78775198)\n- [mysql死锁问题分析](https://www.cnblogs.com/LBSer/p/5183300.html)","tags":["MySQL"],"categories":["MySQL"]},{"title":"Mybatis之拦截器实现及原理","url":"/2019/03/11/Mybatis之拦截器实现及原理/","content":"\n### 为什么要有插件\n可以在映射语句执行前后加一些自定义的操作，比如缓存、分页等\n\n### 可以拦截哪些方法\nExecutor：update、query、flushStatements、commit、rollback、getTransaction、close、isClosed。\n实现类：SimpleExecutor/BatchExecutor/ReuseExecutor/CachingExecutor\n\nParameterHandler：getParameterObject、setParameters。\n实现类：DefaultParameterHandler\n\nResultSetHandler：handleResultSets、handleOutputParameters。\n实现类：DefaultResultSetHandler\n\nStatementHandler：prepare、parameterize、batch、update、query。\n实现类：CallableStatementHandler/PreparedStatementHandler/SimpleStatementHandler/RoutingStatementHandler\n\n\n### 如何自定义插件\n1、只需实现Interceptor接口，并指定要拦截的方法签名\n2、还需要在配置文件中配置你编写的插件\n```java\n@Intercepts({\n    @Signature(\n        type=Executor.class,method=\"update\",args={ MappedStatement.class,Object.class })\n})\npublic class ExamplePlugin implements Interceptor {\n    public Object intercept(Invocation invocation) throws Throwable {\n       //自定义实现\n       return invocation.proceed();\n    }\n    public Object plugin(Object target){\n        return Plugin.wrap(target,this)\n    }\n    public void setProperties(Properties properties){\n      //传入配置项\n      String size = properties.getProperty(\"size\");\n    }\n}\n<!-- mybatis-config.xml -->\n<plugins>\n    <plugin interceptor=\"org.mybatis.example.ExamplePlugin\">\n        <!-- 这里的配置项就传入setProperties方法中 -->\n        <property name=\"size\" value=\"100\">\n    </plugin>\n</plugins>\n\n```\n\n### 拦截器实现原理\nMybatis仅可以编写针对ParameterHandler、ResultSetHandler、StatementHandler、Executor这4种接口的插件，Mybatis使用JDK的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这4种接口对象的方法时，就会进入拦截方法，具体就是InvocationHandler的invoke()方法，当然，只会拦截那些你指定需要拦截的方法。\n```java\n//拦截器接口，供外部实现，实现该接口就定义了一个插件\npublic interface Interceptor {\n  //拦截方法，可以将自定义逻辑写在该方法中\n  Object intercept(Invocation invocation) throws Throwable;\n  //包装成插件，一般Plugin.wrap(target,this)就行了\n  Object plugin(Object target);\n  //传入自定义配置参数\n  void setProperties(Properties properties);\n}\n拦截器上定义的注解\n@Intercepts：拦截器注解，包括一个或多个@Signature，拦截的目标类信息\n@Signature：拦截的目标类信息，包括type、method、args，一个@Intercepts中可包含多个@Signature\n\npublic class Invocation {\n  private Object target;//目标对象\n  private Method method;//调用方法\n  private Object[] args;//方法形参列表\n  //省略get和set方法\n  //执行调用，基于动态代理，在Interceptor的intercept方法中一定要调用该方法\n  public Object proceed() throws InvocationTargetException, IllegalAccessException {\n    return method.invoke(target, args);\n  }\n}\n//动态代理实现\npublic class Plugin implements InvocationHandler {\n  private Object target;\n  private Interceptor interceptor;//拦截器\n  private Map<Class<?>, Set<Method>> signatureMap;//拦截目标类的目标方法\n\n  private Plugin(Object target, Interceptor interceptor, Map<Class<?>, Set<Method>> signatureMap) {\n    this.target = target;\n    this.interceptor = interceptor;\n    this.signatureMap = signatureMap;\n  }\n  //包装目标实例\n  public static Object wrap(Object target, Interceptor interceptor) {\n    Map<Class<?>, Set<Method>> signatureMap = getSignatureMap(interceptor);\n    Class<?> type = target.getClass();\n    //目标类所有接口是否有signatureMap中定义的Class\n    Class<?>[] interfaces = getAllInterfaces(type, signatureMap);\n    //如果拦截器中有定义拦截目标类中的方法时，就返回代理实例 \n   if (interfaces.length > 0) {\n      return Proxy.newProxyInstance(\n          type.getClassLoader(),\n          interfaces,\n          new Plugin(target, interceptor, signatureMap));\n    }\n    //没有就返回目标实例\n    return target;\n  }\n\n  @Override\n  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n    try {\n      Set<Method> methods = signatureMap.get(method.getDeclaringClass());\n      //该方法需要拦截\n      if (methods != null && methods.contains(method)) {\n        return interceptor.intercept(new Invocation(target, method, args));\n      }\n      return method.invoke(target, args);\n    } catch (Exception e) {\n      throw ExceptionUtil.unwrapThrowable(e);\n    }\n  }\n  //获取拦截器上的SignatureMap\n  private static Map<Class<?>, Set<Method>> getSignatureMap(Interceptor interceptor) {\n    Intercepts interceptsAnnotation = interceptor.getClass().getAnnotation(Intercepts.class);\n    if (interceptsAnnotation == null) {\n      throw new PluginException(\"No @Intercepts annotation was found in interceptor \" + interceptor.getClass().getName());      \n    }\n    Signature[] sigs = interceptsAnnotation.value();\n    Map<Class<?>, Set<Method>> signatureMap = new HashMap<Class<?>, Set<Method>>();\n    for (Signature sig : sigs) {\n      Set<Method> methods = signatureMap.get(sig.type());//重复定义的只生效一个\n      if (methods == null) {\n        methods = new HashSet<Method>();\n        signatureMap.put(sig.type(), methods);\n      }\n      try {\n        //获取目标类中的指定方法\n        Method method = sig.type().getMethod(sig.method(), sig.args());\n        methods.add(method);\n      } catch (NoSuchMethodException e) {\n        throw new PluginException(\"Could not find method on \" + sig.type() + \" named \" + sig.method() + \". Cause: \" + e, e);\n      }\n    }\n    return signatureMap;\n  }\n\n  private static Class<?>[] getAllInterfaces(Class<?> type, Map<Class<?>, Set<Method>> signatureMap) {\n    Set<Class<?>> interfaces = new HashSet<Class<?>>();\n    while (type != null) {//获取type上的所有接口\n      for (Class<?> c : type.getInterfaces()) {\n        if (signatureMap.containsKey(c)) {//这里不判断Method,只判断Class<?>\n          interfaces.add(c);\n        }\n      }\n      type = type.getSuperclass();\n    }\n    return interfaces.toArray(new Class<?>[interfaces.size()]);\n  }\n}\n```\n在配置文件中定义的过滤器，都保存在Configuration类的interceptorChain中，这个类保存了mybatis的所有配置，interceptorChain类中保存中所有Interceptor集合组成的拦截器链，这个链是如何添加进去的呢？请看源码。\n```java\n  //XMLConfigBuilder类中解析mybatis-config.xml 核心方法parseConfiguration(XNode root)\n  pluginElement(root.evalNode(\"plugins\"));//插件配置项\n\n private void pluginElement(XNode parent) throws Exception {\n    if (parent != null) {\n    //遍历 plugins的子节点plugin\n    for (XNode child : parent.getChildren()) {\n        String interceptor = child.getStringAttribute(\"interceptor\");//获取interceptor属性值\n        Properties properties = child.getChildrenAsProperties();//获取plugin属性值\n        //创建拦截器实例，这里interceptor值也可以是typeAlias注册的简名\n        Interceptor interceptorInstance = (Interceptor) resolveClass(interceptor).newInstance();\n        //设置属性项\n        interceptorInstance.setProperties(properties);\n        //添加到interceptorChain中\n        configuration.addInterceptor(interceptorInstance);\n      }\n    }\n  }\n  //Configuration类,添加拦截器\n  public void addInterceptor(Interceptor interceptor) {\n    interceptorChain.addInterceptor(interceptor);\n  }\n```\n### 拦截的哪些接口\n```java\n //SQL语句处理器\n  public interface StatementHandler {\n    //预备工作\n    Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException;\n    //参数处理\n    void parameterize(Statement statement) throws SQLException;\n    //批量处理\n    void batch(Statement statement)  throws SQLException;\n    //更新处理\n    int update(Statement statement) throws SQLException;\n    //查询处理\n    <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException;\n  }\n  //返回集处理器\n  public interface ResultSetHandler {\n    //处理返回结果\n    <E> List<E> handleResultSets(Statement stmt) throws SQLException;\n    //处理输出参数\n    void handleOutputParameters(CallableStatement cs) throws SQLException;\n  }\n  //参数处理器\n  public interface ParameterHandler {\n     \n    Object getParameterObject();\n\n    void setParameters(PreparedStatement ps) throws SQLException;\n  }\n```\n### 如何拦截这些接口\n```java\n//创建相应Handler时会将所有拦截器通过动态代理方式返回代理Handler\npublic class Configuration {\n\n  //创建ParameterHandler(参数处理器)\n  public ParameterHandler newParameterHandler(MappedStatement mappedStatement, \n        Object parameterObject, BoundSql boundSql) {\n  // 根据指定Lang(默认RawLanguageDriver)，创建ParameterHandler，将实际参数传递给JDBC语句\n    ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(\n        mappedStatement, parameterObject, boundSql);\n    //返回代理实例\n    parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler);\n    return parameterHandler;\n  }\n\n  //创建ResultSetHandler(结果处理器)\n  public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, \n     RowBounds rowBounds,ParameterHandler parameterHandler,\n     ResultHandler resultHandler,BoundSql boundSql) {\n    //默认使用DefaultResultSetHandler创建ResultSetHandler实例\n    ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement,\n       parameterHandler, resultHandler, boundSql, rowBounds);\n    //返回代理实例\n    resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler);\n    return resultSetHandler;\n  }\n\n  //创建StatementHandler(SQL语句处理器)\n  public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, \n    Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) {\n    //默认使用RoutingStatementHandler(路由作用)\n    //创建指定StatementHandler实例(默认SimpleStatementHandler)\n    StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, \n          parameterObject, rowBounds, resultHandler, boundSql);\n    //返回代理实例\n    statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler);\n    return statementHandler;\n  }\n\n  //创建Executor(执行器)\n  public Executor newExecutor(Transaction transaction, ExecutorType executorType) {\n    //获取executorType，默认是SIMPLE\n    executorType = executorType == null ? defaultExecutorType : executorType;\n    //这一行感觉有点多余啊\n    executorType = executorType == null ? ExecutorType.SIMPLE : executorType;\n    Executor executor;\n    if (ExecutorType.BATCH == executorType) {  //批量执行\n      executor = new BatchExecutor(this, transaction);\n    } else if (ExecutorType.REUSE == executorType) {  //重用\n      executor = new ReuseExecutor(this, transaction);\n    } else {\n      executor = new SimpleExecutor(this, transaction);//通用\n    }\n    if (cacheEnabled) {  //开启缓存\n      executor = new CachingExecutor(executor);\n    }\n    //返回代理实例\n    executor = (Executor) interceptorChain.pluginAll(executor);\n    return executor;\n  }\n}\n//执行器\npublic interface Executor {\n    //更新\n    int update(MappedStatement ms, Object parameter) throws SQLException;\n    //查询(先查缓存)\n    <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, \n          ResultHandler resultHandler, CacheKey cacheKey, BoundSql boundSql) throws SQLException;\n    //查询\n    <E> List<E> query(MappedStatement ms, Object parameter, \n          RowBounds rowBounds, ResultHandler resultHandler) throws SQLException;\n    //查询游标\n    <E> Cursor<E> queryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds) \n          throws SQLException;\n    //刷新Statement\n    List<BatchResult> flushStatements() throws SQLException;\n    //提交事务\n    void commit(boolean required) throws SQLException;\n    //回滚事务\n    void rollback(boolean required) throws SQLException;\n    //创建缓存key\n    CacheKey createCacheKey(MappedStatement ms, Object parameterObject,RowBounds rowBounds, \n          BoundSql boundSql);\n    //是否存在key\n    boolean isCached(MappedStatement ms, CacheKey key);\n    //清除本地缓存\n    void clearLocalCache();\n    //延迟加载\n    void deferLoad(MappedStatement ms, MetaObject resultObject, String property, CacheKey key, \n          Class<?> targetType);\n    //获取事务\n    Transaction getTransaction();\n    //关闭连接\n    void close(boolean forceRollback);\n    //是否关闭\n    boolean isClosed();\n    //设置Executor\n    void setExecutorWrapper(Executor executor);\n}\n```\n### 总结\n当然具体实现肯定不止这么多代码，如果需要了解，需要自行看源码，下面坐下总结。\n- 拦截器实现\nInterceptor接口供插件实现，@Intercepts注解在插件实现上，表示这是一个插件类并配置将要拦截哪些方法，@Signature定义将要拦截的方法信息,如名称/类型/形参列表，Plugin类实现了InvocationHandler接口，是动态代理的具体实现，Invocation类包装了拦截的目标实例，InterceptorChain保存所有拦截器。\n- 如何实现拦截\n创建目标实例，比如A a = new A();\nInterceptor interceptor =  new LogInterceptor();//如果拦截a中的save方法\n将A b = (A)interceptor.plugin(a);这里b就是a的代理实例，在调用a中的save方法时，实际将调用interceptor的intercept方法，在该方法中一定要调用Invocation的proceed方法并将返回值返回。\n\n\n### 参考资料\n- [Mybatis之插件实现原理](https://www.jianshu.com/p/6d52713fb05e)\n- [10 个 MyBatis 常见面试题](https://mp.weixin.qq.com/s?__biz=MzA3MjMwMzg2Nw==&mid=2247483712&idx=1&sn=0ec86ebc8299492d80bc56e6fac56cb7&chksm=9f2114d4a8569dc20147a15ccc9dd710222a148aa3289b9eca68fca0b532cdbaf4b05d2f95ab&scene=21#wechat_redirect)","tags":["Mybatis"],"categories":["Mybatis"]},{"title":"Mybatis初始化加载过程(一)","url":"/2019/03/11/Mybatis初始化加载过程(一)/","content":"\n### 案例\n先看下一次完成的Mybatis查询过程示例代码：\n```java\nString resource = \"mybatis-config.xml\";\nInputStream inputStream = Resources.getResourceAsStream(resource);\nSqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\nSqlSession sqlSession = sqlSessionFactory.openSession();\nUserMapper userMapper = session.getMapper(UserMapper.class);  \n//调用代理对象方法  \nUser user = userMapper.findUserById(27);  \n//关闭session  \nsession.close();  \n```\n本文先重点分析，以下代码背后的原理\n```java\nSqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\nSqlSession sqlSession = sqlSessionFactory.openSession();\n```\n![sqlSessionFactory与sqlSession](sqlSessionFactory与sqlSession.png)\n\n### SqlSessionFactory创建\n\nMyBatis初始化基本过程：\n\nSqlSessionFactoryBuilder根据传入的数据流生成Configuration对象，然后根据Configuration对象创建默认的SqlSessionFactory实例。\nMyBatis通过加载并XML配置文件，将配置文信息组装成内部的Configuration对象,Configuration对象的组织结构和XML配置文件的组织结构几乎完全。\n\n![sqlSessionFactory](sqlSessionFactory.png)\n\n由此SqlSessionFactory的创建，有以下几个步骤：\n\n> - 调用SqlSessionFactoryBuilder对象的build(inputStream)方法；\n\n> - SqlSessionFactoryBuilder会根据输入流inputStream等信息**创建XMLConfigBuilder对象**;\n\n> - SqlSessionFactoryBuilder调用XMLConfigBuilder对象的parse()方法获取**Configuration对象**；\n\n> - SqlSessionFactoryBuilder根据Configuration对象创建一个**DefaultSqlSessionFactory对象**；\n\n> - SqlSessionFactoryBuilder返回 DefaultSqlSessionFactory对象。\n\nSqlSessionFactoryBuilder相关的代码如下所示：\n```java\npublic SqlSessionFactory build(InputStream inputStream)\n{\n    return build(inputStream, null, null);\n}\npublic SqlSessionFactory build(InputStream inputStream, String environment, Properties properties)\n{\n    try\n    {\n        //2. 创建XMLConfigBuilder对象用来解析XML配置文件，生成Configuration对象\n        XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);\n        //3. 将XML配置文件内的信息解析成Java对象Configuration对象\n        Configuration config = parser.parse();\n        //4. 根据Configuration对象创建出SqlSessionFactory对象\n        return build(config);\n    }\n    catch (Exception e)\n    {\n        throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e);\n    }\n    finally\n    {\n        ErrorContext.instance().reset();\n        try\n        {\n            inputStream.close();\n        }\n        catch (IOException e)\n        {\n            // Intentionally ignore. Prefer previous error.\n        }\n    }\n}\n//从此处可以看出，MyBatis内部通过Configuration对象来创建SqlSessionFactory,用户也可以自己通过API构造好Configuration对象，调用此方法创建SqlSessionFactory\npublic SqlSessionFactory build(Configuration config)\n{\n    return new DefaultSqlSessionFactory(config);\n}\n```\n上述的初始化过程中，涉及到了以下几个对象：\n> - SqlSessionFactoryBuilder ： SqlSessionFactory的构造器，用于创建SqlSessionFactory，采用了Builder设计模式\n> - Configuration ：该对象是mybatis-config.xml文件中所有mybatis配置信息\n> - SqlSessionFactory：SqlSession工厂类，以工厂形式创建SqlSession对象，采用了Factory工厂设计模式\n\n#### 生成Configuration对象过程\n- XMLConfigBuilder会将XML配置文件的信息转换为Document对象，而XML配置定义文件DTD转换成XMLMapperEntityResolver对象，然后将二者封装到XpathParser对象中，XpathParser的作用是提供根据Xpath表达式获取基本的DOM节点Node信息的操作。如下图所示：\n![XpathParser](XpathParser.png)\n\n- 之后XMLConfigBuilder调用parse()方法：会从XPathParser中取出 <configuration>节点对应的Node对象，然后解析此Node节点的子Node：properties, settings, typeAliases,typeHandlers, objectFactory, objectWrapperFactory, plugins, environments,databaseIdProvider, mappers\n```java\n public Configuration parse()\n    {\n        if (parsed)\n        {\n            throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\");\n        }\n        parsed = true;\n        //源码中没有这一句，只有 parseConfiguration(parser.evalNode(\"/configuration\"));\n        //为了让读者看得更明晰，源码拆分为以下两句\n        XNode configurationNode = parser.evalNode(\"/configuration\");\n        parseConfiguration(configurationNode);\n        return configuration;\n    }\n    /*\n    解析 \"/configuration\"节点下的子节点信息，然后将解析的结果设置到Configuration对象中\n    */\n  private void parseConfiguration(XNode root) {\n    try {\n      //1.首先处理properties 节点\t\n      propertiesElement(root.evalNode(\"properties\")); //issue #117 read properties first\n      //2.处理typeAliases\n      typeAliasesElement(root.evalNode(\"typeAliases\"));\n      //3.处理插件\n      pluginElement(root.evalNode(\"plugins\"));\n      //4.处理objectFactory\n      objectFactoryElement(root.evalNode(\"objectFactory\"));\n      //5.objectWrapperFactory\n      objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\"));\n      //6.settings\n      settingsElement(root.evalNode(\"settings\"));\n      //7.处理environments\n      environmentsElement(root.evalNode(\"environments\")); // read it after objectFactory and objectWrapperFactory issue #631\n      //8.database\n      databaseIdProviderElement(root.evalNode(\"databaseIdProvider\"));\n      //9. typeHandlers\n      typeHandlerElement(root.evalNode(\"typeHandlers\"));\n      //10 mappers\n      mapperElement(root.evalNode(\"mappers\"));\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e);\n    }\n  }\n\n```\n在上述代码中，还有一个非常重要的地方，就是解析XML配置文件子节点<mappers>的方法mapperElements(root.evalNode(\"mappers\")), 它将解析我们配置的Mapper.xml配置文件。\n\n- 然后将这些值解析出来设置到Configuration对象中。\n\n### 创建SqlSession对象\n在DefaultSqlSessionFactory中openSessionFromDataSource()方法返回DefaultSqlSession对象。\n```java\n/**\n   * 通常一系列openSession方法最终都会调用本方法\n   * @param execType \n   * @param level\n   * @param autoCommit\n   * @return\n   */\n  private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {\n    Transaction tx = null;\n    try {\n      //通过Confuguration对象去获取Mybatis相关配置信息, Environment对象包含了数据源和事务的配置\n      final Environment environment = configuration.getEnvironment();\n      final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);\n      tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);\n      //之前说了，从表面上来看，咱们是用sqlSession在执行sql语句， 实际呢，其实是通过excutor执行， excutor是对于Statement的封装\n      final Executor executor = configuration.newExecutor(tx, execType);\n      //关键看这儿，创建了一个DefaultSqlSession对象\n      return new DefaultSqlSession(configuration, executor, autoCommit);\n    } catch (Exception e) {\n      closeTransaction(tx); // may have fetched a connection so lets call close()\n      throw ExceptionFactory.wrapException(\"Error opening session.  Cause: \" + e, e);\n    } finally {\n      ErrorContext.instance().reset();\n    }\n  }\n```\n\n### 设计模式应用\n在创建SqlSessionFactory和Environment对象时用到了builder设计模式。\n- 由于构造时参数不定，可以为其创建一个构造器Builder，将SqlSessionFactory的构建过程和表示分开\n- 数据库连接环境Environment对象的创建\n```java\n  private void environmentsElement(XNode context) throws Exception {\n    if (context != null) {\n      \n      for (XNode child : context.getChildren()) {\n        String id = child.getStringAttribute(\"id\");\n        \n          //使用了Environment内置的构造器Builder，传递id 事务工厂和数据源\n          Environment.Builder environmentBuilder = new Environment.Builder(id)\n              .transactionFactory(txFactory)\n              .dataSource(dataSource);\n          configuration.setEnvironment(environmentBuilder.build());\n        }\n      }\n  }\n```\n```java\npublic final class Environment {\n  private final String id;\n  private final TransactionFactory transactionFactory;\n  private final DataSource dataSource;\n \n  public Environment(String id, TransactionFactory transactionFactory, DataSource dataSource) {\n    if (id == null) {\n      throw new IllegalArgumentException(\"Parameter 'id' must not be null\");\n    }\n    if (transactionFactory == null) {\n        throw new IllegalArgumentException(\"Parameter 'transactionFactory' must not be null\");\n    }\n    this.id = id;\n    if (dataSource == null) {\n      throw new IllegalArgumentException(\"Parameter 'dataSource' must not be null\");\n    }\n    this.transactionFactory = transactionFactory;\n    this.dataSource = dataSource;\n  }\n \n  public static class Builder {\n      private String id;\n      private TransactionFactory transactionFactory;\n      private DataSource dataSource;\n \n    public Builder(String id) {\n      this.id = id;\n    }\n \n    public Builder transactionFactory(TransactionFactory transactionFactory) {\n      this.transactionFactory = transactionFactory;\n      return this;\n    }\n \n    public Builder dataSource(DataSource dataSource) {\n      this.dataSource = dataSource;\n      return this;\n    }\n \n    public String id() {\n      return this.id;\n    }\n \n    public Environment build() {\n      return new Environment(this.id, this.transactionFactory, this.dataSource);\n    }\n \n  }\n \n  public String getId() {\n    return this.id;\n  }\n \n  public TransactionFactory getTransactionFactory() {\n    return this.transactionFactory;\n  }\n \n  public DataSource getDataSource() {\n    return this.dataSource;\n  }\n \n}\n\n```\n在下文我们将分析在获得sqlSession对象之后是怎样获取Mapper对象的，并执行SQL语句的（**没有Mapper接口实现类的情况**）。\n\n### 参考资料\n- [《深入理解mybatis原理》 Mybatis初始化机制详解](https://blog.csdn.net/luanlouis/article/details/37744073)\n- [深入浅出Mybatis系列（十）---SQL执行流程分析（源码篇）](https://www.cnblogs.com/dongying/p/4142476.html)\n\n\n\n\n\n","tags":["Mybatis"],"categories":["Mybatis"]},{"title":"Mybatis执行mapper过程(二)","url":"/2019/03/11/Mybatis执行mapper过程(二)/","content":"\n### 案例\n先看下一次完成的Mybatis查询过程示例代码：\n```java\nString resource = \"mybatis-config.xml\";\nInputStream inputStream = Resources.getResourceAsStream(resource);\nSqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\nSqlSession sqlSession = sqlSessionFactory.openSession();\nUserMapper userMapper = session.getMapper(UserMapper.class);  \n//调用代理对象方法  \nUser user = userMapper.findUserById(27);  \n//关闭session  \nsession.close();  \n```\n本文先重点分析，以下代码背后的原理\n```java\nUserMapper userMapper = session.getMapper(UserMapper.class);  \nUser user = userMapper.findUserById(27);  \n```\n思考一个问题，为什么userMapper没有接口实现类也能成功执行findUserById()？\n\n### 创建UserMapper代理对象\n首先我们看下getMapper()是怎样获取代理对象的。\n```java\nDefaultSqlSession.java\npublic <T> T getMapper(Class<T> type) {\n  return configuration.<T>getMapper(type, this);\n} \n\n------>>>>>>\n\nConfiguration.java\npublic <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n  return mapperRegistry.getMapper(type, sqlSession);\n}\n\n------>>>>>>\n\nMapperRegistry.java\npublic <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n  //一个Mapper接口类对应一个MapperProxyFactory\n  final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);\n  if (mapperProxyFactory == null) {\n    throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\");\n  }\n  try {\n    return mapperProxyFactory.newInstance(sqlSession);\n  } catch (Exception e) {\n    throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e);\n  }\n}\n\n------>>>>>>\n\nMapperProxyFactory.java\npublic T newInstance(SqlSession sqlSession) {\n  final MapperProxy<T> mapperProxy = new MapperProxy<T>(sqlSession, mapperInterface, methodCache);\n  return newInstance(mapperProxy);\n}\nprotected T newInstance(MapperProxy<T> mapperProxy) {\n  return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);\n}\n```\n![创建Mapper代理对象过程.png](创建Mapper代理对象过程.png)\n\n大致过程，先获取MapperProxyFactory，然后使用JDK动态代理方式构建出代理对象。在MapperRegistry.java中我们可以知道，mapperProxyFactory由knownMappers.get(type)得到，那么knownMappers中的数据什么时候维护进去的呢？我们看下下面的MapperRegistry.java完整的代码。\n\n#### MapperRegistry\n```java\n//这个类通过名字就可以看出 是用来注册Mapper接口与获取生成代理类实例的工具类 \npublic class MapperRegistry {\n  //全局配置文件对象\n  private Configuration config;\n  //一个HashMap Key是mapper的类型对象, Value是MapperProxyFactory对象\n  //这个MapperProxyFactory是创建Mapper代理对象的工厂 我们一会再分析\n  private final Map<Class<?>, MapperProxyFactory<?>> knownMappers = new HashMap<Class<?>, MapperProxyFactory<?>>();\n  public MapperRegistry(Configuration config) {\n    this.config = config;\n  }\n  //获取生成的代理对象\n  @SuppressWarnings(\"unchecked\")\n  public <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n    //通过Mapper的接口类型 去Map当中查找 如果为空就抛异常\n    final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);\n    if (mapperProxyFactory == null)\n      throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\");\n    try {\n      //否则创建一个当前接口的代理对象 并且传入sqlSession\n      return mapperProxyFactory.newInstance(sqlSession);\n    } catch (Exception e) {\n      throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e);\n    }\n  }\n\n  public <T> boolean hasMapper(Class<T> type) {\n    return knownMappers.containsKey(type);\n  }\n\n  //注册Mapper接口！！！！\n  public <T> void addMapper(Class<T> type) {\n    if (type.isInterface()) {\n      if (hasMapper(type)) {\n        throw new BindingException(\"Type \" + type + \" is already known to the MapperRegistry.\");\n      }\n      boolean loadCompleted = false;\n      try {\n        knownMappers.put(type, new MapperProxyFactory<T>(type));\n       \n        MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type);\n        parser.parse();\n        loadCompleted = true;\n      } finally {\n        if (!loadCompleted) {\n          knownMappers.remove(type);\n        }\n      }\n    }\n  }\n  public Collection<Class<?>> getMappers() {\n    return Collections.unmodifiableCollection(knownMappers.keySet());\n  }\n    ResolverUtil<Class<?>> resolverUtil = new ResolverUtil<Class<?>>();\n    resolverUtil.find(new ResolverUtil.IsA(superType), packageName);\n    Set<Class<? extends Class<?>>> mapperSet = resolverUtil.getClasses();\n    for (Class<?> mapperClass : mapperSet) {\n      addMapper(mapperClass);\n    }\n  }\n  //通过包名扫描下面所有接口\n  public void addMappers(String packageName) {\n    addMappers(packageName, Object.class);\n  }\n\n}\n\n```\nMapperRegistry 类是注册Mapper接口与获取代理类实例的工具类。从上述代码可以看到，addMapper(Class<T> type)方法中维护了knownMappers。而XMLConfigBuilder.mapperElement(XNode) 是在读取配置文件时[XMLConfigBuilder 118行]调用了该方法addMapper(Class<T> type)，即在加载配置文件时候为每一个Mapper类（UserMapper）维护了对应的MapperProxyFactory。\n\n#### MapperProxyFactory\n```java\n//这个类负责创建具体Mapper接口代理对象的工厂类\npublic class MapperProxyFactory<T> {\n  //具体Mapper接口的Class对象\n  private final Class<T> mapperInterface;\n  //该接口下面方法的缓存 key是方法对象 value是对接口中方法对象的封装\n  private Map<Method, MapperMethod> methodCache = new ConcurrentHashMap<Method, MapperMethod>();\n  //构造参数没啥好说的\n  public MapperProxyFactory(Class<T> mapperInterface) {\n    this.mapperInterface = mapperInterface;\n  }\n  public Class<T> getMapperInterface() {\n    return mapperInterface;\n  }\n  public Map<Method, MapperMethod> getMethodCache() {\n    return methodCache;\n  }\n  @SuppressWarnings(\"unchecked\")\n  protected T newInstance(MapperProxy<T> mapperProxy) {\n    //创建了一个代理类并返回\n    //关于Proxy的API 可以查看java官方的API\n    return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);\n  }\n  //在这里传入sqlSession 创建一个Mapper接口的代理类\n  public T newInstance(SqlSession sqlSession) {\n    //在这里创建了MapperProxy对象 这个类实现了JDK的动态代理接口 InvocationHandler\n    final MapperProxy<T> mapperProxy = new MapperProxy<T>(sqlSession, mapperInterface, methodCache);\n    //调用上面的方法 返回一个接口的代理类\n    return newInstance(mapperProxy);\n  }\n}\n\n```\n从上述代码可以看到在newInstance(MapperProxy<T> mapperProxy)中，利用mapperProxy作为InvocationHandler来创建代理对象。\n\n#### MapperProxy\nMapperProxy的源码如下：\n```java\n//实现了JDK动态代理的接口 InvocationHandler\n//在invoke方法中实现了代理方法调用的细节\npublic class MapperProxy<T> implements InvocationHandler, Serializable {\n  private static final long serialVersionUID = -6424540398559729838L;\n  //SqlSession\n  private final SqlSession sqlSession;\n  //接口的类型对象\n  private final Class<T> mapperInterface;\n  //接口中方法的缓存 有MapperProxyFactory传递过来的。\n  private final Map<Method, MapperMethod> methodCache;\n  //构造参数\n  public MapperProxy(SqlSession sqlSession, Class<T> mapperInterface, Map<Method, MapperMethod> methodCache) {\n    this.sqlSession = sqlSession;\n    this.mapperInterface = mapperInterface;\n    this.methodCache = methodCache;\n  }\n  //接口代理对象所有的方法调用 都会调用该方法\n  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n    //判断是不是基础方法 比如toString() hashCode()等，这些方法直接调用不需要处理\n    if (Object.class.equals(method.getDeclaringClass())) {\n      return method.invoke(this, args);\n    }\n    //这里进行缓存\n    final MapperMethod mapperMethod = cachedMapperMethod(method);\n    //调用mapperMethod.execute 核心的地方就在这个方法里，这个方法对才是真正对SqlSession进行的包装调用\n    return mapperMethod.execute(sqlSession, args);\n  }\n  //缓存处理\n  private MapperMethod cachedMapperMethod(Method method) {\n    MapperMethod mapperMethod = methodCache.get(method);\n    if (mapperMethod == null) {\n      mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration());\n      methodCache.put(method, mapperMethod);\n    }\n    return mapperMethod;\n  }\n}\n```\n从上述代码可以看到，invoke()方法中的逻辑是执行相应的 SQL 语句并将结果集返回，而没有相应的去执行接口实现类方法的代码。\n这就是为什么mybatis的mapper没有实现类的原因？\n\n#### MapperMethod\nMapperMethod是MapperProxyFactory类在创建MapperProxy对象时传进来的。我们看下源码：\n```java\n//这个类是整个代理机制的核心类，对Sqlsession当中的操作进行了封装\npublic class MapperMethod {\n  //一个内部封 封装了SQL标签的类型 insert update delete select\n  private final SqlCommand command;\n  //一个内部类 封装了方法的参数信息 返回类型信息等\n  private final MethodSignature method;\n  //构造参数\n  public MapperMethod(Class<?> mapperInterface, Method method, Configuration config) {\n    this.command = new SqlCommand(config, mapperInterface, method);\n    this.method = new MethodSignature(config, method);\n  }\n  //这个方法是对SqlSession的包装调用\n  public Object execute(SqlSession sqlSession, Object[] args) {\n    //定义返回结果\n    Object result;\n    //如果是INSERT操作\n    if (SqlCommandType.INSERT == command.getType()) {\n      //处理参数\n      Object param = method.convertArgsToSqlCommandParam(args);\n      //调用sqlSession的insert方法\n      result = rowCountResult(sqlSession.insert(command.getName(), param));\n      //如果是UPDATE操作 同上\n    } else if (SqlCommandType.UPDATE == command.getType()) {\n      Object param = method.convertArgsToSqlCommandParam(args);\n      result = rowCountResult(sqlSession.update(command.getName(), param));\n      //如果是DELETE操作 同上\n    } else if (SqlCommandType.DELETE == command.getType()) {\n      Object param = method.convertArgsToSqlCommandParam(args);\n      result = rowCountResult(sqlSession.delete(command.getName(), param));\n      //如果是SELECT操作 那么情况会多一些 但是也都和sqlSession的查询方法一一对应\n    } else if (SqlCommandType.SELECT == command.getType()) {\n      //如果返回void 并且参数有resultHandler\n      //则调用 void select(String statement, Object parameter, ResultHandler handler);方法\n      if (method.returnsVoid() && method.hasResultHandler()) {\n        executeWithResultHandler(sqlSession, args);\n        result = null;\n      //如果返回多行结果这调用 <E> List<E> selectList(String statement, Object parameter);\n      //executeForMany这个方法调用的\n      } else if (method.returnsMany()) {\n        result = executeForMany(sqlSession, args);\n      //如果返回类型是MAP 则调用executeForMap方法\n      } else if (method.returnsMap()) {\n        result = executeForMap(sqlSession, args);\n      } else {\n        //否则就是查询单个对象\n        Object param = method.convertArgsToSqlCommandParam(args);\n        result = sqlSession.selectOne(command.getName(), param);\n      }\n    } else {\n      //如果全都不匹配 说明mapper中定义的方法不对\n      throw new BindingException(\"Unknown execution method for: \" + command.getName());\n    }\n    //如果返回值为空 并且方法返回值类型是基础类型 并且不是VOID 则抛出异常\n    if (result == null && method.getReturnType().isPrimitive() && !method.returnsVoid()) {\n      throw new BindingException(\"Mapper method '\" + command.getName() \n          + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\");\n    }\n    return result;\n  }\n  private Object rowCountResult(int rowCount) {\n    final Object result;\n    if (method.returnsVoid()) {\n      result = null;\n    } else if (Integer.class.equals(method.getReturnType()) || Integer.TYPE.equals(method.getReturnType())) {\n      result = rowCount;\n    } else if (Long.class.equals(method.getReturnType()) || Long.TYPE.equals(method.getReturnType())) {\n      result = (long) rowCount;\n    } else if (Boolean.class.equals(method.getReturnType()) || Boolean.TYPE.equals(method.getReturnType())) {\n      result = (rowCount > 0);\n    } else {\n      throw new BindingException(\"Mapper method '\" + command.getName() + \"' has an unsupported return type: \" + method.getReturnType());\n    }\n    return result;\n  }\n  private void executeWithResultHandler(SqlSession sqlSession, Object[] args) {\n    MappedStatement ms = sqlSession.getConfiguration().getMappedStatement(command.getName());\n    if (void.class.equals(ms.getResultMaps().get(0).getType())) {\n      throw new BindingException(\"method \" + command.getName() \n          + \" needs either a @ResultMap annotation, a @ResultType annotation,\" \n          + \" or a resultType attribute in XML so a ResultHandler can be used as a parameter.\");\n    }\n    Object param = method.convertArgsToSqlCommandParam(args);\n    if (method.hasRowBounds()) {\n      RowBounds rowBounds = method.extractRowBounds(args);\n      sqlSession.select(command.getName(), param, rowBounds, method.extractResultHandler(args));\n    } else {\n      sqlSession.select(command.getName(), param, method.extractResultHandler(args));\n    }\n  }\n  //返回多行结果 调用sqlSession.selectList方法\n  private <E> Object executeForMany(SqlSession sqlSession, Object[] args) {\n    List<E> result;\n    Object param = method.convertArgsToSqlCommandParam(args);\n    //如果参数含有rowBounds则调用分页的查询\n    if (method.hasRowBounds()) {\n      RowBounds rowBounds = method.extractRowBounds(args);\n      result = sqlSession.<E>selectList(command.getName(), param, rowBounds);\n    } else {\n      //没有分页则调用普通查询\n      result = sqlSession.<E>selectList(command.getName(), param);\n    }\n    // issue #510 Collections & arrays support\n    if (!method.getReturnType().isAssignableFrom(result.getClass())) {\n      if (method.getReturnType().isArray()) {\n        return convertToArray(result);\n      } else {\n        return convertToDeclaredCollection(sqlSession.getConfiguration(), result);\n      }\n    }\n    return result;\n  }\n  private <E> Object convertToDeclaredCollection(Configuration config, List<E> list) {\n    Object collection = config.getObjectFactory().create(method.getReturnType());\n    MetaObject metaObject = config.newMetaObject(collection);\n    metaObject.addAll(list);\n    return collection;\n  }\n  @SuppressWarnings(\"unchecked\")\n  private <E> E[] convertToArray(List<E> list) {\n    E[] array = (E[]) Array.newInstance(method.getReturnType().getComponentType(), list.size());\n    array = list.toArray(array);\n    return array;\n  }\n  private <K, V> Map<K, V> executeForMap(SqlSession sqlSession, Object[] args) {\n    Map<K, V> result;\n    Object param = method.convertArgsToSqlCommandParam(args);\n    if (method.hasRowBounds()) {\n      RowBounds rowBounds = method.extractRowBounds(args);\n      result = sqlSession.<K, V>selectMap(command.getName(), param, method.getMapKey(), rowBounds);\n    } else {\n      result = sqlSession.<K, V>selectMap(command.getName(), param, method.getMapKey());\n    }\n    return result;\n  }\n  public static class ParamMap<V> extends HashMap<String, V> {\n    private static final long serialVersionUID = -2212268410512043556L;\n    @Override\n    public V get(Object key) {\n      if (!super.containsKey(key)) {\n        throw new BindingException(\"Parameter '\" + key + \"' not found. Available parameters are \" + keySet());\n      }\n      return super.get(key);\n    }\n  }\n\n```\n在核心方法execute(SqlSession sqlSession, Object[] args)中，最后还是根据类型去选择到底执行sqlSession中的哪个方法。\nSqlCommand来封装底层的增删改查操作。我们看下SqlCommand源码：\n```java\n//一个内部类 封装了具体执行的动作\n  public static class SqlCommand {\n    //xml标签的id\n    private final String name;\n    //insert update delete select的具体类型\n    private final SqlCommandType type;\n    public SqlCommand(Configuration configuration, Class<?> mapperInterface, Method method) throws BindingException {\n      //拿到全名 比如 org.mybatis.example.BlogMapper.selectBlog\n      String statementName = mapperInterface.getName() + \".\" + method.getName();\n      MappedStatement ms = null;\n      //获取MappedStatement对象 这个对象封装了XML当中一个标签的所有信息 比如下面\n      //<select id=\"selectBlog\" resultType=\"Blog\">\n      //select * from Blog where id = #{id}\n      //</select>\n      if (configuration.hasStatement(statementName)) {\n        ms = configuration.getMappedStatement(statementName);\n      } else if (!mapperInterface.equals(method.getDeclaringClass().getName())) { // 这里是一个BUG\n        String parentStatementName = method.getDeclaringClass().getName() + \".\" + method.getName();\n        if (configuration.hasStatement(parentStatementName)) {\n          ms = configuration.getMappedStatement(parentStatementName);\n        }\n      }\n      //为空抛出异常\n      if (ms == null) {\n        throw new BindingException(\"Invalid bound statement (not found): \" + statementName);\n      }\n      //配置文件节点的ID\n      name = ms.getId();\n      //CRUD \n      type = ms.getSqlCommandType();\n      //判断SQL标签类型 未知就抛异常\n      if (type == SqlCommandType.UNKNOWN) {\n        throw new BindingException(\"Unknown execution method for: \" + name);\n      }\n    }\n    public String getName() {\n      return name;\n    }\n    public SqlCommandType getType() {\n      return type;\n    }\n  }\n\n```\n\n我们都会知道节点上有id属性值。那么MyBatis框架会把每一个节点(如：select节点、delete节点）生成一个MappedStatement类。在SqlCommand中，要找到MappedStatement类就必须通过接口类全限定名+id(方法名)来获得。\n以selectOne()为例，看下底层是怎么执行？\n1、selectOne()方法\n```java\npublic <T> T selectOne(String statement, Object parameter) {\n    // Popular vote was to return null on 0 results and throw exception on too many.\n    //会调用selectList()方法\n    List<T> list = this.<T>selectList(statement, parameter);\n    if (list.size() == 1) {\n      //只返回一个，取第一个即可\n      return list.get(0);\n    } else if (list.size() > 1) {\n      //这是MyBatis中很常见的一种异常\n      throw new TooManyResultsException(\"Expected one result (or null) to be returned by selectOne(), but found: \" + list.size());\n    } else {\n      return null;\n    }\n  }\n\n```\n2、selectList()方法\n```java\n@Override\n  public <E> List<E> selectList(String statement, Object parameter) {\n    return this.selectList(statement, parameter, RowBounds.DEFAULT);\n  }\n\n@Override\n  public <E> List<E> selectList(String statement, Object parameter, RowBounds rowBounds) {\n    try {\n      MappedStatement ms = configuration.getMappedStatement(statement);\n      //委托，单一职责\n      return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);\n    } catch (Exception e) {\n      throw ExceptionFactory.wrapException(\"Error querying database.  Cause: \" + e, e);\n    } finally {\n      ErrorContext.instance().reset();\n    }\n  }\n\n```\nExecutor是一个非常重要的接口：\n![excutor](excutor.png)\n其中BaseExecutor是一个抽象实现类，这里也使用了模板设计模式，这里将一些共性抽取到了BaseExecutor中。\n进入了org.apache.ibatis.executor.BaseExecutor#query\n![](query.png)\nBoundSql是对SQL语句的封装，ms(MapperStatment)由前面接口类全限定名+接口方法从Configuration对象中获取。\n继续看下一步的query方法\n![](query-1.png)\n\n执行querFormData()\n![](querFormData.png)\nlocalCache会先putObject()一下，这行代码的意义是声明一个占位符，当发送一次查询数据的请求时，设置该占位符告诉其他请求正在查询数据库,请其他请求先阻塞或休眠。当这次请求查询到数据之后，将真正的数据放到占位符的位置，缓存数据。如果其他请求与该次请求查询的数据时一样的，直接从一级缓存中拿数据减少了查询请求对数据库的压力 （org.apache.ibatis.executor.BaseExecutor.DeferredLoad#load org.apache.ibatis.executor.BaseExecutor.DeferredLoad#canLoad），接下来会执行doQuery()方法，doQuery()方法是BaseExecutor中的一个模板方法：\n![](doquery.png)\n这里会有一个拦截器链去执行Plugins的拦截：\n![](handler.png)\n当sqlsessionFactory获取sqlsession时，产生的ParameterHandler、ResultSetHandler、StatementHandler、Executor都是由org.apache.ibatis.session.Configuration 类的方法 newParameterHandler、newResultSetHandler、newStatementHandler、newExecutor产生的代理对象，而这些代理对象是经过适用规则的plugin层层代理的 ，最后会返回一个StatementHandler。\n![](statementHandler.png)\n\n在prepareStatement()方法中，获取了Connection：\n![](prepareStatment.png)\n接下来会执行handler.<E>query(stmt, resultHandler)：\n![](prepareStatment1.png)\n\n#### 返回结果处理\n执行完成后会由ResultSetHandler处理结果\n```java\npublic List<Object> handleResultSets(Statement stmt) throws SQLException {\n    //又看到了熟悉的ErrorContext，不过这个activity的名称与之前的不一样\n    ErrorContext.instance().activity(\"handling results\").object(mappedStatement.getId());\n \n    final List<Object> multipleResults = new ArrayList<Object>();\n \n    int resultSetCount = 0;\n    ResultSetWrapper rsw = getFirstResultSet(stmt);\n \n    List<ResultMap> resultMaps = mappedStatement.getResultMaps();\n    int resultMapCount = resultMaps.size();\n    validateResultMapsCount(rsw, resultMapCount);\n    while (rsw != null && resultMapCount > resultSetCount) {\n      ResultMap resultMap = resultMaps.get(resultSetCount);\n      //循环封装好每个查询结果对象\n      handleResultSet(rsw, resultMap, multipleResults, null);\n      rsw = getNextResultSet(stmt);\n      cleanUpAfterHandlingResultSet();\n      resultSetCount++;\n    }\n \n    String[] resultSets = mappedStatement.getResultSets();\n    if (resultSets != null) {\n      while (rsw != null && resultSetCount < resultSets.length) {\n        ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);\n        if (parentMapping != null) {\n          String nestedResultMapId = parentMapping.getNestedResultMapId();\n          ResultMap resultMap = configuration.getResultMap(nestedResultMapId);\n          handleResultSet(rsw, resultMap, null, parentMapping);\n        }\n        rsw = getNextResultSet(stmt);\n        cleanUpAfterHandlingResultSet();\n        resultSetCount++;\n      }\n    }\n \n    return collapseSingleResultList(multipleResults);\n  }\n```\n由handleResultSet()方法逐层深入最后来到getRowValue()方法。\n![](getRowValue.png)\n执行org.apache.ibatis.executor.resultset.DefaultResultSetHandler#createResultObject(org.apache.ibatis.executor.resultset.ResultSetWrapper, org.apache.ibatis.mapping.ResultMap, org.apache.ibatis.executor.loader.ResultLoaderMap, java.lang.String)方法，首先会循环遍历为ResultMapping属性赋值。**如果是嵌套查询而且配置了延迟加载，其中这里的createProxy()方法会生成一个具有延迟加载功能的代理对象（这里采用CGLIB代理生成！！！）**。\n![](createObject.png)\n这里返回的是一个所有属性都为空的结果：\n![](object.png)\n需要在前文getRowValue()中，给各个属性赋值：\n![](赋值.png)\n\n大体的执行过程如下：\n\n![整体过程](整体过程.png)\n### 参考资料\n- [为什么mybatis的mapper没有实现类(原理探究)](https://blog.csdn.net/puhaiyang/article/details/77418012)\n- [mybatis 源码解析之如何实现 mapper 动态代理](https://www.jianshu.com/p/93e18dcc7c10)\n- [Mybatis中Mapper动态代理的实现原理](https://blog.csdn.net/xiaokang123456kao/article/details/76228684)\n- [深入浅出Mybatis系列（十）---SQL执行流程分析（源码篇）](https://www.cnblogs.com/dongying/p/4142476.html)\n- [MyBatis源码分析（Mapper动态代理的实现及执行流程）](https://blog.csdn.net/Dongguabai/article/details/82084958)\n\n","tags":["Mybatis"],"categories":["Mybatis"]},{"title":"Oracle数据库锁表及解锁进程","url":"/2019/03/11/Oracle数据库锁表及解锁进程/","content":"\n整个过程主要涉及了v$locked_object、dba_objects、v$session\n1、查询是否锁表\n```sql\nselect count(*) from v$locked_object;\n\nselect * from v$locked_object;\n```\n\n2、查看哪个表被锁了\n```sql\nselect b.owner,b.object_name,a.session_id,a.locked_mode\n\nfrom v$locked_object a,dba_objects b\n\nwhere b.object_id = a.object_id;\n```\n\n3、查看是哪个session引起的\n```sql\nselect b.username,b.sid,b.serial#,logon_time\n\n from v$locked_object a,v$session b\n\n where a.session_id = b.sid order by b.logon_time;\n```\n\n4、杀掉对应的进程\n```sql\nalter system kill session'1025,41';\n```\n其中1025为sid,41为serial#。","tags":["Oracle"],"categories":["Oracle"]},{"title":"为什么 ArrayList 是线程不安全的","url":"/2019/03/11/为什么-ArrayList-是线程不安全的/","content":"\n先看下面一段代码\n\n![代码](代码.png)\n在高并发情况下，它的输出结果有：\n1、发生 ArrayIndexOutOfBoundsException 异常；问题是出现在多线程并发访问下，由于没有同步锁的保护，造成了 ArrayList 扩容不一致的问题。\n\n2、程序正常运行，输出了少于实际容量的大小；\n\n这个也是多线程并发赋值时，对同一个数组索引位置进行了赋值，所以出现少于预期大小的情况。\n\n3、程序正常运行，输出了预期容量的大小；\n\n这是正常运行结果，未发生多线程安全问题，但这是不确定性的，不是每次都会达到正常预期的。\n","tags":["Java","并发"],"categories":["Java","并发"]},{"title":"Memory Analyzer分析堆快照文件过程","url":"/2019/03/10/Memory-Analyzer分析堆快照文件过程/","content":"\n### 简介\n当应用发生OutOfMemoryError时，我们需要通过`jmap -dump:live,format=b,file=/home/dump20190318.hprof <pid>`导出当前堆快照文件，并利用Memory Analyzer工具进行分析。\n\n> 造成OutOfMemoryError原因一般有2种：\n> - 内存泄露，对象已经死了，无法通过垃圾收集器进行自动回收，通过找出泄露的代码位置和原因，才好确定解决方案；\n> - 内存溢出，内存中的对象都还必须存活着，这说明Java堆分配空间不足，检查堆设置大小（-Xmx与-Xms），检查代码是否存在对象生命周期太长、持有状态时间过长的情况。\n\n\n### 过程\n1、打开堆文件，file-->open dump heap-->leak suspects report-->finish\n![加载文件](加载文件.png)\n2、OverView分析报告\n![overview](overview.png)\n\n#### biggest object by retained size\nbiggest object by retained size：显示在内存较大的对象信息。单击某个扇区就可以根据该对象对其引用情况等进行分析\n![扇区](扇区.png)\n> - list objects-->with outgoing references : 查看这个对象持有的外部对象引用\n                -->with incoming references : 查看这个对象被哪些外部对象引用\n> - show objects by class-->with outgoing references ：查看这个对象类型持有的外部对象引用\n                         -->with incoming references ：查看这个对象类型被哪些外部对象引用\n> - path to gc roots : 显示不同类型引用(strong reference、soft reference 、weak reference)到跟节点的路径\n> - merge shorest paths to gc roots : 合并最短路径到root节点，这个具体没试过\n> - java basics:\n    -->class loader explorer:该对象对应的classloader信息 \n    -->thread details:线程信息\n    -->thread overview and stacks:线程堆栈\n    -->group by value:根据某个字段统计出现的个数 \n> - leak Identification-->top consumers :几个大消耗内存的对象 \n\n#### Action\n在Action标签中，有以下几个重要的功能：\n1、Histogram\n可以列出内存中的对象，对象的个数以及大小\n![histogram](histogram.png)\n> - Class Name：类名称，java类名\n> - Objects：类的对象的数量，这个对象被创建了多少个\n> - Shallow Heap：对象自身占用的内存大小，不包括它引用的对象\n> - Retained Heap：当前对象大小+当前对象可直接或间接引用到的对象的大小总和\n\n下面详细讲下Shallow Heap和Retained Heap：\nShallow Size：对象自身占用的内存大小，不包括它引用的对象。针对非数组类型的对象，它的大小就是对象与它所有的成员变量大小的总和。针对数组类型的对象，它的大小是数组元素对象的大小总和。 \nRetained Size:当前对象大小加上当前对象可直接或间接引用到的对象的大小总和。Retained Size就是当前对象被GC后，从Heap上总共能释放掉的内存。 释放的时候还要排除被GC Roots直接或间接引用的对象，他们暂时不会被被当做Garbage。 \n\n![Retained](Retained.jpg)\nA对象的Retained Size=A对象的Shallow Size \nB对象的Retained Size=B对象的Shallow Size + C对象的Shallow Size \n\n2、Dominator Tree\n可以列出那个线程，以及线程下面的那些对象占用的空间\n![Dominator Tree](Dominator Tree.png)\n> - percentage:列出所有对象在整个内存对象中所占百分比\n\n3、Top consumers\n根据类名和包名列出占用最大的对象\n![Top consumers](Top consumers.png)\n\n4、Duplicate Classes\n查找出在不同classloader中加载的相同类\n\n5、Leak Suspects\n查看内存泄露情况\n![leak](leak.png)\n\n#### Reports\n在Reports标签中，有个重要的功能：\n- Leak Suspects：通过MAT自动分析泄漏的原因\n\n### 总结\n1.首先看retained size最大的那些数据，一般看内存都是想解决内存泄漏问题，可以通过Top Consumers或者是donimator tree等actions。\n2.找到最大的数据后，通过list objects --> with outgoing references 查看具体持有了哪些对象，或者通过java basics --> classloader。查看这个是因为我们这次因为perm区满了，需要查看这个数据。到底还是哪些classloader加载了数据。\n\n\n### 参考资料\n> - [mat（Eclipse Memory Analyzer tool）之二--heap dump分析](http://www.cnblogs.com/duanxz/p/6046055.html)\n> - [mat 使用笔记](https://inter12.iteye.com/blog/1407492)\n> - [low heap & Retained heap](https://bjyzxxds.iteye.com/blog/1532937)\n\n\n\n\n","tags":["JVM","故障排查"],"categories":["JVM"]},{"title":"Linux iostat命令","url":"/2019/03/10/Linux-iostat命令/","content":"\n### 简介\niostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。\n使用命令如下：\n```linux\niostat\n```\n![结果](结果.png)\n参数说明：\n\n> - %user：CPU处在用户模式下的时间百分比\n> - %nice：CPU处在带NICE值的用户模式下的时间百分比\n> - %system：CPU处在系统模式下的时间百分比\n> - %iowait：CPU等待输入输出完成时间的百分比\n> - %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比\n> - %idle：CPU空闲时间百分比\n> - tps：该设备每秒的传输次数\n> - kB_read/s：每秒从设备（drive expressed）读取的数据量\n> - kB_wrtn/s：每秒向设备（drive expressed）写入的数据量\n> - kB_read： 读取的总数据量\n> - kB_wrtn：写入的总数量数据量\n结果分析：\n如果%iowait的值过高，表示硬盘存在I/O瓶颈\n如果%idle值高，表示CPU较空闲\n如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量。\n如果%idle值持续低于10，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。\n\n### 使用实例\n\n#### 查看设备使用率（%util）、响应时间（await）\n```linux\n# -d 表示，显示设备（磁盘）使用状态；-x 显示详细信息；-k某些使用block为单位的列强制使用Kilobytes为单位；\n# 每隔1秒刷新1次，显示10次\niostat -d -x -k 1 10\n```\n结果：\n![设备详情](设备详情.png)\n参数说明：\n> - tps：该设备每秒的传输次数\n> - rkB/s：每秒从设备（drive expressed）读取的数据量\n> - wkB/s：每秒向设备（drive expressed）写入的数据量\n> - rrqm/s：每秒这个设备相关的读取请求有多少被Merge了\n> - wrqm/s：每秒这个设备相关的写入请求有多少被Merge了\n> - r/s：每秒读取的扇区数\n> - w/s：每秒写入的扇区数\n> - await：每一个IO请求的处理的平均时间（单位是毫秒）。这里可以理解为IO的响应时间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。\n> - %util： 在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%，所以该参数暗示了设备的繁忙程度。\n\n#### 查看cpu状态\n```linux\niostat -c 10 1\n```\n![CPU](CPU.png)\n\n","tags":["Linux"],"categories":["Linux"]},{"title":"Linux netstat命令","url":"/2019/03/10/Linux-netstat命令/","content":"\n### 简介\nnetstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。\n> -a (all)显示所有选项，默认不显示LISTEN相关\n> -t (TCP)仅显示TCP相关选项\n> -u (UDP)仅显示UDP相关选项\n> -n 拒绝显示别名，能显示数字的全部转化成数字。\n> -l 仅列出有在 Listen (监听) 的服務状态\n> -p 显示建立相关链接的程序名\n> -r 显示路由信息，路由表\n> -e 显示扩展信息，例如uid等\n> -s 按各个协议进行统计\n> -c 每隔一个固定时间，执行该netstat命令。\n> 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到\n```linux\nActive Internet connections (w/o servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State      \nTCP        0      0 localhost:rsom          localhost:50278         ESTABLISHED\nTCP        0      0 localhost:34622         localhost:ciphire-serv  ESTABLISHED\nTCP        0      0 localhost:50278         localhost:rsom          ESTABLISHED\nTCP        0      0 localhost:rsom          localhost:50284         ESTABLISHED\nTCP        0      0 localhost:56944         localhost:dandv-tester  ESTABLISHED\nTCP        0      0 localhost:50284         localhost:rsom          ESTABLISHED\nTCP        0      0 localhost:34630         localhost:ciphire-serv  ESTABLISHED\nActive UNIX domain sockets (w/o servers)\nProto RefCnt Flags       Type       State         I-Node   Path\nunix  2      [ ]         DGRAM                    9620     /run/systemd/shutdownd\nunix  2      [ ]         DGRAM                    6872     /run/systemd/notify\nunix  2      [ ]         DGRAM                    6874     /run/systemd/cgroups-agent\nunix  5      [ ]         DGRAM                    6894     /run/systemd/journal/socket\nunix  8      [ ]         DGRAM                    6896     /dev/log\nunix  2      [ ]         DGRAM                    1063802  \n```\n输出的结果包含两大部分。一个是Active Internet connections，称为有源TCP连接，其中\"Recv-Q\"和\"Send-Q\"指%0A的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。\n另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。\nProto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。\n\n### 常用命令实例\n#### 列出所有端口(包括监听和未监听的)\n1、列出所有端口\n```linux\nnetstat -a | more\n```\n2、列出所有TCP端口\n```linux\nnetstat -at\n```\n3、列出所有UDP端口\n```linux\nnetstat -au\n```\n#### 列出监听状态的端口\n1、 只显示监听端口 \n```linux\nnetstat -l\n```\n2、 只列出所有监听TCP端口 \n```linux\nnetstat -lt\n```\n3、 只列出所有监听UDP端口\n```linux\nnetstat -lu\n```\n4、只列出所有监听UNIX端口\n```linux\nnetstat -lx\n```\n#### 显示每个协议的统计信息\n1、显示所有端口的统计信息 \n```linux\nnetstat -s\n```\n2、显示TCP端口的统计信息\n```linux\nnetstat -st \n``` \n3、显示UDP端口的统计信息\n```linux\nnetstat -su\n```\n####  在netstat输出中显示PID和进程名称\n```linux\nnetstat -p\n```\n上述可以与其它开关一起使用，如在输出TCP端口的结果中显示进程ID和名称：\n```linux\nnetstat -pt\n```\n#### 持续输出 netstat 信息\n```linux\nnetstat -c\n```\n\n#### 找出程序运行的端口\n1、找出ssh运行的占用的端口\n```linux\nnetstat -ap | grep ssh\n```\n\n2、 找出运行在指定端口的进程，如80端口\n```linux\nnetstat -an | grep ':80'\n```\n\n#### IP和TCP分析\n1、查看连接某服务端口（192.168.1.15:22）最多的的IP地址\n```linux\nnetstat -nat | grep \"192.168.1.15:22\" |awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -nr|head -20\n```\n2、查看TCP连接状态并排序\n```linux\nnetstat -nat |awk '{print $6}'|sort|uniq -c|sort -rn\n```\n3、分析某日志文件中的访问前10名的IP地址\n```linux\nawk '{print $1}' access.log |sort|uniq -c|sort -nr|head -10\n```","tags":["Linux"],"categories":["Linux"]},{"title":"Java线上故障排查手段","url":"/2019/03/08/Java线上故障排查手段/","content":"\n###  高CPU负载\n1、找出最消耗CPU的进程号<pid>，执行以下命令\n```linux\ntop -c #显示进程运行信息列表 \n```\n键入大写的P，让进程按照CPU使用率排序\n![top-c](top-c.png)\n\n在这里可以通过工具*[show-busy-java-threads](https://github.com/oldratlee/useful-scripts/blob/master/show-busy-java-threads)*，直接定位到问题代码，不需要执行后面的步骤2-4。\n使用方式如下：\n```linux\n./show-busy-java-threads -p 3303\n```\n\n2、找出最消耗CPU的线程<nid>，执行以下命令\n```linux\ntop -H -p 3303  #显示一个进程的线程运行信息列表\n```\n这时也可以键入大写的P，让进程按照CPU使用率排序\n![top-h-p.png](top-h-p.png)\n\n3、将线程<nid>转化为16进制。之所以要转化为16进制，是因为堆栈里，线程id是用16进制表示的\n```linux\nprintf \"%x\\n\" 3313\n```\n![printf3303.png](printf3303.png)\n4、定位问题代码\n(1)、在线查看\n```linux\njstack -l 3303 | grep -C 20 nid=0xcf1 --color=auto  #-l 输出锁的附加信息\n```\n(2)、导出文件查看\n```\njstack -l 3303 | more > threadStack20190308.log \n```\n![jstack3003](jstack3003.png)\n \n> **参数介绍**\nprio：线程的优先级\ntid：线程id\nnid:操作系统映射的线程id\n\n5、 分析线程状态\n**jstack日志中的线程状态有：**\n- RUNNABLE: 线程正在执行中，占用了资源，比如处理某个请求/进行计算/文件操作等\n- BLOCKED:线程处于阻塞状态，等待某种资源(可理解为等待资源超时的线程)；\n  具体状态有：\n            - \"waiting to lock <xxx>\"：即等待给xxx上锁，**grep stack文件找locked <xxx>** 查找获得锁的线程；\n            - \"waiting for monitor entry\"：线程通过synchronized(obj){……}申请进入了临界区，但该obj对应的monitor被其他线程拥有，从而处于等待。\n \n- WAITING(parking)/TIMED_WAITING:等待状态，若指定了时间，到达指定的时间后自动退出等待状态，parking指线程处于挂起中；具体状态有：\n            - \"waiting on condition\"需与堆栈中的\"parking to wait for  <xxx> (at java.util.concurrent.SynchronousQueue$TransferStack)\"结合来看。（1）、此线程是在等待某个条件的发生，来把自己唤醒；（2）、SynchronousQueue不是一个队列，其是线程之间移交信息的机制，当我们把一个元素放入到 SynchronousQueue 中时必须有另一个线程正在等待接受移交的任务，因此这就是本线程在等待的条件。\n \n- Deadlock:死锁，资源相互占用。\n\n**对上述各种状态的具体描述如下：**\n- 线程状态为“waiting for monitor entry” 意味着它在等待进入一个临界区 ，所以它在”Entry Set“队列中等待。        此时线程状态一般都是`Blocked：java.lang.Thread.State: BLOCKED (on object monitor)`。\n\n如果大量线程在“waiting for monitor entry”可能是一个全局锁阻塞住了大量线程。如果短时间内打印的 thread dump 文件反映，随着时间流逝，\"waiting for monitor entry\"的线程越来越多，没有减少的趋势，可能意味着某些线程在临界区里呆的时间太长了，以至于越来越多新线程迟迟无法进入临界区。\n    \n- 线程状态为“waiting on condition”说明它在等待另一个条件的发生，来把自己唤醒，或者干脆它是调用了 sleep(N)。\n此时线程状态大致为以下几种：(1)、java.lang.Thread.State: WAITING (parking)：一直等那个条件发生；（2）、        java.lang.Thread.State: TIMED_WAITING (parking或sleeping)：定时的，那个条件不到来，也将定时唤醒自己。\n              \n如果大量线程在“waiting on condition”   可能是它们又跑去获取第三方资源，尤其是第三方网络资源，迟迟获取不到Response，导致大量线程进入等待状态。\n所以如果你发现有大量的线程都处在\"Wait on condition\"，从线程堆栈看，正等待网络读写，这可能是一个网络瓶颈的征兆，因为网络阻塞导致线程无法执行。\n \n- 线程状态为“in Object.wait()” 说明它获得了监视器之后，又调用了 java.lang.Object.wait() 方法。每个 Monitor在某个时刻，只能被一个线程拥有，该线程就是 “Active Thread”。而其它线程都是 “Waiting Thread”，分别在两个队列 “ Entry Set”和 “Wait Set”里面等候。在 “Entry Set”中等待的线程状态是 “Waiting for monitor entry”，而在 “Wait Set”中等待的线程状态是 “in Object.wait()”。当线程获得了 Monitor，如果发现线程继续运行的条件没有满足，它则调用对象（一般就是被 synchronized 的对象）的 wait() 方法，放弃了 Monitor，进入 “Wait Set”队列。此时线程状态大致为以下几种：（1）、java.lang.Thread.State: TIMED_WAITING (on object monitor)；（2）、java.lang.Thread.State: WAITING (on object monitor)；一般都是RMI相关线程（RMI RenewClean、 GC Daemon、RMI Reaper），GC线程（Finalizer），引用对象垃圾回收线程（Reference Handler）等系统线程处于这种状态。\n\n可以使用类似如下命令，查看对应状态的线程情况\n```linux\njstack -l pid |grep \"BLOCKED\"|wc -l\njstack -l pid |grep \"Waiting on condition\"|wc -l\n```\n**Monitor**\n在多线程的 JAVA程序中，实现线程之间的同步，就要说说 Monitor。 Monitor是Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者Class的锁。每一个对象都有，也仅有一个 monitor。下 面这个图，描述了线程和 Monitor之间关系，以 及线程的状态转换图：\n![thread](thread.bmp)\n\n进入区(Entry Set):表示线程通过synchronized要求获取对象的锁。如果对象未被锁住,则迚入拥有者;否则在进入区等待。一旦对象锁被其他线程释放,立即参与竞争。\n拥有者(The Owner):表示某一线程成功竞争到对象锁。\n等待区(Wait Set):表示线程通过对象的wait方法,释放对象的锁,并在等待区等待被唤醒。\n从图中可以看出，一个 Monitor在某个时刻，只能被一个线程拥有，该线程就是 “Active Thread”，而其它线程都是 “Waiting Thread”，分别在两个队列 “ Entry Set”和 “Wait Set”里面等候。在 “Entry Set”中等待的线程状态是 “Waiting for monitor entry”，而在“Wait Set”中等待的线程状态是 “in Object.wait()”。 先看 “Entry Set”里面的线程。我们称被 synchronized保护起来的代码段为临界区。当一个线程申请进入临界区时，它就进入了 “Entry Set”队列。\n> locked <地址> 目标：使用synchronized申请对象锁成功,监视器的拥有者。\n> waiting to lock <地址> 目标：使用synchronized申请对象锁未成功,在迚入区等待。\n> waiting on <地址> 目标：使用synchronized申请对象锁成功后,释放锁幵在等待区等待。\n> parking to wait for <地址> 目标\n\n### 高CPU IO Wait\n1、找到高IO Wait的进程\n```linux\niotop -P    #该工具需要安装\n```\n![iotop](iotop-p.png)\n\n2、找到写入量大的线程信息\n```linux\niotop\n```\n![iotop](iotop.png)\n\n从command 已经可以看到进程信息了，部分情况下可以直接看到进程名称，将24841和24854对应起来。\n3、将线程24854转化为16进制。之所以要转化为16进制，是因为堆栈里，线程id是用16进制表示的\n```linux\nprintf \"%x\\n\" 24854\n```\n![iotopprintf](iotopprintf.png)\n4、定位问题代码\n(1)、在线查看\n```linux\njstack -l 24841 | grep -C 20 nid=0x6116 --color=auto  #-l 输出锁的附加信息\n```\n(2)、导出文件查看\n```\njstack -l 24841 | more > threadStack20190308.log \n```\n![iotop-jstack](iotop-jstack.png)\n\n\n### 频繁GC和堆内存out of memory\n\n第一种方式：\n1、利用jps或ps查看程序的进程ID，如25585\n2、结合GC情况，确认本身的内存分配是不是过小。如果是old区增长的过快，就可能是内存泄露。这个时候，你需要看看到底是什么对象占用了你的内存。\n```linux\njstat -gcutil 25585 5000 10# 查看垃圾回收情况，每5秒打印1次，一共打印10次\njmap -heap 25585 #查看当前堆内存情况\n```\n3、可以通过以下参数调大堆内存\n```java\n-Xms5000m –Xmx5000m\n```\n\n第二种方式：\n\n1、对Java进行如下的配置，可打印出发生out of memory时的堆内存清况\n```java\n- XX:+PrintGC -XX:+PrintGCDateStamps -Xloggc:/home/gc20190318.log -XX:+UseGCLogFileRotation \n- XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=50m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/dump20190318.hprof\n```\n2、利用jps或ps查看程序的进程ID，如25585\n3、利用下面命令，生成堆内存转储文件dump20190318.hprof，结合MAT工具进行分析，找出最消耗内存的对象\n```linux\nkill -3 25585\n```\n\n第三种方式：\n1、用jps或ps查看程序的进程ID，如25585\n2、利用下面命令，找出最消耗内存的对象\n```linux \njmap -histo:live 25585 | more\n```\n\n第四种方式：\n1、用jps或ps查看程序的进程ID，如25585\n2、利用下面命令，生成堆内存转储文件dump20190318.hprof，结合MAT工具，找出最消耗内存的对象\n```linux \njmap -dump:live,format=b,file=/home/dump20190318.hprof 25585\n```\n\n### 参考资料\n> - [线上服务内存OOM问题定位三板斧](https://blog.csdn.net/jjavaboy/article/details/77773754)\n> - [线上服务CPU100%问题快速定位实战](https://blog.csdn.net/jjavaboy/article/details/77771676)\n> - [java线上服务问题排查](https://blog.csdn.net/mynamepg/article/details/82895208)","tags":["Java","故障排查"],"categories":["Java"]},{"title":"双亲委派模型","url":"/2019/03/07/双亲委派模型/","content":"\n### 简介\n双亲委派模型指的是类加载器之间的层次关系。该模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器，而这种父子关系一般通过组合关系来实现，而不是通过继承。\n![类加载器层级关系](类加载器层级关系.png)\n双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，他首先不会自己去尝试加载这个类，而是把这个请求委派父类加载器去完成。每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个请求（他的搜索范围中没有找到所需的类，抛出ClassNotFoundException异常）时，子加载器才会尝试自己去加载（调用自己的findClass()加载）。\n\n### 优势\n在说优势之前，先说下类和类加载器的关系\n> 类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远远不限于类加载阶段。对于任意一个类，都需要由加载他的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类命名空间。这句话可以表达的更通俗一些：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来自同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那这个两个类就必定不相等。\n\n那么，双亲委派模型的优势有哪些呢？有以下2点：\n1、避免类重复加载\n假设用户自己编写了一个称为java.lang.Object的类，\n如果没有使用双亲委派模型，由各个类加载器自行加载的话，那系统将会出现多个不同的Object类，Java类型体系中最基础的行为就无法保证。应用程序也将会变得一片混乱。\n2、程序安全\njava核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。\n\n### 双亲委派模型的破坏\n1、双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前--即JDK1.2发布之前。由于双亲委派模型是在JDK1.2之后才被引入的，而类加载器和抽象类java.lang.ClassLoader则是JDK1.0时候就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协。为了向前兼容，JDK1.2之后的java.lang.ClassLoader添加了一个新的proceted方法findClass()，在此之前，用户去继承java.lang.ClassLoader的唯一目的就是重写loadClass()方法，因为虚拟在进行类加载的时候会调用加载器的私有方法loadClassInternal()，而这个方法的唯一逻辑就是去调用自己的loadClass()。而恰恰在JDK1.2之后双亲委派模型的逻辑就在ClassLoaderd的loadClass()方法里。JDK1.2之后已不再提倡用户再去覆盖loadClass()方法，应当把自己的类加载逻辑写到findClass()方法中，在loadClass()方法的逻辑里，如果父类加载器加载失败，则会调用自己的findClass()方法来完成加载，这样就可以保证新写出来的类加载器是符合双亲委派模型的。\nClassLoaderd的loadClass()代码如下：\n```java\nClass<?> c = findLoadedClass(name);\n    if (c == null) {\n        long t0 = System.nanoTime();\n        try {\n            if (parent != null) {\n                c = parent.loadClass(name, false);\n            } else {\n                c = findBootstrapClassOrNull(name);\n            }\n        } catch (ClassNotFoundException e) {\n            // ClassNotFoundException thrown if class not found\n            // from the non-null parent class loader\n        }\n        if (c == null) {\n            // If still not found, then invoke findClass in order\n            // to find the class.\n            long t1 = System.nanoTime();\n            c = findClass(name);\n        }\n    }\n    if (resolve) {\n        resolveClass(c);\n    }\n```\n2、是这个模型自身的缺陷导致的。我们说，双亲委派模型很好的解决了各个类加载器的基础类的统一问题（越基础的类由越上层的加载器进行加载），基础类之所以称为“基础”，是因为它们总是作为被用户代码调用的API， 但没有绝对，如果基础类调用回用户的代码怎么办呢？\n\n这时就需要破坏双亲委派模型了，父类加载器请求子类加载器去完成类加载的动作。一个典型的例子就是JNDI服务，JNDI现在已经是Java的标准服务，它的代码由启动类加载器去加载（在JDK1.3时就放进去的rt.jar）,但它需要调用由独立厂商实现并部署在应用程序的ClassPath下的JNDI接口提供者（SPI， Service Provider Interface）的代码，但启动类加载器不可能“认识“这些代码啊。因为这些类不在rt.jar中，但是启动类加载器又需要加载。怎么办呢？\n\n为了解决这个问题，Java设计团队只好引入了一个不太优雅的设计：线程上下文类加载器（Thread Context ClassLoader）。这个类加载器可以通过java.lang.Thread类的setContextClassLoader方法进行设置。如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过多的话，那这个类加载器默认即使应用程序类加载器。\n\n嘿嘿，有了线程上下文加载器，JNDI服务使用这个线程上下文加载器去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则。但这无可奈何，Java中所有涉及SPI的加载动作基本胜都采用这种方式。例如JNDI，JDBC，JCE，JAXB，JBI等\n\n3、为了实现热插拔，热部署，模块化，意思是添加一个功能或减去一个功能不用重启，只需要把这模块连同类加载器一起换掉就实现了代码的热替换。\nOSGi实现模块化热部署的关键则是它自定义的类加载器机制的实现。每一个程序模块(Bundle)都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换。在OSGi幻境下，类加载器不再是双亲委派模型中的树状结构，而是进一步发展为更加复杂的网状结构，当受到类加载请求时，OSGi将按照下面的顺序进行类搜索：\n1）将java.＊开头的类委派给父类加载器加载。\n2）否则，将委派列表名单内的类委派给父类加载器加载。\n3）否则，将Import列表中的类委派给Export这个类的Bundle的类加载器加载。\n4）否则，查找当前Bundle的ClassPath，使用自己的类加载器加载。\n5）否则，查找类是否在自己的Fragment Bundle中，如果在，则委派给Fragment Bundle的类加载器加载。\n6）否则，查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载。\n7）否则，类加载器失败。\n\n### 为何JDBC违背双亲委派模型\n原生的JDBC中Driver驱动本身只是一个接口，并没有具体的实现，具体的实现是由不同数据库类型去实现的，所以在这种情况下JDBC不得以需要破坏双亲委派模式。原生的JDBC中的类是放在rt.jar包的，是由启动类加载器进行类加载的，在JDBC中的Driver类中需要动态去加载不同数据库类型的Driver类，而mysql-connector-.jar中的Driver类是用户自己写的代码，那启动类加载器肯定是不能进行加载的，既然是自己编写的代码，那就需要由应用程序启动类去进行类加载。下面看看JDBC中是怎么去应用的\n```java\nprivate static Connection getConnection(\n        String url, java.util.Properties info, Class<?> caller) throws SQLException {\n        /*\n         * callerCL为空的时候，其实说明这个ClassLoader是启动类加载器，\n         * 但是这个启动类加载并不能识别rt.jar之外的类，这个时候就把\n         * callerCL赋值为Thread.currentThread().getContextClassLoader()，也就是应用程序启动类\n         */\n        \n        ClassLoader callerCL = caller != null ? caller.getClassLoader() : null;\n        synchronized(DriverManager.class) {\n            // synchronize loading of the correct classloader.\n            if (callerCL == null) {\n                callerCL = Thread.currentThread().getContextClassLoader();\n            }\n        }\n\n        if(url == null) {\n            throw new SQLException(\"The url cannot be null\", \"08001\");\n        }\n\n        println(\"DriverManager.getConnection(\\\"\" + url + \"\\\")\");\n\n        // Walk through the loaded registeredDrivers attempting to make a connection.\n        // Remember the first exception that gets raised so we can reraise it.\n        SQLException reason = null;\n\n        for(DriverInfo aDriver : registeredDrivers) {\n            // If the caller does not have permission to load the driver then\n            // skip it.\n            //继续看这里 \n            if(isDriverAllowed(aDriver.driver, callerCL)) {\n                try {\n                    println(\"    trying \" + aDriver.driver.getClass().getName());\n                    Connection con = aDriver.driver.connect(url, info);\n                    if (con != null) {\n                        // Success!\n                        println(\"getConnection returning \" + aDriver.driver.getClass().getName());\n                        return (con);\n                    }\n                } catch (SQLException ex) {\n                    if (reason == null) {\n                        reason = ex;\n                    }\n                }\n\n            } else {\n                println(\"    skipping: \" + aDriver.getClass().getName());\n            }\n\n        }\n\n        // if we got here nobody could connect.\n        if (reason != null)    {\n            println(\"getConnection failed: \" + reason);\n            throw reason;\n        }\n\n        println(\"getConnection: no suitable driver found for \"+ url);\n        throw new SQLException(\"No suitable driver found for \"+ url, \"08001\");\n    }\n\n    private static boolean isDriverAllowed(Driver driver, ClassLoader classLoader) {\n        boolean result = false;\n        if(driver != null) {\n            Class<?> aClass = null;\n            try {\n                //这一步会对类进行初始化的动作，而初始化之前自然也要进行的类的加载工作\n                aClass =  Class.forName(driver.getClass().getName(), true, classLoader);\n            } catch (Exception ex) {\n                result = false;\n            }\n\n             result = ( aClass == driver.getClass() ) ? true : false;\n        }\n\n        return result;\n    }\n```\n\n\n### 为何Spring会破坏双亲委派模型\nSpring要对用户程序进行组织和管理，而用户程序一般放在WEB-INF目录下，由WebAppClassLoader类加载器加载，而Spring由Common类加载器或Shared类加载器加载。 \n那么Spring是如何访问WEB-INF下的用户程序呢？ \n使用线程上下文类加载器。 Spring加载类所用的classLoader都是通过Thread.currentThread().getContextClassLoader()获取的。当线程创建时会默认创建一个AppClassLoader类加载器（对应Tomcat中的WebAppclassLoader类加载器）： setContextClassLoader(AppClassLoader)。 \n利用这个来加载用户程序。即任何一个线程都可通过getContextClassLoader()获取到WebAppclassLoader。\n\n\n### 为何Tomcat类加载器违背双亲委派模型\n#### Tomcat类加载器层级关系\n![Tomcat类加载器层级关系](Tomcat类加载器层级关系.png)\n其中WebApp类加载器和Jsp类加载器通常会存在多个实例，每一个Web应用程序对应一个WebApp类加载器，每一个JSP文件对应一个Jsp类加载器。在双亲委派模型中要求除了顶层的启动类加载器之外，其余的类加载器都应当由自己的父类加载器加载。但Tomcat 为了实现隔离性，没有遵守这个约定，每个webappClassLoader加载自己的目录下的class文件，不会传递给父类加载器。但如果父类加载器想加载子类加载器中的类 ，可以使用线程上下文类加载器，去请求子类加载器去完成类加载的动作。\n\n#### 如果Tomcat使用双亲委派模型会有什么问题\n1、 无法加载两个相同类库的不同版本的\n> 在Tomcat里面，一个web容器可能需要部署多个应用程序，不同的应用程序可能会依赖同一个第三方类库的不同版本，不能要求同一个类库在同一个服务器只有一份，因此要保证每个应用程序的类库都是独立的，保证相互隔离。\n\n2、 对于修改后的jsp是不会重新加载的（jsp 文件其实也就是class文件），类加载器会直接取方法区中已经存在的\n> Tomcat的设计是每个jsp文件对应一个唯一的类加载器，当一个jsp文件修改了，就直接卸载这个jsp类加载器，然后重新创建类加载器，重新加载jsp文件。\n\n\n### 参考资料\n\n> - (Java双亲委派模型是什么、优势在哪、双亲委派模型的破坏)[https://blog.csdn.net/qq_22771739/article/details/86163254]\n> -(聊聊JDBC是如何破坏双亲委派模型的)[https://www.jianshu.com/p/60dbd8009c64]\n> -(以JDBC为例谈双亲委派模型的破坏)[https://www.jianshu.com/p/09f73af48a98]\n> -(破坏双亲委派模型)[https://blog.csdn.net/luzhensmart/article/details/82665122]\n","tags":["Java","JVM"],"categories":["Java","JVM"]},{"title":"init与clinit区别","url":"/2019/03/07/init-与-clinit-区别/","content":"\n### clinit\n<clinit>方法只能被jvm调用, 专门承担类变量的初始化工作。但并非所有的类都会拥有一个<clinit>方法, 满足下列条件之一的类不会拥有<clinit>方法:\n\n> - 该类既没有声明任何类变量，也没有静态初始化语句;\n> - 该类声明了类变量，但没有明确使用类变量初始化语句或静态初始化语句初始化;\n> - 该类仅包含静态 final 变量的类变量初始化语句，并且类变量初始化语句是编译时常量表达式;\n\n### init\n<init>方法的执行时期: 对象的初始化阶段。\n实例化一个类的四种途径:\n> - 调用 new 操作符\n> - 调用 Class 或 java.lang.reflect.Constructor 对象的newInstance()方法\n> - 调用任何现有对象的clone()方法\n> - 通过 java.io.ObjectInputStream 类的 getObject() 方法反序列化\n\n\n### 参考资料\n[jvm基础第三节: <clinit> 与 <init> 方法](https://www.jianshu.com/p/8a14ed0ed1e9)\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"主动引用与被动引用","url":"/2019/03/07/主动引用与被动引用/","content":"\n### 主动引用\n当且只有出现以下5种场景去触发类进行初始化，才能称为对一个类进行**主动引用**。\n> 遇到new、getstatic、putstatic或invokestatic这四条字节码指令（注意，newarray指令触发的只是数组类型本身的初始化，而不会导致其相关类型的初始化，比如，new String[]只会直接触发String[]类的初始化，也就是触发对类[Ljava.lang.String的初始化，而直接不会触发String类的初始化）时，如果类没有进行过初始化，则需要先对其进行初始化。生成这四条指令的最常见的Java代码场景是：\n1、使用new关键字实例化对象的时候；2、读取或设置一个类的静态字段（被final修饰，已在编译器把结果放入常量池的静态字段除外）的时候；3、调用一个类的静态方法的时候。\n\n> 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。\n> 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。\n> 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。\n> 当使用jdk1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic,REF_putstatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。\n\n### 被动引用\n除以上的引用类的方式外，都不会触发初始化，称为**被动引用**。主要有以下3种场景：\n> 当访问一个静态域时，只有真正声明这个域的类才会初始化，通过子类引用父类的静态变量，不会导致子类初始化\n> 通过数组定义类引用，不会触发此类的初始化\n> 引用常量（final）不会触发此类的初始化（常量在编译阶段就存入调用类的常量池中了）\n\n#### 举例\n\n1、通过子类引用父类的静态字段，不会导致子类初始化\n```java\npublic class SSClass{\n    static{\n        System.out.println(\"SSClass\");\n    }\n}  \n\npublic class SClass extends SSClass{\n    static{\n        System.out.println(\"SClass init!\");\n    }\n\n    public static int value = 123;\n\n    public SClass(){\n        System.out.println(\"init SClass\");\n    }\n}\n\npublic class SubClass extends SClass{\n    static{\n        System.out.println(\"SubClass init\");\n    }\n\n    static int a;\n\n    public SubClass(){\n        System.out.println(\"init SubClass\");\n    }\n}\n\npublic class NotInitialization{\n    public static void main(String[] args){\n        System.out.println(SubClass.value);\n    }\n}\n//输出结果\nSSClass\nSClass init!\n123     \n```\n\n对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。在本例中，由于value字段是在类SClass中定义的，因此该类会被初始化；此外，在初始化类SClass时，虚拟机会发现其父类SSClass还未被初始化，因此虚拟机将先初始化父类SSClass，然后初始化子类SClass，而SubClass始终不会被初始化。\n\n2、通过数组定义来引用类，不会触发此类的初始化\n```java\npublic class NotInitialization{\n    public static void main(String[] args){\n        SClass[] sca = new SClass[10];\n    }\n}\n```\n上述案例运行之后并没有任何输出，说明虚拟机并没有初始化类SClass。但是，这段代码触发了另外一个名为[Lcn.edu.tju.rico.SClass的类的初始化。从类名称我们可以看出，这个类代表了元素类型为SClass的一维数组，它是由虚拟机自动生成的，直接继承于Object的子类，创建动作由字节码指令newarray触发。\n\n3、常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化\n```java\npublic class ConstClass{\n\n    static{\n        System.out.println(\"ConstClass init!\");\n    }\n\n    public static  final String CONSTANT = \"hello world\";\n}\n\npublic class NotInitialization{\n    public static void main(String[] args){\n        System.out.println(ConstClass.CONSTANT);\n    }\n}\n//输出结果\nhello world\n```\n上述代码运行之后，只输出 “hello world”，这是因为虽然在Java源码中引用了ConstClass类中的常量CONSTANT，但是编译阶段将此常量的值“hello world”存储到了NotInitialization常量池中，对常量ConstClass.CONSTANT的引用实际都被转化为NotInitialization类对自身常量池的引用了。也就是说，实际上NotInitialization的Class文件之中并没有ConstClass类的符号引用入口，这两个类在编译为Class文件之后就不存在关系了。\n\n\n### 题外话\n> 类的实例化是指创建一个类的实例(对象)的过程\n> 类的初始化是指为类中各个类成员(static修饰的成员变量)赋初始值的过程，是类生命周期中的一个阶段。\n\n\n### 参考资料\n> (JVM类生命周期概述：加载时机与加载过程)[https://blog.csdn.net/justloveyou_/article/details/72466105]","tags":["JVM"],"categories":["JVM"]},{"title":"Tomcat中server.xml配置文件","url":"/2019/03/05/Tomcat中server-xml配置文件/","content":"\n### 简介\nTomcat服务器是由一系列可以配置的组件构成，其中核心组件是Catalina Servlet,它是最顶层组件。\nTomcat各组件是在server.xml(CATALINA_HOME\\conf\\server.xml)配置的。\n其详细的配置文件结构如下：\n```xml\n<?xml version='1.0' encoding='utf-8'?>\n<Server port=\"8005\" shutdown=\"SHUTDOWN\">\n  <Listener className=\"org.apache.catalina.startup.VersionLoggerListener\" />\n  <Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\" />\n  <Listener className=\"org.apache.catalina.core.JasperListener\" />\n  <Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\" />\n  <Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" />\n  <Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\" />\n\n  <GlobalNamingResources>\n    <Resource name=\"UserDatabase\" auth=\"Container\" type=\"org.apache.catalina.UserDatabase\" description=\"User database that can be updated and saved\" factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\" pathname=\"conf/tomcat-users.xml\" />\n  </GlobalNamingResources>\n\n  <Service name=\"Catalina\">\n    <Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" />\n    <Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" />\n    <Engine name=\"Catalina\" defaultHost=\"localhost\">\n      <Realm className=\"org.apache.catalina.realm.LockOutRealm\">\n        <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\"\n               resourceName=\"UserDatabase\"/>\n      </Realm>\n\n      <Host name=\"localhost\"  appBase=\"/opt/project/webapps\" unpackWARs=\"true\" autoDeploy=\"true\">\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log.\" suffix=\".txt\" pattern=\"%h %l %u %t &quot;%r&quot; %s %b\" />\n      </Host>\n    </Engine>\n  </Service>\n\n  <Service name=\"Catalina2\">\n    <Connector port=\"8084\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" />\n    <Connector port=\"8010\" protocol=\"AJP/1.3\" redirectPort=\"8443\" />\n    <Engine name=\"Catalina2\" defaultHost=\"localhost\">\n      <Realm className=\"org.apache.catalina.realm.LockOutRealm\">\n        <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\"\n               resourceName=\"UserDatabase\"/>\n      </Realm>\n\n      <Host name=\"localhost\"  appBase=\"/opt/project/webapps2\" unpackWARs=\"true\" autoDeploy=\"true\">\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log.\" suffix=\".txt\" pattern=\"%h %l %u %t &quot;%r&quot; %s %b\" />\n      </Host>\n    </Engine>\n  </Service>\n</Server>\n```\n其抽离的配置文件结构如下：\n```xml\n<Server>\n    <Listener />\n    <GlobaNamingResources>\n    </GlobaNamingResources>\n    <Service>\n        <Connector />\n        <Engine>\n            <Logger />\n            <Realm />\n                <host>\n                    <Logger />\n                    <Context />\n                </host>\n        </Engine>\n    </Service>\n</Server>\n```\n其关系结构图如下：\n\n![server结构](server结构.png) \n\n### 组件\n#### server\nServer即Catalina Servlet组件，它是server.xml的最外层元素\n**常用属性**\n> Address—Tomcat监听shutdown命令的地址，默认为localhost\n> className—指定实现org.apache.catalina.Server接口的类，默认值为org.apache.catalina.core.StandardServer\n> port－Tomcat监听shutdown命令的端口。设置为-1，则禁止通过端口关闭Tomcat，同时shutdown.bat也不能使用\n> shutdown－通过指定的地址（Address）、端口（port）关闭Tomcat所需的字符串。修改shutdown的值，对shutdown.bat无影响\n#### Listener\nListener即监听器，负责监听特定的事件，当特定事件触发时，Listener会捕捉到该事件，并做出相应处理。Listener通常用在Tomcat的启动和关闭过程。Listener可嵌在Server、Engine、Host、Context内\n**常用属性**\n> className－指定实现org.apache.catalina.LifecycleListener接口的类\n#### GlobalNamingResources\nGlobalNamingResources用于配置JNDI\n#### Service\nService包装Executor、Connector、Engine，以组成一个完整的服务。一个Service可以包含多个Connector，但是只能包含一个Engine。\n**常用属性**\n> className—指定实现org.apache.catalina. Service接口的类，默认值为org.apache.catalina.core.StandardService\n> name—Service的名字\n\nServer可以包含多个Service组件\n\n#### Executor\nExecutor即Service提供的线程池，供Service内各组件使用\n**常用属性**\n> className－指定实现org.apache.catalina. Executor接口的类，默认值为org.apache.catalina.core. StandardThreadExecutor\n> name－线程池的名字\n> daemon－是否为守护线程，默认值为true\n> maxIdleTime－总线程数高于minSpareThreads时，空闲线程的存活时间（单位：ms），默认值为60000，即1min\n> maxQueueSize－任务队列上限，默认值为Integer.MAX_VALUE(2147483647)，超过此值，将拒绝\n> maxThreads－线程池内线程数上限，默认值为200\n> minSpareThreads－线程池内线程数下限，默认值为25\n> namePrefix－线程名字的前缀。线程名字通常为namePrefix+ threadNumber\n> prestartminSpareThreads－是否在Executor启动时，就生成minSpareThreads个线程。默认为false\n> threadPriority－Executor内线程的优先级，默认值为5(Thread.NORM_PRIORITY)\n> threadRenewalDelay－重建线程的时间间隔。重建线程池内的线程时，为了避免线程同时重建，每隔threadRenewalDelay（单位：ms）重建一个线程。默认值为1000，设置为负则不重建\n\n#### Connector\nConnector是Tomcat接收请求的入口，每个Connector有自己专属的监听端口\nConnector有两种：HTTP Connector和AJP Connector\n##### HTTP Connector(HTTP/1.1)\nport : 在端口号8080处侦听来自客户browser的HTTP1.1请求.如果把8080改成80,则只要输入http://localhost/即可\nprotocol:设定Http协议,默认值为HTTP/1.1\nminSpareThreads: 该Connector先创建5个线程等待客户请求，每个请求由一个线程负责\nmaxSpareThread:设定在监听端口的线程的最大数目,这个值也决定了服务器可以同时响应客户请求的最大数目.默认值为200\nredirectport : 当客户请求是https时，把该请求转发到端口8443去\nenableLookups:如果设为true,表示支持域名解析,可以把IP地址解析为主机名.WEB应用中调用request.getRemoteHost方法返回客户机主机名.默认值为true\nconnectionTimeout:定义建立客户连接超时的时间.如果为-1,表示不限制建立客户连接的时间\nallowTrace：是否允许HTTP的TRACE方法，默认为false\nemptySessionPath：如果设置为true，用户的所有路径都将设置为/，默认为false。\nenableLookups：调用request、getRemoteHost()执行DNS查询，以返回远程主机的主机名，如果设置为false，则直接返回IP地址。\nmaxPostSize：指定POST方式请求的最大量，没有指定默认为2097152。\nprotocol：值必须为HTTP1.1，如果使用AJP处理器，该值必须为AJP/1.3\nproxyName：如这个连接器正在一个代理配置中被使用，指定这个属性，在request.getServerName()时返回\nredirectPort：如连接器不支持SSL请求，如收到SSL请求，Catalina容器将会自动重定向指定的端口号，让其进行处理。\nscheme：设置协议的名字，在request.getScheme()时返回，SSL连接器设为”https”，默认为”http”\nsecure：在SSL连接器可将其设置为true，默认为false\nURIEncoding：用于解码URL的字符编码，没有指定默认值为ISO-8859-1\nuseBodyEncodingForURI：主要用于Tomcat4.1.x中，指示是否使用在contentType中指定的编码来取代URIEncoding，用于解码URI查询参数，默认为false\nxpoweredBy：为true时，Tomcat使用规范建议的报头表明支持Servlet的规范版本，默认为false\nacceptCount：当所有的可能处理的线程都正在使用时，在队列中排队请求的最大数目。当队列已满，任何接收到的请求都会被拒绝，默认值为10\nbufferSize：设由连接器创建输入流缓冲区的大小，以字节为单位。默认情况下，缓存区大的大小为2048字节\ncompressableMimeType：MIME的列表，默认以逗号分隔。默认值是text/html，text/xml，text/plain\ncompression：指定是否对响应的数据进行压缩。off：表示禁止压缩、on：表示允许压缩（文本将被压缩）、force：表示所有情况下都进行压缩，默认值为off\nconnectionTimeout：设置连接的超时值，以毫秒为单位。默认值为60000=60秒\ndisableUploadTimeOut：允许Servlet容器，正在执行使用一个较长的连接超时值，以使Servlet有较长的时间来完成它的执行，默认值为false\nmaxHttpHeaderSize：HTTP请求和响应头的最大量，以字节为单位，默认值为4096字节\nmaxKeepAliveRequest：服务器关闭之前，客户端发送的流水线最大数目。默认值为100\nmaxSpareThreads：允许存在空闲线程的最大数目，默认值为50\nminSpareThreads：设当连接器第一次启动创建线程的数目，确保至少有这么多的空闲线程可用。默认值为4\nport：服务端套接字监听的TCP端口号，默认值为8080（必须）\nsocketBuffer：设Socket输出缓冲区的大小（以字节为单位），-1表示禁止缓冲，默认值为9000字节\ntoNoDelay：为true时，可以提高性能。默认值为true\nthreadPriority：设JVM中请求处理线程优先级。默认值为NORMAL-PRIORITY\nexecutor－指定线程池\n\n##### AJP Connector(AJP/1.3)\n用于将Apache与Tomcat集成在一起，当Apache接收到动态内容请求时，通过在配置中指定的端口号将请求发送给在此端口号上监听的AJP连接器组件。\n\nbacklog：当所有可能的请求处理线程都在使用时，队列中排队的请求最大数目。默认为10，当队列已满，任何请求都将被拒绝\nmaxSpareThread：允许存在空闲线程的最大数目，默认值为50\nmaxThread：最大线程数，默认值为200\nminSpareThreads：设当连接器第一次启动时创建线程的数目，确保至少有这么多的空闲线程可用，默认值为4\nport：服务端套接字的TCP端口号，默认值为8089（必须）\ntopNoDelay：为true时，可以提高性能，默认值为true\nsoTimeout：超时值\nexecutor－指定线程池\n\n#### Engine\nEngine负责处理Service内的所有请求。它接收来自Connector的请求，并决定传给哪个Host来处理，Host处理完请求后，将结果返回给Engine，Engine再将结果返回给Connector\n**常用属性：**\nname－Engine的名字\ndefaultHost－指定默认Host。Engine接收来自Connector的请求，然后将请求传递给defaultHost，defaultHost 负责处理请求\nclassName－指定实现org.apache.catalina. Engine接口的类，\n默认值为org.apache.catalina.core. StandardEngine\nbackgroundProcessorDelay－Engine及其部分子组件（Host、Context）调用backgroundProcessor方法的时间间隔。backgroundProcessorDelay为负，将不调用backgroundProcessor。\nbackgroundProcessorDelay的默认值为10\n注：Tomcat启动后，Engine、Host、Context会启动一个后台线程，定期调用backgroundProcessor方法。backgroundProcessor方法主要用于重新加载Web应用程序的类文件和资源、扫描Session过期\njvmRoute－Tomcat集群节点的id。部署Tomcat集群时会用到该属性，\nService内必须包含一个Engine组件\nService包含一个或多个Connector组件，Service内的Connector共享一个Engine\n\n#### Host\nHost负责管理一个或多个Web项目\n常用属性：\nname－Host的名字\nappBase－存放Web项目的目录（绝对路径、相对路径均可）\nunpackWARs－当appBase下有WAR格式的项目时，是否将其解压（解成目录结构的Web项目）。设成false，则直接从WAR文件运行Web项目\nautoDeploy－是否开启自动部署。设为true，Tomcat检测到appBase有新添加的Web项目时，会自动将其部署\nstartStopThreads－线程池内的线程数量。Tomcat启动时，Host提供一个线程池，用于部署Web项目\nstartStopThreads为0，并行线程数=系统CPU核数\nstartStopThreads为负数，并行线程数=系统CPU核数+startStopThreads，如果（系统CPU核数+startStopThreads）小于1，并行线程数设为1\nstartStopThreads为正数，并行线程数= startStopThreads\nstartStopThreads默认值为1\nstartStopThreads为默认值时，Host只提供一个线程，用于部署Host下的所有Web项目。如果Host下的Web项目较多，由于只有一个线程负责部署这些项目，因此这些项目将依次部署，最终导致Tomcat的启动时间较长。此时，修改startStopThreads值，增加Host部署Web项目的并行线程数，可降低Tomcat的启动时间\n\n#### Context\nContext代表一个运行在Host上的Web项目。一个Host上可以有多个Context\n将一个Web项目（D:\\MyApp）添加到Tomcat，在Host标签内，添加Context标签\n\n\n常用属性：\npath－该Web项目的URL入口。path设置为””，输入http://localhost:8080即可访问MyApp；path设置为”/test/MyApp”，输入http://localhost:8080/test/MyApp才能访问MyApp\ndocBase－Web项目的路径，绝对路径、相对路径均可\n（相对路径是相对于CATALINA_HOME\\webapps）\nreloadable－设置为true，Tomcat会自动监控Web项目的/WEB-INF/classes/和/WEB-INF/lib变化，当检测到变化时，会重新部署Web项目。reloadable默认值为false。通常项目开发过程中设为true，项目发布的则设为false\ncrossContext－设置为true，该Web项目的Session信息可以共享给同一host下的其他Web项目。默认为false\n\n### Tomcat Server处理一个http请求的过程\n假设来自客户的请求为：http://localhost:8080/wsota/wsota_index.jsp\n\n1) 请求被发送到本机端口8080，被在那里侦听的Coyote HTTP/1.1 Connector获得\n2) Connector把该请求交给它所在的Service的Engine来处理，并等待来自Engine的回应\n3) Engine获得请求localhost/wsota/wsota_index.jsp，匹配它所拥有的所有虚拟主机Host\n4) Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机）\n5) localhost Host获得请求/wsota/wsota_index.jsp，匹配它所拥有的所有Context\n6) Host匹配到路径为/wsota的Context（如果匹配不到就把该请求交给路径名为\"\"的Context去处理）\n7) path=\"/wsota\"的Context获得请求/wsota_index.jsp，在它的mapping table中寻找对应的servlet\n8) Context匹配到URL PATTERN为`*`.jsp的servlet，对应于JspServlet类\n9) 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法\n10)Context把执行完了之后的HttpServletResponse对象返回给Host\n11)Host把HttpServletResponse对象返回给Engine\n12)Engine把HttpServletResponse对象返回给Connector\n13)Connector把HttpServletResponse对象返回给客户browser\n\n![请求流程.png](请求流程.png)\n","tags":["Tomcat"],"categories":["Tomcat"]},{"title":"String.intern浅析","url":"/2019/03/05/String-intern浅析/","content":"\n### 简介\nintern用来返回常量池中的某字符串，如果常量池中已经存在该字符串，则直接返回常量池中该对象的引用。否则，在常量池中加入该对象，然后 返回引用。在jdk1.7之前，字符串常量存储在方法区的PermGen Space。在jdk1.7之后，字符串常量重新被移到了堆中。\n\n### String被设计成final的原因\n\n1. 字符串常量池的需要。字符串常量池的诞生是为了提升效率和减少内存分配。可以说我们编程有百分之八十的时间在处理字符串，而处理的字符串中有很大概率会出现重复的情况。正因为String的不可变性，常量池很容易被管理和优化。\n\n2. 安全性考虑。正因为使用字符串的场景如此之多，所以设计成不可变可以有效的防止字符串被有意或者无意的篡改。从java源码中String的设计中我们不难发现，该类被final修饰，同时所有的属性都被final修饰，在源码中也未暴露任何成员变量的修改方法。（当然如果我们想，通过反射或者Unsafe直接操作内存的手段也可以实现对所谓不可变String的修改）。\n\n3. 作为HashMap、HashTable等hash型数据key的必要。因为不可变的设计，jvm底层很容易在缓存String对象的时候缓存其hashcode，这样在执行效率上会大大提升。\n\n### 实例说明\n```java\nString s1 = new String(\"aaa\");\nString s2 = \"aaa\";\nSystem.out.println(s1 == s2);    // false\n\ns1 = new String(\"bbb\").intern();\ns2 = \"bbb\";\nSystem.out.println(s1 == s2);    // true\n\ns1 = \"ccc\";\ns2 = \"ccc\";\nSystem.out.println(s1 == s2);    // true\n\ns1 = new String(\"ddd\").intern();\ns2 = new String(\"ddd\").intern();\nSystem.out.println(s1 == s2);    // true\n\ns1 = \"ab\" + \"cd\";\ns2 = \"abcd\";    \nSystem.out.println(s1 == s2);    // true\n\nString temp = \"hh\";\ns1 = \"a\" + temp;\n// 如果调用s1.intern 则最终返回true\ns2 = \"ahh\";\nSystem.out.println(s1 == s2);    // false\n\ntemp = \"hh\".intern();\ns1 = \"a\" + temp;\ns2 = \"ahh\";\nSystem.out.println(s1 == s2);    // false\n\ntemp = \"hh\".intern();\ns1 = (\"a\" + temp).intern();\ns2 = \"ahh\";\nSystem.out.println(s1 == s2);    // true\n\ns1 = new String(\"1\");    // 同时会生成堆中的对象 以及常量池中1的对象，但是此时s1是指向堆中的对象的\ns1.intern();            // 常量池中的已经存在\ns2 = \"1\";\nSystem.out.println(s1 == s2);    // false\n\nString s3 = new String(\"1\") + new String(\"1\");    // 此时生成了四个对象 常量池中的\"1\" + 2个堆中的\"1\" + s3指向的堆中的对象（注此时常量池不会生成\"11\"）\ns3.intern();    // jdk1.7之后，常量池不仅仅可以存储对象，还可以存储对象的引用，会直接将s3的地址存储在常量池\nString s4 = \"11\";    // jdk1.7之后，常量池中的地址其实就是s3的地址\nSystem.out.println(s3 == s4); // jdk1.7之前false， jdk1.7之后true\n\ns3 = new String(\"2\") + new String(\"2\");\ns4 = \"22\";        // 常量池中不存在22，所以会新开辟一个存储22对象的常量池地址\ns3.intern();    // 常量池22的地址和s3的地址不同\nSystem.out.println(s3 == s4); // false\n\n// 对于什么时候会在常量池存储字符串对象，我想我们可以基本得出结论: 1. 显示调用String的intern方法的时候; 2. 直接声明字符串字面常量的时候，例如: String a = \"aaa\";\n// 3. 字符串直接常量相加的时候，例如: String c = \"aa\" + \"bb\";  其中的aa/bb只要有任何一个不是字符串字面常量形式，都不会在常量池生成\"aabb\". 且此时jvm做了优化，不会同时生成\"aa\"和\"bb\"在字符串常量池中\n```\n具体的字节码分析：\n```java\n/**\n * 字节码为：\n *   0:   ldc     #16; //String 11   --- 从常量池加载字符串常量11\n     2:   astore_1                   --- 将11的引用存到本地变量1，其实就是将s指向常量池中11的位置\n */\nString s = \"11\";    \n\n/**\n * 0:   new     #16; //class java/lang/String    --- 新开辟了一个地址，存储new出来的对象\n   3:   dup                                      --- 将new出来的对象复制了一份到栈顶（也就是s1最终指向的是堆中的另一个存储字符串11的地址）\n   4:   ldc     #18; //String 11　　　　　　　　　　\n   6:   invokespecial   #20; //Method java/lang/String.\"<init>\":(Ljava/lang/String;)V\n   9:   astore_1\n */\nString s1 = new String(\"11\");\n\n/**\n * 0:   new     #16; //class java/lang/StringBuilder                       --- 可以看到jdk对字符串拼接做了优化，先是建了一个StringBuilder对象\n   3:   dup\n   4:   new     #18; //class java/lang/String                              --- 创建String对象\n   7:   dup\n   8:   ldc     #20; //String 1                                            --- 从常量池加载了1（此时常量池和堆中都会存字符串对象）\n   10:  invokespecial   #22; //Method java/lang/String.\"<init>\":(Ljava/lang/String;)V                    --- 初始化String(\"1\")对象\n   13:  invokestatic    #25; //Method java/lang/String.valueOf:(Ljava/lang/Object;)Ljava/lang/String;\n   16:  invokespecial   #29; //Method java/lang/StringBuilder.\"<init>\":(Ljava/lang/String;)V             --- 初始化StringBuilder对象\n   19:  new     #18; //class java/lang/String\n   22:  dup\n   23:  ldc     #20; //String 1\n   25:  invokespecial   #22; //Method java/lang/String.\"<init>\":(Ljava/lang/String;)V\n   28:  invokevirtual   #30; //Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n   31:  invokevirtual   #34; //Method java/lang/StringBuilder.toString:()Ljava/lang/String;\n   34:  astore_1                                                                                          ---从上可以看到实际上常量池目前只存了1\n  36:  invokevirtual   #38; //Method java/lang/String.intern:()Ljava/lang/String;  --- 调用String.intern中，jdk1.7以后，常量池也是堆中的一部分且常量池可以存引用，这里直接存的是s2的引用\n  39:  pop                                                                                                --- 这里直接返回的是栈顶的元素\n */\nString s2 = new String(\"1\") + new String(\"1\");\ns2.intern();\n\n/**\n * 0:   ldc     #16; //String abc        --- 可以看到此时常量池直接存储的是:abc, 而不会a、b、c各存一份\n   2:   astore_1\n */\nString s3 = \"a\" + \"b\" + \"c\";\n\n/**    \n0:   new     #16; //class java/lang/StringBuilder\n3:   dup\n4:   ldc     #18; //String why                --- 常量池的why\n6:   invokespecial   #20; //Method java/lang/StringBuilder.\"<init>\":(Ljava/lang/String;)V\n9:   ldc     #23; //String true                --- 常量池的true\n11:  invokevirtual   #25; //Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n14:  invokevirtual   #29; //Method java/lang/StringBuilder.toString:()Ljava/lang/String;\n17:  astore_1\n*/\nString s1 = new StringBuilder(\"why\").append(\"true\").toString();\nSystem.out.println(s1 == s1.intern());                            // jdk1.7之前为false，之后为true\n```\n字符串拼接优化\n```java\nString a = \"1\"; \nfor (int i=0; i<10; i++) { \n　　a += i; \n}\n0:   ldc     #16; //String 1\n2:   astore_1\n3:   iconst_0\n4:   istore_2            　　　　　　　　　　　　　　　　　　　--- 循环开始\n5:   goto    30           \n8:   new     #18; //class java/lang/StringBuilder        --- 每个循环都建了一个StringBuilder对象，对性能有损耗。每次循环会new出一个StringBuilder对象，然后进行append操作，最后通过toString方法返回String对象。\n11:  dup\n12:  aload_1\n13:  invokestatic    #20; //Method java/lang/String.valueOf:(Ljava/lang/Object;)Ljava/lang/String;\n16:  invokespecial   #26; //Method java/lang/StringBuilder.\"<init>\":(Ljava/lang/String;)V\n19:  iload_2\n20:  invokevirtual   #29; //Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;\n23:  invokevirtual   #33; //Method java/lang/StringBuilder.toString:()Ljava/lang/String;\n26:  astore_1\n27:  iinc    2, 1        ---- 计数加1\n30:  iload_2\n31:  bipush  10\n33:  if_icmplt       8\n```\n可知，真正的性能瓶颈在于每次循环都建了一个StringBuilder对象\n所以我们优化一下 ：\n```java\nStringBuilder sb = new StringBuilder(\"1\");\nfor (int i=0; i<10; i++) {\n    sb.append(\"1\");\n}\n对应的字节码为：\n0:   new     #16; //class java/lang/StringBuilder        -- 在循环直接初始化了StringBuilder对象\n3:   dup\n4:   ldc     #18; //String 1\n6:   invokespecial   #20; //Method java/lang/StringBuilder.\"<init>\":(Ljava/lang/String;)V        \n9:   astore_1\n10:  iconst_0\n11:  istore_2\n12:  goto    25\n15:  aload_1\n16:  ldc     #18; //String 1\n18:  invokevirtual   #23; //Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n21:  pop\n22:  iinc    2, 1\n25:  iload_2\n26:  bipush  10\n28:  if_icmplt       15\n```\n### 参考资料\n[Java-String.intern的深入研究](https://www.cnblogs.com/Kidezyq/p/8040338.html)","tags":["Java"],"categories":["Java"]},{"title":"Thread.sleep()和Object.wait()区别","url":"/2019/02/27/Thread-sleep-和Object-wait-区别/","content":"\n### 区别\n\n&#8194;&#8194;&#8194;&#8194;下面将从调用方式、是否释放锁对象两方面进行阐述。\n\n&#8194;&#8194;&#8194;&#8194;Thread.sleep(long millis) 是**Thread类的静态方法**，作用是让当前正在执行的线程休眠（暂时停止执行）指定的毫秒数。\n> &#8194;&#8194;&#8194;&#8194;原理是让出cpu时间片，把当前线程放入就绪线程队列中，直到睡眠时间到期自动苏醒，被调度为可执行线程（runnable）。sleep()方法作用的线程一定是当前正在运行的线程，如果代码在一个线程类中，不一定是代码所在的线程实例，即使是在线程对象上调用sleep()或者调用Thread.currentThread().sleep()，**调用sleep()方法并不会释放对象锁**。\n\n&#8194;&#8194;&#8194;&#8194;object.wait()是**实例对象（Object及其子类实列，也包括Class类实例）的方法**，让当前正在执行的线程释放锁，直到被通知。\n\n&#8194;&#8194;&#8194;&#8194;object.wait(long timeout)也会让当前正在执行的线程释放锁，并在超时后会自动唤醒该线程重新竞争锁。在超时时间内也可调用调用notify/notifyAll进行唤醒。\n\n> &#8194;&#8194;&#8194;&#8194;原理是让出cpu时间片，把当前正在执行的线程放入wait线程队列中，并把当前线程注册为指定对象的监听器，并**释放指定对象的锁**；当被notify/notifyAll通知时，重新进入Entry队列去，去竞争指定对象的锁，获得锁的线程进入就绪队列，等待被调度。\n\n&#8194;&#8194;&#8194;&#8194;wait()方法必须在sychronized代码块中，且锁定的对象要与等待通知来源的对象一致，即调用notify/notifyAll的实例对象是同一个。而wait(long)方法阻塞时放入的是就绪队列，等待时间到期或被通知就可被调度。\n\n下面，我们来看下JDK源码对wait()的解释\n```java\n* Causes the current thread to wait until another thread invokes the\n* {@link java.lang.Object#notify()} method or the\n* {@link java.lang.Object#notifyAll()} method for this object.\n* In other words, this method behaves exactly as if it simply\n* performs the call {@code wait(0)}.\n```\n&#8194;&#8194;&#8194;&#8194;**执行这个方法的线程会等待直到调用notify()/notifyAll()方法。**调用wait() 是让调用方法的线程挂起,和调用的是哪个对象上的wait方法没关系。\n\n\n### 题外话\n####  锁对象\n> &#8194;&#8194;&#8194;&#8194;每个锁对象都有两个队列，一个是就绪队列，一个是阻塞队列，就绪队列存储了将要获得锁的线程，阻塞队列存储了被阻塞的线程，当一个被线程被唤醒 (notify)后，才会进入到就绪队列，等待获得锁。\n\n\n**举例说明**\n&#8194;&#8194;&#8194;&#8194;当一开始线程a第一次执行account.add方法时，jvm会检查锁对象account 的就绪队列是否已经有线程在等待，如果有则表明account的锁已经被占用了，由于是第一次运行，account的就绪队列为空，所以线程a获得了锁， 执行account.add方法。如果恰好在这个时候，线程b要执行account.withdraw方法，因为线程a已经获得了锁还没有释放，所以线程 b要进入account的就绪队列，等到得到锁后才可以执行。\n\n\n一个线程执行临界区代码过程如下：\n\n> 1、 获得同步锁\n> 2、 清空工作内存\n> 3、 从主存拷贝变量副本到工作内存\n> 4、 对这些变量计算\n> 5、 将变量从工作内存写回到主存\n> 6、 释放锁\n\n&#8194;&#8194;&#8194;&#8194;可见，synchronized既保证了多线程的并发有序性，又保证了多线程的内存可见性。\n线程释放锁的方式，通常是主动调用notify方法、同步代码块结束释放锁资源。同步代码块结束释放锁资源，对象就绪队列中的某一线程获得锁资源而开始线程；如果不使用notify，那么阻塞队列里线程将一直处于阻塞状态，即使就绪队列里线程都执行完了，阻塞队列里线程也将一直处于阻塞状态。\n\n&#8194;&#8194;&#8194;&#8194;notify不会释放锁，而是通知锁对象的阻塞队列里的某一线程（被阻塞，即主动调用wait方法），进入就绪队列。\n&#8194;&#8194;&#8194;&#8194;notifyAll 是 唤醒阻塞队列里的所有阻塞线程，他们都将进入就绪队列，而notify的数量是一个\n\n\n### Thread.yield与Thread.sleep区别\nyield 即 \"谦让\"，也是 Thread 类的方法。它让掉当前线程 CPU 的时间片，使正在运行中的线程重新变成就绪状态，并重新竞争 CPU 的调度权。它可能会获取到，也有可能被其他线程获取到。\n\n1）yield, sleep 都能暂停当前线程，sleep 可以指定具体休眠的时间，而 yield 则依赖 CPU 的时间片划分。\n\n2）yield, sleep 两个在暂停过程中，如已经持有锁，则都不会释放锁资源。\n\n3）yield 不能被中断，而 sleep 则可以接受中断。\n\n\n### 参考资料\n- [java之Thread.sleep(long)与object.wait()/object.wait(long)的区别及相关概念梳理\n](https://www.cnblogs.com/softidea/p/4162724.html)\n- [每个锁对象都有两个队列，一个是就绪队列，一个是阻塞队列](https://www.cnblogs.com/01picker/p/4832506.html)\n- [多线程 Thread.yield 方法到底有什么用？](https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247487669&idx=2&sn=269b1dc32e6bfb8e04daa9fbd745837b&chksm=eb539583dc241c9565aefff79aca1941600a48b8ee6ae846da814de534a1bec5639f038028c4&mpshare=1&scene=24&srcid=1120N8FghYE7GujqjrwEYe0y#rd)\n","tags":["线程"],"categories":["线程"]},{"title":"drop、delete、truncate区别","url":"/2019/02/27/drop、delete、truncate区别/","content":"\n### 特性\n1、truncate是一个能够快速清空资料表内所有资料的SQL语法，并且能针对具有自动递增值字段重置归零，重新计算的作用。truncate table用于删除表中的所有行，而不是记录单个行删除操作。\n\n2、比delete速度快，且使用的系统和事务日志资源少。delete每删除一行，会在事务日志中记录下这一步操作。truncate table通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。\n\n3、因为truncate table不记录在日志中，所以它不能激活触发器。\n\n4、如果有rollback语句，delete操作将被撤销，但truncate不会撤销。\n\n###  区别\n\n1、drop语句将删除表的结构、被依赖的约束、触发器、索引；依赖于该表的存储过程/函数将保留，但是变为invalid状态。\n2、delete语句是DML语言，需要事务提交后生效；如果有相应的触发器，执行的时候将被触发。truncate 、drop是DDL语言，操作后即生效，元数据不会放到rollback，不能回滚，操作不会触发trigger。\n3、delete语句不影响表所占用的extent、高水线（high watermark）保持原位置不动。drop语句将表所占用的空间全部释放。truncate语句默认情况下将空间释放到minextents的extent，并将高水线复位。\n4、效率方面：drop > truncate > delete\n5、delete是DML语句，不会自动提交。drop/truncate都是DDL语句,执行后会自动提交\n\n\n","tags":["数据库"],"categories":["数据库"]},{"title":"Thread.join()原理","url":"/2019/02/27/Thread-join-原理/","content":"\n### 简介\n&#8194;&#8194;&#8194;&#8194;join()是Thread类的一个方法。t.join()方法阻塞调用此方法的线程(calling thread)，直到线程t完成，此线程再继续执行；通常用于在main()主线程内，等待其它线程完成再结束main()主线程。\n\n\n![Thread.join线程状态图.png](Thread.join线程状态图.png) \n### 示例\n\n```java\npublic static void main(String[] args){\n    \n    //启动一个子线程\n    Thread threadA = new Thread(new Runnable() {\n        @Override\n        public void run() {\n            try {\n                Thread.sleep(1000);\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n            System.out.println(\"threadA run\");\n        }\n    });\n    threadA.start();\n    try {\n        threadA.join();    //调用join()\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    }\n    System.out.println(\"MainThread run finished.\");\n}\n```\n&#8194;&#8194;&#8194;&#8194;在main主线程调用threadA.join()后，threadA线程正常运行，main主线程会等待threadA线程结束后再继续运行。\n\n### 原理分析\n下面看下join()的源码\n```java\npublic final void join() throws InterruptedException {\n    join(0);\n}\n\npublic final synchronized void join(long millis) throws InterruptedException {\n    long base = System.currentTimeMillis();\n    long now = 0;\n\n    if (millis < 0) {\n        throw new IllegalArgumentException(\"timeout value is negative\");\n    }\n\n    if (millis == 0) {        //无限期等待直到线程A结束\n        while (isAlive()) {   //threadA线程状态\n            wait(0);        //threadA.wait(0)，让执行这个方法的线程（主线程）阻塞\n        }\n    } else {                 // 等待固定时间，如果线程A还没结束，那么就不等待了。\n        while (isAlive()) {   //threadA线程状态\n            long delay = millis - now;\n            if (delay <= 0) {\n                break;\n            }\n            wait(delay);    //threadA.wait(delay)，让执行这个方法的线程（主线程）阻塞\n            now = System.currentTimeMillis() - base;\n        }\n    }\n}\n\npublic final synchronized void join(long millis, int nanos) throws InterruptedException {\n\n    if (millis < 0) {\n        throw new IllegalArgumentException(\"timeout value is negative\");\n    }\n\n    if (nanos < 0 || nanos > 999999) {\n        throw new IllegalArgumentException(\n                            \"nanosecond timeout value out of range\");\n    }\n\n    if (nanos >= 500000 || (nanos != 0 && millis == 0)) {\n        millis++;\n    }\n\n    join(millis);\n}\n```\n&#8194;&#8194;&#8194;&#8194;这里使用synchronized是因为在join()里面调用了wait()，此时要进入join(long millis)方法必须持有threadA线程对象锁，也就是主线程持有了threadA这个对象的锁。\n下面重点看这一块的代码\n```java\n while (isAlive()) {   //threadA线程状态\n            wait(0);        //threadA.wait(0)，让执行这个方法的线程（主线程）阻塞\n        }\n```\n&#8194;&#8194;&#8194;&#8194;如果threadA线程是活跃的，则循环调用threadA.wait(0)，此时正在执行的线程（main主线程）释放threadA线程的对象锁，其他线程可以竞争锁并进入threadA.join(0)。一旦threadA线程执行完毕（状态为TERMINATED），JVM会调用lock.notify_all(thread)，唤醒持有threadA这个对象锁的线程，至此阻塞在threadA对象上的线程，即主线程可以继续执行后面的内容。\n\n### 总结\n&#8194;&#8194;&#8194;&#8194;join()方法的底层是通过wait() 实现的。当main主线程调用threadA.join()时，main线程会获得threadA线程对象锁，只有这样才能执行synchronized join()方法内，调用threadA线程对象的wait()。目的是让持有这个threadA线程对象锁的线程都进入等待，等待threadA线程执行完毕。然后JVM底层lock.notify_all(thread)，唤醒持有threadA对象锁的所有线程。\n\n### 参考资料\n- [Java线程的join()方法源码问题，锁的问题](https://bbs.csdn.net/topics/392160414)\n- [Java 浅析 Thread.join()](https://www.cnblogs.com/huangzejun/p/7908898.html)\n\n\n\n\n\n\n\n","tags":["线程"],"categories":["线程"]},{"title":"数据库事务隔离级别原理","url":"/2019/02/22/数据库事务隔离级别原理/","content":"\n\n### 什么是事务\n单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。简单的说，事务就是并发控制的单位，是用户定义的一个操作序列。\n\n### 事务的ACID\n#### 原子性（Atomicity）\n原子性是指事务是一个不可再分割的工作单元，事务中的操作要么都发生，要么都不发生。可采用“A向B转账”这个例子来说明解释在DBMS中，默认情况下一条SQL就是一个单独事务，事务是自动提交的。只有显式的使用start transaction开启一个事务，才能将一个代码块放在事务中执行。\n\n#### 一致性（Consistent）\n一致性是指在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。这是说数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。\n\n如A给B转账，不论转账的事务操作是否成功，其两者的存款总额不变（这是业务逻辑的一致性，至于数据库关系约束的完整性就更好理解了）。\n\n保障机制（也从两方面着手）：数据库层面会在一个事务执行之前和之后，数据会符合你设置的约束（唯一约束，外键约束,check约束等)和触发器设置；此外，数据库的内部数据结构（如 B 树索引或双向链表）都必须是正确的。业务的一致性一般由开发人员进行保证，亦可转移至数据库层面。 \n\n#### 隔离性 (Isolation)\n多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。\n\n在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看到中间状态的数据。\n\n事务最复杂问题都是由事务隔离性引起的。完全的隔离性是不现实的，完全的隔离性要求数据库同一时间只执行一条事务（串行化），这样会严重影响性能。\n\n####  持久性（Durability）\n意味着在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。（完成的事务是系统永久的部分，对系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持）。\n\n\n### 事务的隔离级别\n#### Read uncommitted（读未提交）\n**一个事务可以读取另一个未提交事务的数据**。\n事例：老板要给程序员发工资，程序员的工资是3.6万/月。但是发工资时老板不小心按错了数字，按成3.9万/月，该钱已经打到程序员的户口，但是事务还没有提交，就在这时，程序员去查看自己这个月的工资，发现比往常多了3千元，以为涨工资了非常高兴。但是老板及时发现了不对，马上回滚差点就提交了的事务，将数字改成3.6万再提交。\n\n分析：实际程序员这个月的工资还是3.6万，但是程序员看到的是3.9万。他看到的是老板还没提交事务时的数据。这就是脏读。\n\n那怎么解决脏读呢？**Read committed-读提交**，能解决脏读问题。\n\n#### Read committed （读已提交）\n一个事务要等另一个事务提交后才能读取数据。\n\n事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务提交完）。程序员就会很郁闷，明明卡里是有钱的。\n\n分析：这就是读提交，若有事务对数据进行更新（UPDATE）操作时，**读操作事务要等待这个更新操作事务提交后才能读取数据，可以解决脏读问题**。但在这个事例中，出现了一个事务范围内两个相同的查询却返回了不同数据，这就是不可重复读。\n\n#### Repeatable read (可重复读)\n重复读，就是在开始读取数据（事务开启）时，不再允许修改操作。\n\n事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（事务开启，不允许其他事务的UPDATE修改操作），收费系统事先检测到他的卡里有3.6万。这个时候他的妻子不能转出金额了。接下来收费系统就可以扣款了。\n\n分析：重复读可以解决不可重复读问题。写到这里，应该明白的一点就是，**不可重复读对应的是修改，即UPDATE和DELETE操作当前数据项**。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE和DELETE操作当前数据项。\n\n**什么时候会出现幻读？**\n\n事例：程序员某一天去消费，花了2千元，然后他的妻子去查看他今天的消费记录（全表扫描FTS，妻子事务开启），看到确实是花了2千元，就在这个时候，程序员花了1万买了一部电脑，即新增INSERT了一条消费记录，并提交。当妻子打印程序员的消费记录清单时（妻子事务提交），发现花了1.2万元，似乎出现了幻觉，这就是幻读。\n\n那怎么解决幻读问题？Serializable！\n\n#### Serializable 序列化\nSerializable 是最高的事务隔离级别，在该级别下，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。\n\n大多数数据库默认的事务隔离级别是Read committed，比如Sql Server , Oracle。Mysql的默认隔离级别是Repeatable read。\n在库存系统中，如果数据库是用Oracle，不能用一个数据记录代表一个库存，因为存在不可重复读，会因为其他事务delete或insert库存记录，导致库存不准确，可以是提高隔离级别为Repeatable read或使用Mysql数据库。\n\n\n### MySQL隔离级别的实现\n事务的机制是通过**视图（read-view）**来实现的并发版本控制（MVCC），不同的事务隔离级别创建读视图的时间点不同。\n\n- 可重复读是每个事务重建读视图，整个事务存在期间都用这个视图。\n- 读已提交是每条 SQL 创建读视图，在每个 SQL 语句开始执行的时候创建的。隔离作用域仅限该条 SQL 语句。\n- 读未提交是不创建，直接返回记录上的最新值\n- 串行化隔离级别下直接用加锁的方式来避免并行访问。\n这里的视图可以理解为数据副本，每次创建视图时，将当前已持久化的数据创建副本，后续直接从副本读取，从而达到数据隔离效果。\n\n\n#### undo log\n数据表其实有一些隐藏的属性，比如每一行的事务id，所以每一行数据可能会有多个版本，每一个修改过它的事务都会有一个事务id，并且还会有关联的 undo log，表示这个操作原来的数据是什么，可以用它做回滚。\n\n> - undo log 中存储的是老版本数据。假设修改表中 id=2 的行数据，把 Name=‘B’ 修改为 Name = ‘B2’ ，那么 undo 日志就会用来存放 Name=‘B’ 的记录，如果这个修改出现异常，可以使用 undo 日志来实现回滚操作，保证事务的一致性。\n> - 当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着 undo 链找到满足其可见性的记录。当版本链很长时，通常可以认为这是个比较耗时的操作。\n> - 另外，在回滚段中的 undo log 分为: insert undo log 和 update undo log：\n> - 1、insert undo log : 事务对 insert 新记录时产生的 undo log，只在事务回滚时需要，并且在事务提交后就可以立即丢弃。（谁会对刚插入的数据有可见性需求呢！！）\n> - 2、update undo log : 事务对记录进行 delete 和 update 操作时产生的 undo log。不仅在事务回滚时需要，一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被 purge 线程删除。\n\n**何时删除？**\n在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。\n\n就是当系统里没有比这个回滚日志更早的 read-view 的时候。\n\n#### 长事务\n长事务意味着系统里面会存在很老的事务视图。\n**危害：**\n1、由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的 undo log 都必须保留，这就会导致大量占用存储空间。\n2、长事务还占用锁资源，也可能拖垮整个库。\n\n\n#### InnoDB可重复读\n在RC（Read Committed）和RR（Repeatable Read）两种事务隔离级别下，InnoDB存在两种数据读取方式：\n##### 快照读（Snapshot Read）\n在InnoDB引擎下是基于undo log中保存的快照数据。\n假设有这样一个表：\n```sql\n-- 表结构\nCREATE TABLE `innodb_test` (\n    `id` INT(11) NOT NULL AUTO_INCREMENT,\n    `name` VARCHAR(100) NOT NULL DEFAULT '0',\n    `age` INT(11) NOT NULL DEFAULT '0',\n    PRIMARY KEY (`id`),\n    INDEX `idx_age` (`age`)\n)\nENGINE=InnoDB;\n\n-- 初始数据\nINSERT INTO `innodb_test` (`id`, `name`, `age`) VALUES (1, '貂蝉', 100),(2, '庄周', 120),(3, '项羽', 130);\n```\n- id=1的初始数据行\n![](快照读1.png)\n\n- 事务A执行如下语句\n```sql\nUPDATE innodb_test SET name='嬴政', age=90 WHERE id=1;\n```\n此时innodb会做如下操作：\n\n1、把该行修改前的值Copy到undo log（Copy on write）；\n2、修改当前行的值，填写事务编号，使回滚指针指向undo log中的修改前的行。\n![](快照读2.png)\n\n- 事务B执行如下语句\n```sql\nUPDATE innodb_test SET name='甄姬', age=91 WHERE id=1;\n```\n此时undo log中有2条记录，它们通过回滚指针相连。\n![](快照读3.png)\n\nundo log的存在解决了两个问题，一是数据回滚，二是实现了MVCC (Multi-Version Concurrency Control) ，快照读读取的就是undo log中的数据，所以这种读取是不需要加锁的，避免了读写冲突。常见的快照读语句就是最常见的SELECT，比如：\n\n```sql\nSELECT * FROM innodb_test WHERE id=1;\n\n```\n快照读在RC和RR隔离级别下的表现却是不一样的，为了方便说明，现在将数据还原到初始数据，然后按照下表的顺序操作。\n![](快照读4.png)\n\n> - RC\n输出的是最新提交的结果（1-嬴政-90），RC级别的快照读遵循以下规则：\n\n1. 优先读取当前事务修改的数据，自己修改的，当然可以读到了；\n2. 其次读取最新已提交数据。\n会出现前后读取结果不一样的情况，但读取的是最新数据。\n\n\n> - RR\n输出结果和第一次查询是一样的（1-貂蝉-100），RR级别的快照读遵循以下规则：\n\n1. 优先读取当前事务修改的数据，和RC一样；\n2. 其次读取小于当前事务id的最新一条已提交数据，此时数据版本已经确定了，后面的快照读取始终读取这个版本。\n\n通过这样的机制，保证了快照读的可重复读，但读取到的数据很可能已经过期了。\n\n#####  当前读（Current Read）\n\n当前读，**读取的是最新已提交数据，并且都会加行锁**，如下语句都会产生当前读：\n\n```sql\nSELECT balabala LOCK IN SHARE MODE;\nSELECT balabala FOR UPDATE;\nINSERT balabala;\nUPDATE balabala;\nDELETE balabala;\n```\n当前读需要保证其他并发事务不能修改当前记录，对读取记录加锁。其中，第一条语句，对读取记录加S锁（共享锁），其他的操作，都加的是X锁（排它锁）。当前读在RC和RR隔离级别下的表现也是不一样的，为了方便说明，现在将数据还原到初始数据，然后按照下表的顺序操作。\n![](快照读5.png)\n> - RC\n成功执行，但会造成事务1的幻读，前后两次读取结果不一样。\n\n> - RR\n会锁等待，在RR隔离级别下，事务1的sql不仅会对该记录加X锁，还会**对上下两个数据间隙加间隙锁**，以此确保在数据读取期间，其它事物不会在该间隙内增加数据，从而保证可重复读。\n![](间隙锁.png)\n\n\n#### 小结\nRR隔离级别下，快照读通过undo log来保证可重复读，当前读通过X（S）锁+GAP锁来保证可重复读。\nRR隔离级别下，假设有两个事务A和B共同对同一个数据项进行update，那么只有其中一个事务执行commit操作，另外一个事务才能进行update，否则另外一个事务将一直阻塞，等待释放锁。这是因为select不加锁，update时才对数据项加行锁。另外，**第一个执行update的事务将以undo log中的值为准，而后执行update的事务将以最新事务commit的值为准，即数据库中的最新值。select的值为当前事务最新修改的值。**\n\n\n### 读未提交（READ_UNCOMMITED）\n\n#### 原理\n\n&#8194;&#8194;&#8194;&#8194;1、事务对当前被读取的数据不加锁。\n&#8194;&#8194;&#8194;&#8194;2、事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级共享锁，直到事务结束才释放。\n\n\n#### 现象\n\n&#8194;&#8194;&#8194;&#8194;事务1读取某行记录时，事务2也能对这行记录进行读取、更新（因为事务1并未对数据增加任何锁）\n当事务2对该记录进行更新时，事务1再次读取该记录，能读到事务2对该记录的修改版本（因为事务2只增加了共享读锁，事务1可以再增加共享读锁读取数据），即使该修改尚未被提交。\n&#8194;&#8194;&#8194;&#8194;事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。（因为事务1对数据增加了共享读锁，事务2不能增加排他写锁进行数据的修改）。\n\n### 读已提交（READ_COMMITED）\n\n#### 原理\n&#8194;&#8194;&#8194;&#8194;1、事务对当前被读取的数据加行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁。\n&#8194;&#8194;&#8194;&#8194;2、事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。\n\n#### 现象\n&#8194;&#8194;&#8194;&#8194;事务1在读取某行记录的整个过程中，事务2都可以对该行记录进行读取（因为事务1对该行记录增加行级共享锁的情况下，事务2同样可以对该数据增加共享锁来读数据）。\n\n&#8194;&#8194;&#8194;&#8194;事务1读取某行的一瞬间，事务2不能修改该行数据，但是，只要事务1读取完修改行数据，事务2就可以对该行数据进行修改。（事务1在读取的一瞬间会对数据增加共享锁，任何其他事务都不能对该行数据增加排他锁。但事务1只要读完该行数据，就会释放行级共享锁，一旦锁释放，事务2就可以对数据增加排他锁并修改数据）。\n\n&#8194;&#8194;&#8194;&#8194;事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。（事务1在更新数据的时候，会对该行数据增加排他锁，知道事务结束才会释放锁，所以在事务2没有提交之前，事务1都不能对数据增加共享锁进行数据的读取。所以提交读可以解决脏读的现象）。\n\n\n### 可重复读（REPEATABLE_READ）\n\n#### 原理\n&#8194;&#8194;&#8194;&#8194;1、事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加行级共享锁，直到事务结束才释放。\n&#8194;&#8194;&#8194;&#8194;2、事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。\n\n\n#### 现象\n&#8194;&#8194;&#8194;&#8194;事务1在读取某行记录的整个过程中，事务2都可以对该行记录进行读取（因为事务1对该行记录增加行级共享锁的情况下，事务2同样可以对该数据增加共享锁来读数据）。\n\n&#8194;&#8194;&#8194;&#8194;事务1在读取某行记录的整个过程中，事务2都不能修改该行数据（事务1在读取的整个过程会对数据增加共享锁，直到事务提交才会释放锁，所以整个过程中，任何其他事务都不能对该行数据增加排他锁。所以，可重复读能够解决不可重复读的读现象）。\n\n&#8194;&#8194;&#8194;&#8194;事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。（事务1在更新数据时，会对该行数据增加排他锁，直到事务结束才会释放锁，所以，在事务2没有提交之前，事务1都不能对数据增加共享锁进行数据的读取。所以提交读可以解决脏读的现象）。\n\n\n### 可串行化（SERIALIZABLE）\n\n#### 原理\n&#8194;&#8194;&#8194;&#8194;1、事务在读取数据时，必须先对其加表级共享锁，直到事务结束才释放。\n&#8194;&#8194;&#8194;&#8194;2、事务在更新数据时，必须先对其加表级排他锁，直到事务结束才释放。\n\n\n#### 现象\n&#8194;&#8194;&#8194;&#8194;事务1正在读取A表中的记录时，则事务2也能读取A表，但不能对A表做更新、新增、删除，直到事务1结束。（因为事务1对表增加了表级共享锁，其他事务只能增加共享锁读取数据，不能进行其他任何操作）。\n\n&#8194;&#8194;&#8194;&#8194;事务1正在更新A表中的记录时，则事务2不能读取A表的任何记录，更不可能对A表做更新、新增、删除，直到事务1结束。（事务1 对表增加了表级排他锁，其他事务不能对表增加共享锁或排他锁，也就无法进行任何操作）。\n\n\n\n### 隔离级别相关疑点\n\n#### 幻读和不可重复读区别\n1、幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。对于前者, 只需要锁住满足条件的记录；对于后者, 要锁住满足条件及其相近的记录。\n\n2、不可重复读重点在于update和delete，而幻读的重点在于insert。\n\n如果使用锁机制来实现这两种隔离级别，在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复 读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会 发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。\n\n所以说不可重复读和幻读最大的区别，就在于如何通过锁机制来解决他们产生的问题。\n\n上文说的，是使用悲观锁机制来处理这两种问题，但是**MySQL、ORACLE、PostgreSQL等成熟的数据库，出于性能考虑，都是使用了以乐观锁为理论基础的MVCC（多版本并发控制）来避免这两种问题**。\n\n#### InnoDB的RR可以避免不可重复读和幻象读，那么与串行化有什么区别呢？\nRR隔离级别的防止幻象主要是针对写操作的，即只保证写操作的可串行化，因为只有写操作影响Binlog；而读操作是通过MVCC来保证一致性读（无幻象）。然而，可串行化隔离级别要求读写可串行化。由于在串行化下，查询操作不在使用MVCC来保证一致读，而是使用S锁来阻塞其他写操作。因此做到读写可串行化，然而换来就是并发性能的大大降低。\n\n\n\n#### MySQL的可重复读\n**MySQL的可重复读是通过MVCC版本控制的**，在当前整个事务的过程中如果没有执行update或delete操作，则select的值将还是undo log中的值。否则执行update或delete时，当前事务将会从数据库获取最新的值进行update或delete，则select的值则是undo log最新的值。MySQL不支持对同一数据项进行并发修改。除了保证可重复读，MySQL的RR还一定程度上避免了幻象读。\n\n\n#### MySQL使用可重复读作为默认隔离级别的原因之一\nMySQL使用可重复读来作为默认隔离级别的主要原因是语句级的Binlog。RR能提供SQL语句的写可串行化，保证了绝大部分情况（不安全语句除外）的DB/DR一致。\n\n\n### 参考资料\n- [深入理解Mysql事务隔离级别](https://www.jianshu.com/p/443581ddfa3c)\n- [数据库隔离级别实现原理](https://www.cnblogs.com/heyboom/p/9167394.html)\n- [事物级别，不可重复读和幻读的区别](https://blog.csdn.net/qq_35433593/article/details/86094028)\n- [探究InnoDB可重复读](https://www.jianshu.com/p/17967b72139a)\n- [MySQL使用可重复读作为默认隔离级别的原因之一](https://blog.csdn.net/zxk364961978/article/details/51564832)\n- [轻松理解MYSQL MVCC 实现机制](https://blog.csdn.net/whoamiyang/article/details/51901888)\n- [【mysql】关于innodb中MVCC的一些理解](https://www.cnblogs.com/chenpingzhao/p/5065316.html)\n\n\n","tags":["数据库"],"categories":["数据库"]},{"title":"top命令","url":"/2019/02/15/top命令/","content":"\n### 简介\n\n&#8194;&#8194;&#8194;&#8194;top命令能够实时地对CPU的状态进行监视，可以按CPU使用、内存使用和执行时间对任务进行排序。用户可以通过按键来实时刷新当前的状态。\n![top.png](top命令.png)\n### 显示含义\n\n```linux\ntop - 15:10:45 up 318 days, 19:44,  1 user,  load average: 0.00, 0.02, 0.05\nTasks:  86 total,   1 running,  85 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  0.7 us,  0.3 sy,  0.0 ni, 98.7 id,  0.3 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem :  1883492 total,    74140 free,  1494716 used,   314636 buff/cache\nKiB Swap:        0 total,        0 free,        0 used.   216132 avail Mem \n```\n&#8194;&#8194;&#8194;&#8194;上面这部分内容代表了系统的整体运行情况。\n\n- 第一行是任务队列信息，同uptime命令的执行结果一致。\n\n```linux\n  15:10:45       #当前时间 \n  up 318 days    #系统已经运行时间\n  1 user         #当前登录用户数\n  load average: 0.00, 0.02, 0.05  #系统负载，即任务队列的平均长度。三个数值分别为1分钟、5分钟、15分钟前到现在的平均值。\n```\n- 第二、三行代表进程和CPU的信息。\n\n```linux\nTasks:  \n      86 total       #进程总数\n      1 running      #正在运行的进程数\n      85 sleeping    #睡眠的进程数 \n      0 stopped      #停止的进程数\n      0 zombie       #僵尸进程数\n%Cpu(s):\n       0.7 us        #运行用户进程占用的CPU百分比\n       0.3 sy        #运行系统进程占用的CPU百分比\n       0.0 ni        #运行已调整优先级的用户进程的CPU百分比\n       98.7 id       #空闲CPU百分比\n       0.3 wa        #等待IO完成的CPU百分比\n       0.0 hi        #处理硬中断占用百分比\n       0.0 si        #处理软中断占用百分比\n       0.0 st        #虚拟机占用CPU百分比\n```\n\n&#8194;&#8194;&#8194;&#8194;当us值过高时，表示运行的应用消耗大量的CPU。java应用造成us高的原因主要是线程一直处于可运行（Runnable）状态，通常这些线程在执行无阻塞、循环、正则或纯粹的计算等任务造成的；另外一个可能也会造成us高的原因是频繁GC。\n\n&#8194;&#8194;&#8194;&#8194;当sy值高时，表示linux花费了更多的时间在进行java线程切换。java应用造成这种现象的主要原因是启动的线程比较多，且这些线程多数处于不断的阻塞（例如锁等待，IO等待状态）和执行状态的变化过程中，这就导致了操作系统要不断地切换执行的线程，产生大量的线程上下文切换。\n\n- 第四、五行为内存和交换区（类似于windows的虚拟内存，Linux才有的概念）信息\n\n```linux\nKiB Mem : \n          1883492 total        #物理总内存\n          74140 free           #空闲的物理内存\n          1494716 used         #已使用物理内存\n          314636 buff/cache    #系统的page cache和buffer使用到的内存 \nKiB Swap:\n          0 total              #交换区总量\n          0 free               #空闲的交换区总量 \n          0 used               #已使用交换区的总量\n          216132 avail Mem     #可用的交换区总量\n```\n&#8194;&#8194;&#8194;&#8194;对于buff/cache的占用过高的解决可以看下[Linux中buff-cache占用过高解决手段](https://focusss.github.io/2019/02/10/Linux%E4%B8%ADbuff-cache%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98%E8%A7%A3%E5%86%B3%E6%89%8B%E6%AE%B5/)\n\n&#8194;&#8194;&#8194;&#8194;默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。下面是他们的含义\n```linux\nPID         #进程ID\nUSER　　　　 #进程所有者ID\nPR          #优先级\nNI          #nice值。负值表示高优先级，正值表示低优先级\nVIRT        #进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES\nRES         #进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\nSHR         #共享内存大小，单位kb\nS           #进程状态(D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程)\n%CPU        #上次更新到现在的CPU时间占用百分比\n%MEM        #进程使用的物理内存百分比\nTIME+       #进程使用的CPU时间总计，单位1/100秒\nCOMMAND     #命令名/命令行\n```\n### 命令使用格式\n```linux\ntop [-] [d] [p] [q] [c] [C] [S] [s]  [n]\n```\n参数说明\n> - d 指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。 \n> - p 通过指定监控进程ID来仅仅监控某个进程的状态。 \n> - q 该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。 \n> - S 指定累计模式 \n> - s 使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。 \n> - i 使top不显示任何闲置或者僵死进程。 \n> - c 显示整个命令行而不只是显示命令名 \n\n#### 常用操作\n```linux\ntop   //每隔5秒显式所有进程的资源占用情况\ntop -d 2  //每隔2秒显式所有进程的资源占用情况\ntop -c  //每隔5秒显式进程的资源占用情况，并显示进程的命令行参数(默认只有进程名)\ntop -p 12345 -p 6789//每隔5秒显示pid是12345和pid是6789的两个进程的资源占用情况\ntop -d 2 -c -p 123456 //每隔2秒显示pid是12345的进程的资源使用情况，并显式该进程启动的命令行参数\n```\n#### 交互命令\n&#8194;&#8194;&#8194;&#8194;在输入完top命令，可以直接键入以下命令，动态显示结果。如果在命令中使用了s选项，其中一些命令可能会被屏蔽。\n> - h 显示帮助画面，给出一些简短的命令总结说明\n> - k 终止一个进程。\n> - i 忽略闲置和僵死进程。这是一个开关式命令。\n> - q 退出程序\n> - r 重新安排一个进程的优先级别\n> - S 切换到累计模式\n> - s 改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成ms。输入0值则系统将不断刷新，默认值是5 s\n> - f或者F 从当前显示中添加或者删除项目\n> - o或者O 改变显示项目的顺序\n> - l 切换显示平均负载和启动时间信息\n> - m 切换显示内存信息\n> - t 切换显示进程和CPU状态信息\n> - c 切换显示命令名称和完整命令行\n> - M 根据驻留内存大小进行排序\n> - P 根据CPU使用百分比大小进行排序\n> - T 根据时间/累计时间进行排序\n> - W 将当前设置写入`~/.`toprc文件中\n\n\n### 参考资料\n- [top命令性能分析工具](https://www.cnblogs.com/lovychen/p/5237852.html) \n","tags":["Linux"],"categories":["Linux"]},{"title":"责任链模式","url":"/2019/02/11/责任链模式/","content":"\n### 简介\n\n&#8194;&#8194;&#8194;&#8194;责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。\n\n### 特点\n- 有多个对象共同对一个任务进行处理。\n- 这些对象使用链式存储结构，形成一个链，每个对象知道自己的下一个对象。\n- 一个对象对任务进行处理，可以添加一些操作后将对象传递个下一个任务。也可以在此对象上结束任务的处理，并结束任务。\n- 客户端负责组装链式结构，但是客户端不需要关心最终是谁来处理了任务。\n\n### 分析\n在责任链模式中，存在着这么几个角色：\n- Handler-处理者\nhandler定义了处理请求的接口，同时指定了下一个处理者。如果当前handler无法处理请求，就转给下一个处理者。\n- ConcreteHandler-具体的处理者\n具体的处理者是处理请求的具体的角色。\n- client \n请求者角色就是向第一个具体的handler发送请求的角色，并连接好责任链\n\n![责任链模式](责任链模式.png)\n\n### 举例\n\n1、创建处理器接口\n```java\npackage chain.patten;\n/**\n * 责任链接口\n *\n */\npublic abstract class Handler {\n    //下一级责任链\n    public Handler handler;\n    //设置下一级责任链\n    public void setSuccessor(Handler handler){\n        this.handler=handler;\n    }\n    public abstract void request(int request);\n}\n```\n\n2、创建处理器对象1\n```java\npackage chain.patten;\n\npublic class ConcreteHandler1 extends Handler {\n    @Override\n    public void request(int request) {\n        if(request<10){\n            System.out.println(\"我是handler1，我处理了请求：\"+request);\n        }else {\n            this.handler.request(request);\n        }\n    }\n}\n\n```\n3、创建处理器对象2\n```java\npackage chain.patten;\n\npublic class ConcreteHandler2 extends Handler {\n    @Override\n    public void request(int request) {\n        if(request>10){\n            System.out.println(\"我是handler2，我处理了请求：\"+request);\n        }else {\n            System.out.println(\"请求\"+request+\"没人能处理\");\n        }\n    }\n}\n\n```\n4、创建客户端\n```java\npackage chain.patten;\n\npublic class Client {\n    public static void main(String[] args) {\n        //创建处理器\n        Handler handler1=new ConcreteHandler1();\n        Handler handler2=new ConcreteHandler2();\n        //客户端创建处理器的关联，形成链\n        handler1.setSuccessor(handler2);\n        //创建任务，此处为一些数字，不同大小，处理器处理结果不同\n        int[] requests={4,10,59,2,16};\n        //调用处理器处理        \n        for(int request:requests){\n            handler1.request(request);\n        }\n    }\n}\n\n```\n\n\n### 优点 \n1、降低耦合度。它将请求的发送者和接收者解耦。 \n2、简化了对象。使得对象不需要知道链的结构。 3、增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。\n4、增加新的请求处理类很方便。\n\n### 缺点 \n1、不能保证请求一定被接收。 \n2、系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。\n3、可能不容易观察运行时的特征，有碍于除错。\n\n### 具体应用\n- servlet中的filter\n- dubbo中的filter\n\n#### servlet中的Filter\n&#8194;&#8194;&#8194;&#8194;servlet中分别定义了一个 Filter和FilterChain的接口，核心代码如下：\n```java\npublic final class ApplicationFilterChain implements FilterChain {\n    private int pos = 0; //当前执行filter的offset\n    private int n; //当前filter的数量\n    private ApplicationFilterConfig[] filters;  //filter配置类，通过getFilter()方法获取Filter\n    private Servlet servlet\n  \n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response) {\n        if (pos < n) {\n            ApplicationFilterConfig filterConfig = filters[pos++];\n            Filter filter = filterConfig.getFilter();\n            filter.doFilter(request, response, this);\n        } else {\n            // filter都处理完毕后，执行servlet\n            servlet.service(request, response);\n        }\n    }\n  \n}\n```\n\n#### Dubbo中的Filter\n&#8194;&#8194;&#8194;&#8194;Dubbo在创建Filter的时候是另外一个方法，通过把Filter封装成 Invoker的匿名类，通过链表这样的数据结构来完成责任链，核心代码如下：\n```java\nprivate static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {\n    Invoker<T> last = invoker;\n    //只获取满足条件的Filter\n    List<Filter> filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group);\n    if (filters.size() > 0) {\n        for (int i = filters.size() - 1; i >= 0; i --) {\n            final Filter filter = filters.get(i);\n            final Invoker<T> next = last;\n            last = new Invoker<T>() {\n                ...\n                public Result invoke(Invocation invocation) throws RpcException {\n                    return filter.invoke(next, invocation);\n                }\n                ...\n            };\n        }\n    }\n    return last;\n}\n```\n### 参考资料\n- [责任链模式实现的三种方式](https://www.cnblogs.com/lizo/p/7503862.html)\n\n\n","tags":["Java","设计模式"],"categories":["Java","设计模式"]},{"title":"Linux中buff-cache占用过高解决手段","url":"/2019/02/10/Linux中buff-cache占用过高解决手段/","content":"\n### 简介\n&#8194;&#8194;&#8194;&#8194;使用free -h命令可以查看当前系统的内存使用情况\n```linux\n      total        used        free      shared  buff/cache   available \nMem:  1.8G        1.4G         66M        952K        313M        211M\nSwap:  0B          0B          0B\n```\n> available表示应用程序还可以申请到的内存\n\n首先了解下两个概念buff和cache\n> - buff（Buffer Cache）是一种I/O缓存，用于内存和硬盘的缓冲，是io设备的读写缓冲区。根据磁盘的读写设计的，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。 \n\n> - cache（Page Cache）是一种高速缓存，用于CPU和内存之间的缓冲 ,是文件系统的cache。 \n把读取过的数据保存起来，重新读取时若命中（找到需要的数据）就不要去读硬盘了，若没有命中就读硬盘。其中的数据会根据读取频率进行组织，把最频繁读取的内容放在最容易找到的位置，把不再读的内容不断往后排，直至从中删除。 \n\n&#8194;&#8194;&#8194;&#8194;它们都是占用内存。两者都是RAM中的数据。简单来说，buff是即将要被写入磁盘的，而cache是被从磁盘中读出来的。\n\n&#8194;&#8194;&#8194;&#8194;目前进程正在实际被使用的内存的计算方式为used-buff/cache，通过释放buff/cache内存后，我们还可以使用的内存量free+buff/cache。通常我们在频繁存取文件后，会导致buff/cache的占用量增高。\n\n### 处理方式\n\n#### 手动清除\n&#8194;&#8194;&#8194;&#8194;执行以下命令即可\n```linux\n[root@izbp17wg1wphb6f95b76obz ~]# sync\n[root@izbp17wg1wphb6f95b76obz ~]# echo 1 > /proc/sys/vm/drop_caches\n[root@izbp17wg1wphb6f95b76obz ~]# echo 2 > /proc/sys/vm/drop_caches\n[root@izbp17wg1wphb6f95b76obz ~]# echo 3 > /proc/sys/vm/drop_caches\n```\n- sync：将所有未写的系统缓冲区写到磁盘中，包含已修改的i-node、已延迟的块I/O和读写映射文件\n- echo 1 > /proc/sys/vm/drop_caches：清除page cache\n- echo 2 > /proc/sys/vm/drop_caches：清除回收slab分配器中的对象（包括目录项缓存和inode缓存）。slab分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的pagecache。\n- echo 3 > /proc/sys/vm/drop_caches：清除pagecache和slab分配器中的缓存对象。\n/proc/sys/vm/drop_caches的值,默认为0\n\n#### 定时清除\n1、创建脚本cleanCache.sh\n```linux\n#!/bin/bash#每两小时清除一次缓存\necho \"开始清除缓存\"\nsync;sync;sync #写入硬盘，防止数据丢失\nsleep 10#延迟10秒\necho 1 > /proc/sys/vm/drop_caches\necho 2 > /proc/sys/vm/drop_caches\necho 3 > /proc/sys/vm/drop_caches\n```\n2、创建定时任务\n```linux\ncrontab -e #弹出配置文件\n```\n3、添加定时任务执行频率\n```linux\n#分　 时　 日　 月　 周　 命令\n0 */2 * * * ./cleanCache.sh\n```\n4、设置crond启动以及开机自启\n```linux\nsystemctl start crond.service\nsystemctl enable crond.service\n```\n5、查看定时任务是否被执行\n```linux\ncat /var/log/cron | grep cleanCache\n```\n\n### 参考资料\n- [linux top命令中的cache & buffers](https://blog.csdn.net/Cooling88/article/details/50969013) \n- [buff/cache的问题](https://blog.csdn.net/dyh4201/article/details/85266235) \n- [Linux 内存缓存占用过大，Centos7设置定时清除buff/cache的脚本](http://www.sapv.cn/article/83) ","tags":["Linux"],"categories":["Linux"]},{"title":"方法区和永久代区别","url":"/2019/02/05/方法区和永久代区别/","content":"\n\n### 区别\n&#8194;&#8194;&#8194;&#8194;永久代（PerGen space）是对方法区的一种实现，类似实现类和接口的关系。可以说，方法区是JVM的一种规范，而永久代是对这一种规范的实现。另外只有hotspot虚拟机才有永久代的概念，而其他虚拟机，如JRockit(Oracle)、J9(IBM)，并没有永久代的概念。 由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易造成永久代的内存溢出。比较典型的场景就是，在jsp页面比较多的情况下，容易出现永久代内存溢出（java.lang.OutOfMemoryError: PermGen）。\n\n&#8194;&#8194;&#8194;&#8194;在jdk7中已经将字符串常量池从方法区移除，并在Java堆中开辟一块新的区域存放字符串常量池，譬如符号引用（symbols）转移到了native heap；字面量（interned strings）转移到了java heap；类的静态变量（class statics）转移到了java heap。而在jdk8中，已经没有了永久代，取而代之的是叫做元空间（metaspace）的内存区域。\n\n&#8194;&#8194;&#8194;&#8194;元空间与永久代最大的区别就是元空间的内存区域并不在虚拟机中，而是使用本地内存。因此，默认情况下元空间的大小仅受本地内存限制。\n移除永久代后，不会遇到永久代存在的内存溢出错误，也不会出现泄漏的数据移到交换区这样的事情。最终用户可以为元空间设置一个可用空间最大值，如果不进行设置，JVM会自动根据类的元数据大小动态增加元空间的容量。\n\n### 题外话\n\n&#8194;&#8194;&#8194;&#8194;Heap Memory是供Java应用程序使用的。Native Memory没有相应的参数来控制大小，其大小依赖于操作系统进程的最大值，以及生成的Java字节码大小、创建的线程数量、维持java对象的状态信息大小（用于GC）以及一些第三方的包，比如JDBC驱动使用的native内存。\n\n#### Native Memory\n- 管理java heap的状态数据（用于GC）;\n- JNI调用，也就是Native Stack;\n- JIT（即使编译器）编译时使用Native Memory，并且JIT的输入（Java字节码）和输出（可执行代码）也都是保存在Native Memory；\n- NIO direct buffer。对于IBM JVM和Hotspot，都可以通过-XX:MaxDirectMemorySize来设置nio直接缓冲区的最大值。默认是64M。超过这个时，会按照32M自动增大。\n\n#### DirectBuffer\n&#8194;&#8194;&#8194;&#8194;DirectBuffer访问更快，避免了从HeapBuffer还需要从java堆拷贝到本地堆，操作系统直接访问的是DirectBuffer。DirectBuffer对象的数据实际是保存在native heap中，但是引用保存在HeapBuffer中。另外，DirectBuffer的引用是直接分配在堆得Old区的，因此其回收时机是在FullGC时。因此，需要避免频繁的分配DirectBuffer，这样很容易导致Native Memory溢出。\n\n### 参考资料\n[java 8中撤销永久代，引入元空间](https://www.cnblogs.com/mengchunchen/p/7819670.html)\n[JVM的Heap Memory和Native Memory](https://blog.csdn.net/u013721793/article/details/51204001)","tags":["JVM"],"categories":["JVM"]},{"title":"偏向锁、自旋锁、轻量级锁、重量级锁","url":"/2018/10/23/偏向锁、自旋锁、轻量级锁、重量级锁/","content":"\n## 线程阻塞\n操作系统在唤醒或阻塞一个线程的时候，需要在用户态和核心态之间切换，这种切换会消耗大量的系统资源。因为在用户态和核心态都有各自专用的内存空间、寄存器等。用户态切换到核心态需要传递许多变量、参数给内核，内核也需要保存用户态在切换时的一些寄存器值、变量等，以便核心态调用结束后切换回用户态继续工作。\n\n## Java对象头\n锁存在Java对象头。如果对象是数组类型，则虚拟机用3个word（字宽）存储对象头，如果对象是非数组类型，则用2个字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。对象头的结构如下：\n\n| 长度       | 内容   |  说明  |\n| --------   | -----:   | :----: |\n| 32/64bit        | Mark Word      |   存储对象的hashCode或锁信息等   |\n| 32/64bit        | Class Metadata Address      |   存储到对象类型数据的指针   |\n| 32/64bit        | Array length      |   组的长度（如果当前对象是数组）   |\n\n在Java对象头中，与锁相关的结构就是Mark Word了。默认存储了对象的hashcode、分代年龄\n锁标记位。32位JVM的Mark Word的默认存储结构如下：\n\n|  锁状态         | 25 bit   |  4bit |   1bit（是否位偏向锁） | 2bit（锁标志位） |\n| --------        | -----:   | ----: | ----: | :----: |\n| 无锁状态        | 对象的hashCode     |  对象分代年龄   | 0 | 01 |\n\n最后2bit是锁状态标志位，用来标记当前对象的状态，对象的所处的状态，决定了Mark Word存储的内容。标志位的情况大致如下：\n\n| 状态      | 标志位   |  存储内容  |\n| --------   | -----:   | :----: |\n| 未锁定        | 01      |   对象哈希码、对象分代年龄  |\n| 轻量级锁定        | 00      |   指向锁记录的指针  |\n| 膨胀(重量级锁定)        | 10      |   执行重量级锁定的指针 |\n| GC标记        | 11      |    空(不需要记录信息)  |\n| 可偏向        | 01      |   偏向线程ID、偏向时间戳、对象分代年龄 |\n在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化，32位虚拟机在不同状态下Mark Word结构如下图所示：\n![markword](markword.png)\n\n\n## 锁种类\nsynchronized是重量级锁，会导致争用不到锁的线程进入阻塞状态，是悲观锁的一种。java默认开启了自旋锁，它和轻量级锁、偏向锁一样都是乐观锁。在Java中锁一共有四种状态：**无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态**。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。下面来看几种锁机制。 \n\n### 自旋锁\n线程的阻塞和唤醒需要从用户态转为核心态，频繁的阻塞和唤醒对CPU来说一件负担很重的工作。很多对象的锁定状态只会持续很短的一段时间，在很短的时间内阻塞并唤醒线程显然是不值得。因此，可以利用自旋锁。让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于**running状态**，但是基于JVM线程调度，会让出时间片，所以其他线程依旧有申请锁和释放锁的机会。\n如果持有锁的线程执行的时间超过自旋等待的最大时间（默认自旋10次）仍没有释放锁，就会导致其它竞争锁的线程在最大等待时间内还是获取不到锁，这时竞争线程会停止自旋进入阻塞状态。\nJDK6引入自适应的自旋锁：自旋时间不固定，由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机会认为这次自旋很有可能再次成功，进而允许更长的自旋等待时间。\n#### 优缺点\n对于锁竞争不激烈且占用锁时间非常短的场景，自旋锁可以尽可能地减少线程的阻塞。但如果锁竞争激烈或者持有锁的线程需要长时间占用锁，这时候就不适合使用自旋锁。因为自旋锁在获取锁前一直都占用CPU，同时还有大量线程在竞争一个锁，导致获取锁的时间很长。自旋的消耗大于线程阻塞挂起的消耗。\n#### 设置\n在JDK6中，Java虚拟机提供`-XX:+UseSpinning`参数来开启自旋锁，使用`-XX:PreBlockSpin`参数来设置自旋锁等待的次数。\n在JDK7开始，自旋锁的参数被取消，虚拟机不再支持由用户配置自旋锁，自旋锁总是会执行，自旋锁次数也由虚拟机自动调整。\n\n### 偏向锁\n如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不做了。\n偏向锁会偏向于第一个获得它的线程（Mark Word中的偏向线程ID信息），如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。\n![偏向锁获取和撤销](偏向锁获取和撤销过程.png)\n#### 偏向锁的获取\n当锁对象第一次被线程获取的时候，虚拟机会把对象头中的标志位设为**01**，即偏向模式。同时使用CAS操作把获取到这个锁的线程ID记录在对象头的Mark Work之中。\n\n#### 偏向锁的撤销\n偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，**线程不会主动释放偏向锁**。偏向锁的撤销，需要等待全局安全点（在这个时间点没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断对象是否处于被锁定的状态撤销偏向锁后恢复到未锁定（标志位为**01**）或轻量级锁（标志位为**00**）的状态。\n![偏向锁、轻量级锁状态转换](偏向锁、轻量级锁状态转换.png)\n\n#### 偏向锁的设置\n偏向锁在JDK6 和JDK 7中默认时开启的，它会在应用程序启动几秒后激活，可以使用`-XX：BiasedLockingStartupDelay=0`来关闭延迟。如果应用程序中所有的锁通常处于竞争状态情况下，可以使用`-XX:-UseBiasedLocking=false`来关闭偏向锁，那么所有的锁一开始默认会进入轻量级锁状态。\n\n#### 适用场景\n始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作； 在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向锁的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用。\n\n### 轻量级锁\n由偏向锁升级而来，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁竞争的时候，偏向锁就会升级为轻量级锁。\n![轻量级锁膨胀](轻量级锁膨胀过程.png)\n#### 加锁过程\n在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为**01**状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word拷贝（官方名为Displaced Mark Word），这时候线程堆栈与对象头的状态如下图所示。\n![轻量级锁MarkWork复制](轻量级锁MarkWork复制.png)\n然后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位转变为**00**，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如下图所示。\n![轻量级锁定](轻量级锁定.png)\n如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧。如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程抢占了。**如果有两个以上的线程争用同一个锁，那么轻量级锁就不再有效，要升级为重量级锁，锁标志的状态值变为10，Mark Word中存储的就是指向重量级（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。** 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。\n\n#### 解锁过程\n解锁过程也是通过CAS操作来进行的，如果对象的Mark Word仍然指向着线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来，如果替换成功，整个同步过程就完成了。如果替换失败，说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程。\n\n### 重量级锁\n如果线程尝试获取锁的时候，轻量级锁正被其他线程占有，那么它就会修改Mark Word,升级为重量级锁。重量锁在JVM中又叫对象监视器（Monitor）。\n\n> JVM基于进入和退出monitor对象来实现方法同步和代码块同步的。代码块同步是使用**monitorenter**和**monitorexit**指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。\n\n当多个线程同时请求某个对象监视器时，对象监视器会设置几种状态用来区分请求的线程：\n\n- Contention List：一个先进先出（FIFO）的队列，所有请求锁的线程将被首先放置到该竞争队列。每次新加入Node时都会在队头进行，而取得操作则发生在队尾。\n\n- Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List\n\n- Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set\n\n- OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck\n\n- Owner：获得锁的线程称为Owner\n\n- !Owner：释放锁的线程\n\n下图反映了个状态转换关系：\n\n![对象监视器](对象监视器.png)\nJVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的并发线程进行CAS访问。为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。Owner线程会在unlock时，将ContentList中的部分线程迁移到EntryList中，并指定EntryList中的某个线程为OnDeck线程（一般时最先进去的那个线程）。Owner线程并不直接把锁传递给OnDeck线程，而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM中，也把这种选择行为称为“竞争切换”。\nOnDeck线程获取锁资源后，会变为Owner线程，而没有得到锁资源的仍然停留在EntryList中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进去EntryList中。处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的。\n\n#### Synchronized\n它可以把任意一个非NULL的对象当作锁：\n- 作用于方法时，锁住的是对象的实例\n- 当作用于静态方法时，锁住的是Class对象，相当于类的一个全局锁。会锁住所有调用该方法的线程\n- 作用于一个对象实例时，锁住的是所有以该对象为锁的代码块\n\nSynchronized是非公平锁。Synchronized在线程进入ContentList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有就是自旋获取锁的线程还有可能直接抢占OnDeck线程的锁资源。\n\n#### Synchronized执行过程\n- 检测Mark Word里面是不是当前线程的ID。如果是，表示当前线程处于偏向锁；如果不是，则使用CAS将当前线程的ID替换Mark Word。替换成功则表示当前线程获得偏向锁，设置锁状态标志位为**01**；失败则说明发生竞争，撤销偏向锁，升级为轻量级锁。\n- 当前线程使用CAS将对象头的Mark Word替换为锁记录指针。如果成功，当前线程获得锁；如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。如果自旋成功，则依然处于轻量级状态，如果自旋失败，则升级为重量级锁。另外，等待轻量级锁的线程不会阻塞，它会一直自旋等待锁。\n\n#### Synchronized与volatile区别\nvolatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的\nvolatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性\nvolatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。\nvolatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化\n\n## 锁的优化策略\n- 减少锁持有时间 \n         例如：对一个方法加锁，不如对方法中需要同步的几行代码加锁。\n- 减小锁粒度\n        例如：ConcurrentHashMap采取对segment加锁而不是整个map加锁，提高并发性。\n- 锁分离 \n        根据同步操作的性质，把锁划分为的读锁和写锁，读锁之间不互斥，提高了并发性。\n- 锁粗化 \n        针对一个线程中来说，只有个别地方需要同步，所以把锁加在同步的语句上而不是更大的范围，\n        减少线程持有锁的时间；假如在一个循环里面，重复使用synchronized关键字。需要频繁地获\n        取锁、释放锁。要知道锁的取得（假如只考虑重量级MutexLock）是需要操作系统调用的，从用\n        户态进入内核态，开销很大。于是针对这种情况也许虚拟机发现了之后会适当扩大加锁的范围\n        （所以叫锁粗化）以避免频繁的拿锁释放锁的过程。 \n- 锁消除  \n        锁消除是编译器做的事，根据代码逃逸技术，如果判断到一段代码中，堆上的数据不会逃逸出\n        当前线程（即不会影响线程空间外的数据），那么可以认为这段代码是线程安全的，虚拟机会\n        直接去掉这个锁。\n\n## 总结\n\n>- 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。\n\n>- 轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。\n\n>- 重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。\n\n>- 自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。\n\n在所有的锁都启用的情况下线程进入临界区时会先去获取偏向锁，如果已经存在偏向锁了，则会尝试使用CAS操作获取轻量级锁，启用自旋锁，如果自旋也没有获取到锁，则使用重量级锁，没有获取到锁的线程阻塞挂起，直到持有锁的线程执行完同步块唤醒他们。\n偏向锁是在无锁争用的情况下使用的，也就是同步开在当前线程没有执行完之前，没有其它线程会执行该同步块。如果仍然是同个线程去获得这个锁，尝试偏向锁时会直接进入同步块，不需要再次获得锁。一旦有了第二个线程的争用，偏向锁就会升级为轻量级锁，如果轻量级锁自旋到达阈值后，没有获取到锁，就会升级为重量级锁。\n\n### 优缺点\n| 锁      | 优点   |  缺点  | 适用场景 |\n| --------   | -----:   | ----: | ----: |\n| 偏向锁      | 加锁和解锁不需要额外的消耗，与执行非同步方法相比仅存在纳秒级的差距   | 如果线程存在锁竞争，会带来额外的锁撤销的消耗  | 适用于只有一个线程访问同步块的场景 |\n| 轻量级锁      | 竞争的线程不会阻塞，提高了程序的响应速度   | 如果始终得不到锁竞争的线程会使用自旋消耗CPU  | 追求响应时间，锁占用时间很短|\n| 重量级锁      | 线程竞争不使用自旋，不会消耗CPU   | 线程阻塞，响应时间缓慢  | 追求吞吐量，锁占用时间较长|","tags":["JVM","锁机制"],"categories":["JVM"]},{"title":"Java并发编程-Callable与Runnable","url":"/2018/10/16/Java并发编程-Callable与Runnable/","content":"\n## Callable与Runnable的区别\n\n- Callable接口类有返回值，具体返回值在Callable接口类的call()方法返回，该返回值可以通过实现Future接口的对象的get()方法获取，该方法会阻塞主线程（如果call方法还没执行完）；而Runnable是没有返回值的，因为Runnable接口类的run()方法是没有返回值的，Runnable接口方法是不会造成主线程阻塞的(仅在使用new Thread创建线程或利用线程池创建线程但不执行FutureTask的get()方法情况下)\n\n- Callable接口类中的call()方法可以抛出异常；而Runable接口类中的run()方法是不可以抛出异常的，异常只能在run方法内必须得到处理，不能向外界抛出\n\n- 在使用Thread类实现多线程的情况下， Callable接口实现类首先需要将自己的对象实例作为参数来创建一个FutureTask对象，然后才可以通过new Thread(Runnable target)来创建线程；而Runnable接口实现类可以直接通过new Thread(Runnable target)创建线程\n\n> FutureTask类实现了RunnableFuture接口，而RunnableFuture接口继承了Runnable, Future<V>接口，即FutureTask类也实现了Runnable, Future<V>接口。\n\n\n## Callable与Runnable的相同点\n\n- 两者都可以将自己接口实现类的实例作为参数传递给ExecutorService接口类中的submit()方法直接分配线程运行，多个submit()可以异步执行，如: <T> Future<T> submit(Callable<T> task)、 Future<?> submit(Runnable task)\n- 只要调用了Future的get()方法了，无论是submit()方法中的参数是Callable还是Runnable，都会阻塞主线程，直到Callable中的call()方法或Runnable中的run()方法执行完毕，主线程才能继续执行\n\n> ExecutorService的execute()和submit()区别：\n> - 参数及返回值不一样。execute()只接受Runnable对象作为参数，且没有返回值，无法判断任务是否成功完成；submit()可以接受Runnable对象或Callable对象作为参数，且该方法返回一个Future对象，可以用这个Future对象来判断任务是否成功完成及获取Callable线程方法返回结果\n> -submit方便Exception处理\n\n## 使用方式\n### Callable\n#### Thread方式\n1、 CallableTest.java\n```java\npublic class CallableTest{\n\n\tpublic static void main(String[] args) {\n\t        //创建实现了Callable接口的对象\n\t\t\tMyCallable callable = new MyCallable();\n\t\t\t//将实现Callable接口的对象作为参数创建一个FutureTask对象\n\t\t\tFutureTask<String> task = new FutureTask<String>(callable);\n\t\t\t//创建线程处理当前callable任务\n\t\t\tThread thread = new Thread(task);\n\t\t\t//开启线程\n\t\t\tlong  startTime = System.currentTimeMillis();\n\t\t\tthread.start();\n\t\t\t//获取到call方法的返回值\n\t\t\ttry {\n\t\t\t\tString result = task.get();\n\t\t\t\tlong  endTime = System.currentTimeMillis();\n\t\t\t\tSystem.out.println(\"得到返回值: \"+result);\n\t\t\t\tSystem.out.println(\"结束执行get的时间: \"+ (endTime-startTime)/(1000) + \"秒\");\n\t\t\t} catch (Exception e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t }\n}\n```\n2、MyCallable.java\n```java\npublic class MyCallable implements Callable<String> {\n\n\t@Override\n\tpublic String call() throws Exception {\n\t\tThread.sleep(3000);\n\t\treturn \"call method result\";\n\t}\n\n}\n```\n执行结果：\n![CallableThread](CallableThread.png)\n当主线程执行到`String result = task.get();`时就阻塞了。等待callable对象中的call()方法执行完，main线程才能继续往下执行。\n#### 线程池方式\n将CallableTest改一改换成用线程池的方式\n```java\npublic class CallableTest{\n\n\tpublic static void main(String[] args) {\n\t\t\t\t//创建实现了Callable接口的对象\n\t\t\t\tMyCallable callable = new MyCallable();\n\t\t\t\t//创建线程池\n\t\t\t\tExecutorService executorService = Executors.newFixedThreadPool(2);\n\t\t\t\tFuture<String> task  = (FutureTask<String>) executorService.submit(callable);\n\t\t\t\t\n\t\t\t\t//开启线程\n\t\t\t\tlong  startTime = System.currentTimeMillis();\n\t\t\t\t//获取到call方法的返回值\n\t\t\t\ttry {\n\t\t\t\t\tString result = task.get();\n\t\t\t\t\tlong  endTime = System.currentTimeMillis();\n\t\t\t\t\tSystem.out.println(\"得到返回值: \"+result);\n\t\t\t\t\tSystem.out.println(\"结束执行get的时间: \"+ (endTime-startTime)/(1000) + \"秒\");\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}finally{\n\t\t\t\t\texecutorService.shutdown();\n\t\t\t\t}\n\t }\n}\n```\n执行结果：\n![CallableThread](CallableThread.png)\n\n### Runnable\n#### Thread方式\n1、RunnableTest.java\n```java\npublic class RunnableTest {\n\tpublic static void main(String[] args) {\n\t\tMyRunnable runnable = new MyRunnable();\n\t\tThread thread = new Thread(runnable);\n\t\tlong startTime = System.currentTimeMillis();\n\t\tthread.start();\n\t\tlong endTime = System.currentTimeMillis();\n\t\tSystem.out.println(\"启动任务之后时间:  \"+ (endTime-startTime)/(1000) + \"秒\");\n\t}\n}\n```\n2、MyRunnable.java\n```java\npublic class MyRunnable implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\t\ttry {\n\t\t\tThread.sleep(3000);\n\t\t\tSystem.out.println(\"MyRunnable线程：\"+Thread.currentThread().getName()+\"执行完毕\");\n\t\t} catch (InterruptedException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n执行结果：\n![RunnableThread](RunnableThread.png)\nrunnable对象中run()方法不会阻塞main线程的执行。\n#### 线程池方式\n将RunnableTest改一改换成用线程池的方式\n```java\npublic class RunnableTest {\n\tpublic static void main(String[] args) {\n\t\tMyRunnable runnable = new MyRunnable();\n\t\t//创建线程池\n\t\tExecutorService executorService = Executors.newFixedThreadPool(2);\n\t\tlong startTime = System.currentTimeMillis();\n\t\tFuture<String> task  = (FutureTask<String>) executorService.submit(runnable);\n\t\ttry {\n\t\t\tSystem.out.println(task.get());\n\t\t} catch (InterruptedException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t} catch (ExecutionException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}finally{\n\t\t\texecutorService.shutdown();\n\t\t}\n\t\tlong endTime = System.currentTimeMillis();\n\t\tSystem.out.println(\"启动任务之后时间:  \"+ (endTime-startTime)/(1000) + \"秒\");\n\t}\n}\n```\n执行结果：\n![Runnable-get](Runnable-get.png)\n可以发现，只要调用了Future的get()方法，主线程就阻塞了。去掉该方法，重新执行下，结果如下：\n![Runnable-non-get](Runnable-non-get.png)\n结果跟用Thread方式执行的结果一致。\n\n## ExecutorService-submit()封装过程\n```java\n\n    protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {\n        return new FutureTask<T>(runnable, value);\n    }\n\n  \n    protected <T> RunnableFuture<T> newTaskFor(Callable<T> callable) {\n        return new FutureTask<T>(callable);\n    }\n\n   \n    public Future<?> submit(Runnable task) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture<Void> ftask = newTaskFor(task, null);\n        execute(ftask);\n        return ftask;\n    }\n    \n    public <T> Future<T> submit(Callable<T> task) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture<T> ftask = newTaskFor(task);\n        execute(ftask);\n        return ftask;\n    }\n\n```\n在AbstractExecutorService类的源码中可以看到，submit中的newTaskFor()方法将Callable对象或Runnable对象封装成了FutureTask对象返回。\n\n## Future-get()获取返回值及阻塞原因\nFutureTask类实现了Future接口，所以我们以FutureTask类源码为例进行分析。\nFutureTask源码中的几个静态类变量及构造方法\n```java\n /**\n     * The run state of this task, initially NEW.  The run state\n     * transitions to a terminal state only in methods set,\n     * setException, and cancel.  During completion, state may take on\n     * transient values of COMPLETING (while outcome is being set) or\n     * INTERRUPTING (only while interrupting the runner to satisfy a\n     * cancel(true)). Transitions from these intermediate to final\n     * states use cheaper ordered/lazy writes because values are unique\n     * and cannot be further modified.\n     * \n     * Possible state transitions:  任务状态之间的转换过程\n     * NEW -> COMPLETING -> NORMAL\n     * NEW -> COMPLETING -> EXCEPTIONAL\n     * NEW -> CANCELLED\n     * NEW -> INTERRUPTING -> INTERRUPTED\n     */\n    private volatile int state;  //任务状态变量，由CAS操作保证原子性\n    private static final int NEW          = 0; //任务新建和执行中\n\tprivate static final int COMPLETING   = 1; //任务将要执行完毕\n\tprivate static final int NORMAL       = 2; //任务正常执行结束\n\tprivate static final int EXCEPTIONAL  = 3; //任务异常\n\tprivate static final int CANCELLED    = 4; //任务取消\n\tprivate static final int INTERRUPTING = 5; //任务线程即将被中断\n\tprivate static final int INTERRUPTED  = 6; //任务线程已中断\n\n    public FutureTask(Callable<V> callable) {\n        if (callable == null)\n            throw new NullPointerException();\n        this.callable = callable;\n        this.state = NEW;       // ensure visibility of callable\n    }\n```\n以Thread方式的Callable为例，在调用了线程的start方法之后会使得该线程处于就绪状态，有了竞争CPU时间片的权限，当分配到时间片之后，就会执行FutureTask的run()方法，其源码如下：\n```java\npublic void run() {\n        if (state != NEW ||\n            !UNSAFE.compareAndSwapObject(this, runnerOffset,\n                                         null, Thread.currentThread()))\n            return;\n        try {\n            Callable<V> c = callable;\n            if (c != null && state == NEW) {\n                V result;\n                boolean ran;\n                try {\n                    result = c.call();   //任务执行\n                    ran = true;\n                } catch (Throwable ex) {\n                    result = null;\n                    ran = false;\n                    setException(ex);  //异常对象赋给outcome\n                }\n                if (ran)\n                    set(result);    //执行结果赋给outcome\n            }\n        } finally {\n            // runner must be non-null until state is settled to\n            // prevent concurrent calls to run()\n            runner = null;\n            // state must be re-read after nulling runner to prevent\n            // leaked interrupts\n            int s = state;\n            if (s >= INTERRUPTING)\n                handlePossibleCancellationInterrupt(s);\n        }\n    }\n```\n在调用完call()方法后，将执行结果赋值给result。如果程序正常执行的话，就将result在set()方法进行具体的赋值操作，set()方法的源码如下：\n```java\n protected void set(V v) {\n \t    //将state由NEW更新为COMPLETING\n        if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {\n            outcome = v;\n             //赋值完毕，将state由COMPLETING更新为NORMAL\n            UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state\n            finishCompletion();\n        }\n    }\n```\nset方法将result赋给了outcome，outcome是Object类型的全局变量，同时将state状态设置为NORMAL，接着会执行finishCompletion()方法，finishCompletion()其实就是用来唤醒get()方法的。get()方法的源码如下：\n```java\n public V get() throws InterruptedException, ExecutionException {\n        int s = state;\n        if (s <= COMPLETING)\n            s = awaitDone(false, 0L);  \n        return report(s);\n    }\n```\n如果Callable中call()方法的业务逻辑还没处理完毕，此时state为NEW，对应的值小于COMPLETING，执行awaitDone() 方法（阻塞线程的地方），其源码如下：\n```java\nprivate int awaitDone(boolean timed, long nanos)\n        throws InterruptedException {\n    // 任务截止时间\n    final long deadline = timed ? System.nanoTime() + nanos : 0L;\n    WaitNode q = null;\n    boolean queued = false;\n    // 自旋\n    for (;;) {\n        if (Thread.interrupted()) {\n            //线程中断则移除等待线程,并抛出异常\n            removeWaiter(q);\n            throw new InterruptedException();\n        }\n        int s = state;\n        if (s > COMPLETING) {\n            // 任务可能已经完成或者被取消了\n            if (q != null)\n                q.thread = null;\n            return s;\n        }\n        else if (s == COMPLETING)\n            // 可能任务线程被阻塞了,主线程让出CPU\n            Thread.yield();\n        else if (q == null)\n            // 等待线程节点为空,则初始化新节点并关联当前线程\n            q = new WaitNode();\n        else if (!queued)\n            // 等待线程入队列,成功则queued=true\n            queued = UNSAFE.compareAndSwapObject(this, waitersOffset,\n                    q.next = waiters, q);\n        else if (timed) {\n            nanos = deadline - System.nanoTime();\n            if (nanos <= 0L) {\n                //已经超时的话,移除等待节点\n                removeWaiter(q);\n                return state;\n            }\n            // 未超时,将当前线程挂起指定时间\n            LockSupport.parkNanos(this, nanos);\n        }\n        else\n            // timed=false时会走到这里,挂起当前线程\n            LockSupport.park(this);\n    }\n}\n```\n执行过程：\n- 计算deadline，也就是到某个时间点后如果还没有返回结果，那么就超时了。\n- 进入自旋，也就是死循环。\n- 首先判断是否响应线程中断。对于线程中断的响应往往会放在线程进入阻塞之前。\n- 判断state值，如果>COMPLETING表明任务已经取消或者已经执行完毕，就可以直接返回了。\n- 如果任务还在执行，则为当前线程初始化一个等待节点WaitNode，入等待队列。\n- 计算nanos，判断是否已经超时。如果已经超时，则移除所有等待节点，直接返回state。超时的话，state的值仍然还是COMPLETING。\n- 如果还未超时，就通过LockSupprot类提供的方法在指定时间内挂起当前线程，等待任务线程唤醒或者超时  \n\n在awaitDone方法中，会一直自旋(正常情况下)，直到set()方法将state更新为NORMAL并执行完finishCompletion()方法，来唤醒get()方法中的awaitDone()方法挂起的线程。其源码如下：\n```java\nprivate void finishCompletion() {\n    //遍历等待节点\n    for (WaitNode q; (q = waiters) != null;) {\n        if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {\n            for (;;) {\n                Thread t = q.thread;\n                if (t != null) {\n                    q.thread = null;\n                    //唤醒等待线程\n                    LockSupport.unpark(t);\n                }\n                WaitNode next = q.next;\n                if (next == null)\n                    break;\n                // unlink to help gc\n                q.next = null;\n                q = next;\n            }\n            break;\n        }\n    }\n    //模板方法,可以被覆盖\n    done();\n    //清空callable\n    callable = null;\n}\n```\n当任务正常结束或者异常时，都会调用finishCompletion()方法去唤醒等待线程。当get()方法中的awaitDone()方法挂起的线程被唤醒后，就可以继续执行get()方法中的report()方法返回执行结果。\n\n## 总结\nCallable由FutureTask的run()方法启动线程：1、在Callable对象中的call()方法的业务逻辑执行完后；2、调用FutureTask的set()方法对任务的state进行更新为COMPLETING；3、对全局变量结果outcome进行赋值；4、再次更新state为NORMAL；5、调用finishCompletion()唤醒FutureTask的get()中挂起的线程，继续执行get()方法中awaitDone下面的代码。\nFutureTask的get()方法中，先判断state<=COMPLETING，若是则调用awaitDone()挂起线程，自旋等待上述1-5步骤执行完毕，才能返回全局变量结果outcome；若不是则直接返回全局变量结果outcome。FutureTask的get()阻塞是通过自旋+挂起线程实现。\n\n\n\n\n","tags":["Java","并发"],"categories":["Java","并发"]},{"title":"Java并发编程-辅助类：CountDownLatch、CyclicBarrier和Semaphore","url":"/2018/10/16/Java并发编程-辅助类：CountDownLatch、CyclicBarrier和Semaphore/","content":"\n## CountDownLatch\nCountDownLatch是一个非常实用的多线程控制工具类，该类位于java.util.concurrent包下。这个工具类通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。利用它可以实现类似倒计时器的功能。\n对于倒计时器，一种典型的场景就是火箭发射。在火箭发射前，往往需要进行各项设备、仪器检查(*该过程可以是并行的*)。只有等所有的检查完毕后，引擎才能点火。这种场景就非常适用CountDownLatch。它可以使得点火线程等待所有检查线程全部完工后，再执行。  \nCountDownLatch类只提供了一个构造器\n```java\npublic CountDownLatch(int count){};//参数count为计数值\n```\n以下3个方法是CountDownLatch类中最重要的方法：\n```java\npublic void await() throws InterruptedException { };   //d调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行\npublic boolean await(long timeout, TimeUnit unit) throws InterruptedException { };  //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行\npublic void countDown() { };  //将count值减1\n```\n下面的示例，演示了CountDownLatch的使用\n```java\npublic class CountDownLatchDemo implements Runnable {\n\tfinal static CountDownLatchDemo demo = new CountDownLatchDemo(); \n\tfinal static CountDownLatch latch = new CountDownLatch(6);\n\t@Override\n\tpublic void run() {\n\t\ttry {\n\t\t\tThread.sleep(new Random().nextInt(10)*1000);\n\t\t\tSystem.out.println(\"线程[\"+Thread.currentThread().getName()+\"],check Complete!\");\n\t\t\tlatch.countDown(); //计数器减1\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t}\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tExecutorService executor = Executors.newFixedThreadPool(6);\n\t\tfor(int i = 0 ; i < 6 ;i ++){\n\t\t\texecutor.submit(demo);\n\t\t}\n\t\tlatch.await(); //等待6个线程执行完毕\n\t\tSystem.out.println(\"start fire\");\n\t\texecutor.shutdown();\n\t}\n}\n```\n执行结果：\n```java\n线程[pool-1-thread-5],check Complete!\n线程[pool-1-thread-1],check Complete!\n线程[pool-1-thread-3],check Complete!\n线程[pool-1-thread-4],check Complete!\n线程[pool-1-thread-2],check Complete!\n线程[pool-1-thread-6],check Complete!\nstart fire\n```\n## CyclicBarrier\nCyclicBarrier是另外一种多线程并发控制实用工具。CyclicBarrier可以理解为循环栅栏。通过它可以让一组线程等待至某个状态之后全部同时执行。当所有线程执行完毕后，CyclicBarrier可以被重复使用。CyclicBarrier类位于java.util.concurrent包下，CyclicBarrier提供2个构造器：\n```java\npublic CyclicBarrier(int parties, Runnable barrierAction) {}\n \npublic CyclicBarrier(int parties) {}\n```\n参数parties指需要多少个线程或者任务在“栅栏外”等待的；参数barrierAction为当这些线程都达到某个状态时，会执行的动作。  \n然后CyclicBarrier中最重要的方法就是await方法，它有2个重载版本：\n```java\npublic int await() throws InterruptedException, BrokenBarrierException { };\npublic int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException { };\n```\n第一个版本比较常用，用来挂起当前线程，直到所有线程都到达某个状态后，再同时执行后续任务；\n第二个版本是让这些线程等待至一定的时间，如果还有线程没有到达某个状态，就直接让先到达的线程执行后续的任务。  \n下面的示例，演示了CyclicBarrier的使用:\n```java\npublic class CyclicBarrierDemo {\n\t\n\tstatic class Writer extends Thread{\n\t\tprivate CyclicBarrier cyclicBarrier;\n\t\tpublic Writer(CyclicBarrier cyclicBarrier){\n\t\t\tthis.cyclicBarrier = cyclicBarrier;\n\t\t}\n\t\t\n\t\t@Override\n\t\tpublic void run(){\n\t\t\tSystem.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据\");\n\t\t\ttry {\n\t\t\t\tThread.sleep(5000); //模拟写入数据操作\n\t\t\t\tSystem.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据\");\n\t\t\t\tcyclicBarrier.await();\n\t\t\t} catch (Exception e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\tSystem.out.println(\"所有线程写入完毕，继续处理其他任务...\");\n\t\t}\n\t}\n\t\n\tpublic static void main(String[] args) {\n\t\tint n = 4;\n\t\tCyclicBarrier barrier = new CyclicBarrier(n, new Runnable() {\n\t\t\t\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\tSystem.out.println(\"所有线程都到达“栅栏外”\");\n\t\t\t\t\n\t\t\t}\n\t\t});\n\t\tfor(int i = 0 ; i < n ; i ++){\n\t\t\tnew Writer(barrier).start();\n\t\t}\n\t\t\n\t\ttry {\n            Thread.sleep(10000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n \n        System.out.println(\"CyclicBarrier重用\");\n        \n        for(int i = 0 ; i < n ; i ++){\n\t\t\tnew Writer(barrier).start();\n\t\t}\n\t}\n}\n```\n执行结果：\n```java\n线程Thread-0正在写入数据\n线程Thread-2正在写入数据\n线程Thread-3正在写入数据\n线程Thread-1正在写入数据\n线程Thread-3写入数据\n线程Thread-2写入数据\n线程Thread-1写入数据\n线程Thread-0写入数据\n所有线程都到达“栅栏外”\n所有线程写入完毕，继续处理其他任务...\n所有线程写入完毕，继续处理其他任务...\n所有线程写入完毕，继续处理其他任务...\n所有线程写入完毕，继续处理其他任务...\nCyclicBarrier重用\n线程Thread-4正在写入数据\n线程Thread-5正在写入数据\n线程Thread-6正在写入数据\n线程Thread-7正在写入数据\n线程Thread-5写入数据\n线程Thread-4写入数据\n线程Thread-6写入数据\n线程Thread-7写入数据\n所有线程都到达“栅栏外”\n所有线程写入完毕，继续处理其他任务...\n所有线程写入完毕，继续处理其他任务...\n所有线程写入完毕，继续处理其他任务...\n所有线程写入完毕，继续处理其他任务...\n\n```\n### Semaphore\nSemaphore可以允许多个线程同时访问。相对内部锁synchronized还是重入锁ReetrantLock，一次都只允许一个线程访问一个资源，而信号量却可以指定多个线程，同时访问一个资源。Semaphore类位于java.util.concurrent包下，它提供了2个构造器：\n```java\npublic Semaphore(int permits) {          //参数permits表示许可数目，即同时可以允许多少线程进行访问\n    sync = new NonfairSync(permits);\n}\npublic Semaphore(int permits, boolean fair) {    //这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可\n    sync = (fair)? new FairSync(permits) : new NonfairSync(permits);\n}\n```\nSemaphore类中比较重要的几个方法:\n```java\npublic void acquire() throws InterruptedException {  }     //获取一个许可\npublic void acquire(int permits) throws InterruptedException { }    //获取permits个许可\npublic void release() { }          //释放一个许可\npublic void release(int permits) { }    //释放permits个许可\n```\nacquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。\nrelease()用来释放许可。注意，在释放许可之前，必须先获获得许可。\n这4个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法：\n```java\npublic boolean tryAcquire() { };    //尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回false\npublic boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException { };  //尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false\npublic boolean tryAcquire(int permits) { }; //尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回false\npublic boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException { }; //尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false\n```\n另外还可以通过availablePermits()方法得到可用的许可数目。\n下面的示例，演示了Semaphore的使用:\n```java\npublic class SemaphoreDemo implements Runnable {\n\t\n\tfinal Semaphore semaphore = new Semaphore(5);\n\t\n\t@Override\n\tpublic void run() {\n\t\ttry {\n\t\t\tSystem.out.println(\"线程\"+Thread.currentThread().getName()+\"，申请资源\");\n\t\t\tsemaphore.acquire();\n\t\t\tThread.sleep(2000);\n\t\t\tSystem.out.println(\"线程\"+Thread.currentThread().getName()+\"，释放资源\");\n\t\t\tsemaphore.release();\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t}\n\n\tpublic static void main(String[] args) {\n\t\t ExecutorService executor = Executors.newFixedThreadPool(5);\n\t\t SemaphoreDemo demo = new SemaphoreDemo();\n\t\t for(int i = 0 ; i < 8 ; i ++){\n\t\t\t executor.submit(demo);\n\t\t }\n\t}\n\n}\n```\n执行结果：\n```java\n线程pool-1-thread-1，申请资源\n线程pool-1-thread-5，申请资源\n线程pool-1-thread-4，申请资源\n线程pool-1-thread-2，申请资源\n线程pool-1-thread-3，申请资源\n线程pool-1-thread-2，释放资源\n线程pool-1-thread-3，释放资源\n线程pool-1-thread-4，释放资源\n线程pool-1-thread-2，申请资源\n线程pool-1-thread-5，释放资源\n线程pool-1-thread-1，释放资源\n线程pool-1-thread-4，申请资源\n线程pool-1-thread-3，申请资源\n线程pool-1-thread-2，释放资源\n线程pool-1-thread-4，释放资源\n线程pool-1-thread-3，释放资源\n\n```\n### 总结\n- CountDownLatch和CyclicBarrier都能够实现线程之间的等待。CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行。另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用。\n- Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。\n\n\n\n\n","tags":["Java","并发"],"categories":["Java","并发"]},{"title":"class文件常量池、运行时常量池、字符串常量池","url":"/2018/10/13/class文件常量池、运行时常量池、字符串常量池/","content":"\n## 简介\n\n常量池是为了避免频繁的创建和销毁对象而影响系统性能，其实现了对象的共享。例如字符串常量池，在编译阶段就把所有的字符串文字放到一个常量池中。\n\n> 节省内存空间：常量池中所有相同的字符串常量被合并，只占用一个空间。\n> 节省运行时间：比较字符串时，==比equals()快。对于两个引用变量，只用==判断引用是否相等，也就可以判断实际值是否相等。\n\n## class文件常量池（静态常量池）\nclass文件常量池是指编译生成的class字节码文件结构中的一个常量池（Constant Pool Table），用于存放编译期间生成的各种字面量和符号引用，这部分内容将在类加载后，存放于方法区的运行时常量池。\n> - 字面量指的是**字符串字面量和声明为final的常量值（基本数据类型）**。\n> - &ensp;&ensp;字符串字面量除了类中所有双引号括起来的字符串（包括方法体内的），还包括所有用到的类名、方法名和这些类与方法的字符串描述、字段（成员变量）的名称和描述符\n> - &ensp;&ensp;声明为final的常量值指的是成员变量，不包含本地变量，本地变量是属于方法的。\n> - 符号引用包括类和接口的全限定名（包括包路径的完整名）、字段的名称和描述符、方法的名称和描述。只不过是以一组符号来描述所引用的目标，和内存并无关，所以称为符号引用，直接指向内存中某一地址的引用称为直接引用  \n\n### 常量池结构\n前端的两个字节占有的位置叫做常量池计数器(constant_pool_count)，它记录着常量池的组成元素-常量池项(cp_info)的个数（从１开始，将０表示不引用任何常量）。紧接着会排列着constant_pool_count-1个常量池项(cp_info)。每个常量池项(cp_info) 都会对应记录着class文件中的某种类型的字面量。cp_info项的结构如下：\n```java\ncp_info{\n\tu1 tag;\n\tu1 info[];\n}\n```\nJVM会根据tag的值来确定当前常量池项表示什么类型的字面量。  \n\n| Tag        | 类型     |  描述  |\n| --------   | -----:  | :----: |\n| 1          | CONSTANT_utf8_info      | UTF-8编码的字符串字面量    |\n| 3          | CONSTANT_Integer_info      |   整型字面量   |\n| 4          | CONSTANT_Float_info      |  浮点型字面量   |\n| 5          | CONSTANT_Long_info      |   长整型字面量    |\n| 6          | CONSTANT_Double_info      |   双精度浮点型字面量    |\n| 7          | CONSTANT_Class_info\t      |  \t类或接口的符号引用    |\n| 8          | CONSTANT_String_info      |  字符串类型字面量    |\n| 9          | CONSTANT_Fieldref_info      |   字段的符号引用    |\n| 10         | CONSTANT_Methodref_info      |   类中方法的符号引用    |\n| 11         | CONSTANT_InterfaceMethodref_info     |   接口中方法的符号引用    |\n| 12         | CONSTANT_NameAndType_info      |  字段或方法的符号引用    |\n| 15          | CONSTANT_MethodHandle_info     |   \t表示方法句柄    |\n| 16         | CONSTANT_MothodType_info      |   表示方法类型    |\n| 18          | CONSTANT_InvokeDynamic_info      |   表示一个动态方法调用点    |  \n\n### 基本数据类型常量在常量池存储\n通过下面的例子来讲解下\n```java\npublic class Test {  \n      \n    private final int a = 10;  \n    private final int b = 10;  \n    private float c = 11f;  \n    private float d = 11f;  \n    private float e = 11f;  \n\n    private String s1 = \"JVM原理\";  \n    private String s2 = \"JVM原理\";  \n      \n}  \n```\n创建完上面的java文件后，执行`javac Test.java`Test.class文件，再执行`javap -v Test` 查看class文件。\n![class常量池](class常量池1.png)\n从上面的结果我们可以看到在常量池中，只有一个常量10 、一个常量11f、一个常量JVM原理。代码中所有用到 int 类型 10 的地方，会使用指向常量池的指针值#16（符号引用）定位到第#16个常量池项(cp_info)，即值为 10的结构体CONSTANT_Integer_info，而用到float类型的11f时，也会指向常量池的指针值#4来定位到第#4个常量池项(cp_info) 即值为11f的结构体CONSTANT_Float_info。我们可以看到CONSTANT_String_info结构体位于常量池的第#8个索引位置，且该结构体直接存储了指针值#37，用来指向第#37个常量池项。而存放\"JVM原理\"字符串的UTF-8编码格式的字节数组被放到CONSTANT_Utf8_info结构体中，该结构体位于常量池的第#37个索引位置。\n\n### 类文件中定义的类名和类中使用到的类常量在常量池存储\nCONSTANT_Class_info结构体中，存在一个索引值，用于指向存储了[类二进制形式的完全限定名称]字符串的CONSTANT_String_info结构体。该索引值占两个字节大小，所以它能表示的最大索引是65535（2的16次方-1），也就是说常量池中最多能容纳65535个常量项。所在在定义类时要注意类的大小。  \n\n> 假设我们定义了一个 ClassTest的类，并把它放到com.focus.jvm 包下，则 ClassTest类的完全限定名为com.focus.jvm.ClassTest，将JVM编译器将类编译成class文件后，此完全限定名在class文件中，是以二进制形式的完全限定名存储的，即它会把完全限定符的\".\"换成\"/\" ，即在class文件中存储的 ClassTest类的完全限定名称是\"com/focus/jvm/ClassTest\"。因为这种形式的完全限定名是放在了class二进制形式的字节码文件中，所以就称之为二进制形式的完全限定名。  \n\n```java\npackage com.focus.jvm;  \nimport  java.util.Date;  \npublic class ClassTest {  \n    private Date date1 =new Date();  \n    private Date date2;  \n    private Date date3;\n\n    public ClassTest(){  \n        date2  = new Date();  \n    }  \n} \n```\n![class常量池2](class常量池2.png)\n由上图可以看到，在ClassTest.class文件的常量池中，共有3个CONSTANT_Class_info结构体，表示ClassTest中用到的Class信息。一个java/util/Date的CONSTANT_Class_info结构体，它在常量池中的位置是#2，存储的指针值为#19，它指向了常量池的第19个常量池项；一个com/focus/ClassTest的CONSTANT_Class_info结构体，它在常量池中的位置是#6，存储的指针值为#22，它指向了常量池的第22个常量池项；另外一个java/lang/Object的CONSTANT_Class_info结构体，它在常量池中的位置是#7，存储的指针值为#23，它指向了常量池的第23个常量池项。\n\n> Java中规定所有的类都要继承java.lang.Object类，即所有类都是java.lang.Object的子类。JVM在编译类的时候，即使我们没有显示地继承Object，JVM编译器在编译的时候会自动帮我们加上去。所以对于某个类而言，其class文件中至少会有两个CONSTANT_Class_info常量池项，用来表示自己的类信息和其父类信息。如果类声明实现了某些接口，那么接口的信息也会生成对应的CONSTANT_Class_info常量池项。  \n\n如果在类中使用到了其他的类，只有真正使用到了相应的类，JDK编译器才会将类的信息组成CONSTANT_Class_info常量池项放置到常量池中。如下面的代码：\n```java\npackage com.focus.jvm;  \nimport  java.util.Date;  \npublic class ClassTest {  \n     \n    private Date date3;\n\n   \n} \n```\n编译后结果\n![class常量池3](class常量池3.png)\n在JDK将其编译成class文件时，常量池中并没有java.util.Date对应的CONSTANT_Class_info常量池项。它认为你只是声明了“Ljava/util/Date”类型的变量，并没有实际使用到Ljava/util/Date类。\n### 总结\n > - 对于某个类或接口而言，其自身、父类和继承或实现的接口的信息会被直接组装成CONSTANT_Class_info常量池项放置到常量池中；  \n\n> - 类中或接口中使用到了其他的类，只有在类中实际使用到了该类时，该类的信息才会在常量池中有对应的CONSTANT_Class_info常量池项；\n\n> - 类中或接口中仅仅定义某种类型的变量，JDK只会将变量的类型描述信息以UTF-8字符串组成CONSTANT_Utf8_info常量池项放置到常量池中。\n\n## 运行时常量池\n运行时常量池是方法区的一部分，是一块内存区域。class文件常量池将在类加载后进入方法区的运行时常量池中存放。**一个类加载到JVM中后对应一个运行时常量池**，运行时常量池相对于class文件常量池来说具备动态性，**即字面量可以动态的添加**。Java语言并不要求常量一定只能在编译期产生，运行期间也可能产生新的常量（基本类型包装类和String），这些常量被放在运行时常量池中。class文件常量池只是一个静态存储结构，里面的引用都是符号引用。而运行时常量池可以在运行期间将符号引用解析为直接引用。可以说运行时常量池就是用来索引、查找字段和方法名称和描述符的。给定任意一个字段或方法的索引，最终可得到该字段或方法所属的类型信息和名称及描述符信息。\n\n### 基本类型\njava中基本类型的包装类的大部分都实现了常量池技术，即Byte,Short,Integer,Long,Character,Boolean。这5种包装类默认创建了数值[-128，127]的相应类型的缓存数据，但是超出此范围仍然会去创建新的对象。两种浮点数类型的包装类Float,Double并没有实现缓存池技术。\n\n\n\n## 字符串常量池\n字符串常量池是**全局的**，JVM中独此一份，因此也称为全局字符串常量池。运行时常量池中的字符串字面量若是成员的，则在类加载初始化阶段就使用到了字符串常量池；若是本地的，则在使用到的时候才会使用字符串常量池。其实，“使用常量池”对应的字节码是一个ldc指令，在给String类型的引用赋值的时候会先执行这个指令，看常量池中是否存在这个字符串对象的引用，若有就直接返回这个引用，若没有，就在堆里创建这个字符串对象并在字符串常量池中记录下这个引用。String类的intern()方法还可以在运行期间把字符串放到字符串常量池中。\n- 在 jdk1.6（含）之前也是方法区的一部分，并且其中存放的是字符串的实例；\n- 在 jdk1.7（含）之后是在堆内存之中，存储的是字符串对象的引用，字符串实例是在堆中；\n- jdk1.8 已移除永久代，字符串常量池是在本地内存当中，存储的也只是引用\n\n> - JVM中除了字符串常量池，8种基本数据类型中除了两种浮点类型外，其它的6种基本数据类型的包装类都使用了缓冲池，但是Byte、Short、Integer、Long、Character这几个包装类只有对应值在[-128,127]时才会使用缓冲池，超出此范围仍会去创建新的对象。","tags":["JVM"],"categories":["JVM"]},{"title":"JVM垃圾回收","url":"/2018/09/28/JVM垃圾回收/","content":"\n## 概念\n垃圾回收(Garbage Collection)是JVM提供的一种用于在空闲时间不定时回收无任何对象引用的对象占据的内存空间的一种机制。\n\n**注意：**垃圾回收器回收的是无任何引用的对象占据的内存空间而不是对象本身。换言之，垃圾回收只会负责释放那些对象占有的内存。对象是个抽象的词，包括引用和其占据的内存空间。当对象没有任何引用时其占据的内存空间随即被收回备用，此时对象也就被销毁。\n\n## 引用介绍\n如果Reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。引用又分为**强引用，软引用，弱引用，虚引用**，引用强度依次逐渐减弱。\n\n> - 强引用（Strong Reference）：如“Object obj = new Object（）”，这类引用是Java程序中最普遍的。只要强引用还存在，垃圾收集器就永远不会回收掉被引用的对象。\n> - 软引用（Soft Reference）：它用来描述一些可能还有用，但并非必须的对象。在系统内存不够用时，这类引用关联的对象将被垃圾收集器回收。JDK1.2之后提供了SoftReference类来实现软引用。\n> - 弱引用（Weak Reference）：它也是用来描述非须对象的，但它的强度比软引用更弱些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK1.2之后，提供了WeakReference类来实现弱引用。\n> - 虚引用（Phantom Reference）：最弱的一种引用关系，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的是希望能在这个对象被收集器回收时收到一个系统通知。JDK1.2之后提供了PhantomReference类来实现虚引用。\n\n\n## 垃圾对象的确定\n任何一种垃圾回收算法一般要做以下2件基本的事情：  \n\n> - 找到所有存活对象\n> - 回收被无用对象占用的内存空间，使该空间可被程序再次使用 \n\n那么如何找到堆中哪些是存活对象，哪些是无用对象，通常有以下几种算法来确定。\n\n### 引用计数算法（Reference Counting Collector）\n堆中每个对象都有一个引用计数器，当一个对象被创建并初始化赋值后，该计数器数值设置为1。每当有一个地方引用它时，计数器就加1，如a=b，b被引用，则b的引用计数器加1。当引用失效时，如一个对象的某个引用超过了生命周期或者被设置为一个新值时，则计数器值减1。任何引用计数器为0的对象都可以被当作垃圾回收。当一个对象被垃圾回收时，它引用的任何对象计数器减1。  \n> - **优点：**执行简单，判定效率高，与程序并发运行\n> - **缺点：**难以检测出对象之间的循环引用。引用计数器增加了程序执行的开销。现大多数JVM采用下面的**根搜索算法**。\n\n### 根搜索算法（Tracing Collector）\n这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下一级一级地搜索，并沿途标记路径上的每个节点，搜索所走过的路径称为引用链（Reference Chain），这时引用链上的节点即是存活对象。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。\n![根搜索算法](根搜索算法.png)\n图中蓝色标记的为存活对象，灰色标记的垃圾对象，即GC Roots不可达的对象。\n哪些对象可以作为`GC Roots`对象，主要有以下几种：\n> - 虚拟机栈中引用的对象(栈帧中的本地变量表)  \n> - 方法区中的常量引用的对象\n> - 方法区中的类静态属性引用的对象\n> - 本地方法栈中JNI(Native方法)的引用对象  \n\n由于这些GC Roots对象不能被其他对象引用，所以也就不会出现引用计数算法中循环引用的问题了。在标记阶段有几个地方是需要注意的：\n> - 开始标记前，需要暂停应用线程(STW)，以便JVM可以准确地进行标记工作\n> - 暂停时间地长短取决于存活对象的多少，而不是堆内对象的多少或堆的大小。因此，调高堆的大小并不会影响到标记阶段的时间长短。\n> - 在根搜索算法中，要真正判定一个对象是否存活，至少要经历两次标记过程： \n  - 如果对象在进行根搜索后，发现没有与GC Roots相连接的引用链，那么它会被第一次标记并且进行一次筛选。筛选的条件是此对象是否有必要执行finalize()方法。虚拟机会将以下两种情况是为没有必要执行finalize()方法：1、对象没有覆盖finalize()方法；2、finalize()方法已被虚拟机调用过。\n  - 如果对象被判定为没有必要执行finalize()方法，则直接将其回收。反之，如果该对象被判定为有必要执行finalize()方法，那么这个对象会被放置在一个名为F-Queue队列中，并由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行该对象的finalize()方法。然后，GC将堆F-Queue中的对象进行第二次小规模标记，再次判断该对象是否可达。如果想要让该对象存活下来，就需要在finalize()方法中让该对象重新引用GC Roots链上的任何一个对象，建立起关联即可。但如果对象还没有关联到任何GC Roots链上的引用，即该对象不可达，那么它就会被回收。finalize()方法是该对象判定为存活的最后一次机会，它最多只会被系统自动调用一次。\n\n\n## 垃圾回收算法\n\n### 标记-清除算法(Mark-Sweep)\n标记-清除算法是现代垃圾回收算法的思想基础。*CMS垃圾回收器中的old gc就是基于标记-清除算法实现的。*标记-清除算法将垃圾回收分为两个阶段：**标记阶段和清除阶段**。\n> - **标记阶段：**首先通过根节点(GC Roots)，标记所有从根节点开始的可达对象。因此，未被标记的对象就是未被引用的垃圾对象\n> - **清除阶段：**清除所有未被标记的对象  \n\n![标记-清除算法](根搜索算法.png)\n在标记清除期间内应用程序会暂停运行，发生STW事件。  \n\n**缺点：**\n> - 效率比较低，需要遍历全堆的存活对象，导致STW事件比较长\n> - 清除后的空闲内存不是连续的，难以为大对象分配内存空间。同时JVM不得不维护一个内存的空闲列表。\n\n### 复制算法(Copying)\n将原有的内存空间分为两块，每次只使用其中一块，在垃圾回收时，将正在使用的内存中的存活对象复制到未使用的内存块中。之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收。\n![复制算法](复制算法.png)\n\n**注意：**\n> - 复制算法不适用于存活对象较多的场合，如老年代。相反，适合于新生代的GC。  \n\n**缺点：**\n> - 空间浪费。复制算法使得每次都只对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况。只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。  \n\n该收集算法适用于来回收新生代内存空间。新生代中的对象大多数的都是存活率较低的，所以并不需要按照1：1比例来划分内存空间，而是将内存分为一块比较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。当Survivor空间不够用时，需要依赖老年代进行分配担保，所以大对象直接进入老年代。\n老年代不适合用复制算法进行垃圾回收的原因有2个：\n\n> - 当对象的存活率较高时就要进行较多的复制操作，效率就会降低\n> - JVM不会对老年代的空间进行划分，此时就需要额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况\n\n### 标记-整理算法(Mark-Compact)\n该算法适用于存活对象较多的场合，如老年代。它在标记-清除的基础上做了一些优化。和标记-清除算法一样，标记-整理算法也需要从根节点开始，对所有可达对象做一次标记，然后将所有存活对象压缩到内存的一端，接着再清理边界外的所有空间。\n![标记整理算法](标记整理算法.png)\n\n**具体过程：**\n> - **标记：**这个阶段与标记-清除算法的第一个阶段是一样的，均是遍历GC Roots，然后将存活的对象标记。\n> - **整理：**移动所有存活对象，且按照内存地址次序依次排列，然后将末端内存地址后的内存全部回收。  \n\n**优点：**\n> - 弥补了标记-清除算法当中，内存区域分散的缺点。当我们需要给新对象分配内存时，JVM只要持有一个内存的起始地址即可。相比维护一个空闲列表，少了很多开销。\n> - 消除了复制算法当中，内存减半的高额代价。\n\n**缺点：**\n> - 效率不高，低于复制算法。不仅要标记所有存活对象，还要整理所有存活对象的引用地址。\n\n### 分代收集算法(Generational Collection)\n分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般是把Java堆分为新生代和老年代：短命对象归为新生代，长命对象归为老年代。  \n> - 少量对象存活，适合复制算法：在新生代中，每次GC时都发现有大批对象被回收，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成GC。  \n>- 大量对象存活，适合用标记-清理或标记-整理算法：在老年代中，因为对象存活率高、没有额外空间对他进行分配担保，就必须使用标记-清理或标记-整理算法进行GC。  \n\n**注意：**老年代的对象中，有一小部分是因为在新生代回收时，老年代做担保，进来的对象；绝大部分对象是因为很多次GC都没有被回收掉而进入老年代。\n\n\n### 总结\n**标记-清除算法、复制算法、标记-整理算法**相同点：  \n> - 都是基于根搜索算法去判断一个对象是否应该被回收。支撑根搜索算法可以正常工作的理论依据是语法中变量作用域的相关内容。因此，要想防止内存泄露，最根本的办法就是掌握好变量作用区域。\n> - 在GC过程中，它们都要暂停应用程序(STW)。  \n\n那么这三个算法之间的区别如下：\n> - 效率：复制算法 > 标记-整理算法 > 标记-清除算法\n> - 内存整齐度：复制算法 = 标记-整理算法 > 标记-清除算法\n> - 内存利用率：标记-整理算法 =  标记-清除算法 > 复制算法  \n\n\n### 老年代和新生代的区别(题外话)\n> - 新生代对象的生命周期短，老年代对象的生命周期长\n> - 新生代对象回收采用复制算法，老年代对象回收采用标记-清除或标记-整理算法\n> - 新生代空间满了就执行Minor GC，一般采用复制算法；老年代空间就执行Full GC，一般采用Mark-Compact算法清理\n","tags":["JVM","GC"],"categories":["JVM"]},{"title":"JVM-内存模型结构","url":"/2018/09/28/JVM-内存模型结构/","content":"\n## JVM简介\n\n### 概念\n- JVM是一种用于计算设备的规范，它是一个虚构出来的机器，是通过在实际的计算机上仿真模拟各种功能实现的。\n- JVM是JRE的一部分，屏蔽了与具体操作系统平台相关的信息，使Java程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。  \n\nJVM在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行。JVM在整个jdk中处于最底层，负责于操作系统的交互，用来屏蔽操作系统环境，提供一个完整的Java运行环境。  \n\n我们可以通过java.exe或者javaw.exe来启动一个虚拟机实例。只要启动了几个java应用，相对应地也启动了几个java虚拟机实例。\n\n### 原理\n- JVM是Java的核心和基础，在Java编译器和os平台之间的虚拟处理器，可在上面执行字节码程序。\n- Java编译器只面向JVM，生成JVM能理解的字节码文件。Java源文件经编译成字节码程序，通过JVM将每条指令翻译成不同的机器码，通过特定平台运行。\n![JVM原理](JVM-内存模型结构/JVM原理.png)  \n\n### 生命周期\n1、 JVM实例对应了一个独立运行的Java程序，它是进程级别的。 \n> - **启动：**启动一个Java程序时，一个JVM实例就产生了，任何一个拥有public static void \nmain(String[] args)函数的class都可以作为JVM实例运行的起点。\n> - **运行：**main()作为该程序初始线程的起点，任何其他线程均由该线程启动。JVM内部有两种线程：**守护线程和非守护线程**。main()属于非守护线程，守护线程通常由JVM自己使用，Java程序也可以表明自己创建的线程是守护线程。 \n> - **消亡：**当程序中的所有非守护线程都终止时，JVM才退出；若安全管理器允许，程序也可以使用Runtime类或者System.exit()来退出。  \n\n2、JVM执行引擎实例则对应了属于用户运行程序的线程，它是线程级别的。  \n\n\n### 架构\nJVM架构图如下：\n![JVM体系](JVM-内存模型结构/JVM体系.png) \n\nJVM分为三个主要子系统：\n- 类加载器子系统（Class Loader Subsystem）\n- 运行时数据区（Runtime Data Area）\n- 执行引擎（Execution Engine）  \n\n#### 类加载器子系统\nJava的动态类加载功能由类加载器子系统处理，处理过程包括加载和链接，并在类文件运行时，首次引用类时就开始实例化类文件，而不是在编译时进行。\n##### 加载  \n**Bootstrap类加载器**、**Extension类加载器**和**Application类加载器**是实现类加载过程的三个类加载器。\n> - **Bootstrap类加载器：**负责从引导类路径加载类，除了rt.jar，它具有最高优先级\n> - **Extension类加载器：**负责加载ext文件夹（jre\\lib）中的类\n> - **Application类加载器：**负责加载应用程序级类路径、环境变量中指定的路径等信息  \n上面的类加载器在加载类文件时遵循委托层次算法\n##### 链接  \n> - **验证（Verify）：** 字节码验证器将验证生成的字节码是否正确，如果验证失败，将提示验证错误\n> - **准备（Prepare）：**对所有静态变量，内存将会以默认值进行分配\n> - **解释（Resolve）：**有符号存储器的引用都将被替换为来自方法区（Method Area）的原始引用\n##### 初始化\n这是类加载的最后阶段，所有的静态变量都将被赋予原始值，并且静态区块将被执行。  \n\n#### 运行时数据区\n运行时数据区可分为5个主要组件：方法区、堆、虚拟机栈、本地方法栈、程序计数器。各个组件的详细内容会在后面讲到。\n\n#### 执行引擎\n分配给运行时数据区的字节码将由执行引擎执行，执行引擎读取字节码并逐个执行。  \n> - **解释器：**解释器可以更快地解释字节码，但执行缓慢。解释器的缺点是当一个方法被调用多次时，每次都需要一个新的解释。\n> - **JIT编译器：**JIT编译器消除了解释器的缺点。执行引擎将在转换字节码时使用解释器的帮助，但是当它发现重复代码时，将使用JIT编译器编译整个字节码并将其更改为本地代码。这个本地代码将直接用于重复的方法调用，这提高了系统的性能。  \n**JIT的构成组件有：**\n &ensp;&ensp;&ensp;&ensp; **1、中间代码生成器（Intermediate Code Generator）：**生成中间代码 \n &ensp;&ensp;&ensp;&ensp; **2、代码优化器（Code Optimizer）：**负责优化上面生成的中间代码 \n &ensp;&ensp;&ensp;&ensp; **3、目标代码生成器（Target Code Generator）：**负责生成机器代码或本地代码\n &ensp;&ensp;&ensp;&ensp; **4、分析器（Profiler）：**一个特殊组件，负责查找热点，即该方法是否被多次调用\n> - **垃圾收集器：**收集和删除未引用的对象。\n\n#### 本地库接口（JNI）\nJNI将与本机方法库进行交互，并提供执行引擎所需的本机库。\n\n#### 本地方法库（Native Method Libraries）\n它是执行引擎所需的本机库的集合。\n\n### 执行程序过程\n\n当一个程序启动之前，它的class文件会被类加载器装入方法区（包括类信息、静态变量），执行引擎读取方法区的字节码自适应解析运行。执行引擎可以通过解释器和JIT编译器把字节码转换成可以直接被JVM执行的语言。然后pc寄存器指向了main函数所在位置，虚拟机开始为main函数在java栈中预留一个栈帧（每个方法都对应一个栈帧），然后开始执行main函数，main函数里的代码被执行引擎映射成本地操作系统里相应的实现，然后调用本地方法接口，本地方法运行的时候，操纵系统会为本地方法分配本地方法栈，用来储存一些临时变量，然后运行本地方法，调用操作系统API等等。  \n\n\n## 内存结构划分\nJava程序在运行时，需要在内存中的分配空间。为了提高运算效率，就需要对数据进行了不同空间的划分，因为每一片区域都有特定的处理数据方式和内存管理方式。  \n\nJVM内存结构指的是JVM架构中的运行时数据区，整个JVM内存结构图如下表示：\n![内存模型结构](JVM-内存模型结构/内存模型结构.png)\n### 各结构的作用\n\n#### 程序计数器\n程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。\n\n由于Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为**“线程私有”**的内存。\n\n如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie 方法，这个计数器值则为空（Undefined）。由于程序计数器中存储的数据所占空间的大小不会随程序的执行而发生改变，**此内存区域是唯一一个在Java 虚拟机规范中没有规定任何OutOfMemoryError 情况的区域**。\n\n#### 虚拟机栈\n虚拟机栈（VM Stack）也是**线程私有**的。每个线程在创建的时候都会创建一个虚拟机栈，其生命周期与线程一致，线程退出时，线程的虚拟机栈也会被回收。线程执行的基本行为是函数调用，每次函数调用的数据都是通过虚拟机栈传递的。 虚拟机栈内部保持一个个的栈帧，**每个栈帧用于存储局部变量表、操作数栈、动态链接（当前方法所属的类的运行时常量池的引用）、方法返回地址**。每次方法调用都会进行压栈，JVM对栈帧的操作只有出栈和压栈两种。当函数返回时，栈帧从Java栈中被弹出。\n> Java方法区有两种返回函数的方式，一种是正常的函数返回，使用return指令，另一种是抛出异常。不管使用哪种方式，都会导致栈帧被弹出。 \n\n**局部变量表用于保存函数的参数以及局部变量，即方法运行期间所需要的数据**。局部变量表中的变量只在当前函数调用中有效，当函数调用结束，随着函数栈帧的弹出销毁，局部变量表也会随之销毁。局部变量表可保存有编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress 类型（指向了一条字节码指令的地址）。其中64 位长度的long 和double 类型的数据会占用2 个局部变量空间（Slot），其余的数据类型只占用1 个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。  \n\n由于局部变量表在栈帧之中，因此，如果函数的参数和局部变量很多，会使得局部变量表膨胀，从而每一次函数调用就会占用更多的栈空间，最终导致函数的嵌套调用次数减少。在相同的栈容量下，局部变量少的函数可以支持更深的函数调用。通过jclasslib工具可以查看函数的局部变量表。局部变量表中的变量也是垃圾回收根节点，只要被局部变量表中直接或者间接引用的对象都是不会被回收的。  \n\n操作数栈用于计算时，临时数据的存储区域。操作数栈的长度由编译期间确定，操作数栈初始时为空，每一个操作数栈的成员(Entry)可以保存JVM定义的任意数据类型的值。long和double占用2个栈深单位，其它数据类型占用一个栈深单位。可以通过入栈和出栈来访问操作数栈。其访问过程如下图：\n![操作数栈](JVM-内存模型结构/操作数栈.png)  \n上述表示两个数100和98相加的过程。\n\n```java\npublic class LocalvarGC {\n　　public void localvarGc1(){\n　　　　byte[] a = new byte[6*1024*1024];//6M\n　　　　System.gc();\n　　}\n　\n　　public void localvarGc2(){\n　　　　localvarGc1();\n　　　　System.gc();\n　　} \n}\n```\n\n在localvarGc1()中，在申请空间后，立即进行垃圾回收，很明显由于byte数组被变量a引用，因此无法回收这块空间。\n\n对于localvarGc2()，它首先调用了localvarGc1()，很明显，在localvarGc1()中并没有释放byte数组，但在localvarGc1()返回后，它的栈帧被销毁，自然也包含了栈帧中的所有局部变量，故byte数组失去了引用，在localvarGc5()的垃圾回收中被回收。\n\n在Java 虚拟机规范中，对虚拟机栈规定了两种异常状况：\n> - 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；\n> - 如果虚拟机栈可以动态扩展（当前大部分的Java 虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的\n虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError 异常。  \n\n#### 本地方法栈\n本地方法栈（Native Method Stacks）是**线程私有**的区域，与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java 方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError 和OutOfMemoryError异常。\n\n#### 方法区\n方法区(Method Area)与堆一样，是**所有的线程共享的**，存储被虚拟机加载的元数据(Meta)，包括**类信息、常量、静态变量、即时编译器(JIT)编译后的代码**等数据。Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择规定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域很少出现，**这个区域垃圾回收的主要目标是针对常量池的回收和类型的卸载**。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError:PermGen space异常。由于早期HotSpot JVM的实现，将GC分代收集拓展到方法区，因此很多人将*方法区称为永久代*。\n\n\n#### 运行时常量池\n运行时常量池（Run-Time Constant Pool)，这是方法区的一部分，受到方法区内存的限制，当常量池无法再申请到内存时，会抛出OutOfMemoryError:PermGen space异常。在class文件中，除了有类的版本、方法、字段、接口等描述信息外，还有一项描述信息是常量池。每个class文件的头四字节称为Magic Number，它的作用是确定这是否是一个可以被虚拟机接受的文件，接着的四个字节存储的是class文件的版本号。在版本号后面的就是常量池入口了。常量池主要存放两大类常量：  \n> - 字面量(Literal)，如文本字符串、final常量值\n> - 符号引用，存放了与编译相关的一些常量，因为Java不像C++那样有连接的过程，因此字段方法这些符号引用在运行期就需要进行转换，以便得到真正的内存入口地址  \n\nclass文件中的常量池，也称为静态常量池，JVM虚拟机完成类装载操作后，会把静态常量池加载到内存中，存放在运行时常量池。运行时常量池相对于class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只能在编译期产生，也就是并非预置入class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern() 方法。 \n\n#### 堆\nJava 堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建，并且是**完全自动化管理**的。Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。如果在堆中没有内存完成对象实例的分配，并且堆无法再扩展时，将抛出OutOfMemoryError异常，抛出的错误信息是“Java.lang.OutOfMemoryError:Java heap space”。可以通过-Xmx和-Xms来控制堆内存的大小，发生堆上OOM的可能是存在内存泄露，也可能是堆大小分配不合理。  \n\n从内存回收的角度看，由于现在垃圾收集器基本都是采用的分代收集算法，所以Java 堆中还可以细分为：新生代和老年代；再细致一点新生代可以分为Eden 空间、From Survivor 空间、To Survivor 空间等。如果从内存分配的角度看，线程共享的Java 堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB）。\n![堆内存](JVM-内存模型结构/堆内存.png)\n\n##### 新生代Eden空间\n在新生代的Eden空间，对象会优先分配在该空间，同时JVM可以为每个线程分配一个私有的缓存区域，称为TLAB（Thread Local Allocation Buffer），避免多线程同时分内存时需要使用加锁等机制而影响分配速度。**TLAB在堆的Eden空间上工作**，内存中Eden的结构大体为：\n\n![TLAB](JVM-内存模型结构/TLAB.png) \n\nTLAB的管理主要是依靠三个指针：**start、end、top**。start与end标记了Eden中被该TLAB管理的区域空间，该区域空间不会被其他线程分配内存所使用。top是指分配指针，开始时指向start的位置，随着内存分配的进行，慢慢向end靠近，当到达end位置时触发TLAB refill。TLAB缺省情况下仅占有整个Eden空间的1%，当然可以通过选项-XX:TLABWasteTargetPercent设置TLAB空间所占用Eden空间的百分比大小。  \n\n##### 新生代Survivor空间\n当Eden空间足够大时，大部分新建对象会被分配在Eden区，有些大对象会被直接分配在老年代空间。  \n当Eden空间不足时，会发生一次Minor GC，未被引用的对象会被回收，Eden中仍存活的对象会被移动到From Survivor（*避免直接进入老年代导致过早触发Full GC*）。Survivor中的对象每经过一次Minor GC，对象的age会加1，默认age超过15依然存活的对象会被移入老年代空间。  \n当发生Minor GC时，如果Survivor空间不足以保存Eden区中存活的对象，那么该对象会被直接移入老年代；如果Survivor中同age的对象占用空间的总和达到或超过其中一个Survivor的一半，那么所有同age对象都会被移入老年代。  \n通常情况下，只有其中一个Survivor空间是存在对象的，另一个Survivor是空的。当再次发生GC时，Eden中的对象被复制到标记为To的空的Surivivor中，原来From中依然存活的未到达年龄的对象也会复制到To，此时To被标记为From，原来的From置空并被标记为To，轮换是为了避免Surivivor中因没有连续空间（*避免内存碎片的产生*）而导致对象被直接移入老年代。\n\n![survivor](JVM-内存模型结构/survivor.png)\n##### 老年代\n老年代用于存放生命周期长的对象，通常是从Survivor空间移入过来的对象。当对象过大时，无法在新生代用连续内存分配，那么这个大对象会直接分配在老年代上。一般来说，普通的对象都是分配在TLAB上，较大的对象，直接分配在Eden区上的其他内存区域，而过大的对象，直接分配在老年代上。当老年代被占用的空间达到一定比例就会触发Full GC。\n\n##### 永久代\n永久代是HotSpot的概念，方法区是Java虚拟机规范中的定义，是一种规范。HotSpot虚拟机把GC分代收集扩展至方法区，使用永久代来实现方法区，进而实现对方法区内存的回收。永久代存放着类信息、常量、静态变量、JIT编译后的代码，其物理上是堆的一部分。可以通过-XX:PermSize、-XX:MaxPermSize来控制方法区初始大小和最大大小，\n超过这个值将会抛出OutOfMemoryError: PermGen异常。\n> 由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在 jsp 页面比较多的情况，容易出现永久代内存溢出。\n\n##### Vritual空间\n当使用Xms与Xmx来指定堆的最小与最大空间时，如果Xms小于Xmx，堆的大小不会直接扩展到上限，而是留着一部分等待内存需求不断增长时，再分配给新生代。Vritual空间便是这部分保留的内存区域。\n\n#### 直接内存\n直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常。\n\nJava中的NIO类可以使用Native函数库，直接分配堆外内存，然后通过一个存储在Java堆里面的DirectoryByteBuffer对象作为这块内存的引用进行操作，这样能避免在Java堆和Native堆中来回复制数据，在一些场景中显著提高性能。通常访问直接内存的速度会优于Java堆。因此出于性能的考虑，读写频繁的场合可能会考虑使用直接内存。\n\n从上面可以知道，本机直接内存的分配不会受到Java堆大小的限制。但还是会受到本机总内存（RAM及SWAP区或者分页文件）的大小及处理器寻址空间的限制。在配置虚拟机参数时，一般会根据实际内存设置-Xmx等参数信息，但会经常忽略直接内存，使得各个内存区域的总和大于物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常。  \n![JVM内存溢出汇总](JVM-内存模型结构/JVM内存溢出汇总.png)\n\n### 对象创建过程\n\n最普通的对象创建会涉及到**Java堆、虚拟机栈、方法区**。假设在某个方法中创建一个对象，`Object obj = new Object()`。那`Object obj`这部分予以将会反映到虚拟机栈的本地变量表中，作为一个reference类型数据出现。而`new Object()`这部分语义将会反映到Java堆中，形成**一块存储了Object类型所有实例数据值（Instance Data，对象中各个实例字段的数据）的结构化内存**，根据具体类型以及虚拟机实现的对象内存布局（Object Memory Layout）的不同，这块内存的长度不是固定的。而对象的类型数据，如对象类型、父类、实现的接口、方法等，则存储在方法区中。这些类型的地址信息则存储能查到对象类型数据的地址信息。  \n\n由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过哪种方式去定位，以及访问Java堆中的对象具体位置。现主流的访问方式有两种：**使用句柄和直接指针**。\n\n#### 句柄访问方式\nJava堆中将会划分出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。  \n![句柄访问](JVM-内存模型结构/JVM句柄访问.png)  \n#### 直接指针访问方式 \nJava 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，reference中直接存储的就是对象地址。  \n![句柄访问](JVM-内存模型结构/JVM直接指针访问.png) \n\n#### 区别\n- 使用句柄访问方式的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（如垃圾回收）时，只会改变句柄中的实例数据指针，而reference本身不需要修改。   \n- 使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销。  \n\n\n### 内存溢出代码示例\n\n#### Java堆溢出\n控制参数：-verbose:gc -Xms20M -Xmx20M -XX:+PrintGCDetails\n```java\npublic class HeapOutOfMemory {\n    public static void main(String[] args) {\n     \n\n       while(true){\n           new TestCase();\n       }\n    }\n}\nclass TestCase{\n}\n```\n\n通过参数`-XX:+HeapDumpOnOutOfMemoryError`可以让虚拟机在出现内存溢出异常时Dump出当前的内存堆情况快照。通过快照分析确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）。如果是内存泄漏，可以查看泄漏对象到GC Roots的引用链，找出导致垃圾收集器无法自动回收的原因。如果不存在泄漏，就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（-Xmx 与-Xms）。\n#### 虚拟机栈溢出(栈层级不足) \n控制参数:-Xss128k\n```java\npublic class StackOverFlow {\n    private int i ;\n\n    public void plus() {\n       i++;\n       plus();\n    }\n\n    public static void main(String[] args) {\n       StackOverFlow stackOverFlow = new StackOverFlow();\n       try {\n           stackOverFlow.plus();\n       } catch (Exception e) {\n           System.out.println(\"Exception:stack length:\"+stackOverFlow.i);\n           e.printStackTrace();\n       } catch (Error e) {\n           System.out.println(\"Error:stack length:\"+stackOverFlow.i);\n           e.printStackTrace();\n       }\n    }\n}\n```\n\n#### 常量池溢出 \n控制参数： -XX:PermSize=10M -XX:MaxPermSize=10M\n```java\npublic class ConstantOutOfMemory {\n    public static void main(String[] args) throws Exception {\n       try {\n\n           List<String> strings = new ArrayList<String>();\n           int i = 0;\n           while(true){\n              strings.add(String.valueOf(i++).intern());\n\n           }\n       } catch (Exception e) {\n           e.printStackTrace();\n           throw e;\n       }\n    }\n}\n```\n\n#### 方法区溢出 \n控制参数： -XX:PermSize=10M -XX:MaxPermSize=10M\n```java\npublic class MethodAreaOutOfMemory {\n    public static void main(String[] args) {\n\n       while(true){\n\n           Enhancer enhancer = new Enhancer();\n\n           enhancer.setSuperclass(TestCase.class);\n\n           enhancer.setUseCache(false);\n\n           enhancer.setCallback(new MethodInterceptor() {\n\n              @Override\n\n              public Object intercept(Object arg0, Method arg1, Object[] arg2,\n\n                     MethodProxy arg3) throws Throwable {\n\n                  return arg3.invokeSuper(arg0, arg2);\n\n              }\n\n           });\n\n           enhancer.create();\n       }\n    }\n}\n\nclass TestCase{\n\n}\n```\n\n#### 直接内存溢出\n控制参数：-Xmx20M -XX:MaxDirectMemorySize=10M\n```java\npublic class DirectoryMemoryOutOfmemory {\n\n    private static final int ONE_MB = 1024*1024;\n\n    private static int count = 1;\n    public static void main(String[] args) {\n\n       try {\n\n           Field field = Unsafe.class.getDeclaredField(\"theUnsafe\");\n\n           field.setAccessible(true);\n\n           Unsafe unsafe = (Unsafe) field.get(null);\n\n           while (true) {\n\n              unsafe.allocateMemory(ONE_MB);\n\n              count++;\n\n           }\n       } catch (Exception e) {\n\n           System.out.println(\"Exception:instance created \"+count);\n\n           e.printStackTrace();\n\n       } catch (Error e) {\n\n           System.out.println(\"Error:instance created \"+count);\n           e.printStackTrace();\n       }\n    }\n}\n```\n\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"JVM-G1和CMS的区别","url":"/2018/09/19/JVM-G1和CMS的区别/","content":"\n## 堆(Heap)空间分配不同\n&ensp;&ensp;&ensp;&ensp;CMS 将堆逻辑上分成**[Eden，Survivor(S0，S1)，Old]**，并且他们是固定大小JVM启动的时候就已经设定不能改变，并且是连续的内存块。\nG1 将堆分成多个大小相同的Region(区域)，默认2048个，在1Mb到32Mb之间大小，逻辑上分成**[Eden，Survivor，Old，巨型，空闲]**，他们不是固定大小，会根据每次GC的信息做出调整。\n## 并发标记阶段三色标记算法处理结果不同\n&ensp;&ensp;&ensp;&ensp;CMS 在三色标记算法阶段，如果将白色对象重新分配给黑色对象时，在分配期间采用增量更新方式(写屏障中发现白色对象引用被分配给黑色对象时，分配过程中将白色重新设置为灰色，即插入的时候就记录修改)。\nG1 在三色标记算法阶段，如果将白色对象重新分配给黑色对象时，采用SATB，并发标记阶段，所有被改变的对象入队，在写屏障中统一处理为灰色。\n## 压缩策略不同\n&ensp;&ensp;&ensp;&ensp;CMS中不启用压缩会产生很多内存碎片，当产生很多内存碎片的时候，找不到空间来分配剩余的对象，或者设定参数，使它合并相邻的的空闲内存，当合并超过一定次数后触发Full GC，进行压缩。\nG1中每次回收过程中，将多个Region拷贝到空闲Region的时候都会进行压缩。\n## 可预测停顿\n&ensp;&ensp;&ensp;&ensp;相比CMS，G1可以设定每次GC的时间，从而让GC在规定时间内回收效益最大的内存。\n## GC策略不同\n&ensp;&ensp;&ensp;&ensp;CMS中，GC的策略分为：Young GC，Old GC，Full GC\n&ensp;&ensp;&ensp;&ensp;G1中，GC的策略分为：Young GC，Mixed GC，Full GC\n## Young GC不同\n&ensp;&ensp;&ensp;&ensp;CMS的Young GC就是依赖并行GC(ParNew)去完成的，需要STW。而只有老年代中使用CMS GC(也就是Old GC)。\n\n## 最终标记（final marking，在实现中也叫remarking）不同\n&ensp;&ensp;&ensp;&ensp;在完成并发标记后，每个Java线程还会有一些剩下的SATB write barrier记录的引用尚未处理。这个阶段就负责把剩下的引用处理完。同时这个阶段也进行弱引用处理（reference processing）。\n注意这个暂停与CMS的remark有一个本质上的区别，那就是这个暂停只需要扫描SATB buffer，而CMS的remark需要重新扫描mod-union table里的dirty card外加整个根集合，而此时整个young gen（不管对象死活）都会被当作根集合的一部分，因而CMS remark有可能会非常慢。\n&ensp;&ensp;&ensp;&ensp;CMS的incremental update设计使得它在remark阶段必须重新扫描所有线程栈和整个young gen作为root；G1的SATB设计在remark阶段则只需要扫描剩下的satb_mark_queue。\n\n**CMS Young GC大致过程**:\n&ensp;&ensp;&ensp;&ensp;年轻代分成了Eden，Survivor(S0，S1)，当Eden区域满了就触发Young GC，将Eden中存活的数据复制到S0或者S1中的一个中去。如果对象太大，Survivor中无法分配就直接存到Old去，然后回收垃圾的数据。这时Eden被清空了，Survivor其中一个被填了数据。等到Eden再次满了，就会再次存入之前的Survivor中去。如果Survivor也满了，就会将将Eden和Survivor中存活的对象复制到另外一个Survivor区域中，每次GC一次依然存活的对象的age都+1，默认当age=15的时候(经历了多次Young GC)那么就会晋升到Old去，然后清空Eden和Survivor。\n\n**G1 Young GC大致过程**:  \n&ensp;&ensp;&ensp;&ensp;G1 Young GC是自己去清理的，而不是并行GC处理。Eden区域数据满了，将Eden区域中存活的复制到Survivor中去，其中符合条件的晋升。如果Survivor空间不够，那么将Survivor和Eden中存活的数据一起复制到一个新的区域中去，这时这个新的区域就是Survivor，然后回收掉之前的Eden和Survivor。每次Young GC之后，根据之前一次GC的信息调整Eden和Survivor的大小，因为G1中这两个区域并不是物理上连续的内存，而只是逻辑上的，因此可以动态分配。\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"JVM-G1垃圾收集器","url":"/2018/09/19/JVM-G1垃圾收集器/","content":"\n## 简介\n### 概念\n&ensp;&ensp;&ensp;&ensp;全称`Garbage First`，垃圾优先收集器，是jdk1.9的默认垃圾收集器。G1的设计初衷是为用户提供**大内存**、**低GC停顿时间**的应用解决方案。G1会跟踪各个Region里面的垃圾堆积的价值大小(回收所获得的空间大小以及回收所需要的时间经验值)，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。\n\n&ensp;&ensp;&ensp;&ensp;**G1的设计目标：**\n> - 像CMS那样做到并发GC，提高GC并行和并发表现  \n> - 没有内存碎片问题，内存整理过程不需要延长GC时间，不需要STW  \n> - 可预测的GC停顿时间  \n> - 更高的吞吐量  \n> - 在不增加堆内存大小下更好地利用堆内存\n> - 尽量缩短处理超大堆（6-8GB）时产生的停顿\n\n\n&ensp;&ensp;&ensp;&ensp;**与CMS区别，G1优点包括：**\n\n> - G1是内存整理虚拟机，G1通过对堆内存划分区域（region）分区管理避免使用细粒度空闲列表来实现高效内存整理\n> - G1提供比CMS更加可预测的GC停顿时间，并允许用户设定停顿时间目标\n\n&ensp;&ensp;&ensp;&ensp;但是，G1为了垃圾收集产生的内存占用以及程序运行时的额外执行负载都比CMS要高。\n&ensp;&ensp;&ensp;&ensp;在HotSpot垃圾收集器里，除G1以外，其他的垃圾收集器使用内置的JVM线程执行GC的多线程操作；而G1 GC可以采用用户线程承担后台运行的GC工作，即当JVM的GC线程处理速度慢时，系统会调用用户线程帮忙加速垃圾回收过程。\n\n&ensp;&ensp;&ensp;&ensp;**推荐使用场景：**\n> - FullGC发生频繁或总时间过长\n> - 对象分配率或对象升级至老年代的比例波动较大\n> - 较长的垃圾收集或内存整理停顿（大于0.5至1秒）\n\n&ensp;&ensp;&ensp;&ensp;G1在回收的时候将对象从一个小堆区复制到另一个小堆区，这意味着G1在回收垃圾的时候同时完成了堆的部分内存压缩，相对于CMS的优势而言就是内存碎片的产生率大大降低。heap被划分为一系列**大小相等**的“小堆区”，也称为**region**。每个小堆区region的大小为**1-32MB**，数值必须是**2的幂**，所以Region的大小只能是1M、2M、4M、8M、16M或32M。整个堆默认划分为2048个小堆区，比如堆内存为16g，G1就会采用16G / 2048 = 8M 的Region。  \n\n&ensp;&ensp;&ensp;&ensp;G1在逻辑上同样会将堆划分出**Eden、Survivor和Old**，只是**Eden、Survivor和Old**空间对应的小堆区的**个数不是固定的，各代小堆区存储地址是不连续的**。此外heap堆还存在着一些未被使用的空间，这些空间同样也会被进行划分。**Eden、Survivor和Old**空间大小不再是固定的，每个代分区的数量是可以动态调整的。\n![堆分布图](堆分布图.png)\n图中的H代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj）。  \n\n### 大对象分配\n&ensp;&ensp;&ensp;&ensp;如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。为此，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。\n\n> - 对象的大小<0.5个RegionSize直接存在新生代Eden Region区\n> - 对象的大小>=0.5个RegionSize且对象的大小<1个RegionSize,存到大对象区Humongous Region\n> - 对象的大小>=1个RegionSize存到连续的大对象区Humongous Region\n\n### 数据结构\n\n&ensp;&ensp;&ensp;&ensp;G1垃圾收集器占用内存会比CMS大，增大的部分主要与*accouting*数据结构有关，如`Remembered Set(RSet)`、`Card Table`和`Collection Set(CSet)`。\n\n![RSet](RSet.png)\n\n#### RSet\n&ensp;&ensp;&ensp;&ensp;**Remembered Set**： 每个Region都包含一个RSet，RSet记录的是其他Region中的对象引用本Region对象的关系，用来记录**不同代之间的引用关系**，主要是老年代到新生代之间的引用的一个集合，至于新生代之间的引用记录会在每次GC时被扫描，所以不用记录新生代到新生代之间的引用。每个Region对应一个RSet，RSet对整体内存占用的影响少于5%。**RSet是一个空间换时间的数据结构，有了RSet可以避免对整个堆进行扫描**。\n\n&ensp;&ensp;&ensp;&ensp;在CMS中，也有RSet的概念，在老年代中有一块区域用来记录指向新生代的引用，即我引用了谁的对象。这是一种point-out，在进行Young GC时，扫描根时，仅仅需要扫描这一块区域，而不需要扫描整个老年代。\n&ensp;&ensp;&ensp;&ensp;但在G1中，并没有使用point-out，这是由于一个Region太小，Region数量太多，如果是用point-out的话，会造成大量的扫描浪费，有些根本不需要GC的Region引用也扫描了。于是G1中使用point-in来解决。point-in的意思是哪些Region引用了当前Region中的对象。这样，仅仅**将这些对象当做根来扫描就避免了无效的扫描**。\n\n&ensp;&ensp;&ensp;&ensp;比如a=b（a引用b），若采用point out结构，则在a的RSet中记录b的地址；若采用point in结构，则在b的RSet中记录a的地址。G1的RSet采用的是point in结构，即谁引用了我；Card Table采用的是point out结构。\n\n&ensp;&ensp;&ensp;&ensp;RSet其实是一个 hash table，key是别的Region的起始地址，value是一个集合，里面的元素是 card table的 Index。举例来说，如果region A的Rset里有一项的key是 region B，value里有 index为1234的card，它的意思就是 region B的一个card里有引用指向region A。所以对 region A来说该RSet记录的是 points-in的关系，而 card table仍然记录了 points-out的关系。\n\n&ensp;&ensp;&ensp;&ensp;由于新生代有多个，那么我们需要在新生代之间记录引用吗？这是不必要的，原因在于每次GC时，所有新生代都会被扫描，所以只需要记录**老年代到新生代之间的引用**即可。\n\n##### GC为什么需要记录跨代的引用\n&ensp;&ensp;&ensp;&ensp;Young GC只会回收年轻代，Old GC只会回收老年代，无论是哪一种GC都会面临跨代引用的情况，比如老年代对象引用新生代或者新生代对象引用老年代。\n&ensp;&ensp;&ensp;&ensp;Young GC在回收年轻代时，需要判断年轻代的对象是否存活，而年轻代的部分对象可能被老年代的对象引用，因此必须扫描老年代才不会发生误判年轻代的对象为垃圾；同理，在回收老年代时，也需要扫描年轻代。\n&ensp;&ensp;&ensp;&ensp;那么无论是只回收新生代还是老年代，都需要扫描其他代的对象，相当于进行全堆扫描，效率很低。那么将代际之间的引用关系记录在一个单独的地方，只需要扫描这个地方即可，避免全堆扫描。  \n\n##### RSet带来的问题\n> - RSet需要额外的内存空间来存储这些引用关系，一般是JVM最大的额外开销的1%-20%之间；\n> - RSet中的对象可能已经死亡，那么这个时候引用的对象会被认为活跃对象，实际上它是浮动垃圾；\n> - RSet是通过写屏障来完成的，即在内存分配的地方，插入一段代码来执行RSet的更新，如果对象的创建/修改/回收比较频繁，那么写RSet的性能开销还是比较大的。因此一般不会记录年轻代到老年代的引用。\n\n##### G1-RSet记录 \n主要分析哪些引用的关系需要记录在RSet中；\n\n> - 分区内部的引用\n\n无论是新生代还是老年代的分区内部的引用，都不需要记录引用关系。因为是针对一个分区进行的垃圾回收，要么这个分区被回收，要么不被回收。\n\n> - 新生代引用新生代\n\nG1的三种回收算法（YGC/MIXED GC/FULL GC）都会全量处理新生代分区，所以新生代都会被遍历到。因此无需记录这种引用关系。\n\n> - 新生代引用老年代\n\n无需记录。G1的YGC回收新生代，无需这个引用关系。\n**混合GC时，G1会采用新生代分区作为根**，那么在遍历新生代分区时就能找到老年代分区了，无需这个引用关系。\nFGC时，所有分区都会被处理，也无需这个引用关系。\n\n> - 老年代引用新生代\n\n**需要记录**。YGC在回收新生代时，如果新生代的对象被老年代引用，那么需要标记为存活对象。即此时的根对象有两种，一个是栈空间/全局变量的引用，一个是老年代到新生代的引用。\n\n> - 老年代引用老年代\n\n**需要记录**。混合GC时，只会回收部分老年代，被回收的老年代需要正确的标记哪些对象存活。\n\n##### RSet的更新\nG1中采用post-write barrier和concurrent refinement threads实现了RSet的更新。\n\nG1的RSet的更新是通过写屏障完成的，在写变更时，通过插入一条额外的代码把引用关系放入到DCQ（dirty card queue）队列中，随后refinement线程取出DCQ队列的引用关系，更新RSet。比如，每一次将一个老年代对象的引用修改为指向新生代对象时，都会被写屏障捕获，并且记录下来。\n\n\n对于一个写屏障来时，过滤掉不必要的写操作是十分必要的，G1进行以下过滤：\n> - 不记录新生代到新生代的引用 或者 新生代到老年代的引用\n> - 过滤一个分区内部的引用\n> - 过滤空引用\n\n##### RSet的问题\n我们得知应用线程只负责把更新字段所在的Card插入到dirty card queue中，然后由后台线程refinement threads负责RSet的更新操作，如果应用线程插入速度过快，refinement threads来不及处理，那么应用线程将接管RSet更新的任务，这是必须要避免的。\nrefinement threads线程数量可以通过`-XX:G1ConcRefinementThreads`或`-XX:ParallelGCThreads`参数设置\n\n#### Card Table\n**Card Table**：Card Table（全局卡表）是一个位图，全局只有一个，每个Region又被分成了若干个大小为512字节的Card，这些Card都会记录在全局卡表中。\nCard中的每个元素对应着其标识的内存区域中一块特定大小的内存块，这个内存块被称为卡页。一个卡页的内存中通常不止一个对象，只有要卡页中有一个及以上对象的字段存在着**跨Region引用（老年代之间跨Region、老年代到年轻代之间跨Region）**，这个对应的元素的值就标识为1。\n\n比如G1默认的Region有2048个，默认每个Region为2M，那每个Region对应的Card的每个元素对应的卡页的大小为2M / 512=4K，即这4K内存中只要有一个或一个以上的对象存在着跨Region对年轻代的引用，这个卡页对应的Card的元素值为1。\n\n![card](card.png)\n\n在Young GC时，只需要将脏的Region中的那个卡页加入GC Roots一并扫描即可。比起扫描老年代的所有对象，。\n在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old->young的跨代引用，避免了扫描整个old generation，大大减少了扫描的数据量，提升了效率。 而mixed gc的时候，old generation中记录了old->old的RSet，young->old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。\n\n\n\n**Collection Set**：CSet记录在一次GC中将被回收的区域集合。所有CSet区域中的存活对象都会被移动到新的区域中，这些区域可以是**Eden、Survivor和Old代的，并且可以同时包含这几代分区的内容**。CSet对JVM内存占用影响少于1%。\n\n\n\n\n\n### 停顿预测模型\n\n&ensp;&ensp;&ensp;&ensp;G1不是实时垃圾收集器，它会尽量让停顿时间低于用户设置的停顿时间目标但不能保证一定如此。G1根据历史垃圾收集监测数据来预测每个区域的回收时间，然后根据用户设定的目标停顿时间决定每次GC时可以回收哪些区域。G1通过这种方式建立比较精确的区域回收时间预测模型。\n\n## G1的两种GC模式\n&ensp;&ensp;&ensp;&ensp;G1提供了两种GC模式：**Young GC**和**Mixed GC**，两种都是**完全Stop The World**的。无论是Young GC还是Mixed GC都是**并发拷贝**的。  \n\n- **Young GC**：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。\n- **Mixed GC**：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。\nMixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满，无法继续进行Mixed GC，就会使用full GC来收集整个GC heap。\n\n&ensp;&ensp;&ensp;&ensp;G1的整体运行过程：会在Young GC和Mixed GC之间不断的切换运行，同时定期的做全局并发标记，在实在赶不上回收速度的情况下使用Full GC(Serial GC)。初始标记是搭在YoungGC上执行的，在进行全局并发标记的时候不会做Mix GC，在做Mixed GC的时候也不会启动初始标记阶段。当MixGC赶不上对象产生的速度的时候就退化成Full GC。\n\n### Young GC 模式\nYoung GC也可以被称为Minor GC。Young GC并不代表年轻代内存不足，它事实上只表示在Eden区上的GC，  \n\n**特性：** \n\n> - 会发生Stop The World事件\n> - GC线程可以并发执行\n\n**过程：**  \n\n![young gc](young gc.png)\n\n&ensp;&ensp;&ensp;&ensp;Eden空间存活的对象会被复制移动到另外一个或是多个Survivor小堆区，如果Survivor空间不够，Eden空间的部分对象会直接晋升到老年代空间。Survivor区的对象移动到新的Survivor区中，也有部分对象(达到年龄=15)晋升到老年代空间中。上述的整个过程会发生STW事件（*在STW过程会同时计算出Eden的大小和Survivor的大小，为下一次Young GC做准备。Accounting信息会被保存用于计算大小*），最终Eden空间的数据会被清空，GC停止工作，应用线程继续执行。  \n\n**总结：**\n\n> - 堆内存是一个单独的内存区域，被分为多个大小相同的区域\n> - 新生代内存由一系列不连续的区域组成，按需调整内存大小很简单\n> - 新生代垃圾回收（Young GC）需要STW，所有应用线程需要停顿\n> - Young GC多线程并行执行\n> - 存活对象复制到新的survivor区或老年代区\n> - 可以回收年轻代也可以是老年代区域\n\n### Mixed GC 模式\n\n#### 初始标记阶段（Initial Marking Phase）\n\n![Initial Marking](InitialMarking.png)\n\n&ensp;&ensp;&ensp;&ensp;新生代垃圾收集捎带着一次存活对象的初始标记。在GC日志中打印为`GCpause(young)(inital-mark)`。\n这个过程会发生STW事件。  \n\n#### 并发标记阶段（Concurrent Marking Phase）\n\n![Concurrent Marking](ConcurrentMarking.png)\n\n&ensp;&ensp;&ensp;&ensp;本阶段会与应用程序并发地查找存活的对象，如果找到了空的小堆区（图中标记为红叉的），他们会在*重新标记阶段*被马上清除。同时，计算各区域活跃度（回收优先级）的所需的信息在这个阶段统计。在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：对象丢失问题。\n\n#### 重新标记阶段（Remark Phase）\n\n![Remark](Remark.png)\n\n&ensp;&ensp;&ensp;&ensp;这一阶段空区域被回收，计算出所有区域活跃度。它会短暂地停止应用线程(**STW**)，停止并发更新日志的写入，处理其中的少量信息，并标记所有在并发标记开始时未被标记的存活对象。这一阶段也执行某些额外的清理，如引用处理或者类卸载。\n\n#### 复制/清除阶段（Copying/Cleanup Phase）\n\n![CopyingCleanup](CopyingCleanup2.png)\n\n &ensp;&ensp;&ensp;&ensp;**清除阶段**  \n\n> - 执行存活对象的accounting和完全释放空的小堆区（**STW**）\n> - 擦除RSets（**STW**）\n> - 重置空的小堆区并将他们归还给free list，也就是空闲表（Concurrent）  \n\n &ensp;&ensp;&ensp;&ensp;**复制阶段**  \n\n> - 本阶段在复制移动存活对象到新的未被使用的区域时，会有**STW停顿**。停顿时间的控制，是通过选择CSet的数量来达到控制时间长短的目标。在新生代小堆区完成时会被记录为 `[GC pause (young)]`，如果在新生代和老年代的小堆区一起执行时会被记录为`[GC Pause (mixed)]`\n\n![CopyingCleanup](CopyingCleanup1.png)  \n\n&ensp;&ensp;&ensp;&ensp;G1会优先选择活跃度最低的小堆区，因为这些区域会被最快地的回收。还有新生代和老年代都会在本阶段被回收。\n\n#### 复制/清除阶段后期（After Copying/Cleanup Phase）\n\n![After CopyingCleanup](AfterCopyingCleanup1.png)\n\n&ensp;&ensp;&ensp;&ensp;被选中区域的存活对象移动到新的区域中，原区域被回收加入空白列表。\n\n![After CopyingCleanup](AfterCopyingCleanup2.png)\n\n#### 总结（Old GC）\n\n&ensp;&ensp;&ensp;&ensp;**并发标记阶段**  \n\n> - 在应用程序运行时并发地计算活跃度信息\n> - 活跃度信息甄别出哪个小堆区是在撤离暂停时最适合回收的  \n\n&ensp;&ensp;&ensp;&ensp;**重新标记阶段**  \n\n> - 使用Snapshot-at-the-Beginning (SATB) 算法，这个算法比CMS所使用的要快得多\n> - 回收空的小堆区  \n\n&ensp;&ensp;&ensp;&ensp;**复制/清除阶段**  \n\n> - 新生代和老年代同时被回收\n> - 老年代的小堆区会根据活跃度而进行部分的选定，确定回收优先级\n\n## 使用方式\n\n- `-XX:+UseG1GC` 启用G1垃圾收集器\n- `-XX:G1HeapRegionSize=n`参数可以设置Region的大小  \n- `-XX:MaxGCPauseMillis=n`参数设置用户期待的应用程序暂停时间。暂停时间设置的太短，就会导致出现G1跟不上垃圾产生的速度，最终导致Full GC。一般情况下这个值设置到100-200，单位是ms。  \n- `-XX:InitiatingHeapOccupancyPercent=45` 设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%，达到这个阈值就会进行mixed gc\n- `-XX:ParallelGCThreads=n`设置 STW 工作线程数的值。将n的值设置为逻辑处理器的数量。**n 的值与逻辑处理器的数量相同，最多为 8**。如果逻辑处理器不止8个，则将 n 的值设置为逻辑处理器数的 5/8 左右\n\n- `-XX:ConcGCThreads=n`设置并行标记的线程数。将n设置为并行垃圾回收线程数(ParallelGCThreads) 的 1/4 左右。适当提高线程数，可尽可能避免转移失败。\n-`-XX:G1ReservePercent=n`为堆内存设置虚拟使用上限，预留一部分空间防止to-space情况出现，以降低失败的可能性，默认值是 10。\n\n开发人员仅仅需要声明以下参数即可：\n```java\n-XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis=200\n```\n**NOTE：**避免使用`-Xmn`选项或`-XX:NewRatio`等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。\n\n\n### 参考资料\n- [总结G1垃圾收集器面试题](https://segmentfault.com/a/1190000038430433)\n- [G1的RSet解读](https://blog.csdn.net/stone_yw/article/details/105982148)\n- [G1垃圾收集器之RSet](https://www.jianshu.com/p/870abddaba41)\n\n\n\n\n","tags":["JVM","G1"],"categories":["JVM"]},{"title":"JVM-CMS垃圾收集器","url":"/2018/09/18/JVM-CMS垃圾收集器/","content":"\n## 简介\n全称`Concurrent Mark Sweep`，以牺牲吞吐量为代价来获得最短停顿时间的垃圾收集器，适用于对**响应时间的侧重性大于吞吐量**的场景。CMS仅针对老年代（Old Generation）的回收，减少full gc发生的几率。默认情况下在老年代使用了68%及以上的内存的时候就开始进行CMS。并发标记和并发清除阶段的GC线程是和用户线程并发执行，默认GC线程数为物理CPU核心数的1/4。在使用CMS垃圾收集器的情况下，对于年轻代的回收，是用并行垃圾收集器(ParNew GC)去完成的。\n\n## 工作周期\n### 初始标记(Initial Mark)\n这个过程会暂停所有的应用程序线程，只运行GC线程，因此会**发生STW（stop the world）**事件。  \n\n整个过程需要标记的对象有：\n- 老年代中所有的`GC Roots`所指的直接对象\n- 被活着年轻代中的对象引用老年代的对象（引用的对象指老年代中的对象）  \n![Initial Mark](initial mark.png)  \n\n因为标记的对象比较少，所以**暂停时间会比较短**。\n\n### 并发标记(Concurrent Mark) \n在初始标记阶段中所标记的节点往下检索,标记出所有老年代中存活的对象。该过程会**和应用程序线程并发地执行，不会发生停顿**。注意此时会有部分对象的引用被改变。\n![Concurrent Mark](concurrent mark.png)\n\n### 并发预清理(Concurrent Preclean)\n也是一个并发阶段，**会和应用程序线程并发地执行**。前一个阶段在并行运行的时候，一些对象的引用已经发生了变化，当这些引用发生变化的时候，JVM会标记堆的这个区域为`Dirty Card`(包含被标记但是改变了的对象，被认为\"dirty\")，这就是 `Card Marking`。\n![Concurrent Mark1](concurrent preclean1.png)  \n在`pre-clean`阶段，那些能够从`dirty card`对象到达的对象也会被标记，这个标记做完之后，`dirty card`标记就会被清除了\n![Concurrent Mark2](concurrent preclean2.png)\n\n### 可中止的并发预清理（Concurrent Abortable Preclean）\n又一个并发阶段不会停止应用程序线程。这个阶段尝试着去承担STW的Final Remark阶段足够多的工作。这个阶段持续的时间依赖好多的因素，由于这个阶段是重复的做相同的事情直到发生aboart的条件（比如：重复的次数、多少量的工作、持续的时间等等）之一才会停止。\n\n### 重新标记(Final Remark) \n这个阶段是**CMS中第二个并且是最后一个STW的阶段**。该阶段的任务是完成标记整个年老代的所有的存活对象,包括重新标记并发标记阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致），所以**STW时间会比第一阶段的长**。\n通过以上5个阶段的标记，老年代所有存活的对象已经被标记并且现在要通过Garbage Collector采用清扫的方式回收那些不能用的对象了。\n\n### 并发清理(Concurrent Sweep)\n**和应用程序线程同时进行**，不需要STW。这个阶段的目的就是移除那些不用的对象，回收他们占用的空间并且为将来使用。\n![Concurrent Sweep](concurrent sweep.png)\n\n### 并发标记重置（concurrent reset）\n重新设置CMS算法内部的数据结构，准备下一个CMS生命周期的使用，与应用程序线程并发地执行。\n\n## 使用方式\n- `-XX:+UseConcMarkSweepGC` ,启用CMS，同时`-XX:+UseParNewGC`会被自动打开。\n- CMS默认启动的回收线程数目是 (ParallelGCThreads + 3)/4) ，如果你需要明确设定，可以通过`-XX:ParallelCMSThreads=20`来设定,其中**ParallelGCThreads是年轻代的并行收集线程数**。\n- 年轻代的并行收集线程数默认是(cpu <= 8) ? cpu : 3 + ((cpu * 5) / 8)，如果你希望降低这个线程数，可以通过`-XX:ParallelGCThreads= N `来调整。\n- `-XX:CMSInitiatingOccupancyFraction`,设置第一次启动CMS的阈值，默认是68%\n- CMS收集器默认不会对永久代进行垃圾回收（在1.7中是默认关闭，但是在1.8中是默认打开的），为了避免Perm区满引起的full gc，建议开启CMS回收Perm区选项：\n`+CMSPermGenSweepingEnabled -XX:+CMSClassUnloadingEnabled`\n-`-XX:+CMSScavengeBeforeRemark`,强制remark之前开始一次minor GC，可以减少remark的等待时间，因为老生代的对象有的会依赖于新生代的对象，当增加了这个命令时会在remark之前执行一次minor GC的操作，从而可以减少老生代到新生代的可到达对象数。默认为false。\n- `-XX：UseCompactAtFullCollection`来启动整理堆碎片，启动这个功能后，默认每次执行Full GC的时候会进行整理（也可以通过`-XX：CMSFullGCsBeforeCompaction=n`来制定多少次Full GC之后来执行整理），**整理碎片会stop-the-world**。\n\n### 完整例子\n```\n -Xms1536m -Xmx1536m -XX:NewSize=256m -XX:MaxNewSize=256m -XX:PermSize=64m \n-XX:MaxPermSize=64m -XX:-UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection \n-XX:CMSInitiatingOccupancyFraction=80 -XX:+CMSParallelRemarkEnabled \n-XX:SoftRefLRUPolicyMSPerMB=0 -verbose:gc -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:/home/test/logs/gc.log\n```\n## CMS优缺点\n### 优点\n\n- 并发收集\n- 低停顿 \n\n### 缺点\n\n- CMS收集器对CPU资源非常敏感。在并发处理阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。\n- CMS收集器无法处理浮动垃圾，可能会出现“Concurrent Mode Failure（并发模式故障）”失败而导致Full GC产生。\n- CMS是一款“标记-清除”算法实现的收集器，容易出现大量空间碎片。当空间碎片过多，将会给大对象分配带来很大的麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。\n\n> 浮动垃圾：由于CMS并发清理阶段用户线程还在运行着，伴随着程序运行自然就会有新的垃圾不断产生，这部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC中再清理。这些垃圾就是“浮动垃圾”\n> 标记-清除算法：从根集合开始扫描，对存活的对象进行标记，比较完毕后，再扫描整个空间中未标记的对象，然后将没有标记的对象全部清除掉，不需要对象进行移动\n\n\n## Full GC\nCMS 进行垃圾回收时可能会发生**Full GC**的情况:\n- **prommotion failed**\n原因：存活区（surivivor）空间不足，对象进入老年代，而此时老年代没有空间容纳对象，将导致一次 Full GC\n解决方式：调整`-XX:SurvivorRatio`参数，这个参数是Eden区和Survivor区的大小比值，默认是32，即32：1。调小这个参数增大survivor区空间，让对象尽量在survitor区呆长一点，减少进入年老代的对象。\n- **concurrent mode failed**\n原因：CMS 回收速度慢，CMS 完成前，老年代已被占满，将导致一次 Full GC\n解决方式：调小`-XX:CMSInitiatingOccupancyFraction`参数的值，让CMS更早更频繁的触发，降低年老代被占满的可能。\n\n\n\n","tags":["JVM","CMS"],"categories":["JVM"]},{"title":"zookeeper的watcher乐观锁实现","url":"/2018/09/17/zookeeper的watcher乐观锁实现/","content":"\n## 乐观锁简介\n### 实现过程\n乐观锁对事务的控制分为**数据读取、写入校验、数据写入**，JDK中最典型的乐观锁实现就是CAS。\n### 适用场景\n乐观锁适合使用在**并发量不高，数据竞争不大、事务冲突较少，多读，写操作不频繁**的应用场景。这是因为如果事务经常产生冲突，上层应用会不断的进行retry，进行频繁的上下文切换，这样反倒是降低了性能。另外当应用并发量高的时候，version值在频繁变化，会对数据库产生很大的写压力。\n## 在zookeeper中的实际应用 \n在zookeeper中是使用`version`属性来实现乐观锁的**写入校验**。在zookeeper服务器的`PreRequestProcessor`处理器类中，在处理每一个数据更新（`setDataRequest`）请求时，会进行版本检查。\n```java\n   version = setDataRequest.getVersion();\n   int currentVersion = nodeRecord.stat.getVersion();\n   if(version != -1 && version != currentVersion)\n   {\n       throw new KeeperException.BadVersionException(path);\n   }\n   version = currentVersion + 1;\n```\n在进行一次`setDataRequest`请求处理时，首先进行了版本检查：zookeeper会从`setDataRequest`请求中获取当前请求的版本`version`，同时从数据记录`noderecord`中获取到当前服务器上该数据的最新版本`currentversion`。如果`version`为-1，那么说明客户端并不要求使用乐观锁，可以忽略版本对比；如果`version`不是-1，那么就对比`version`和`currentversion`，如果两个版本不匹配，那么就会抛出`BadVersionException`异常。\n\n","tags":["zookeeper"],"categories":["zookeeper"]},{"title":"vi编辑模式下的查找替换","url":"/2018/09/17/vi编辑模式下的查找替换/","content":"\n## 打开文件 \n\n- 使用`vi`命令打开文件\n- 按下`Esc`键，然后再按下`shift`+`：`键进入命令行输入模式\n\n## 查找命令  \n- 命令  \n\n```bash\n/pattern #向下查找pattern匹配字符串 \n?pattern #向上查找pattern匹配字符串 \n```  \n例子：  \n```bash\n/^abc #查找以abc开始的行\n/abc$ #查找以abc结束的行\n//^abc #查找^abc字符串\n```  \n\n- 使用方式  \n输完上述命令后，按下`Enter`键，同时使用如下两个键快速查找：  \n\n> n：按照同一方向继续查找  \n> N：按照反方向查找  \n\n## 替换命令  \n\n- 命令  \n\n```bash\n%s+/usr/local/bin+/usr/bin #/usr/local/bin替换成/usr/bin\n```  \n- 使用方式  \n\n输完上述命令后，按下`Enter`键即可。\n","tags":["Linux"],"categories":["Linux"]},{"title":"openOffice和swftools安装及环境配置过程","url":"/2018/09/14/openOffice和swftools安装及环境配置过程/","content":"## windows系统\n### 安装SWFtools\n![windows-swftools](window-swftools.png) \n\n直接双击安装  \n\n### 安装xpdf语言包  \n\n![windows-xpdf-chinese](window-xpdf-chinese.png) \n无须安装，直接在项目中通过路径引用  \n\n### 安装OpenOffice\n![windows-openoffice](window-openoffice.png)  \n\n- 直接双击，这时候只是解压文件；然后在解压文件中找到setup.exe双击安装！\n- 启动openoffice服务  \n> 运行→cmd，输入：  \n`cd F:\\OpenOffice 4\\program`  \n回车  \n再输入  \n`soffice -headless -accept=\"socket,host=127.0.0.1,port=8100;urp;\" -nofirststartwizard`  \n回车  \n \n## Linux系统\n### 安装SWFtools\n- 安装好所需的库和组件  \n\n```bash\nyum install gcc* automake zlib-devel libjpeg-devel giflib-devel freetype-devel\n```  \n- 解压、编译、安装SWFtools  \n\n```bash\ntar vxzf swftools-0.9.2.tar.gz  \n\ncd swftools-0.9.2  \n\n./configure --prefix=/usr/local/swftools  \n\nmake  \n\nmake install\n```  \n- 设置环境变量，让pdf2swf可以在任意目录下都能执行到  \n\n```bash\nvi /etc/profile\n```  \n在文件最后一行加上  \n\n```bash\nexport PATH=$PATH:/usr/local/swftools/bin/\n```  \n\n### 安装xpdf语言包\n- 直接解压到/usr/local目录下  \n\n```bash\ntar vxzf xpdf-chinese-simplified.tar.gz\n```  \n- 测试  \n在当前目录下新建一个pdf文件-*test.pdf*,执行以下命令  \n\n```bash\npdf2swf -s languagedir=/usr/local/xpdf-chinese-simplified -T 9  \"/usr/local/test.pdf\" -o \"/usr/local/%.swf\"\n```  \n\n### 安装 OpenOffice\n- 解压  \n\n```bash\ntar -zxvf  Apache_OpenOffice_4.1.3_Linux_x86-64_install-rpm_zh-CN.tar.gz\n```  \n\n- 进入zh-CN/RPMS目录，安装OpenOffice的所有组件  \n\n```bash\ncd zh-CN/RPMS/\nrpm -ivh *.rpm\n```  \n\n- 启动openOffice服务  \n\n```bash\ncd /usr/local/openoffice4/program\n./soffice \"-accept=socket,host=*你自己主机的IP*,port=8100;urp;StarOffice.ServiceManager\" -nologo -headless -nofirststartwizard &\n```  \n\n### 注意点\n- 查看端口是否被占用  \n\n```bash\n lsof -i:8100\n```  \n\n## 项目引用过程  \n\n- Java引用swftools、swf语言包  \n\n```java\n    /**\n\t * windows-swftools工具目录\n\t */\n\tprivate final static String SWFTOOL_DIR = \"F:\\\\swftools\";\n\t/**\n\t * windows-pdf转swf语言包路径\n\t */\n\tprivate final static String PDF2SWF_LANG = \"F:\\\\xpdf-chinese-simplified\";\n\n\t/**\n\t * Linux-swftools工具目录\n\t */\n\tprivate final static String SWFTOOL_DIR = \"/usr/local/swftools/bin\";\n\t/**\n\t * Linux-pdf转swf语言包路径\n\t */\n\tprivate final static String PDF2SWF_LANG = \"/usr/local/xpdf-chinese-simplified\";\n```  \n\n- Java连接openoffice方式  \n\n```java\n//windows、linux链接写法\nOpenOfficeConnection connection = new SocketOpenOfficeConnection(\"127.0.0.1\", 8100); \n```  \n实际例子可参照我的项目[[tools]](https://github.com/Focusss/tools) \n\n## 安装包下载\n> 链接：https://pan.baidu.com/s/1b8nSJ8DIpTvz1fKy5ZRANg 密码：qiyh\n","tags":["Java"],"categories":["Java"]},{"title":"阿里云上使用redis集群的一些问题","url":"/2018/08/30/阿里云上使用redis集群的一些问题/","content":"\n## Cannot assign requested address  \n当在`redis.conf`中配置`bind 阿里云公网IP`，启动时就出现了下面的问题\n\n> annot assign requested address  \n\n`redis.conf`中的bind表示的是指定本机可以接受连接的网卡地址，即使用该IP来接受外部的连接。将其改回`bind 阿里云私网IP`就可以解决问题。\n\n##  Could not get a resource from the pool\n在redis集群搭建完成功运行之后，使用jedisCluster进行连接redis集群时就出现了下面的问题\n> Could not get a resource from the pool  \n\n&ensp;&ensp;&ensp;&ensp;通过调试发现，HostAndPort中的节点IP都是阿里云私网IP地址，这是因为在上一个问题中，我们将redis bind在阿里云私网IP地址上了。进一步调试发现，HostAndPort的信息是通过命令`cluster nodes`获取的,其访问的节点信息来源于`nodes-xxx.conf`配置文件。修改配置文件中的IP为**阿里云公网IP地址**即可。\n ![nodes配置文件.png](nodes配置文件.png)\n\n该配置文件是redis cluster集群**启动后生成**的，不是redis实例中的配置文件。\n\n![cluster配置文件.png](cluster配置文件.png)\n","tags":["Redis"],"categories":["Redis"]},{"title":"redis cluster集群-ruby及相关依赖安装","url":"/2018/08/29/redis cluster集群-ruby安装/","content":"## 环境准备\n> - centos7.4\n> - redis-3.0.7  \n\n我觉得安装redis cluster集群的主要难点在于ruby及相关依赖安装 \n## 安装相关依赖包  \n\n```\nyum -y install make openssl-devel zlib-devel gcc gcc-c++ make   \nautoconf readline-devel curl-devel expat-devel gettext-devel  \nncurses-devel sqlite3-devel mysql-devel httpd-devel wget which \n```\n我们可以通过`yum list installed | grep **依赖包名**`来检测包是否已安装。如果已安装会直接显示出来，没有安装则不显示  \n\n## 下载安装yaml  \n```\ncd /opt/software\nwget http://pyyaml.org/download/libyaml/yaml-0.1.5.tar.gz\ntar zxf yaml-0.1.5.tar.gz\ncd yaml-0.1.5\n./configure --prefix=/usr/local\nmake && make install\n```\n\n如果下载链接已经失效了，可以直接下载好包[yaml-0.1.5.tar.gz](yaml-0.1.5.tar.gz)，上传到服务器进行解压安装  \n\n## 下载安装ruby-1.9.3\n\n```\ncd /opt/software  \nwget http://ftp.ruby-lang.org/pub/ruby/1.9/ruby-1.9.3-p0.tar.gz  \ntar zxf ruby-1.9.3-p0.tar.gz  \ncd ruby-1.9.3-p0  \n./configure --prefix=/usr/local -disable-install-doc --with-opt-dir=/usr/local/lib  \nmake && make install\n```\n\n> 在执行make命令的时候会报错,报错信息如下：  \n\n```\nError: ossl_pkey_ec.c:In functin 'ossl_ec_group_initialize':  \n\nossl_pkey_ec.c:816:error: 'EC_GROUP_new_curve_GF2m' undeclard  \n\n (first use in this function) ossl_pkey_ec.c:816:error:(Each   \n\n undeclard indentifier is reported only once ossl_pkey_ec.c:816  \n\n  error:for each function it appearts in.)\n```\n问题原因：  \n\n> 由于centos新版本默认openssl的配置变更取消了对EC_xx的支持，所以出现该错误\n\n解决方法：  \n\n> 修改目录`ruby-1.9.3/ext/openssl/ossl_pkey_ec.c`的两处源码  \n\n![修改ruby源码1.png](修改ruby源码1.png)\n\n![修改ruby源码2.png](修改ruby源码2.png)\n\n> 然后ruby-1.9.3 目录下执行以下命令:\n\n\n``` \nmake clean  #清除旧的文件\n./configure --prefix=/usr/local -disable-install-doc --with-opt-dir=/usr/local/lib  \nmake && make install  \n```\n\n> 查看ruby是否安装成功  \n\n![ruby成功.png](ruby成功.png)\n\n## 安装ruby的redis客户端依赖\n\n> 可以在ruby-1.9.3-p0目录下，直接执行以下命令进行安装  \n\n```\ngem install redis  \n```  \n> 如果会提示你Fetching：redis-4.0.0.gem 需要更高版本的ruby。那么可以上传[redis-3.2.1.gem](redis-3.2.1.gem)至服务器，然后执行`gem install --local /opt/software/redis-3.2.1.gem`进行本地安装。下面就可以直接使用命令`redis-trib.rb create --replicas`创建redis cluster集群了\n\n\n\n\n\n","tags":["Redis"],"categories":["Redis"]},{"title":"Linux环境变量","url":"/2018/08/29/Linux环境变量/","content":"\n> &ensp;&ensp;&ensp;&ensp;在Linux系统下，安装完新的软件，在命令行中输入启动程序的命令，有时候会出现`command  not found ` 的提示内容。这是因为在当前的目录下找不到对应的启动文件，所以需要进入到该程序所在的目录才能执行启动程序命令。如果想在任何目录下都能执行该程序命令，只需要在Linux的环境变量**PATH**中加上该程序所在目录的**绝对路径**。\n &ensp;&ensp;&ensp;&ensp;可以通过`echo $PATH`显示当前**PATH**环境变量，该变量的值由一系列以冒号分隔的目录名组成。如：/usr/local/bin:/bin:/usr/bin。当我们执行程序命令时，shell自动根据PATH变量的值去搜索对应目录下的程序。\n\n\n## Linux下环境变量设置的3种方法\n- **在控制台中设置,关闭控制台后就会失效**\n\n``` \nPATH=$PATH:/NEW_PATH \n```\n添加**/NEW_PATH**到**PATH**环境变量\n\n- **修改 /etc/profile 文件，对所有用户都生效**\n执行下面命令打开profile文件\n\n```\nvi /etc/profile\n```\n在`/etc/profile`的最下面添加：`export  PATH=\"$PATH:/NEW_PATH\"`\n\n- **修改bashrc文件，只针对某个特定用户生效**\n执行下面命令打开.bashrc文件\n\n```\nvi ~/.bashrc \n```\n在`.bashrc`文件的最下面添加：`export  PATH=\"$PATH:/NEW_PATH\"`  \n`~/`表示当前用户名目录下，如：`/home/cjwei/`\n\n","tags":["Linux"],"categories":["Linux"]},{"title":"Github+Hexo搭建个人博客","url":"/2018/08/27/Github+Hexo搭建个人博客/","content":"\n**环境准备**\n\n>- 注册一个github账号；\n>- 安装git for windows（或者其它git客户端）\n##  安装node.js\n>- 先到[node.js官网](https://nodejs.org/en/download/)下载node.js文件的压缩版\n\n![node.js下载文件](node-js下载.png)\n\n>- 然后解压缩，并新建两个目录\n\n![node-js新建目录](node-js新建目录.png)\n\n>- 配置环境变量\n\n![node-js环境变量](node-js环境变量.png)\n\n>- 在cmd执行命令`node -v`和`npm -v`测试是否安装成功\n\n![node-js测试](node-js测试.png)\n\n>- 在cmd执行以下命令，将npm与node-global、node-cache做相关连\n\n``` bash\nnpm config set prefix \"G:\\node-v10.3.0-win-x86\\node_global\"\nnpm config set cache \"G:\\node-v10.3.0-win-x86\\node_global\"\n```\n##  创建Github仓库\n\n> - 创建的仓库名字格式必须为**账户名.github.io**\n\n![github新建仓库](github新建仓库.png)\n\n> - 创建完后，打开你刚新建的仓库，选中`settings`选项卡，找到`Github Pages`，就可以看到你的博客地址。\n当然现在仓库里面还没有提交什么内容。\n\n![gitHub-pages](gitHub-pages.png)\n\n## 配置ssh key认证\n> - 在你本地提交代码到github时，需要你的权限认证才能通过。这里我们使用ssh key来解决本地和服务器的连接问题。\n\n```\n$ cd ~/.ssh #检查本机已存在的ssh密钥\n```\n如果提示：`No such file or directory` 说明你是第一次使用git。\n\n> - 使用ssh-keygen 来生成ssh公钥认证所需的公钥和私钥文件\n\n```\nssh-keygen -t rsa -C \"446193412@qq.com\" #你的邮箱地址\n```\n![ssh-gen.png](ssh-gen.png)\n\n&ensp;&ensp;&ensp;&ensp;然后连续3次回车，最终会生成一个文件在用户目录下，打开用户目录，找到`.ssh\\id_rsa.pub`文件。若找不到.ssh文件夹，请检查以下两点：  \n\n- 请检查git是否安装成功；\n- 重新配置下面内容\n\n```\n$ git config --global user.name \"focusss\"  #你的github用户名，非昵称\n$ git config --global user.email  \"xxx@qq.com\"  #填写你的github注册\n```\n> - 打开`id_rsa.pub`文件并复制里面的内容。到你的github主页，进入settings -> SSH and GPG keys -> New SSH key，将刚复制的内容粘贴到key那里，title随便填，保存。  \n\n> - 测试ssh key是否生效  \n\n```\nssh -T git@github.com #这里的邮箱地址是固定的，不用修改\n```\n到这里需要的环境配置已经搭建好了，下面就是搭建博客的过程\n\n## 搭建hexo博客\n\n> - 新建一个文件夹用于存放你的博客系统代码，比如我的是E:\\blog。进入到E:\\blog文件夹，对其进行初始化下载。\n\n``` bash\n$ npm install -g hexo xo init\n$ hexo init\n```\n初始化完后的目录结构如下：\n![blog目录结构](blog目录结构.png)\n\n> - 启动你本地博客服务\n\n``` bash\n$ hexo g  #生成相关html文件到public文件夹中去，后续需要提交到github\n$ hexo s  #启动服务\n```\n> - 打开浏览器访问 http://localhost:4000\n\n![hexo](hexo.png)\n\n若遇到页面加载不出来，可以试着通过另外的端口进行访问  \n\n```\n$ hexo server -p 端口号\n```\n## 修改hexo主题\n\n> - 进入到E:\\blog文件夹,执行以下命令:\n\n```\n$ git clone https://github.com/fi3ework/hexo-theme-archer.git\n```\n下载新的主题，我自己用的主题是`archer`,大家也可以到`https://hexo.io/themes/`下载自己喜欢的主题\n\n> - 下载好的主题会存放在themes文件夹里面，同时修改blog文件夹下的修改`_config.yml`中的`theme: landscape`改为`theme:archer`，然后重新执行`hexo g`来重新生成博客主题。`  \n\n\n## 新建文章\n\n> - 定位到我们的hexo根目录，执行命令：  \n\n```\nhexo new 'my-first-blog'\n```\nhexo会帮我们在_posts文件夹下生成相关md文件，不同的主题生成md头部的信息格式不一样，一般格式如下：\n\n```\n---\ntitle: Github+Hexo搭建个人博客\ndate: 2018-08-27 20:36:06\ncategories: Github\ntags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格\ndescription: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面\n---\n\n```\n> - 按照MarkDown规范编写完文章内容后，执行以下命令就可以在本地预览刚刚写的博客了\n\n``` bash\n$ hexo g  #生成相关html文件到public文件夹中去，后续需要提交到github\n$ hexo s  #启动服务\n```\n\n## 提交到Github\n\n> - 确保ssh key已经配置好  \n\n> - 修改bolg文件夹下`_config.yml`中有关deploy的部分内容：  \n\n```\ndeploy:\n  type: git\n  repository: git@github.com:Focusss/Focusss.github.io.git\n  branch: master\n```\n**注意冒号之后是有空格的**  \n> - 除此之外还需要安装一个插件  \n\n```\nnpm install hexo-deployer-git --save\n```  \n> - 执行`hexo d`就可以发布到github上了\n\n","tags":["github","hexo"],"categories":["github"]}]